{"id": "2511.19514", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.19514", "abs": "https://arxiv.org/abs/2511.19514", "authors": ["Yang Wu", "Qian Li", "Yuling Xiong", "Hongbo Tang", "Xun Liu", "Jun Zhang", "Huan Yu", "Jie Jiang", "Hailong Shi"], "title": "SCoTER: Structured Chain-of-Thought Transfer for Enhanced Recommendation", "comment": "12 pages,4 figures", "summary": "Harnessing the reasoning power of Large Language Models (LLMs) for recommender systems is hindered by two fundamental challenges. First, current approaches lack a mechanism for automated, data-driven discovery of effective reasoning patterns, relying instead on brittle manual templates or unstable zero-shot prompting. Second, they employ structure-collapsing integration: direct prompting incurs prohibitive online inference costs, while feature extraction collapses reasoning chains into single vectors, discarding stepwise logic. To address these challenges, we propose SCoTER (Structured Chain-of-Thought Transfer for Enhanced Recommendation), a unified framework that treats pattern discovery and structure-aware transfer as a jointly optimized problem. Specifically, SCoTER operationalizes this through two synergistic components: a GVM pipeline for automated pattern discovery and a structure-preserving integration architecture that transfers stepwise logic to efficient models. Formally, we provide information-theoretic justification proving that structure-preserving transfer achieves tighter performance bounds than structure-agnostic alternatives. Empirically, experiments on four benchmarks demonstrate improvements of 3.75\\%-11.59\\% over a strong TIGER backbone. Moreover, in production deployment on the Tencent Advertising Platform, SCoTER achieved a 2.14\\% lift in Gross Merchandise Value (GMV) while eliminating online LLM inference costs. Overall, SCoTER establishes a principled and production-validated blueprint for transferring structured LLM reasoning to large-scale recommender systems.", "AI": {"tldr": "SCoTER\u662f\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u6a21\u5f0f\u53d1\u73b0\u548c\u7ed3\u6784\u4fdd\u6301\u96c6\u6210\uff0c\u5c06LLM\u7684\u63a8\u7406\u80fd\u529b\u9ad8\u6548\u8f6c\u79fb\u5230\u63a8\u8350\u7cfb\u7edf\u4e2d\uff0c\u6d88\u9664\u4e86\u5728\u7ebfLLM\u63a8\u7406\u6210\u672c\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u7f3a\u4e4f\u81ea\u52a8\u53d1\u73b0\u6709\u6548\u63a8\u7406\u6a21\u5f0f\u7684\u673a\u5236\uff0c\u4f9d\u8d56\u624b\u52a8\u6a21\u677f\u6216\u4e0d\u7a33\u5b9a\u7684\u96f6\u6837\u672c\u63d0\u793a\uff1b\u540c\u65f6\u91c7\u7528\u7ed3\u6784\u574d\u584c\u7684\u96c6\u6210\u65b9\u5f0f\uff0c\u8981\u4e48\u63a8\u7406\u6210\u672c\u8fc7\u9ad8\uff0c\u8981\u4e48\u4e22\u5931\u9010\u6b65\u903b\u8f91\u3002", "method": "\u5305\u542b\u4e24\u4e2a\u534f\u540c\u7ec4\u4ef6\uff1aGVM\u7ba1\u9053\u7528\u4e8e\u81ea\u52a8\u5316\u6a21\u5f0f\u53d1\u73b0\uff0c\u7ed3\u6784\u4fdd\u6301\u96c6\u6210\u67b6\u6784\u5c06\u9010\u6b65\u903b\u8f91\u8f6c\u79fb\u5230\u9ad8\u6548\u6a21\u578b\u3002\u901a\u8fc7\u4fe1\u606f\u8bba\u8bc1\u660e\u7ed3\u6784\u4fdd\u6301\u8f6c\u79fb\u6bd4\u7ed3\u6784\u65e0\u5173\u65b9\u6cd5\u6709\u66f4\u7d27\u7684\u6027\u80fd\u754c\u9650\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u6bd4\u5f3a\u57fa\u7ebfTIGER\u63d0\u53473.75%-11.59%\uff1b\u5728\u817e\u8baf\u5e7f\u544a\u5e73\u53f0\u90e8\u7f72\u5b9e\u73b0\u4e862.14%\u7684GMV\u63d0\u5347\uff0c\u540c\u65f6\u6d88\u9664\u4e86\u5728\u7ebfLLM\u63a8\u7406\u6210\u672c\u3002", "conclusion": "SCoTER\u4e3a\u5c06\u7ed3\u6784\u5316LLM\u63a8\u7406\u8f6c\u79fb\u5230\u5927\u89c4\u6a21\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u4e14\u7ecf\u8fc7\u751f\u4ea7\u9a8c\u8bc1\u7684\u84dd\u56fe\u3002"}}
{"id": "2511.19931", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19931", "abs": "https://arxiv.org/abs/2511.19931", "authors": ["Ziwei Liu", "Qidong Liu", "Wanyu Wang", "Yejing Wang", "Tong Xu", "Wei Huang", "Chong Chen", "Peng Chuan", "Xiangyu Zhao"], "title": "LLM-EDT: Large Language Model Enhanced Cross-domain Sequential Recommendation with Dual-phase Training", "comment": null, "summary": "Cross-domain Sequential Recommendation (CDSR) has been proposed to enrich user-item interactions by incorporating information from various domains. Despite current progress, the imbalance issue and transition issue hinder further development of CDSR. The former one presents a phenomenon that the interactions in one domain dominate the entire behavior, leading to difficulty in capturing the domain-specific features in the other domain. The latter points to the difficulty in capturing users' cross-domain preferences within the mixed interaction sequence, resulting in poor next-item prediction performance for specific domains. With world knowledge and powerful reasoning ability, Large Language Models (LLMs) partially alleviate the above issues by performing as a generator and an encoder. However, current LLMs-enhanced CDSR methods are still under exploration, which fail to recognize the irrelevant noise and rough profiling problems. Thus, to make peace with the aforementioned challenges, we proposed an LLMs Enhanced Cross-domain Sequential Recommendation with Dual-phase Training ({LLM-EDT}). To address the imbalance issue while introducing less irrelevant noise, we first propose the transferable item augmenter to adaptively generate possible cross-domain behaviors for users. Then, to alleviate the transition issue, we introduce a dual-phase training strategy to empower the domain-specific thread with a domain-shared background. As for the rough profiling problem, we devise a domain-aware profiling module to summarize the user's preference in each domain and adaptively aggregate them to generate comprehensive user profiles. The experiments on three public datasets validate the effectiveness of our proposed LLM-EDT. To ease reproducibility, we have released the detailed code online at {https://anonymous.4open.science/r/LLM-EDT-583F}.", "AI": {"tldr": "\u63d0\u51faLLM-EDT\u65b9\u6cd5\u89e3\u51b3\u8de8\u57df\u5e8f\u5217\u63a8\u8350\u4e2d\u7684\u4e0d\u5e73\u8861\u95ee\u9898\u548c\u8f6c\u79fb\u95ee\u9898\uff0c\u901a\u8fc7\u53ef\u8f6c\u79fb\u9879\u76ee\u589e\u5f3a\u5668\u3001\u53cc\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u548c\u57df\u611f\u77e5\u5206\u6790\u6a21\u5757\u6765\u63d0\u5347\u63a8\u8350\u6027\u80fd", "motivation": "\u5f53\u524d\u8de8\u57df\u5e8f\u5217\u63a8\u8350\u5b58\u5728\u4e0d\u5e73\u8861\u95ee\u9898\u548c\u8f6c\u79fb\u95ee\u9898\uff0c\u524d\u8005\u5bfc\u81f4\u4e00\u4e2a\u57df\u7684\u884c\u4e3a\u4e3b\u5bfc\u6574\u4e2a\u884c\u4e3a\u5e8f\u5217\uff0c\u540e\u8005\u96be\u4ee5\u6355\u6349\u7528\u6237\u7684\u8de8\u57df\u504f\u597d\u3002\u73b0\u6709LLM\u589e\u5f3a\u65b9\u6cd5\u672a\u80fd\u6709\u6548\u5904\u7406\u65e0\u5173\u566a\u58f0\u548c\u7c97\u7565\u5206\u6790\u95ee\u9898", "method": "1. \u53ef\u8f6c\u79fb\u9879\u76ee\u589e\u5f3a\u5668\u81ea\u9002\u5e94\u751f\u6210\u8de8\u57df\u884c\u4e3a\uff1b2. \u53cc\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u8d4b\u4e88\u57df\u7279\u5b9a\u7ebf\u7a0b\u57df\u5171\u4eab\u80cc\u666f\uff1b3. \u57df\u611f\u77e5\u5206\u6790\u6a21\u5757\u603b\u7ed3\u5404\u57df\u7528\u6237\u504f\u597d\u5e76\u81ea\u9002\u5e94\u805a\u5408", "result": "\u5728\u4e09\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86LLM-EDT\u7684\u6709\u6548\u6027", "conclusion": "\u63d0\u51fa\u7684LLM-EDT\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u8de8\u57df\u5e8f\u5217\u63a8\u8350\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u901a\u8fc7LLM\u589e\u5f3a\u548c\u521b\u65b0\u7684\u8bad\u7ec3\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6027\u80fd"}}
{"id": "2511.19979", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.19979", "abs": "https://arxiv.org/abs/2511.19979", "authors": ["Kaike Zhang", "Jiakai Tang", "Du Su", "Shuchang Liu", "Julian McAuley", "Lina Yao", "Qi Cao", "Yue Feng", "Fei Sun"], "title": "The 2nd Workshop on Human-Centered Recommender Systems", "comment": null, "summary": "Recommender systems shape how people discover information, form opinions, and connect with society. Yet, as their influence grows, traditional metrics, e.g., accuracy, clicks, and engagement, no longer capture what truly matters to humans. The workshop on Human-Centered Recommender Systems (HCRS) calls for a paradigm shift from optimizing engagement toward designing systems that truly understand, involve, and benefit people. It brings together researchers in recommender systems, human-computer interaction, AI safety, and social computing to explore how human values, e.g., trust, safety, fairness, transparency, and well-being, can be integrated into recommendation processes. Centered around three thematic axes-Human Understanding, Human Involvement, and Human Impact-HCRS features keynotes, panels, and papers covering topics from LLM-based interactive recommenders to societal welfare optimization. By fostering interdisciplinary collaboration, HCRS aims to shape the next decade of responsible and human-aligned recommendation research.", "AI": {"tldr": "HCRS\u7814\u8ba8\u4f1a\u547c\u5401\u63a8\u8350\u7cfb\u7edf\u4ece\u4f18\u5316\u53c2\u4e0e\u5ea6\u8f6c\u5411\u771f\u6b63\u7406\u89e3\u3001\u53c2\u4e0e\u548c\u9020\u798f\u4eba\u7c7b\u7684\u8bbe\u8ba1\uff0c\u91cd\u70b9\u5173\u6ce8\u4eba\u7c7b\u7406\u89e3\u3001\u4eba\u7c7b\u53c2\u4e0e\u548c\u4eba\u7c7b\u5f71\u54cd\u4e09\u4e2a\u4e3b\u9898\u8f74\u3002", "motivation": "\u968f\u7740\u63a8\u8350\u7cfb\u7edf\u5f71\u54cd\u529b\u589e\u957f\uff0c\u4f20\u7edf\u6307\u6807\u5982\u51c6\u786e\u6027\u3001\u70b9\u51fb\u7387\u548c\u53c2\u4e0e\u5ea6\u5df2\u65e0\u6cd5\u771f\u6b63\u53cd\u6620\u5bf9\u4eba\u7c7b\u91cd\u8981\u7684\u4ef7\u503c\uff0c\u9700\u8981\u5c06\u4eba\u7c7b\u4ef7\u503c\u89c2\u6574\u5408\u5230\u63a8\u8350\u8fc7\u7a0b\u4e2d\u3002", "method": "\u901a\u8fc7\u4e3e\u529e\u7814\u8ba8\u4f1a\uff0c\u6c47\u96c6\u63a8\u8350\u7cfb\u7edf\u3001\u4eba\u673a\u4ea4\u4e92\u3001AI\u5b89\u5168\u548c\u793e\u4ea4\u8ba1\u7b97\u9886\u57df\u7684\u7814\u7a76\u4eba\u5458\uff0c\u56f4\u7ed5\u4e09\u4e2a\u4e3b\u9898\u8f74\u8fdb\u884c\u4e3b\u9898\u6f14\u8bb2\u3001\u5c0f\u7ec4\u8ba8\u8bba\u548c\u8bba\u6587\u4ea4\u6d41\u3002", "result": "\u7814\u8ba8\u4f1a\u4fc3\u8fdb\u4e86\u8de8\u5b66\u79d1\u5408\u4f5c\uff0c\u63a2\u7d22\u5982\u4f55\u5c06\u4fe1\u4efb\u3001\u5b89\u5168\u3001\u516c\u5e73\u3001\u900f\u660e\u548c\u798f\u7949\u7b49\u4eba\u7c7b\u4ef7\u503c\u89c2\u6574\u5408\u5230\u63a8\u8350\u8fc7\u7a0b\u4e2d\u3002", "conclusion": "HCRS\u65e8\u5728\u901a\u8fc7\u4fc3\u8fdb\u8de8\u5b66\u79d1\u5408\u4f5c\uff0c\u5851\u9020\u672a\u6765\u5341\u5e74\u8d1f\u8d23\u4efb\u4e14\u4e0e\u4eba\u7c7b\u5bf9\u9f50\u7684\u63a8\u8350\u7814\u7a76\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2511.19999", "categories": ["cs.IR", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.19999", "abs": "https://arxiv.org/abs/2511.19999", "authors": ["Anton Lyubinin"], "title": "Popularity Bias Alignment Estimates", "comment": null, "summary": "We are extending Popularity Bias Memorization theorem from arXiv:archive/2404.12008 in several directions. We extend it to arbitrary degree distributions and also prove both upper and lower estimates for the alignment with top-k singular hyperspace.", "AI": {"tldr": "\u6269\u5c55\u4e86\u6d41\u884c\u5ea6\u504f\u5dee\u8bb0\u5fc6\u5316\u5b9a\u7406\uff0c\u5c06\u5176\u63a8\u5e7f\u5230\u4efb\u610f\u5ea6\u5206\u5e03\uff0c\u5e76\u8bc1\u660e\u4e86\u4e0etop-k\u5947\u5f02\u8d85\u7a7a\u95f4\u5bf9\u9f50\u7684\u4e0a\u4e0b\u754c\u4f30\u8ba1", "motivation": "\u6269\u5c55arXiv:2404.12008\u4e2d\u7684\u6d41\u884c\u5ea6\u504f\u5dee\u8bb0\u5fc6\u5316\u5b9a\u7406\uff0c\u4f7f\u5176\u9002\u7528\u4e8e\u66f4\u4e00\u822c\u7684\u573a\u666f", "method": "\u5c06\u5b9a\u7406\u63a8\u5e7f\u5230\u4efb\u610f\u5ea6\u5206\u5e03\uff0c\u5e76\u63a8\u5bfc\u4e0etop-k\u5947\u5f02\u8d85\u7a7a\u95f4\u5bf9\u9f50\u7684\u4e0a\u4e0b\u754c\u4f30\u8ba1", "result": "\u83b7\u5f97\u4e86\u9002\u7528\u4e8e\u4efb\u610f\u5ea6\u5206\u5e03\u7684\u6d41\u884c\u5ea6\u504f\u5dee\u8bb0\u5fc6\u5316\u5b9a\u7406\uff0c\u5e76\u5efa\u7acb\u4e86\u5bf9\u9f50\u5ea6\u7684\u4e0a\u4e0b\u754c", "conclusion": "\u6210\u529f\u6269\u5c55\u4e86\u6d41\u884c\u5ea6\u504f\u5dee\u8bb0\u5fc6\u5316\u7406\u8bba\uff0c\u4e3a\u66f4\u5e7f\u6cdb\u7684\u5ea6\u5206\u5e03\u573a\u666f\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1"}}
{"id": "2511.20009", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.20009", "abs": "https://arxiv.org/abs/2511.20009", "authors": ["Yulong Deng", "Zheng Guan", "Min He", "Xue Wang", "Jie Liu", "Zheng Li"], "title": "Adaptive Knowledge Transfer for Cross-Disciplinary Cold-Start Knowledge Tracing", "comment": "10 pages, 5 figures", "summary": "Cross-Disciplinary Cold-start Knowledge Tracing (CDCKT) faces a critical challenge: insufficient student interaction data in the target discipline prevents effective knowledge state modeling and performance prediction. Existing cross-disciplinary methods rely on overlapping entities between disciplines for knowledge transfer through simple mapping functions, but suffer from two key limitations: (1) overlapping entities are scarce in real-world scenarios, and (2) simple mappings inadequately capture cross-disciplinary knowledge complexity. To overcome these challenges, we propose Mixed of Experts and Adversarial Generative Network-based Cross-disciplinary Cold-start Knowledge Tracing Framework. Our approach consists of three key components: First, we pre-train a source discipline model and cluster student knowledge states into K categories. Second, these cluster attributes guide a mixture-of-experts network through a gating mechanism, serving as a cross-domain mapping bridge. Third, an adversarial discriminator enforces feature separation by pulling same-attribute student features closer while pushing different-attribute features apart, effectively mitigating small-sample limitations. We validate our method's effectiveness across 20 extreme cross-disciplinary cold-start scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e13\u5bb6\u6df7\u5408\u548c\u5bf9\u6297\u751f\u6210\u7f51\u7edc\u7684\u8de8\u5b66\u79d1\u51b7\u542f\u52a8\u77e5\u8bc6\u8ffd\u8e2a\u6846\u67b6\uff0c\u89e3\u51b3\u76ee\u6807\u5b66\u79d1\u5b66\u751f\u4ea4\u4e92\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u77e5\u8bc6\u72b6\u6001\u805a\u7c7b\u3001\u4e13\u5bb6\u6df7\u5408\u7f51\u7edc\u548c\u5bf9\u6297\u5224\u522b\u5668\u5b9e\u73b0\u6709\u6548\u7684\u8de8\u5b66\u79d1\u77e5\u8bc6\u8fc1\u79fb\u3002", "motivation": "\u8de8\u5b66\u79d1\u51b7\u542f\u52a8\u77e5\u8bc6\u8ffd\u8e2a\u9762\u4e34\u76ee\u6807\u5b66\u79d1\u5b66\u751f\u4ea4\u4e92\u6570\u636e\u4e0d\u8db3\u7684\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5b66\u79d1\u95f4\u91cd\u53e0\u5b9e\u4f53\u8fdb\u884c\u7b80\u5355\u6620\u5c04\uff0c\u4f46\u5b58\u5728\u91cd\u53e0\u5b9e\u4f53\u7a00\u7f3a\u548c\u7b80\u5355\u6620\u5c04\u65e0\u6cd5\u6355\u6349\u8de8\u5b66\u79d1\u77e5\u8bc6\u590d\u6742\u6027\u7684\u5c40\u9650\u3002", "method": "1) \u9884\u8bad\u7ec3\u6e90\u5b66\u79d1\u6a21\u578b\u5e76\u805a\u7c7b\u5b66\u751f\u77e5\u8bc6\u72b6\u6001\u4e3aK\u7c7b\uff1b2) \u4f7f\u7528\u805a\u7c7b\u5c5e\u6027\u901a\u8fc7\u95e8\u63a7\u673a\u5236\u6307\u5bfc\u4e13\u5bb6\u6df7\u5408\u7f51\u7edc\u4f5c\u4e3a\u8de8\u57df\u6620\u5c04\u6865\u6881\uff1b3) \u4f7f\u7528\u5bf9\u6297\u5224\u522b\u5668\u62c9\u8fd1\u540c\u5c5e\u6027\u5b66\u751f\u7279\u5f81\u3001\u63a8\u8fdc\u4e0d\u540c\u5c5e\u6027\u7279\u5f81\uff0c\u7f13\u89e3\u5c0f\u6837\u672c\u9650\u5236\u3002", "result": "\u572820\u4e2a\u6781\u7aef\u8de8\u5b66\u79d1\u51b7\u542f\u52a8\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u901a\u8fc7\u4e13\u5bb6\u6df7\u5408\u7f51\u7edc\u548c\u5bf9\u6297\u5b66\u4e60\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u5b66\u79d1\u51b7\u542f\u52a8\u77e5\u8bc6\u8ffd\u8e2a\u4e2d\u7684\u77e5\u8bc6\u8fc1\u79fb\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u91cd\u53e0\u5b9e\u4f53\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u5b9e\u73b0\u826f\u597d\u7684\u6027\u80fd\u9884\u6d4b\u3002"}}
{"id": "2511.20122", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.20122", "abs": "https://arxiv.org/abs/2511.20122", "authors": ["Ximing Chen", "Pui Ieng Lei", "Yijun Sheng", "Yanyan Liu", "Zhiguo Gong"], "title": "Towards A Tri-View Diffusion Framework for Recommendation", "comment": "13 pages, 11 figures, accepted by KDD2026 (First Cycle)", "summary": "Diffusion models (DMs) have recently gained significant interest for their exceptional potential in recommendation tasks. This stems primarily from their prominent capability in distilling, modeling, and generating comprehensive user preferences. However, previous work fails to examine DMs in recommendation tasks through a rigorous lens. In this paper, we first experimentally investigate the completeness of recommender models from a thermodynamic view. We reveal that existing DM-based recommender models operate by maximizing the energy, while classic recommender models operate by reducing the entropy. Based on this finding, we propose a minimalistic diffusion framework that incorporates both factors via the maximization of Helmholtz free energy. Meanwhile, to foster the optimization, our reverse process is armed with a well-designed denoiser to maintain the inherent anisotropy, which measures the user-item cross-correlation in the context of bipartite graphs. Finally, we adopt an Acceptance-Rejection Gumbel Sampling Process (AR-GSP) to prioritize the far-outnumbered unobserved interactions for model robustness. AR-GSP integrates an acceptance-rejection sampling to ensure high-quality hard negative samples for general recommendation tasks, and a timestep-dependent Gumbel Softmax to handle an adaptive sampling strategy for diffusion models. Theoretical analyses and extensive experiments demonstrate that our proposed framework has distinct superiority over baselines in terms of accuracy and efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u70ed\u529b\u5b66\u89c6\u89d2\u7684\u6700\u5c0f\u5316\u6269\u6563\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5927\u5316\u4ea5\u59c6\u970d\u5179\u81ea\u7531\u80fd\u540c\u65f6\u8003\u8651\u80fd\u91cf\u6700\u5927\u5316\u548c\u71b5\u51cf\u5c11\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4fdd\u6301\u5404\u5411\u5f02\u6027\u7684\u53bb\u566a\u5668\u548c\u63a5\u53d7-\u62d2\u7edd\u91c7\u6837\u8fc7\u7a0b\u6765\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u63a8\u8350\u7cfb\u7edf\u7f3a\u4e4f\u4e25\u683c\u7684\u7406\u8bba\u5206\u6790\uff0c\u4f5c\u8005\u4ece\u70ed\u529b\u5b66\u89d2\u5ea6\u53d1\u73b0\u6269\u6563\u6a21\u578b\u901a\u8fc7\u6700\u5927\u5316\u80fd\u91cf\u8fd0\u4f5c\uff0c\u800c\u7ecf\u5178\u63a8\u8350\u6a21\u578b\u901a\u8fc7\u51cf\u5c11\u71b5\u8fd0\u4f5c\uff0c\u9700\u8981\u7edf\u4e00\u8fd9\u4e24\u79cd\u673a\u5236\u3002", "method": "\u63d0\u51fa\u6700\u5c0f\u5316\u6269\u6563\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5927\u5316\u4ea5\u59c6\u970d\u5179\u81ea\u7531\u80fd\u7edf\u4e00\u80fd\u91cf\u548c\u71b5\u56e0\u7d20\uff1b\u8bbe\u8ba1\u4fdd\u6301\u4e8c\u90e8\u56fe\u7528\u6237-\u7269\u54c1\u4ea4\u53c9\u76f8\u5173\u6027\u7684\u53bb\u566a\u5668\uff1b\u91c7\u7528\u63a5\u53d7-\u62d2\u7eddGumbel\u91c7\u6837\u8fc7\u7a0b\u5904\u7406\u5927\u91cf\u672a\u89c2\u6d4b\u4ea4\u4e92\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u6846\u67b6\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u6269\u6563\u6a21\u578b\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u7406\u8bba\u57fa\u7840\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u63d0\u51fa\u7684\u6846\u67b6\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u5177\u6709\u660e\u663e\u4f18\u52bf\u3002"}}
{"id": "2511.20177", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.20177", "abs": "https://arxiv.org/abs/2511.20177", "authors": ["Tianjie Dai", "Xu Chen", "Yunmeng Shu", "Jinsong Lan", "Xiaoyong Zhu", "Jiangchao Yao", "Bo Zheng"], "title": "Enhancing Sequential Recommendation with World Knowledge from Large Language Models", "comment": null, "summary": "Sequential Recommendation System~(SRS) has become pivotal in modern society, which predicts subsequent actions based on the user's historical behavior. However, traditional collaborative filtering-based sequential recommendation models often lead to suboptimal performance due to the limited information of their collaborative signals. With the rapid development of LLMs, an increasing number of works have incorporated LLMs' world knowledge into sequential recommendation. Although they achieve considerable gains, these approaches typically assume the correctness of LLM-generated results and remain susceptible to noise induced by LLM hallucinations. To overcome these limitations, we propose GRASP (Generation Augmented Retrieval with Holistic Attention for Sequential Prediction), a flexible framework that integrates generation augmented retrieval for descriptive synthesis and similarity retrieval, and holistic attention enhancement which employs multi-level attention to effectively employ LLM's world knowledge even with hallucinations and better capture users' dynamic interests. The retrieved similar users/items serve as auxiliary contextual information for the later holistic attention enhancement module, effectively mitigating the noisy guidance of supervision-based methods. Comprehensive evaluations on two public benchmarks and one industrial dataset reveal that GRASP consistently achieves state-of-the-art performance when integrated with diverse backbones. The code is available at: https://anonymous.4open.science/r/GRASP-SRS.", "AI": {"tldr": "GRASP\u662f\u4e00\u4e2a\u7075\u6d3b\u7684\u5e8f\u5217\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u589e\u5f3a\u68c0\u7d22\u548c\u6574\u4f53\u6ce8\u610f\u529b\u589e\u5f3a\u6765\u6574\u5408LLM\u7684\u4e16\u754c\u77e5\u8bc6\uff0c\u6709\u6548\u7f13\u89e3LLM\u5e7b\u89c9\u5e26\u6765\u7684\u566a\u58f0\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u534f\u540c\u8fc7\u6ee4\u5e8f\u5217\u63a8\u8350\u6a21\u578b\u56e0\u534f\u4f5c\u4fe1\u53f7\u6709\u9650\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\uff0c\u73b0\u6709LLM\u65b9\u6cd5\u5047\u8bbeLLM\u751f\u6210\u7ed3\u679c\u6b63\u786e\u4f46\u6613\u53d7\u5e7b\u89c9\u566a\u58f0\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u751f\u6210\u589e\u5f3a\u68c0\u7d22\u8fdb\u884c\u63cf\u8ff0\u6027\u5408\u6210\u548c\u76f8\u4f3c\u6027\u68c0\u7d22\uff0c\u7ed3\u5408\u6574\u4f53\u6ce8\u610f\u529b\u589e\u5f3a\u6a21\u5757\u4f7f\u7528\u591a\u7ea7\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5229\u7528\u68c0\u7d22\u5230\u7684\u76f8\u4f3c\u7528\u6237/\u7269\u54c1\u4f5c\u4e3a\u8f85\u52a9\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5171\u57fa\u51c6\u548c\u4e00\u4e2a\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u7684\u7efc\u5408\u8bc4\u4f30\u663e\u793a\uff0cGRASP\u4e0e\u4e0d\u540c\u9aa8\u5e72\u7f51\u7edc\u7ed3\u5408\u65f6\u59cb\u7ec8\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "GRASP\u6846\u67b6\u80fd\u6709\u6548\u5229\u7528LLM\u7684\u4e16\u754c\u77e5\u8bc6\uff0c\u5373\u4f7f\u5b58\u5728\u5e7b\u89c9\u4e5f\u80fd\u66f4\u597d\u5730\u6355\u6349\u7528\u6237\u52a8\u6001\u5174\u8da3\uff0c\u7f13\u89e3\u76d1\u7763\u65b9\u6cd5\u7684\u566a\u58f0\u6307\u5bfc\u95ee\u9898\u3002"}}
{"id": "2511.20227", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.20227", "abs": "https://arxiv.org/abs/2511.20227", "authors": ["Anyang Tong", "Xiang Niu", "ZhiPing Liu", "Chang Tian", "Yanyan Wei", "Zenglin Shi", "Meng Wang"], "title": "HKRAG: Holistic Knowledge Retrieval-Augmented Generation Over Visually-Rich Documents", "comment": null, "summary": "Existing multimodal Retrieval-Augmented Generation (RAG) methods for visually rich documents (VRD) are often biased towards retrieving salient knowledge(e.g., prominent text and visual elements), while largely neglecting the critical fine-print knowledge(e.g., small text, contextual details). This limitation leads to incomplete retrieval and compromises the generator's ability to produce accurate and comprehensive answers. To bridge this gap, we propose HKRAG, a new holistic RAG framework designed to explicitly capture and integrate both knowledge types. Our framework features two key components: (1) a Hybrid Masking-based Holistic Retriever that employs explicit masking strategies to separately model salient and fine-print knowledge, ensuring a query-relevant holistic information retrieval; and (2) an Uncertainty-guided Agentic Generator that dynamically assesses the uncertainty of initial answers and actively decides how to integrate the two distinct knowledge streams for optimal response generation. Extensive experiments on open-domain visual question answering benchmarks show that HKRAG consistently outperforms existing methods in both zero-shot and supervised settings, demonstrating the critical importance of holistic knowledge retrieval for VRD understanding.", "AI": {"tldr": "HKRAG\u662f\u4e00\u4e2a\u9488\u5bf9\u89c6\u89c9\u4e30\u5bcc\u6587\u6863\u7684\u591a\u6a21\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u6df7\u5408\u63a9\u7801\u68c0\u7d22\u5668\u548c\u4e0d\u786e\u5b9a\u6027\u5f15\u5bfc\u751f\u6210\u5668\uff0c\u540c\u65f6\u6355\u83b7\u663e\u8457\u77e5\u8bc6\u548c\u7ec6\u7c92\u5ea6\u77e5\u8bc6\uff0c\u663e\u8457\u63d0\u5347\u89c6\u89c9\u95ee\u7b54\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u504f\u5411\u4e8e\u68c0\u7d22\u663e\u8457\u77e5\u8bc6\u800c\u5ffd\u7565\u7ec6\u7c92\u5ea6\u77e5\u8bc6\uff0c\u5bfc\u81f4\u68c0\u7d22\u4e0d\u5b8c\u6574\u548c\u56de\u7b54\u4e0d\u51c6\u786e\u3002\u9700\u8981\u4e00\u79cd\u80fd\u540c\u65f6\u5904\u7406\u4e24\u79cd\u77e5\u8bc6\u7c7b\u578b\u7684\u6574\u4f53\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u63a9\u7801\u6574\u4f53\u68c0\u7d22\u5668\u5206\u522b\u5efa\u6a21\u663e\u8457\u548c\u7ec6\u7c92\u5ea6\u77e5\u8bc6\uff0c\u4ee5\u53ca\u4e0d\u786e\u5b9a\u6027\u5f15\u5bfc\u7684\u4ee3\u7406\u751f\u6210\u5668\u52a8\u6001\u8bc4\u4f30\u4e0d\u786e\u5b9a\u6027\u5e76\u6574\u5408\u4e24\u79cd\u77e5\u8bc6\u6d41\u3002", "result": "\u5728\u5f00\u653e\u57df\u89c6\u89c9\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cHKRAG\u5728\u96f6\u6837\u672c\u548c\u76d1\u7763\u8bbe\u7f6e\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u6574\u4f53\u77e5\u8bc6\u68c0\u7d22\u5bf9\u89c6\u89c9\u4e30\u5bcc\u6587\u6863\u7406\u89e3\u81f3\u5173\u91cd\u8981\uff0cHKRAG\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2511.20235", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.20235", "abs": "https://arxiv.org/abs/2511.20235", "authors": ["Liren Yu", "Wenming Zhang", "Silu Zhou", "Zhixuan Zhang", "Dan Ou"], "title": "HHFT: Hierarchical Heterogeneous Feature Transformer for Recommendation Systems", "comment": null, "summary": "We propose HHFT (Hierarchical Heterogeneous Feature Transformer), a Transformer-based architecture tailored for industrial CTR prediction. HHFT addresses the limitations of DNN through three key designs: (1) Semantic Feature Partitioning: Grouping heterogeneous features (e.g. user profile, item information, behaviour sequennce) into semantically coherent blocks to preserve domain-specific information; (2) Heterogeneous Transformer Encoder: Adopting block-specific QKV projections and FFNs to avoid semantic confusion between distinct feature types; (3) Hiformer Layer: Capturing high-order interactions across features. Our findings reveal that Transformers significantly outperform DNN baselines, achieving a +0.4% improvement in CTR AUC at scale. We have successfully deployed the model on Taobao's production platform, observing a significant uplift in key business metrics, including a +0.6% increase in Gross Merchandise Value (GMV).", "AI": {"tldr": "HHFT\u662f\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u5de5\u4e1aCTR\u9884\u6d4b\u67b6\u6784\uff0c\u901a\u8fc7\u8bed\u4e49\u7279\u5f81\u5206\u533a\u3001\u5f02\u6784Transformer\u7f16\u7801\u5668\u548cHiformer\u5c42\u8bbe\u8ba1\uff0c\u663e\u8457\u8d85\u8d8aDNN\u57fa\u7ebf\uff0c\u5728\u6dd8\u5b9d\u751f\u4ea7\u5e73\u53f0\u4e0a\u6210\u529f\u90e8\u7f72\u5e76\u63d0\u5347\u5173\u952e\u4e1a\u52a1\u6307\u6807\u3002", "motivation": "\u89e3\u51b3DNN\u5728CTR\u9884\u6d4b\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5904\u7406\u5f02\u6784\u7279\u5f81\uff08\u7528\u6237\u753b\u50cf\u3001\u5546\u54c1\u4fe1\u606f\u3001\u884c\u4e3a\u5e8f\u5217\u7b49\uff09\u65f6\u8bed\u4e49\u6df7\u6dc6\u7684\u95ee\u9898\u3002", "method": "1. \u8bed\u4e49\u7279\u5f81\u5206\u533a\uff1a\u5c06\u5f02\u6784\u7279\u5f81\u6309\u8bed\u4e49\u5206\u7ec4\uff1b2. \u5f02\u6784Transformer\u7f16\u7801\u5668\uff1a\u91c7\u7528\u5757\u7279\u5b9a\u7684QKV\u6295\u5f71\u548cFFN\u907f\u514d\u8bed\u4e49\u6df7\u6dc6\uff1b3. Hiformer\u5c42\uff1a\u6355\u83b7\u7279\u5f81\u95f4\u7684\u9ad8\u9636\u4ea4\u4e92\u3002", "result": "Transformer\u663e\u8457\u8d85\u8d8aDNN\u57fa\u7ebf\uff0cCTR AUC\u63d0\u5347+0.4%\uff0c\u5728\u6dd8\u5b9d\u751f\u4ea7\u5e73\u53f0\u90e8\u7f72\u540e\uff0cGMV\u63d0\u5347+0.6%\u3002", "conclusion": "HHFT\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86\u5f02\u6784\u7279\u5f81\u5904\u7406\u7684\u6311\u6218\uff0c\u5728\u5de5\u4e1a\u89c4\u6a21CTR\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5df2\u6210\u529f\u5e94\u7528\u4e8e\u5b9e\u9645\u4e1a\u52a1\u573a\u666f\u3002"}}
