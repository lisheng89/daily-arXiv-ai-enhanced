<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 10]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [BiCoRec: Bias-Mitigated Context-Aware Sequential Recommendation Model](https://arxiv.org/abs/2512.13848)
*Mufhumudzi Muthivhi,Terence L van Zyl,Hairong Wang*

Main category: cs.IR

TL;DR: BiCoRec：通过协同注意力机制和一致性损失函数，自适应处理用户对热门与冷门物品偏好变化的序列推荐框架


<details>
  <summary>Details</summary>
Motivation: 当前最先进的序列推荐模型存在固有的流行度偏差问题，无法很好地适应用户对热门和冷门物品偏好的动态变化，特别是对于偏好冷门物品的用户群体

Method: 提出BiCoRec框架，采用协同注意力机制获取流行度加权的用户序列表示，并设计新的训练方案，利用一致性损失函数从未来偏好中学习

Result: 对于偏好冷门物品的用户，BiCoRec在NDCG@10指标上比现有最佳基线平均提升26.00%；在完整物品集排序中，在Movies、Fashion、Games和Music数据集上分别获得0.0102、0.0047、0.0021和0.0005的NDCG@10分数

Conclusion: BiCoRec通过自适应处理用户对热门与冷门物品的偏好变化，有效缓解了序列推荐中的流行度偏差问题，显著提升了推荐性能，特别是对偏好冷门物品的用户群体

Abstract: Sequential recommendation models aim to learn from users evolving preferences. However, current state-of-the-art models suffer from an inherent popularity bias. This study developed a novel framework, BiCoRec, that adaptively accommodates users changing preferences for popular and niche items. Our approach leverages a co-attention mechanism to obtain a popularity-weighted user sequence representation, facilitating more accurate predictions. We then present a new training scheme that learns from future preferences using a consistency loss function. BiCoRec aimed to improve the recommendation performance of users who preferred niche items. For these users, BiCoRec achieves a 26.00% average improvement in NDCG@10 over state-of-the-art baselines. When ranking the relevant item against the entire collection, BiCoRec achieves NDCG@10 scores of 0.0102, 0.0047, 0.0021, and 0.0005 for the Movies, Fashion, Games and Music datasets.

</details>


### [2] [Intent-Guided Reasoning for Sequential Recommendation](https://arxiv.org/abs/2512.14034)
*Yifan Shao,Peilin Zhou*

Main category: cs.IR

TL;DR: IGR-SR：一种用于序列推荐的意图引导推理框架，通过显式提取高层意图来解决现有推理增强方法中的推理不稳定性和表面级推理问题。


<details>
  <summary>Details</summary>
Motivation: 现有序列推荐中的推理增强方法仅以下一个目标物品作为监督，导致两个关键问题：1）推理不稳定性——过程对近期行为和偶然点击等虚假交互过于敏感；2）表面级推理——模型记忆物品间转移而非理解内在行为模式。

Method: 提出IGR-SR框架，包含三个核心组件：1）潜在意图蒸馏器（LID）使用冻结编码器和可学习token高效提取多层面意图；2）意图感知审慎推理器（IDR）通过双注意力架构将推理解耦为意图审议和决策制定；3）意图一致性正则化（ICR）通过强制不同意图视图间表示一致性确保鲁棒性。

Result: 在三个公共数据集上的实验显示，IGR-SR相比最先进基线平均提升7.13%。在20%行为噪声下，IGR-SR性能仅下降10.4%，而竞争方法下降16.2%和18.6%，验证了意图引导推理的有效性和鲁棒性。

Conclusion: IGR-SR通过显式提取和利用高层意图来引导推理过程，有效解决了序列推荐中推理增强方法的局限性，显著提升了推荐性能和鲁棒性。

Abstract: Sequential recommendation systems aim to capture users' evolving preferences from their interaction histories. Recent reasoningenhanced methods have shown promise by introducing deliberate, chain-of-thought-like processes with intermediate reasoning steps. However, these methods rely solely on the next target item as supervision, leading to two critical issues: (1) reasoning instability--the process becomes overly sensitive to recent behaviors and spurious interactions like accidental clicks, and (2) surface-level reasoning--the model memorizes item-to-item transitions rather than understanding intrinsic behavior patterns. To address these challenges, we propose IGR-SR, an Intent-Guided Reasoning framework for Sequential Recommendation that anchors the reasoning process to explicitly extracted high-level intents. Our framework comprises three key components: (1) a Latent Intent Distiller (LID) that efficiently extracts multi-faceted intents using a frozen encoder with learnable tokens, (2) an Intent-aware Deliberative Reasoner (IDR) that decouples reasoning into intent deliberation and decision-making via a dual-attention architecture, and (3) an Intent Consistency Regularization (ICR) that ensures robustness by enforcing consistent representations across different intent views. Extensive experiments on three public datasets demonstrate that IGR-SR achieves an average 7.13% improvement over state-of-the-art baselines. Critically, under 20% behavioral noise, IGR-SR degrades only 10.4% compared to 16.2% and 18.6% for competing methods, validating the effectiveness and robustness of intent-guided reasoning.

</details>


### [3] [DTRec: Learning Dynamic Reasoning Trajectories for Sequential Recommendation](https://arxiv.org/abs/2512.14036)
*Yifan Shao,Peilin Zhou,Shoujin Wang,Weizhi Zhang,Xu Cai,Sunghun Kim*

Main category: cs.IR

TL;DR: DTRec：动态推理轨迹的序列推荐框架，通过分层过程监督和自适应推理停止机制，在方向和深度上实现动态推理，显著提升性能并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有推理增强序列推荐方法存在两个关键限制：1）静态推理方向，使用扁平监督信号，与人类分层推理不匹配；2）固定推理深度，对所有用户应用相同计算量，不考虑行为模式复杂性。这些刚性导致性能次优和计算浪费。

Method: 提出DTRec框架，在方向和深度上探索动态推理轨迹：1）分层过程监督（HPS）提供从粗到细的监督信号，模拟人类认知过程的渐进细化；2）自适应推理停止（ARH）机制，通过联合监控三个指标动态调整推理步数。

Result: 在三个真实世界数据集上的实验表明，该方法优于强基线，性能提升高达24.5%，同时计算成本降低高达41.6%。

Conclusion: DTRec通过动态推理轨迹解决了现有方法的刚性限制，实现了更高效、更准确的序列推荐，平衡了性能与计算效率。

Abstract: Inspired by advances in LLMs, reasoning-enhanced sequential recommendation performs multi-step deliberation before making final predictions, unlocking greater potential for capturing user preferences. However, current methods are constrained by static reasoning trajectories that are ill-suited for the diverse complexity of user behaviors. They suffer from two key limitations: (1) a static reasoning direction, which uses flat supervision signals misaligned with human-like hierarchical reasoning, and (2) a fixed reasoning depth, which inefficiently applies the same computational effort to all users, regardless of pattern complexity. These rigidity lead to suboptimal performance and significant computational waste. To overcome these challenges, we propose DTRec, a novel and effective framework that explores the Dynamic reasoning Trajectory for Sequential Recommendation along both direction and depth. To guide the direction, we develop Hierarchical Process Supervision (HPS), which provides coarse-to-fine supervisory signals to emulate the natural, progressive refinement of human cognitive processes. To optimize the depth, we introduce the Adaptive Reasoning Halting (ARH) mechanism that dynamically adjusts the number of reasoning steps by jointly monitoring three indicators. Extensive experiments on three real-world datasets demonstrate the superiority of our approach, achieving up to a 24.5% performance improvement over strong baselines while simultaneously reducing computational cost by up to 41.6%.

</details>


### [4] [From Feature Interaction to Feature Generation: A Generative Paradigm of CTR Prediction Models](https://arxiv.org/abs/2512.14041)
*Mingjia Yin,Junwei Pan,Hao Wang,Ximei Wang,Shangyu Zhang,Jie Jiang,Defu Lian,Enhong Chen*

Main category: cs.IR

TL;DR: 提出SFG框架，将CTR预测从判别式的特征交互范式转向生成式的特征生成范式，解决嵌入维度塌缩和信息冗余问题


<details>
  <summary>Details</summary>
Motivation: 现有CTR预测模型主要采用判别式范式，过度依赖原始ID嵌入的特征交互，导致嵌入维度塌缩和信息冗余两个关键问题

Method: 提出监督特征生成（SFG）框架，包含编码器构建特征隐藏嵌入和解码器从隐藏表示重构特征嵌入，使用监督损失而非自监督损失

Result: SFG能有效缓解嵌入塌缩和减少信息冗余，在各种数据集和基础模型上带来显著性能提升，且能与大多数现有CTR模型无缝集成

Conclusion: SFG框架通过范式转变解决了CTR预测中的关键问题，展示了从判别式特征交互到生成式特征生成的有效性

Abstract: Click-Through Rate (CTR) prediction, a core task in recommendation systems, aims to estimate the probability of users clicking on items. Existing models predominantly follow a discriminative paradigm, which relies heavily on explicit interactions between raw ID embeddings. However, this paradigm inherently renders them susceptible to two critical issues: embedding dimensional collapse and information redundancy, stemming from the over-reliance on feature interactions \emph{over raw ID embeddings}. To address these limitations, we propose a novel \emph{Supervised Feature Generation (SFG)} framework, \emph{shifting the paradigm from discriminative ``feature interaction" to generative ``feature generation"}. Specifically, SFG comprises two key components: an \emph{Encoder} that constructs hidden embeddings for each feature, and a \emph{Decoder} tasked with regenerating the feature embeddings of all features from these hidden representations. Unlike existing generative approaches that adopt self-supervised losses, we introduce a supervised loss to utilize the supervised signal, \ie, click or not, in the CTR prediction task. This framework exhibits strong generalizability: it can be seamlessly integrated with most existing CTR models, reformulating them under the generative paradigm. Extensive experiments demonstrate that SFG consistently mitigates embedding collapse and reduces information redundancy, while yielding substantial performance gains across various datasets and base models. The code is available at https://github.com/USTC-StarTeam/GE4Rec.

</details>


### [5] [AsarRec: Adaptive Sequential Augmentation for Robust Self-supervised Sequential Recommendation](https://arxiv.org/abs/2512.14047)
*Kaike Zhang,Qi Cao,Fei Sun,Xinran Liu*

Main category: cs.IR

TL;DR: AsarRec：一种自适应序列增强框架，通过可学习的转换矩阵动态生成增强视图，解决传统静态增强策略在序列推荐中的局限性，提升模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实世界用户行为存在噪声（人为错误、不确定性、行为模糊性），传统自监督学习方法依赖预定义的静态增强策略，存在两个关键问题：1）不同场景下最优增强类型差异很大；2）不恰当的增强可能降低推荐性能。

Method: 提出AsarRec框架：1）将现有基本增强操作统一为结构化转换矩阵；2）通过编码用户序列为概率转移矩阵，使用可微分的Semi-Sinkhorn算法投影为硬半双随机矩阵来学习生成转换矩阵；3）联合优化多样性、语义不变性和信息性三个目标。

Result: 在三个基准数据集上，在不同噪声水平下进行广泛实验，验证了AsarRec的有效性，展示了其优越的鲁棒性和一致的性能提升。

Conclusion: AsarRec通过自适应增强策略克服了传统静态增强的局限性，能够动态生成适合不同场景的增强视图，显著提升了序列推荐系统在噪声环境下的鲁棒性和性能。

Abstract: Sequential recommender systems have demonstrated strong capabilities in modeling users' dynamic preferences and capturing item transition patterns. However, real-world user behaviors are often noisy due to factors such as human errors, uncertainty, and behavioral ambiguity, which can lead to degraded recommendation performance. To address this issue, recent approaches widely adopt self-supervised learning (SSL), particularly contrastive learning, by generating perturbed views of user interaction sequences and maximizing their mutual information to improve model robustness. However, these methods heavily rely on their pre-defined static augmentation strategies~(where the augmentation type remains fixed once chosen) to construct augmented views, leading to two critical challenges: (1) the optimal augmentation type can vary significantly across different scenarios; (2) inappropriate augmentations may even degrade recommendation performance, limiting the effectiveness of SSL. To overcome these limitations, we propose an adaptive augmentation framework. We first unify existing basic augmentation operations into a unified formulation via structured transformation matrices. Building on this, we introduce AsarRec (Adaptive Sequential Augmentation for Robust Sequential Recommendation), which learns to generate transformation matrices by encoding user sequences into probabilistic transition matrices and projecting them into hard semi-doubly stochastic matrices via a differentiable Semi-Sinkhorn algorithm. To ensure that the learned augmentations benefit downstream performance, we jointly optimize three objectives: diversity, semantic invariance, and informativeness. Extensive experiments on three benchmark datasets under varying noise levels validate the effectiveness of AsarRec, demonstrating its superior robustness and consistent improvements.

</details>


### [6] [SPARQL-LLM: Real-Time SPARQL Query Generation from Natural Language Questions](https://arxiv.org/abs/2512.14277)
*Panayiotis Smeros,Vincent Emonet,Ruijie Wang,Ana-Claudia Sima,Tarcisio Mendes de Farias*

Main category: cs.IR

TL;DR: SPARQL-LLM是一个开源、三元存储无关的方法，利用轻量级元数据从自然语言生成SPARQL查询，在准确性、多语言支持、联邦查询能力和成本效率方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的SPARQL查询生成方法主要关注单一数据源的准确性，而忽略了联邦查询能力、运行时性能和成本等生产部署的关键因素，导致难以在实际（特别是联邦）知识图谱中部署。

Method: SPARQL-LLM采用模块化架构，包含元数据索引、提示构建、查询生成与执行三个核心组件，利用轻量级元数据实现三元存储无关的查询生成。

Result: 在state-of-the-art挑战中F1分数提升24%，支持英语和西班牙语等高资源语言，能够生成复杂的联邦生物信息学查询，比其他系统快达36倍，每个问题成本最高仅0.01美元。

Conclusion: SPARQL-LLM是一个生产就绪的解决方案，适用于实时、低成本的文本到SPARQL应用，已在实际的分散知识图谱中部署（如https://www.expasy.org/chat）。

Abstract: The advent of large language models is contributing to the emergence of novel approaches that promise to better tackle the challenge of generating structured queries, such as SPARQL queries, from natural language. However, these new approaches mostly focus on response accuracy over a single source while ignoring other evaluation criteria, such as federated query capability over distributed data stores, as well as runtime and cost to generate SPARQL queries. Consequently, they are often not production-ready or easy to deploy over (potentially federated) knowledge graphs with good accuracy. To mitigate these issues, in this paper, we extend our previous work and describe and systematically evaluate SPARQL-LLM, an open-source and triplestore-agnostic approach, powered by lightweight metadata, that generates SPARQL queries from natural language text. First, we describe its architecture, which consists of dedicated components for metadata indexing, prompt building, and query generation and execution. Then, we evaluate it based on a state-of-the-art challenge with multilingual questions, and a collection of questions from three of the most prevalent knowledge graphs within the field of bioinformatics. Our results demonstrate a substantial increase of 24% in the F1 Score on the state-of-the-art challenge, adaptability to high-resource languages such as English and Spanish, as well as ability to form complex and federated bioinformatics queries. Furthermore, we show that SPARQL-LLM is up to 36x faster than other systems participating in the challenge, while costing a maximum of $0.01 per question, making it suitable for real-time, low-cost text-to-SPARQL applications. One such application deployed over real-world decentralized knowledge graphs can be found at https://www.expasy.org/chat.

</details>


### [7] [Dynamic Context Selection for Retrieval-Augmented Generation: Mitigating Distractors and Positional Bias](https://arxiv.org/abs/2512.14313)
*Malika Iratni,Mohand Boughanem,Taoufiq Dkaki*

Main category: cs.IR

TL;DR: 本文系统分析了RAG系统中干扰文档对生成质量的影响，研究了相关段落位置效应，并提出基于查询的动态文档数量预测方法，显著提升了RAG性能。


<details>
  <summary>Details</summary>
Motivation: 标准RAG系统使用固定的top k检索策略存在两个问题：1) 可能遗漏相关信息或引入语义无关的干扰文档，降低输出质量；2) 检索段落在输入上下文中的位置会影响模型注意力，出现"中间丢失"现象。需要系统分析这些因素并改进RAG系统。

Method: 1) 系统分析干扰文档对生成质量的影响，量化不同条件下的效果；2) 研究相关段落在上下文窗口中的位置如何影响生成结果；3) 基于这些洞察，提出上下文大小分类器，根据查询特定的信息需求动态预测最优检索文档数量；4) 将该方法集成到完整的RAG流程中。

Result: 提出的动态文档数量预测方法在完整RAG流程中表现出优于固定k基线的性能，有效解决了干扰文档和位置效应问题。

Conclusion: 通过系统分析RAG中的干扰文档效应和位置效应，提出的动态文档检索策略能够根据查询需求优化检索数量，显著提升RAG系统的生成质量，为更智能的检索增强生成系统提供了有效解决方案。

Abstract: Retrieval Augmented Generation (RAG) enhances language model performance by incorporating external knowledge retrieved from large corpora, which makes it highly suitable for tasks such as open domain question answering. Standard RAG systems typically rely on a fixed top k retrieval strategy, which can either miss relevant information or introduce semantically irrelevant passages, known as distractors, that degrade output quality. Additionally, the positioning of retrieved passages within the input context can influence the model attention and generation outcomes. Context placed in the middle tends to be overlooked, which is an issue known as the "lost in the middle" phenomenon. In this work, we systematically analyze the impact of distractors on generation quality, and quantify their effects under varying conditions. We also investigate how the position of relevant passages within the context window affects their influence on generation. Building on these insights, we propose a context-size classifier that dynamically predicts the optimal number of documents to retrieve based on query-specific informational needs. We integrate this approach into a full RAG pipeline, and demonstrate improved performance over fixed k baselines.

</details>


### [8] [PushGen: Push Notifications Generation with LLM](https://arxiv.org/abs/2512.14490)
*Shifu Bie,Jiangxia Cao,Zixiao Luo,Yichuan Zou,Lei Liang,Lu Zhang,Linxun Chen,Zhaojie Liu,Xuanping Li,Guorui Zhou,Kaiqiao Zhan,Kun Gai*

Main category: cs.IR

TL;DR: PushGen是一个自动生成高质量推送通知的框架，通过可控类别提示和奖励模型来保证风格一致性和质量，已在大规模工业应用中部署


<details>
  <summary>Details</summary>
Motivation: 随着生成模型的发展，利用LLM生成推送内容变得简单且成本效益高，但如何保持风格控制和可靠的质量评估仍然具有挑战性，这两者直接影响用户参与度

Method: PushGen包含两个关键组件：(1) 可控类别提示技术，引导LLM输出符合期望风格的内容；(2) 奖励模型，对生成的候选内容进行排序和选择

Result: 大量离线和在线实验证明了PushGen的有效性，该框架已在大规模工业应用中部署，每天为数亿用户提供服务

Conclusion: PushGen通过结合可控提示和奖励模型，成功解决了LLM生成推送内容时的风格控制和质量评估问题，实现了高质量推送通知的自动化生成

Abstract: We present PushGen, an automated framework for generating high-quality push notifications comparable to human-crafted content. With the rise of generative models, there is growing interest in leveraging LLMs for push content generation. Although LLMs make content generation straightforward and cost-effective, maintaining stylistic control and reliable quality assessment remains challenging, as both directly impact user engagement. To address these issues, PushGen combines two key components: (1) a controllable category prompt technique to guide LLM outputs toward desired styles, and (2) a reward model that ranks and selects generated candidates. Extensive offline and online experiments demonstrate its effectiveness, which has been deployed in large-scale industrial applications, serving hundreds of millions of users daily.

</details>


### [9] [RecGPT-V2 Technical Report](https://arxiv.org/abs/2512.14503)
*Chao Yi,Dian Chen,Gaoyang Guo,Jiakai Tang,Jian Wu,Jing Yu,Mao Zhang,Wen Chen,Wenjun Yang,Yujie Luo,Yuning Jiang,Zhujin Gao,Bo Zheng,Binbin Cao,Changfa Wu,Dixuan Wang,Han Wu,Haoyi Hu,Kewei Zhu,Lang Tian,Lin Yang,Qiqi Huang,Siqi Yang,Wenbo Su,Xiaoxiao He,Xin Tong,Xu Chen,Xunke Xi,Xiaowei Huang,Yaxuan Wu,Yeqiu Yang,Yi Hu,Yujin Yuan,Yuliang Yan,Zile Zhou*

Main category: cs.IR

TL;DR: RecGPT-V2通过分层多智能体系统、元提示框架、约束强化学习和智能体即法官评估框架，解决了V1版本的计算效率、解释多样性、泛化能力和评估标准问题，在淘宝A/B测试中显著提升了推荐效果。


<details>
  <summary>Details</summary>
Motivation: RecGPT-V1虽然成功将LLM推理引入推荐系统，但存在四个根本限制：计算效率低下和认知冗余、解释多样性不足、监督学习范式下泛化能力有限、评估标准过于简单不符合人类标准。需要解决这些问题以实现LLM驱动的意图推理在工业规模上的部署。

Method: 1. 分层多智能体系统：通过协调协作重构意图推理，消除认知重复，实现多样化意图覆盖；结合混合表示推理压缩用户行为上下文
2. 元提示框架：动态生成上下文自适应提示，提升解释多样性
3. 约束强化学习：缓解多奖励冲突，优化标签预测和解释接受度
4. 智能体即法官框架：将评估分解为多步推理，提升人类偏好对齐

Result: 1. 计算效率：GPU消耗降低60%，专属召回率从9.39%提升至10.99%
2. 解释多样性：提升+7.3%
3. 预测性能：标签预测提升+24.1%，解释接受度提升+13.0%
4. 在线A/B测试：CTR提升+2.98%，IPV提升+3.71%，TV提升+2.19%，NER提升+11.46%
5. 建立了LLM驱动的意图推理在工业规模部署的技术可行性和商业可行性

Conclusion: RecGPT-V2通过四项关键创新成功解决了V1版本的根本限制，在计算效率、解释多样性、预测性能和人类偏好对齐方面都取得了显著改进。该框架不仅证明了LLM驱动的意图推理在工业规模部署的技术可行性，还展示了其商业价值，成功弥合了认知探索与工业实用性之间的差距。

Abstract: Large language models (LLMs) have demonstrated remarkable potential in transforming recommender systems from implicit behavioral pattern matching to explicit intent reasoning. While RecGPT-V1 successfully pioneered this paradigm by integrating LLM-based reasoning into user interest mining and item tag prediction, it suffers from four fundamental limitations: (1) computational inefficiency and cognitive redundancy across multiple reasoning routes; (2) insufficient explanation diversity in fixed-template generation; (3) limited generalization under supervised learning paradigms; and (4) simplistic outcome-focused evaluation that fails to match human standards.
  To address these challenges, we present RecGPT-V2 with four key innovations. First, a Hierarchical Multi-Agent System restructures intent reasoning through coordinated collaboration, eliminating cognitive duplication while enabling diverse intent coverage. Combined with Hybrid Representation Inference that compresses user-behavior contexts, our framework reduces GPU consumption by 60% and improves exclusive recall from 9.39% to 10.99%. Second, a Meta-Prompting framework dynamically generates contextually adaptive prompts, improving explanation diversity by +7.3%. Third, constrained reinforcement learning mitigates multi-reward conflicts, achieving +24.1% improvement in tag prediction and +13.0% in explanation acceptance. Fourth, an Agent-as-a-Judge framework decomposes assessment into multi-step reasoning, improving human preference alignment. Online A/B tests on Taobao demonstrate significant improvements: +2.98% CTR, +3.71% IPV, +2.19% TV, and +11.46% NER. RecGPT-V2 establishes both the technical feasibility and commercial viability of deploying LLM-powered intent reasoning at scale, bridging the gap between cognitive exploration and industrial utility.

</details>


### [10] [Pairwise Comparison for Bias Identification and Quantification](https://arxiv.org/abs/2512.14565)
*Fabian Haak,Philipp Schaer*

Main category: cs.IR

TL;DR: 本文提出通过成对比较来标注语言偏见，开发了成本感知的优化方法，并在模拟和真实数据中验证了其有效性，为大规模主观语言标注提供了实用方案。


<details>
  <summary>Details</summary>
Motivation: 在线新闻和社交媒体中的语言偏见普遍存在但难以测量，主要挑战包括主观性、语境依赖性和高质量标注数据稀缺。现有方法标注成本高，需要更高效的标注方案。

Method: 采用成对比较方法进行偏见标注，通过模拟环境评估不同评分技术和三种成本感知替代方案的参数效果。模拟包括潜在严重性分布、距离校准噪声和合成标注者偏见。最后在人类标注的偏见基准数据集上评估最有前景的设置。

Result: 研究支持使用成对比较作为量化主观语言方面的实用基础，实现了可复现的偏见分析。优化了比较和匹配组件，提供了端到端评估框架和成本感知大规模标注的实现蓝图。

Conclusion: 成对比较方法为创建高质量基准数据集和量化偏见等主观语言特征提供了可行方案，该方法既适用于人类标注也适用于大语言模型标注，有助于推动语言偏见研究的可重复性。

Abstract: Linguistic bias in online news and social media is widespread but difficult to measure. Yet, its identification and quantification remain difficult due to subjectivity, context dependence, and the scarcity of high-quality gold-label datasets. We aim to reduce annotation effort by leveraging pairwise comparison for bias annotation. To overcome the costliness of the approach, we evaluate more efficient implementations of pairwise comparison-based rating. We achieve this by investigating the effects of various rating techniques and the parameters of three cost-aware alternatives in a simulation environment. Since the approach can in principle be applied to both human and large language model annotation, our work provides a basis for creating high-quality benchmark datasets and for quantifying biases and other subjective linguistic aspects.
  The controlled simulations include latent severity distributions, distance-calibrated noise, and synthetic annotator bias to probe robustness and cost-quality trade-offs. In applying the approach to human-labeled bias benchmark datasets, we then evaluate the most promising setups and compare them to direct assessment by large language models and unmodified pairwise comparison labels as baselines. Our findings support the use of pairwise comparison as a practical foundation for quantifying subjective linguistic aspects, enabling reproducible bias analysis. We contribute an optimization of comparison and matchmaking components, an end-to-end evaluation including simulation and real-data application, and an implementation blueprint for cost-aware large-scale annotation

</details>
