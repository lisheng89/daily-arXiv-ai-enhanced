<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 2]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [GPR: Towards a Generative Pre-trained One-Model Paradigm for Large-Scale Advertising Recommendation](https://arxiv.org/abs/2511.10138)
*Jun Zhang,Yi Li,Yue Liu,Changping Wang,Yuan Wang,Yuling Xiong,Xun Liu,Haiyang Wu,Qian Li,Enming Zhang,Jiawei Sun,Xin Xu,Zishuai Zhang,Ruoran Liu,Suyuan Huang,Zhaoxin Zhang,Zhengkai Guo,Shuojin Yang,Meng-Hao Guo,Huan Yu,Jie Jiang,Shi-Min Hu*

Main category: cs.IR

TL;DR: GPR是首个将广告推荐重新定义为端到端生成任务的统一模型框架，通过统一表示、异构分层解码器和多阶段联合训练策略，解决了传统多阶段推荐系统的目标不一致和误差传播问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多阶段广告推荐系统存在目标不一致和误差传播问题，难以实现全局最优；而统一的生成式推荐模型仍难以满足实际工业应用需求。

Method: 提出GPR框架，包含三个关键创新：1）统一输入模式和分词方法，将广告和自然内容映射到共享的多层次语义ID空间；2）异构分层解码器（HHD），解耦用户意图建模和广告生成；3）多阶段联合训练策略，整合多令牌预测、价值感知微调和层次增强策略优化算法。

Result: GPR已在腾讯微信视频号广告系统全面部署，在GMV和CTCVR等关键业务指标上取得显著提升。

Conclusion: GPR成功实现了广告推荐从传统级联范式向统一生成式方法的转变，为工业级广告推荐系统提供了有效的解决方案。

Abstract: As an intelligent infrastructure connecting users with commercial content, advertising recommendation systems play a central role in information flow and value creation within the digital economy. However, existing multi-stage advertising recommendation systems suffer from objective misalignment and error propagation, making it difficult to achieve global optimality, while unified generative recommendation models still struggle to meet the demands of practical industrial applications. To address these issues, we propose GPR (Generative Pre-trained Recommender), the first one-model framework that redefines advertising recommendation as an end-to-end generative task, replacing the traditional cascading paradigm with a unified generative approach. To realize GPR, we introduce three key innovations spanning unified representation, network architecture, and training strategy. First, we design a unified input schema and tokenization method tailored to advertising scenarios, mapping both ads and organic content into a shared multi-level semantic ID space, thereby enhancing semantic alignment and modeling consistency across heterogeneous data. Second, we develop the Heterogeneous Hierarchical Decoder (HHD), a dual-decoder architecture that decouples user intent modeling from ad generation, achieving a balance between training efficiency and inference flexibility while maintaining strong modeling capacity. Finally, we propose a multi-stage joint training strategy that integrates Multi-Token Prediction (MTP), Value-Aware Fine-Tuning and the Hierarchy Enhanced Policy Optimization (HEPO) algorithm, forming a complete generative recommendation pipeline that unifies interest modeling, value alignment, and policy optimization. GPR has been fully deployed in the Tencent Weixin Channels advertising system, delivering significant improvements in key business metrics including GMV and CTCVR.

</details>


### [2] [Don't Waste It: Guiding Generative Recommenders with Structured Human Priors via Multi-head Decoding](https://arxiv.org/abs/2511.10492)
*Yunkai Zhang,Qiang Zhang,Feng,Lin,Ruizhong Qiu,Hanchao Yu,Jason Liu,Yinglong Xia,Zhuoran Yu,Zeyu Zheng,Diji Yang*

Main category: cs.IR

TL;DR: 提出了一个与骨干模型无关的框架，将人类先验知识直接集成到生成式推荐系统的端到端训练中，通过轻量级适配器头来引导模型解耦用户意图，显著提升准确性和多样性等目标。


<details>
  <summary>Details</summary>
Motivation: 工业实践中积累了丰富的结构化领域知识（人类先验），但现有方法要么在排序后进行调整而与核心模型学习脱节，要么以完全无监督方式学习用户意图而丢弃这些宝贵先验。需要一种能在端到端训练中无缝集成人类先验的方法。

Method: 使用轻量级的先验条件适配器头，受高效LLM解码策略启发，引导模型沿人类可理解的维度（如交互类型、长短期兴趣）解耦用户意图，并引入分层组合策略建模不同先验类型间的复杂交互。

Result: 在三个大规模数据集上的广泛实验表明，该方法显著提升了准确性和多样性等目标，同时人类先验使骨干模型能更有效地利用更长的上下文长度和更大的模型规模。

Conclusion: 提出的框架成功将人类先验知识集成到生成式推荐系统的端到端训练中，不仅提升了推荐性能，还增强了模型的可解释性和可扩展性。

Abstract: Optimizing recommender systems for objectives beyond accuracy, such as diversity, novelty, and personalization, is crucial for long-term user satisfaction. To this end, industrial practitioners have accumulated vast amounts of structured domain knowledge, which we term human priors (e.g., item taxonomies, temporal patterns). This knowledge is typically applied through post-hoc adjustments during ranking or post-ranking. However, this approach remains decoupled from the core model learning, which is particularly undesirable as the industry shifts to end-to-end generative recommendation foundation models. On the other hand, many methods targeting these beyond-accuracy objectives often require architecture-specific modifications and discard these valuable human priors by learning user intent in a fully unsupervised manner.
  Instead of discarding the human priors accumulated over years of practice, we introduce a backbone-agnostic framework that seamlessly integrates these human priors directly into the end-to-end training of generative recommenders. With lightweight, prior-conditioned adapter heads inspired by efficient LLM decoding strategies, our approach guides the model to disentangle user intent along human-understandable axes (e.g., interaction types, long- vs. short-term interests). We also introduce a hierarchical composition strategy for modeling complex interactions across different prior types. Extensive experiments on three large-scale datasets demonstrate that our method significantly enhances both accuracy and beyond-accuracy objectives. We also show that human priors allow the backbone model to more effectively leverage longer context lengths and larger model sizes.

</details>
