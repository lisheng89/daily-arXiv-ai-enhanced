<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 13]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [A survey: Information search time optimization based on RAG (Retrieval Augmentation Generation) chatbot](https://arxiv.org/abs/2601.07838)
*Jinesh Patel,Arpit Malhotra,Ajay Pande,Prateek Caire*

Main category: cs.IR

TL;DR: RAG聊天机器人在组织内部信息检索中相比传统搜索方法可节省80-95%的时间


<details>
  <summary>Details</summary>
Motivation: 评估RAG聊天机器人在企业环境中检索复杂信息时相比传统搜索方法的时间节省效果，特别是在"X Systems"这样的隐身模式公司中

Method: 在"X Systems"公司对105名跨部门员工进行调研，比较相同查询下传统搜索方法与RAG聊天机器人的信息检索时间，以每次查询的平均检索时间为指标

Result: RAG聊天机器人相比传统搜索方法在信息检索时间上平均有80-95%的改进，显著优化了搜索过程

Conclusion: RAG聊天机器人不仅能节省信息检索时间，还能有效优化搜索过程，在企业环境中具有显著的实际应用价值

Abstract: Retrieval-Augmented Generation (RAG) based chatbots are not only useful for information retrieval through questionanswering but also for making complex decisions based on injected private data.we present a survey on how much search time can be saved when retrieving complex information within an organization called "X Systems"(a stealth mode company) by using a RAG-based chatbot compared to traditional search methods. We compare the information retrieval time using standard search techniques versus the RAG-based chatbot for the same queries. Our results conclude that RAG-based chatbots not only save time in information retrieval but also optimize the search process effectively. This survey was conducted with a sample of 105 employees across departments, average time spending on information retrieval per query was taken as metric. Comparison shows us, there are average 80-95% improvement on search when use RAG based chatbot than using standard search.

</details>


### [2] [Cost and accuracy of long-term graph memory in distributed LLM-based multi-agent systems](https://arxiv.org/abs/2601.07978)
*Benedict Wolff,Jacopo Bennati*

Main category: cs.IR

TL;DR: 该研究比较了分布式多智能体系统中两种长期记忆框架：向量基的mem0和图基的Graphiti，在有无网络约束条件下评估其计算、财务和准确性表现，发现mem0在效率上显著优于Graphiti，而准确性差异不显著。


<details>
  <summary>Details</summary>
Motivation: 分布式多智能体系统使用大语言模型实现协作智能同时保护隐私，但缺乏在网络约束下对长期记忆系统的系统性评估。现有研究对mem0（向量基记忆框架）和Graphiti（图基知识图谱）在真实网络条件下的表现比较有限。

Method: 研究建立了一个灵活测试平台，使用LOCOMO长上下文基准，在无约束和约束网络条件下比较mem0和Graphiti。测量了计算效率（加载时间）、财务成本（资源消耗）、网络开销和准确性指标。

Result: mem0在效率方面显著优于Graphiti：加载时间更快、资源消耗更低、网络开销最小。两种框架的准确性差异在统计上不显著。应用统计帕累托效率框架分析，mem0被确定为在成本与准确性之间达到最佳平衡的选择。

Conclusion: mem0是分布式多智能体系统中更优的长期记忆解决方案，它在保持与Graphiti相当准确性的同时，提供了显著更高的效率、更低的成本和更好的网络适应性，是平衡成本与准确性的帕累托最优选择。

Abstract: Distributed multi-agent systems use large language models to enable collaborative intelligence while preserving privacy, yet systematic evaluations of long-term memory under network constraints remain limited. This study presents a flexible testbed comparing mem0, a vector-based memory framework, and Graphiti, a graph-based knowledge graph, using the LOCOMO long-context benchmark. Experiments were conducted under unconstrained and constrained network conditions, measuring computational, financial, and accuracy metrics. Results indicate that mem0 significantly outperforms Graphiti in efficiency, with faster loading times, lower resource consumption, and minimal network overhead, while accuracy differences are not statistically significant. Applying a statistical pareto efficiency framework, mem0 is identified as the optimal choice that balances cost and accuracy in DMAS.

</details>


### [3] [Enriching Semantic Profiles into Knowledge Graph for Recommender Systems Using Large Language Models](https://arxiv.org/abs/2601.08148)
*Seokho Ahn,Sungbok Shin,Young-Duk Seo*

Main category: cs.IR

TL;DR: SPiKE模型结合LLMs和KGs优势：用LLMs从知识源提取压缩语义档案，用KGs传播档案扩展覆盖范围，通过档案感知KG聚合和成对档案偏好匹配提升推荐效果。


<details>
  <summary>Details</summary>
Motivation: 当前推荐系统中用户档案构建和利用方法缺乏共识，需要更丰富的信息化档案来捕捉用户偏好以提升推荐质量。LLMs擅长从多样知识源提取压缩推理，而KGs更适合传播档案扩展覆盖范围。

Method: 提出SPiKE模型：1) 实体档案生成：用LLMs为所有KG实体生成语义档案；2) 档案感知KG聚合：将这些档案整合到KG中；3) 成对档案偏好匹配：在训练中对齐LLM和KG的表示。

Result: 在真实场景实验中，SPiKE持续优于最先进的基于KG和LLM的推荐系统。

Conclusion: 结合LLMs的语义提取能力和KGs的传播能力，SPiKE模型有效解决了用户档案构建和利用问题，显著提升了推荐系统性能。

Abstract: Rich and informative profiling to capture user preferences is essential for improving recommendation quality. However, there is still no consensus on how best to construct and utilize such profiles. To address this, we revisit recent profiling-based approaches in recommender systems along four dimensions: 1) knowledge base, 2) preference indicator, 3) impact range, and 4) subject. We argue that large language models (LLMs) are effective at extracting compressed rationales from diverse knowledge sources, while knowledge graphs (KGs) are better suited for propagating these profiles to extend their reach. Building on this insight, we propose a new recommendation model, called SPiKE. SPiKE consists of three core components: i) Entity profile generation, which uses LLMs to generate semantic profiles for all KG entities; ii) Profile-aware KG aggregation, which integrates these profiles into the KG; and iii) Pairwise profile preference matching, which aligns LLM- and KG-based representations during training. In experiments, we demonstrate that SPiKE consistently outperforms state-of-the-art KG- and LLM-based recommenders in real-world settings.

</details>


### [4] [Markovian Pre-Trained Transformer for Next-Item Recommendation](https://arxiv.org/abs/2601.08275)
*Cong Xu,Guoliang Li,Jun Wang,Wei Zhang*

Main category: cs.IR

TL;DR: MPT是一种基于马尔可夫链预训练的可迁移推荐模型，仅需微调轻量适配器即可达到SOTA性能，其成功源于序列推荐的"马尔可夫性"本质。


<details>
  <summary>Details</summary>
Motivation: 现有先进序列推荐器实际上主要依赖最近一次交互进行预测，历史交互仅作为推断用户一般身份的辅助线索。这种"马尔可夫性"表明通用推荐模型需要有效总结用户序列并特别关注最新交互。

Method: 提出马尔可夫预训练变换器(MPT)，在合成马尔可夫链上完全预训练，学习从上下文估计转移概率并关注最后状态的能力。与异构交互数据不同，无限量的可控马尔可夫链可用于提升模型容量。

Result: 在来自三个不同平台的五个公共数据集上进行广泛实验，验证了马尔可夫预训练相对于传统推荐预训练和近期语言预训练范式的优越性。

Conclusion: MPT具有成为通用可迁移推荐模型的潜力，其基于马尔可夫链的预训练方法能够有效捕捉序列推荐的本质特性，仅需微调轻量适配器即可在不同平台上取得优异性能。

Abstract: We introduce the Markovian Pre-trained Transformer (MPT) for next-item recommendation, a transferable model fully pre-trained on synthetic Markov chains, yet capable of achieving state-of-the-art performance by fine-tuning a lightweight adaptor. This counterintuitive success stems from the observation of the `Markovian' nature: advanced sequential recommenders coincidentally rely on the latest interaction to make predictions, while the historical interactions serve mainly as auxiliary cues for inferring the user's general, non-sequential identity. This characteristic necessitates the capabilities of a universal recommendation model to effectively summarize the user sequence, with particular emphasis on the latest interaction. MPT inherently has the potential to be universal and transferable. On the one hand, when trained to predict the next state of Markov chains, it acquires the capabilities to estimate transition probabilities from the context (one adaptive manner for summarizing sequences) and attend to the last state to ensure accurate state transitions. On the other hand, unlike the heterogeneous interaction data, an unlimited amount of controllable Markov chains is available to boost the model capacity. We conduct extensive experiments on five public datasets from three distinct platforms to validate the superiority of Markovian pre-training over traditional recommendation pre-training and recent language pre-training paradigms.

</details>


### [5] [AgriLens: Semantic Retrieval in Agricultural Texts Using Topic Modeling and Language Models](https://arxiv.org/abs/2601.08283)
*Heba Shakeel,Tanvir Ahmad,Tanya Liyaqat,Chandni Saxena*

Main category: cs.IR

TL;DR: 提出一个统一框架，用于可解释主题建模、零样本主题标注和主题引导的语义检索，应用于大规模农业文本语料库


<details>
  <summary>Details</summary>
Motivation: 随着各领域非结构化文本数据快速增长，急需可扩展的方法来实现可解释的信息组织、摘要和检索，特别是在标注数据有限的专门领域

Method: 使用BERTopic提取语义连贯的主题，将每个主题转换为结构化提示，让语言模型以零样本方式生成有意义的主题标签和摘要，通过密集嵌入和向量搜索支持查询和文档探索，并设有专门的评估模块

Result: 该框架支持在标注数据有限的专门领域进行可扩展和可解释的信息访问

Conclusion: 提出的统一框架能够有效解决大规模文本语料库中的信息组织、摘要和检索问题，特别适用于农业等专门领域

Abstract: As the volume of unstructured text continues to grow across domains, there is an urgent need for scalable methods that enable interpretable organization, summarization, and retrieval of information. This work presents a unified framework for interpretable topic modeling, zero-shot topic labeling, and topic-guided semantic retrieval over large agricultural text corpora. Leveraging BERTopic, we extract semantically coherent topics. Each topic is converted into a structured prompt, enabling a language model to generate meaningful topic labels and summaries in a zero-shot manner. Querying and document exploration are supported via dense embeddings and vector search, while a dedicated evaluation module assesses topical coherence and bias. This framework supports scalable and interpretable information access in specialized domains where labeled data is limited.

</details>


### [6] [MLPlatt: Simple Calibration Framework for Ranking Models](https://arxiv.org/abs/2601.08345)
*Piotr Bajger,Roman Dusek,Krzysztof Galias,Paweł Młyniec,Aleksander Wawer,Paweł Zawistowski*

Main category: cs.IR

TL;DR: 本文提出MLPlatt方法，用于电商排名模型的后处理校准，将排名输出转换为可解释的点击率概率，同时保持项目排序不变。


<details>
  <summary>Details</summary>
Motivation: 电商排名模型通常存在可解释性差和缺乏尺度校准的问题，特别是在使用典型排名损失函数训练时。现有方法难以同时保持排序质量和实现良好校准。

Method: 提出MLPlatt方法：一种简单有效的排名模型校准方法，通过上下文感知设计，将排名器输出转换为可解释的点击率概率，同时保持项目排序不变。

Result: 在两个数据集上，MLPlatt相比现有方法在F-ECE（字段期望校准误差）指标上提升超过10%，且在不影响排名质量的情况下实现高质量校准。

Conclusion: MLPlatt方法能够有效解决电商排名模型的校准问题，提供可解释的点击率概率，同时保持排序性能，对电商平台具有重要商业价值。

Abstract: Ranking models are extensively used in e-commerce for relevance estimation. These models often suffer from poor interpretability and no scale calibration, particularly when trained with typical ranking loss functions. This paper addresses the problem of post-hoc calibration of ranking models. We introduce MLPlatt: a simple yet effective ranking model calibration method that preserves the item ordering and converts ranker outputs to interpretable click-through rate (CTR) probabilities usable in downstream tasks. The method is context-aware by design and achieves good calibration metrics globally, and within strata corresponding to different values of a selected categorical field (such as user country or device), which is often important from a business perspective of an E-commerce platform. We demonstrate the superiority of MLPlatt over existing approaches on two datasets, achieving an improvement of over 10\% in F-ECE (Field Expected Calibration Error) compared to other methods. Most importantly, we show that high-quality calibration can be achieved without compromising the ranking quality.

</details>


### [7] [Scalable Sequential Recommendation under Latency and Memory Constraints](https://arxiv.org/abs/2601.08360)
*Adithya Parthasarathy,Aswathnarayan Muthukrishnan Kirubakaran,Vinoth Punniyamoorthy,Nachiappan Chockalingam,Lokesh Butra,Kabilan Kannan,Abhirup Mazumder,Sumit Saha*

Main category: cs.IR

TL;DR: HoloMambaRec：结合全息降维表示和选择性状态空间编码的轻量级序列推荐架构，在有限训练预算下实现高效长序列建模


<details>
  <summary>Details</summary>
Motivation: 序列推荐系统需要在严格的内存和延迟约束下建模长范围用户行为。基于Transformer的方法虽然准确率高，但存在二次注意力复杂度问题，需要截断用户历史记录，限制了长序列建模的实用性。

Method: 1. 使用全息降维表示进行属性感知嵌入；2. 采用选择性状态空间编码器进行线性时间序列处理；3. 通过循环卷积绑定项目和属性信息；4. 基于Mamba风格模型的浅层选择性状态空间主干；5. 包含前向兼容机制，支持时间捆绑和推理时压缩。

Result: 在Amazon Beauty和MovieLens-1M数据集上，HoloMambaRec在10个epoch的有限训练预算下，性能持续优于SASRec，与GRU4Rec竞争，同时保持显著更低的内存复杂度。

Conclusion: HoloMambaRec为可扩展、元数据感知的序列推荐提供了一个实用且可扩展的替代方案，平衡了准确性、效率和内存使用。

Abstract: Sequential recommender systems must model long-range user behavior while operating under strict memory and latency constraints. Transformer-based approaches achieve strong accuracy but suffer from quadratic attention complexity, forcing aggressive truncation of user histories and limiting their practicality for long-horizon modeling. This paper presents HoloMambaRec, a lightweight sequential recommendation architecture that combines holographic reduced representations for attribute-aware embedding with a selective state space encoder for linear-time sequence processing. Item and attribute information are bound using circular convolution, preserving embedding dimensionality while encoding structured metadata. A shallow selective state space backbone, inspired by recent Mamba-style models, enables efficient training and constant-time recurrent inference. Experiments on Amazon Beauty and MovieLens-1M datasets demonstrate that HoloMambaRec consistently outperforms SASRec and achieves competitive performance with GRU4Rec under a constrained 10-epoch training budget, while maintaining substantially lower memory complexity. The design further incorporates forward-compatible mechanisms for temporal bundling and inference-time compression, positioning HoloMambaRec as a practical and extensible alternative for scalable, metadata-aware sequential recommendation.

</details>


### [8] [PosIR: Position-Aware Heterogeneous Information Retrieval Benchmark](https://arxiv.org/abs/2601.08363)
*Ziyang Zeng,Dun Zhang,Yu Yan,Xu Sun,Yudong Zhou,Yuqing Yang*

Main category: cs.IR

TL;DR: PosIR是一个用于诊断检索模型中位置偏见的基准测试，包含310个数据集、10种语言、31个领域，通过将相关性与精确参考片段绑定来分离文档长度和信息位置的影响。


<details>
  <summary>Details</summary>
Motivation: 现有检索模型评估通常使用位置无关的相关性标签，混淆了处理长上下文的挑战与对特定证据位置偏见的区分。需要专门基准来诊断检索模型中的位置偏见问题。

Method: 构建PosIR基准，包含310个跨语言和领域的数据集，通过严格流程将相关性与精确参考片段绑定，确保文档长度与信息位置的严格分离。使用10个最先进的嵌入模型进行实验，并进行基于梯度的显著性分析。

Result: 1) PosIR在长上下文设置下的性能与MMTEB基准相关性差，暴露了当前短文本基准的局限性；2) 位置偏见普遍存在且随文档长度加剧，多数模型显示首因偏见，某些模型显示近因偏见；3) 梯度显著性分析揭示了驱动这些位置偏好的不同内部注意力机制。

Conclusion: PosIR作为一个有价值的诊断框架，有助于促进开发位置鲁棒的检索系统，揭示了现有检索模型中普遍存在的位置偏见问题及其机制。

Abstract: While dense retrieval models have achieved remarkable success, rigorous evaluation of their sensitivity to the position of relevant information (i.e., position bias) remains largely unexplored. Existing benchmarks typically employ position-agnostic relevance labels, conflating the challenge of processing long contexts with the bias against specific evidence locations. To address this challenge, we introduce PosIR (Position-Aware Information Retrieval), a comprehensive benchmark designed to diagnose position bias in diverse retrieval scenarios. PosIR comprises 310 datasets spanning 10 languages and 31 domains, constructed through a rigorous pipeline that ties relevance to precise reference spans, enabling the strict disentanglement of document length from information position. Extensive experiments with 10 state-of-the-art embedding models reveal that: (1) Performance on PosIR in long-context settings correlates poorly with the MMTEB benchmark, exposing limitations in current short-text benchmarks; (2) Position bias is pervasive and intensifies with document length, with most models exhibiting primacy bias while certain models show unexpected recency bias; (3) Gradient-based saliency analysis further uncovers the distinct internal attention mechanisms driving these positional preferences. In summary, PosIR serves as a valuable diagnostic framework to foster the development of position-robust retrieval systems.

</details>


### [9] [GraphFusionSBR: Denoising Multi-Channel Graphs for Session-Based Recommendation](https://arxiv.org/abs/2601.08497)
*Jia-Xin He,Hung-Hsuan Chen*

Main category: cs.IR

TL;DR: 提出多通道推荐模型（知识图谱通道、会话超图通道、会话线图通道），通过自适应去噪、缓解物品主导问题、最大化互信息等机制提升会话推荐准确性。


<details>
  <summary>Details</summary>
Motivation: 现有会话推荐模型存在物品交互主导和噪声会话问题，需要从多源信息中捕捉用户隐式意图。

Method: 设计三通道模型：知识图谱通道（自适应去除冗余边）、会话超图通道、会话线图通道；通过知识图谱与超图表示协作缓解物品主导；生成会话内注意力去噪；最大化超图与线图通道间的互信息作为辅助任务。

Result: 实验证明该方法在电商和多媒体推荐等多种场景中提升了推荐准确性。

Conclusion: 提出的多通道模型能有效捕捉多源信息，通过去噪和缓解物品主导问题显著提升会话推荐性能。

Abstract: Session-based recommendation systems must capture implicit user intents from sessions. However, existing models suffer from issues such as item interaction dominance and noisy sessions. We propose a multi-channel recommendation model, including a knowledge graph channel, a session hypergraph channel, and a session line graph channel, to capture information from multiple sources. Our model adaptively removes redundant edges in the knowledge graph channel to reduce noise. Knowledge graph representations cooperate with hypergraph representations for prediction to alleviate item dominance. We also generate in-session attention for denoising. Finally, we maximize mutual information between the hypergraph and line graph channels as an auxiliary task. Experiments demonstrate that our method enhances the accuracy of various recommendations, including e-commerce and multimedia recommendations. We release the code on GitHub for reproducibility.\footnote{https://github.com/hohehohe0509/DSR-HK}

</details>


### [10] [VeriTaS: The First Dynamic Benchmark for Multimodal Automated Fact-Checking](https://arxiv.org/abs/2601.08611)
*Mark Rothermel,Marcus Kornmann,Marcus Rohrbach,Anna Rohrbach*

Main category: cs.IR

TL;DR: VeriTaS是首个动态多模态自动事实核查基准，包含24,000个真实世界声明，覆盖54种语言，通过自动化管道季度更新，旨在解决现有基准的数据泄露问题。


<details>
  <summary>Details</summary>
Motivation: 现有自动事实核查基准存在多方面限制：任务范围窄、模态单一、领域有限、语言多样性不足、真实性不够、虚假信息类型覆盖不全，且都是静态基准，容易因声明进入LLM预训练语料库而导致数据泄露，使得基准性能无法可靠反映实际核查能力。

Method: 开发了VeriTaS动态基准，包含24,000个来自108个专业事实核查组织的真实声明，覆盖54种语言和文本/视听内容。采用全自动七阶段管道：标准化声明表述、检索原始媒体、将异构专家裁决映射到新颖的标准化解耦评分方案（含文本理由）。管道每季度自动更新数据。

Result: 通过人工评估验证了自动化标注与人类判断高度一致。建立了首个防数据泄露的基准，支持在基础模型快速演进时代进行有意义的自动事实核查评估。代码和数据将公开。

Conclusion: VeriTaS是首个动态多模态自动事实核查基准，通过季度更新和标准化处理解决了现有静态基准的数据泄露问题，为快速发展的基础模型时代提供了可靠的事实核查评估工具。

Abstract: The growing scale of online misinformation urgently demands Automated Fact-Checking (AFC). Existing benchmarks for evaluating AFC systems, however, are largely limited in terms of task scope, modalities, domain, language diversity, realism, or coverage of misinformation types. Critically, they are static, thus subject to data leakage as their claims enter the pretraining corpora of LLMs. As a result, benchmark performance no longer reliably reflects the actual ability to verify claims. We introduce Verified Theses and Statements (VeriTaS), the first dynamic benchmark for multimodal AFC, designed to remain robust under ongoing large-scale pretraining of foundation models. VeriTaS currently comprises 24,000 real-world claims from 108 professional fact-checking organizations across 54 languages, covering textual and audiovisual content. Claims are added quarterly via a fully automated seven-stage pipeline that normalizes claim formulation, retrieves original media, and maps heterogeneous expert verdicts to a novel, standardized, and disentangled scoring scheme with textual justifications. Through human evaluation, we demonstrate that the automated annotations closely match human judgments. We commit to update VeriTaS in the future, establishing a leakage-resistant benchmark, supporting meaningful AFC evaluation in the era of rapidly evolving foundation models. We will make the code and data publicly available.

</details>


### [11] [RMBRec: Robust Multi-Behavior Recommendation towards Target Behaviors](https://arxiv.org/abs/2601.08705)
*Miaomiao Cai,Zhijie Zhang,Junfeng Fang,Zhiyong Cheng,Xiang Wang,Meng Wang*

Main category: cs.IR

TL;DR: RMBRec是一个鲁棒的多行为推荐框架，通过信息论原则处理辅助行为（点击、加购）与目标行为（购买）之间的不一致性，提高推荐准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 多行为推荐面临关键挑战：辅助行为（如点击、加购）通常存在噪声、弱相关或语义不对齐问题，导致偏好学习偏差和次优性能。现有方法缺乏处理这种行为不一致性的鲁棒机制。

Method: 提出RMBRec框架，基于信息论鲁棒性原则：1）表示鲁棒性模块（RRM）通过最大化用户辅助行为与目标行为表示之间的互信息来增强局部语义一致性；2）优化鲁棒性模块（ORM）通过最小化跨行为预测风险方差来强制全局稳定性，这是对不变风险最小化的高效近似。

Result: 在三个真实世界数据集上的实验表明，RMBRec不仅在准确性上优于最先进方法，而且在各种噪声扰动下保持显著稳定性。

Conclusion: RMBRec通过局部-全局协作，以理论一致的方式桥接了表示纯化和优化不变性，为多行为推荐中的行为不一致问题提供了鲁棒解决方案。

Abstract: Multi-behavior recommendation faces a critical challenge in practice: auxiliary behaviors (e.g., clicks, carts) are often noisy, weakly correlated, or semantically misaligned with the target behavior (e.g., purchase), which leads to biased preference learning and suboptimal performance. While existing methods attempt to fuse these heterogeneous signals, they inherently lack a principled mechanism to ensure robustness against such behavioral inconsistency.
  In this work, we propose Robust Multi-Behavior Recommendation towards Target Behaviors (RMBRec), a robust multi-behavior recommendation framework grounded in an information-theoretic robustness principle. We interpret robustness as a joint process of maximizing predictive information while minimizing its variance across heterogeneous behavioral environments. Under this perspective, the Representation Robustness Module (RRM) enhances local semantic consistency by maximizing the mutual information between users' auxiliary and target representations, whereas the Optimization Robustness Module (ORM) enforces global stability by minimizing the variance of predictive risks across behaviors, which is an efficient approximation to invariant risk minimization. This local-global collaboration bridges representation purification and optimization invariance in a theoretically coherent way. Extensive experiments on three real-world datasets demonstrate that RMBRec not only outperforms state-of-the-art methods in accuracy but also maintains remarkable stability under various noise perturbations. For reproducibility, our code is available at https://github.com/miaomiao-cai2/RMBRec/.

</details>


### [12] [FusID: Modality-Fused Semantic IDs for Generative Music Recommendation](https://arxiv.org/abs/2601.08764)
*Haven Kim,Yupeng Hou,Julian McAuley*

Main category: cs.IR

TL;DR: FusID是一个多模态融合的语义ID框架，通过联合编码跨模态信息解决现有独立模态标记方法的冗余和交互缺失问题，在音乐推荐中实现零ID冲突和更好的推荐效果。


<details>
  <summary>Details</summary>
Motivation: 现有生成推荐系统使用语义ID表示物品，但独立标记每个模态的方法存在两个关键限制：1) 跨模态冗余降低效率；2) 无法捕捉模态间交互限制物品表示能力。

Method: FusID包含三个关键组件：1) 多模态融合，通过联合编码跨模态信息学习统一表示；2) 表示学习，使频繁共现的物品嵌入更接近，同时保持区分性并防止特征冗余；3) 产品量化，将融合的连续嵌入转换为多个离散标记以缓解ID冲突。

Result: 在多模态下一首歌曲推荐基准测试中，FusID实现了零ID冲突（确保每个标记序列映射到唯一歌曲），缓解了码本利用不足问题，在MRR和Recall@k（k=1,5,10,20）指标上优于基线方法。

Conclusion: FusID通过多模态融合的语义ID框架有效解决了跨模态冗余和交互缺失问题，在保持ID唯一性的同时提升了推荐性能，为生成推荐系统提供了更优的物品表示方法。

Abstract: Generative recommendation systems have achieved significant advances by leveraging semantic IDs to represent items. However, existing approaches that tokenize each modality independently face two critical limitations: (1) redundancy across modalities that reduces efficiency, and (2) failure to capture inter-modal interactions that limits item representation. We introduce FusID, a modality-fused semantic ID framework that addresses these limitations through three key components: (i) multimodal fusion that learns unified representations by jointly encoding information across modalities, (ii) representation learning that brings frequently co-occurring item embeddings closer while maintaining distinctiveness and preventing feature redundancy, and (iii) product quantization that converts the fused continuous embeddings into multiple discrete tokens to mitigate ID conflict. Evaluated on a multimodal next-song recommendation (i.e., playlist continuation) benchmark, FusID achieves zero ID conflicts, ensuring that each token sequence maps to exactly one song, mitigates codebook underutilization, and outperforms baselines in terms of MRR and Recall@k (k = 1, 5, 10, 20).

</details>


### [13] [MemRec: Collaborative Memory-Augmented Agentic Recommender System](https://arxiv.org/abs/2601.08816)
*Weixin Chen,Yuhan Zhao,Jingyuan Huang,Zihe Ye,Clark Mingxuan Ju,Tong Zhao,Neil Shah,Li Chen,Yongfeng Zhang*

Main category: cs.IR

TL;DR: MemRec是一个推荐系统框架，通过架构解耦推理与记忆管理，利用专门的LM_Mem管理动态协作记忆图，为下游LLM_Rec提供高信号上下文，实现高效协作增强。


<details>
  <summary>Details</summary>
Motivation: 现有推荐代理依赖孤立记忆，忽视了关键的协作信号。需要解决两个挑战：1) 从庞大图上下文中提取信息而不增加推理代理的认知负担；2) 高效演化协作记忆而不产生过高计算成本。

Method: 提出MemRec框架，架构上解耦推理与记忆管理。引入专门的LM_Mem管理动态协作记忆图，通过高效检索和成本效益高的异步图传播管道，为下游LLM_Rec提供合成的高信号上下文。

Result: 在四个基准测试上的广泛实验表明，MemRec实现了最先进的性能。架构分析确认了其灵活性，建立了新的帕累托前沿，平衡了推理质量、成本和隐私，支持包括本地开源模型在内的多样化部署。

Conclusion: MemRec通过架构解耦有效解决了协作记忆管理的挑战，在保持高效计算的同时实现了卓越的推荐性能，为推荐系统在智能体时代的发展提供了新的解决方案。

Abstract: The evolution of recommender systems has shifted preference storage from rating matrices and dense embeddings to semantic memory in the agentic era. Yet existing agents rely on isolated memory, overlooking crucial collaborative signals. Bridging this gap is hindered by the dual challenges of distilling vast graph contexts without overwhelming reasoning agents with cognitive load, and evolving the collaborative memory efficiently without incurring prohibitive computational costs. To address this, we propose MemRec, a framework that architecturally decouples reasoning from memory management to enable efficient collaborative augmentation. MemRec introduces a dedicated, cost-effective LM_Mem to manage a dynamic collaborative memory graph, serving synthesized, high-signal context to a downstream LLM_Rec. The framework operates via a practical pipeline featuring efficient retrieval and cost-effective asynchronous graph propagation that evolves memory in the background. Extensive experiments on four benchmarks demonstrate that MemRec achieves state-of-the-art performance. Furthermore, architectural analysis confirms its flexibility, establishing a new Pareto frontier that balances reasoning quality, cost, and privacy through support for diverse deployments, including local open-source models. Code:https://github.com/rutgerswiselab/memrec and Homepage: https://memrec.weixinchen.com

</details>
