{"id": "2511.02052", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02052", "abs": "https://arxiv.org/abs/2511.02052", "authors": ["Karol Radziszewski", "Micha\u0142 Szpunar", "Piotr Ociepka", "Mateusz Buczy\u0144ski"], "title": "Solving cold start in news recommendations: a RippleNet-based system for large scale media outlet", "comment": null, "summary": "We present a scalable recommender system implementation based on RippleNet,\ntailored for the media domain with a production deployment in Onet.pl, one of\nPoland's largest online media platforms. Our solution addresses the cold-start\nproblem for newly published content by integrating content-based item\nembeddings into the knowledge propagation mechanism of RippleNet, enabling\neffective scoring of previously unseen items. The system architecture leverages\nAmazon SageMaker for distributed training and inference, and Apache Airflow for\norchestrating data pipelines and model retraining workflows. To ensure\nhigh-quality training data, we constructed a comprehensive golden dataset\nconsisting of user and item features and a separate interaction table, all\nenabling flexible extensions and integration of new signals.", "AI": {"tldr": "\u57fa\u4e8eRippleNet\u7684\u53ef\u6269\u5c55\u63a8\u8350\u7cfb\u7edf\u5b9e\u73b0\uff0c\u9488\u5bf9\u5a92\u4f53\u9886\u57df\uff0c\u5728\u6ce2\u5170\u5927\u578b\u5728\u7ebf\u5a92\u4f53\u5e73\u53f0Onet.pl\u4e2d\u90e8\u7f72\u3002\u901a\u8fc7\u5c06\u57fa\u4e8e\u5185\u5bb9\u7684\u7269\u54c1\u5d4c\u5165\u96c6\u6210\u5230RippleNet\u7684\u77e5\u8bc6\u4f20\u64ad\u673a\u5236\u4e2d\uff0c\u89e3\u51b3\u65b0\u53d1\u5e03\u5185\u5bb9\u7684\u51b7\u542f\u52a8\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u5a92\u4f53\u63a8\u8350\u7cfb\u7edf\u4e2d\u65b0\u53d1\u5e03\u5185\u5bb9\u7684\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u4e3a\u5927\u578b\u5728\u7ebf\u5a92\u4f53\u5e73\u53f0\u63d0\u4f9b\u6709\u6548\u7684\u63a8\u8350\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u96c6\u6210\u57fa\u4e8e\u5185\u5bb9\u7684\u7269\u54c1\u5d4c\u5165\u5230RippleNet\u7684\u77e5\u8bc6\u4f20\u64ad\u673a\u5236\u4e2d\uff0c\u5229\u7528Amazon SageMaker\u8fdb\u884c\u5206\u5e03\u5f0f\u8bad\u7ec3\u548c\u63a8\u7406\uff0c\u4f7f\u7528Apache Airflow\u7f16\u6392\u6570\u636e\u7ba1\u9053\u548c\u6a21\u578b\u91cd\u8bad\u7ec3\u5de5\u4f5c\u6d41\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b\u7528\u6237\u548c\u7269\u54c1\u7279\u5f81\u4ee5\u53ca\u4ea4\u4e92\u8868\u7684\u7efc\u5408\u9ec4\u91d1\u6570\u636e\u96c6\uff0c\u5b9e\u73b0\u4e86\u5bf9\u65b0\u7269\u54c1\u7684\u6709\u6548\u8bc4\u5206\uff0c\u7cfb\u7edf\u5df2\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u90e8\u7f72\u3002", "conclusion": "\u63d0\u51fa\u7684\u89e3\u51b3\u65b9\u6848\u6210\u529f\u89e3\u51b3\u4e86\u5a92\u4f53\u63a8\u8350\u4e2d\u7684\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u901a\u8fc7\u96c6\u6210\u5185\u5bb9\u5d4c\u5165\u548c\u77e5\u8bc6\u4f20\u64ad\u673a\u5236\uff0c\u4e3a\u5927\u89c4\u6a21\u5a92\u4f53\u5e73\u53f0\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u63a8\u8350\u80fd\u529b\u3002"}}
{"id": "2511.02113", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.02113", "abs": "https://arxiv.org/abs/2511.02113", "authors": ["Hai-Dang Kieu", "Min Xu", "Thanh Trung Huynh", "Dung D. Le"], "title": "Enhancing Multimodal Recommendations with Vision-Language Models and Information-Aware Fusion", "comment": null, "summary": "Recent advances in multimodal recommendation (MMR) have shown that\nincorporating rich content sources such as images and text can lead to\nsignificant gains representation quality. However, existing methods often rely\non coarse visual features and uncontrolled fusion, leading to redundant or\nmisaligned representations. As a result, visual encoders often fail to capture\nsalient, item-relevant semantics, limiting their contribution in multimodal\nfusion. From an information-theoretic perspective, effective fusion should\nbalance the unique, shared, and redundant information across modalities,\npreserving complementary cues while avoiding correlation bias. This paper\npresents VLIF, a vision-language and information-theoretic fusion framework\nthat enhances multimodal recommendation through two key components. (i) A\nVLM-based visual enrichment module generates fine-grained, title-guided\ndescriptions to transform product images into semantically aligned\nrepresentations. (ii) An information-aware fusion module, inspired by Partial\nInformation Decomposition (PID), disentangles redundant and synergistic signals\nacross modalities for controlled integration. Experiments on three Amazon\ndatasets demonstrate that VLIF consistently outperforms recent multimodal\nbaselines and substantially strengthens the contribution of visual features.", "AI": {"tldr": "VLIF\u662f\u4e00\u4e2a\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u548c\u4fe1\u606f\u8bba\u7684\u591a\u6a21\u6001\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u89c6\u89c9\u589e\u5f3a\u6a21\u5757\u751f\u6210\u7ec6\u7c92\u5ea6\u56fe\u50cf\u63cf\u8ff0\uff0c\u5e76\u57fa\u4e8e\u90e8\u5206\u4fe1\u606f\u5206\u89e3\u8fdb\u884c\u53ef\u63a7\u7684\u591a\u6a21\u6001\u878d\u5408\uff0c\u663e\u8457\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u63a8\u8350\u65b9\u6cd5\u4f9d\u8d56\u7c97\u7cd9\u7684\u89c6\u89c9\u7279\u5f81\u548c\u4e0d\u53d7\u63a7\u7684\u878d\u5408\uff0c\u5bfc\u81f4\u5197\u4f59\u6216\u4e0d\u5bf9\u9f50\u7684\u8868\u5f81\uff0c\u89c6\u89c9\u7f16\u7801\u5668\u96be\u4ee5\u6355\u6349\u4e0e\u7269\u54c1\u76f8\u5173\u7684\u5173\u952e\u8bed\u4e49\uff0c\u9650\u5236\u4e86\u591a\u6a21\u6001\u878d\u5408\u7684\u6548\u679c\u3002", "method": "\u63d0\u51faVLIF\u6846\u67b6\uff1a1\uff09\u57fa\u4e8eVLM\u7684\u89c6\u89c9\u589e\u5f3a\u6a21\u5757\uff0c\u751f\u6210\u7ec6\u7c92\u5ea6\u7684\u6807\u9898\u5f15\u5bfc\u63cf\u8ff0\uff0c\u5c06\u4ea7\u54c1\u56fe\u50cf\u8f6c\u6362\u4e3a\u8bed\u4e49\u5bf9\u9f50\u7684\u8868\u5f81\uff1b2\uff09\u4fe1\u606f\u611f\u77e5\u878d\u5408\u6a21\u5757\uff0c\u57fa\u4e8e\u90e8\u5206\u4fe1\u606f\u5206\u89e3\u7406\u8bba\uff0c\u89e3\u8026\u6a21\u6001\u95f4\u7684\u5197\u4f59\u548c\u534f\u540c\u4fe1\u53f7\u8fdb\u884c\u53ef\u63a7\u96c6\u6210\u3002", "result": "\u5728\u4e09\u4e2aAmazon\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cVLIF\u6301\u7eed\u4f18\u4e8e\u6700\u65b0\u7684\u591a\u6a21\u6001\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u663e\u8457\u589e\u5f3a\u4e86\u89c6\u89c9\u7279\u5f81\u7684\u8d21\u732e\u3002", "conclusion": "VLIF\u901a\u8fc7\u7ec6\u7c92\u5ea6\u89c6\u89c9\u8868\u5f81\u548c\u4fe1\u606f\u611f\u77e5\u878d\u5408\uff0c\u6709\u6548\u63d0\u5347\u4e86\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u4fe1\u606f\u8bba\u6307\u5bfc\u7684\u591a\u6a21\u6001\u878d\u5408\u7b56\u7565\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.02181", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.02181", "abs": "https://arxiv.org/abs/2511.02181", "authors": ["Yuhan Wang", "Qing Xie", "Zhifeng Bao", "Mengzi Tang", "Lin Li", "Yongjian Liu"], "title": "KGBridge: Knowledge-Guided Prompt Learning for Non-overlapping Cross-Domain Recommendation", "comment": "13 pages, 4 figures", "summary": "Knowledge Graphs (KGs), as structured knowledge bases that organize\nrelational information across diverse domains, provide a unified semantic\nfoundation for cross-domain recommendation (CDR). By integrating symbolic\nknowledge with user-item interactions, KGs enrich semantic representations,\nsupport reasoning, and enhance model interpretability. Despite this potential,\nexisting KG-based methods still face major challenges in CDR, particularly\nunder non-overlapping user scenarios. These challenges arise from: (C1)\nsensitivity to KG sparsity and popularity bias, (C2) dependence on overlapping\nusers for domain alignment and (C3) lack of explicit disentanglement between\ntransferable and domain-specific knowledge, which limit effective and stable\nknowledge transfer. To this end, we propose KGBridge, a knowledge-guided prompt\nlearning framework for cross-domain sequential recommendation under\nnon-overlapping user scenarios. KGBridge comprises two core components: a\nKG-enhanced Prompt Encoder, which models relation-level semantics as soft\nprompts to provide structured and dynamic priors for user sequence modeling\n(addressing C1), and a Two-stage Training Paradigm, which combines cross-domain\npretraining and privacy-preserving fine-tuning to enable knowledge transfer\nwithout user overlap (addressing C2). By combining relation-aware semantic\ncontrol with correspondence-driven disentanglement, KGBridge explicitly\nseparates and balances domain-shared and domain-specific semantics, thereby\nmaintaining complementarity and stabilizing adaptation during fine-tuning\n(addressing C3). Extensive experiments on benchmark datasets demonstrate that\nKGBridge consistently outperforms state-of-the-art baselines and remains robust\nunder varying KG sparsity, highlighting its effectiveness in mitigating\nstructural imbalance and semantic entanglement in KG-enhanced cross-domain\nrecommendation.", "AI": {"tldr": "KGBridge\u662f\u4e00\u4e2a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u63d0\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u975e\u91cd\u53e0\u7528\u6237\u573a\u666f\u4e0b\u7684\u8de8\u57df\u5e8f\u5217\u63a8\u8350\u95ee\u9898\uff0c\u901a\u8fc7\u5173\u7cfb\u7ea7\u8bed\u4e49\u5efa\u6a21\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\u5b9e\u73b0\u6709\u6548\u7684\u77e5\u8bc6\u8fc1\u79fb\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u8de8\u57df\u63a8\u8350\u65b9\u6cd5\u5728\u975e\u91cd\u53e0\u7528\u6237\u573a\u666f\u4e0b\u9762\u4e34\u4e09\u5927\u6311\u6218\uff1a\u5bf9\u77e5\u8bc6\u56fe\u8c31\u7a00\u758f\u6027\u548c\u6d41\u884c\u5ea6\u504f\u5dee\u654f\u611f\u3001\u4f9d\u8d56\u91cd\u53e0\u7528\u6237\u8fdb\u884c\u57df\u5bf9\u9f50\u3001\u7f3a\u4e4f\u53ef\u8fc1\u79fb\u77e5\u8bc6\u548c\u57df\u7279\u5b9a\u77e5\u8bc6\u7684\u663e\u5f0f\u89e3\u8026\u3002", "method": "\u63d0\u51faKGBridge\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1aKG\u589e\u5f3a\u7684\u63d0\u793a\u7f16\u7801\u5668\uff08\u5c06\u5173\u7cfb\u7ea7\u8bed\u4e49\u5efa\u6a21\u4e3a\u8f6f\u63d0\u793a\uff09\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\uff08\u8de8\u57df\u9884\u8bad\u7ec3+\u9690\u79c1\u4fdd\u62a4\u5fae\u8c03\uff09\uff0c\u901a\u8fc7\u5173\u7cfb\u611f\u77e5\u8bed\u4e49\u63a7\u5236\u548c\u5bf9\u5e94\u9a71\u52a8\u89e3\u8026\u6765\u5206\u79bb\u57df\u5171\u4eab\u548c\u57df\u7279\u5b9a\u8bed\u4e49\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cKGBridge\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5728\u4e0d\u540c\u77e5\u8bc6\u56fe\u8c31\u7a00\u758f\u5ea6\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u7ed3\u6784\u4e0d\u5e73\u8861\u548c\u8bed\u4e49\u7ea0\u7f20\u95ee\u9898\u3002", "conclusion": "KGBridge\u901a\u8fc7\u7ed3\u5408\u7ed3\u6784\u5316\u77e5\u8bc6\u5f15\u5bfc\u548c\u63d0\u793a\u5b66\u4e60\uff0c\u5728\u975e\u91cd\u53e0\u7528\u6237\u573a\u666f\u4e0b\u5b9e\u73b0\u4e86\u7a33\u5b9a\u6709\u6548\u7684\u8de8\u57df\u77e5\u8bc6\u8fc1\u79fb\uff0c\u4e3a\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u7684\u8de8\u57df\u63a8\u8350\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2511.02571", "categories": ["cs.IR", "math.PR", "Primary 60E05, 60C05, Secondary 62R07, 68T05"], "pdf": "https://arxiv.org/pdf/2511.02571", "abs": "https://arxiv.org/abs/2511.02571", "authors": ["Tetiana Manzhos", "Tetiana Ianevych", "Olga Melnyk"], "title": "Average Precision at Cutoff k under Random Rankings: Expectation and Variance", "comment": "17 pages, 2 tables, 2 figures", "summary": "Recommender systems and information retrieval platforms rely on ranking\nalgorithms to present the most relevant items to users, thereby improving\nengagement and satisfaction. Assessing the quality of these rankings requires\nreliable evaluation metrics. Among them, Mean Average Precision at cutoff k\n(MAP@k) is widely used, as it accounts for both the relevance of items and\ntheir positions in the list.\n  In this paper, the expectation and variance of Average Precision at k (AP@k)\nare derived since they can be used as biselines for MAP@k. Here, we covered two\nwidely used evaluation models: offline and online. The expectation establishes\nthe baseline, indicating the level of MAP@k that can be achieved by pure\nchance. The variance complements this baseline by quantifying the extent of\nrandom fluctuations, enabling a more reliable interpretation of observed\nscores.", "AI": {"tldr": "\u672c\u6587\u63a8\u5bfc\u4e86AP@k\u7684\u671f\u671b\u548c\u65b9\u5dee\uff0c\u4e3aMAP@k\u5efa\u7acb\u4e86\u968f\u673a\u57fa\u51c6\uff0c\u6709\u52a9\u4e8e\u66f4\u53ef\u9760\u5730\u8bc4\u4f30\u63a8\u8350\u7cfb\u7edf\u548c\u4fe1\u606f\u68c0\u7d22\u5e73\u53f0\u7684\u6392\u540d\u7b97\u6cd5\u8d28\u91cf\u3002", "motivation": "\u63a8\u8350\u7cfb\u7edf\u548c\u4fe1\u606f\u68c0\u7d22\u5e73\u53f0\u4f9d\u8d56\u6392\u540d\u7b97\u6cd5\u5411\u7528\u6237\u5c55\u793a\u6700\u76f8\u5173\u7684\u5185\u5bb9\uff0c\u9700\u8981\u53ef\u9760\u7684\u8bc4\u4f30\u6307\u6807\u3002MAP@k\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u9700\u8981\u5efa\u7acb\u968f\u673a\u57fa\u51c6\u6765\u66f4\u597d\u5730\u89e3\u91ca\u89c2\u5bdf\u5230\u7684\u8bc4\u5206\u3002", "method": "\u63a8\u5bfc\u4e86AP@k\u7684\u671f\u671b\u548c\u65b9\u5dee\uff0c\u8986\u76d6\u4e86\u79bb\u7ebf\u548c\u5728\u7ebf\u4e24\u79cd\u5e7f\u6cdb\u4f7f\u7528\u7684\u8bc4\u4f30\u6a21\u578b\u3002\u671f\u671b\u5efa\u7acb\u4e86\u968f\u673a\u57fa\u51c6\uff0c\u65b9\u5dee\u91cf\u5316\u4e86\u968f\u673a\u6ce2\u52a8\u7a0b\u5ea6\u3002", "result": "\u5f97\u5230\u4e86AP@k\u7684\u671f\u671b\u548c\u65b9\u5dee\u8868\u8fbe\u5f0f\uff0c\u8fd9\u4e9b\u53ef\u4ee5\u4f5c\u4e3aMAP@k\u7684\u57fa\u51c6\uff0c\u5e2e\u52a9\u533a\u5206\u7b97\u6cd5\u6027\u80fd\u4e0e\u968f\u673a\u6ce2\u52a8\u3002", "conclusion": "AP@k\u7684\u671f\u671b\u548c\u65b9\u5dee\u4e3aMAP@k\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u7edf\u8ba1\u57fa\u51c6\uff0c\u4f7f\u8bc4\u4f30\u7ed3\u679c\u66f4\u52a0\u53ef\u9760\u548c\u53ef\u89e3\u91ca\u3002"}}
