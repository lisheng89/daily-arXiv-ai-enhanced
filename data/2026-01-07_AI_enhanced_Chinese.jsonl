{"id": "2601.02361", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.02361", "abs": "https://arxiv.org/abs/2601.02361", "authors": ["Ziheng Ni", "Congcong Liu", "Cai Shang", "Yiming Sun", "Junjie Li", "Zhiwei Fang", "Guangpeng Chen", "Jian Li", "Zehua Zhang", "Changping Peng", "Zhangang Lin", "Ching Law", "Jingping Shao"], "title": "GCRank: A Generative Contextual Comprehension Paradigm for Takeout Ranking Model", "comment": null, "summary": "The ranking stage serves as the central optimization and allocation hub in advertising systems, governing economic value distribution through eCPM and orchestrating the user-centric blending of organic and advertising content. Prevailing ranking models often rely on fragmented modules and hand-crafted features, limiting their ability to interpret complex user intent. This challenge is further amplified in location-based services such as food delivery, where user decisions are shaped by dynamic spatial, temporal, and individual contexts. To address these limitations, we propose a novel generative framework that reframes ranking as a context comprehension task, modeling heterogeneous signals in a unified architecture. Our architecture consists of two core components: the Generative Contextual Encoder (GCE) and the Generative Contextual Fusion (GCF). The GCE comprises three specialized modules: a Personalized Context Enhancer (PCE) for user-specific modeling, a Collective Context Enhancer (CCE) for group-level patterns, and a Dynamic Context Enhancer (DCE) for real-time situational adaptation. The GCF module then seamlessly integrates these contextual representations through low-rank adaptation. Extensive experiments confirm that our method achieves significant gains in critical business metrics, including click-through rate and platform revenue. We have successfully deployed our method on a large-scale food delivery advertising platform, demonstrating its substantial practical impact. This work pioneers a new perspective on generative recommendation and highlights its practical potential in industrial advertising systems.", "AI": {"tldr": "\u63d0\u51fa\u751f\u6210\u5f0f\u4e0a\u4e0b\u6587\u7406\u89e3\u6846\u67b6\uff0c\u5c06\u5e7f\u544a\u6392\u5e8f\u91cd\u6784\u4e3a\u4e0a\u4e0b\u6587\u7406\u89e3\u4efb\u52a1\uff0c\u901a\u8fc7\u7edf\u4e00\u67b6\u6784\u5efa\u6a21\u5f02\u6784\u4fe1\u53f7\uff0c\u5728\u98df\u54c1\u914d\u9001\u5e7f\u544a\u5e73\u53f0\u4e2d\u663e\u8457\u63d0\u5347\u70b9\u51fb\u7387\u548c\u5e73\u53f0\u6536\u5165\u3002", "motivation": "\u73b0\u6709\u5e7f\u544a\u6392\u5e8f\u6a21\u578b\u4f9d\u8d56\u788e\u7247\u5316\u6a21\u5757\u548c\u624b\u5de5\u7279\u5f81\uff0c\u96be\u4ee5\u7406\u89e3\u590d\u6742\u7528\u6237\u610f\u56fe\uff0c\u7279\u522b\u662f\u5728\u98df\u54c1\u914d\u9001\u7b49\u4f4d\u7f6e\u670d\u52a1\u4e2d\uff0c\u7528\u6237\u51b3\u7b56\u53d7\u52a8\u6001\u7a7a\u95f4\u3001\u65f6\u95f4\u548c\u4e2a\u4f53\u4e0a\u4e0b\u6587\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u751f\u6210\u5f0f\u6846\u67b6\uff0c\u5305\u542b\u751f\u6210\u5f0f\u4e0a\u4e0b\u6587\u7f16\u7801\u5668(GCE)\u548c\u751f\u6210\u5f0f\u4e0a\u4e0b\u6587\u878d\u5408(GCF)\u3002GCE\u6709\u4e09\u4e2a\u4e13\u95e8\u6a21\u5757\uff1a\u4e2a\u6027\u5316\u4e0a\u4e0b\u6587\u589e\u5f3a\u5668(PCE)\u7528\u4e8e\u7528\u6237\u7279\u5b9a\u5efa\u6a21\uff0c\u96c6\u4f53\u4e0a\u4e0b\u6587\u589e\u5f3a\u5668(CCE)\u7528\u4e8e\u7fa4\u4f53\u7ea7\u6a21\u5f0f\uff0c\u52a8\u6001\u4e0a\u4e0b\u6587\u589e\u5f3a\u5668(DCE)\u7528\u4e8e\u5b9e\u65f6\u60c5\u5883\u9002\u5e94\u3002GCF\u901a\u8fc7\u4f4e\u79e9\u9002\u5e94\u65e0\u7f1d\u6574\u5408\u8fd9\u4e9b\u4e0a\u4e0b\u6587\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\u8be5\u65b9\u6cd5\u5728\u5173\u952e\u4e1a\u52a1\u6307\u6807\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u5305\u62ec\u70b9\u51fb\u7387\u548c\u5e73\u53f0\u6536\u5165\u3002\u5df2\u6210\u529f\u90e8\u7f72\u5728\u5927\u578b\u98df\u54c1\u914d\u9001\u5e7f\u544a\u5e73\u53f0\uff0c\u5c55\u793a\u4e86\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5f00\u521b\u4e86\u751f\u6210\u5f0f\u63a8\u8350\u7684\u65b0\u89c6\u89d2\uff0c\u7a81\u51fa\u4e86\u5176\u5728\u5de5\u4e1a\u5e7f\u544a\u7cfb\u7edf\u4e2d\u7684\u5b9e\u9645\u6f5c\u529b\uff0c\u4e3a\u590d\u6742\u4e0a\u4e0b\u6587\u73af\u5883\u4e0b\u7684\u5e7f\u544a\u6392\u5e8f\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.02362", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02362", "abs": "https://arxiv.org/abs/2601.02362", "authors": ["Itzhak Ziv", "Moshe Unger", "Hilah Geva"], "title": "The Impact of LLM-Generated Reviews on Recommender Systems: Textual Shifts, Performance Effects, and Strategic Platform Control", "comment": null, "summary": "The rise of generative AI technologies is reshaping content-based recommender systems (RSes), which increasingly encounter AI-generated content alongside human-authored content. This study examines how the introduction of AI-generated reviews influences RS performance and business outcomes. We analyze two distinct pathways through which AI content can enter RSes: user-centric, in which individuals use AI tools to refine their reviews, and platform-centric, in which platforms generate synthetic reviews directly from structured metadata. Using a large-scale dataset of hotel reviews from TripAdvisor, we generate synthetic reviews using LLMs and evaluate their impact across the training and deployment phases of RSes. We find that AI-generated reviews differ systematically from human-authored reviews across multiple textual dimensions. Although both user- and platform-centric AI reviews enhance RS performance relative to models without textual data, models trained on human reviews consistently achieve superior performance, underscoring the quality of authentic human data. Human-trained models generalize robustly to AI content, whereas AI-trained models underperform on both content types. Furthermore, tone-based framing strategies (encouraging, constructive, or critical) substantially enhance platform-generated review effectiveness. Our findings highlight the strategic importance of platform control in governing the generation and integration of AI-generated reviews, ensuring that synthetic content complements recommendation robustness and sustainable business value.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8AI\u751f\u6210\u8bc4\u8bba\u5bf9\u63a8\u8350\u7cfb\u7edf\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4eba\u7c7b\u8bc4\u8bba\u8d28\u91cf\u4f18\u4e8eAI\u8bc4\u8bba\uff0c\u5e73\u53f0\u63a7\u5236AI\u5185\u5bb9\u751f\u6210\u7b56\u7565\u5bf9\u63a8\u8350\u6548\u679c\u81f3\u5173\u91cd\u8981", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u6280\u672f\u7684\u53d1\u5c55\uff0c\u63a8\u8350\u7cfb\u7edf\u9762\u4e34AI\u751f\u6210\u5185\u5bb9\u4e0e\u4eba\u7c7b\u521b\u4f5c\u5185\u5bb9\u5e76\u5b58\u7684\u65b0\u73af\u5883\uff0c\u9700\u8981\u7814\u7a76AI\u5185\u5bb9\u5982\u4f55\u5f71\u54cd\u63a8\u8350\u7cfb\u7edf\u6027\u80fd\u548c\u5546\u4e1a\u7ed3\u679c", "method": "\u4f7f\u7528TripAdvisor\u9152\u5e97\u8bc4\u8bba\u6570\u636e\u96c6\uff0c\u901a\u8fc7LLM\u751f\u6210\u5408\u6210\u8bc4\u8bba\uff0c\u5206\u6790\u7528\u6237\u4e2d\u5fc3\uff08\u7528\u6237\u4f7f\u7528AI\u5de5\u5177\u4f18\u5316\u8bc4\u8bba\uff09\u548c\u5e73\u53f0\u4e2d\u5fc3\uff08\u5e73\u53f0\u4ece\u7ed3\u6784\u5316\u5143\u6570\u636e\u751f\u6210\u8bc4\u8bba\uff09\u4e24\u79cdAI\u5185\u5bb9\u5f15\u5165\u9014\u5f84\uff0c\u8bc4\u4f30\u5bf9\u63a8\u8350\u7cfb\u7edf\u8bad\u7ec3\u548c\u90e8\u7f72\u9636\u6bb5\u7684\u5f71\u54cd", "result": "AI\u751f\u6210\u8bc4\u8bba\u5728\u591a\u4e2a\u6587\u672c\u7ef4\u5ea6\u4e0a\u4e0e\u4eba\u7c7b\u8bc4\u8bba\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u5f02\uff1b\u4eba\u7c7b\u8bc4\u8bba\u8bad\u7ec3\u7684\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff1b\u4eba\u7c7b\u6a21\u578b\u80fd\u826f\u597d\u6cdb\u5316\u5230AI\u5185\u5bb9\uff0c\u800cAI\u6a21\u578b\u5bf9\u4e24\u79cd\u5185\u5bb9\u7c7b\u578b\u90fd\u8868\u73b0\u4e0d\u4f73\uff1b\u57fa\u4e8e\u8bed\u8c03\u7684\u6846\u67b6\u7b56\u7565\uff08\u9f13\u52b1\u6027\u3001\u5efa\u8bbe\u6027\u6216\u6279\u5224\u6027\uff09\u80fd\u663e\u8457\u63d0\u5347\u5e73\u53f0\u751f\u6210\u8bc4\u8bba\u7684\u6548\u679c", "conclusion": "\u5e73\u53f0\u5728\u63a7\u5236AI\u751f\u6210\u8bc4\u8bba\u7684\u751f\u6210\u548c\u6574\u5408\u65b9\u9762\u5177\u6709\u6218\u7565\u91cd\u8981\u6027\uff0c\u9700\u8981\u786e\u4fdd\u5408\u6210\u5185\u5bb9\u80fd\u591f\u8865\u5145\u63a8\u8350\u7cfb\u7edf\u7684\u7a33\u5065\u6027\u548c\u53ef\u6301\u7eed\u5546\u4e1a\u4ef7\u503c\uff0c\u4eba\u7c7b\u771f\u5b9e\u6570\u636e\u8d28\u91cf\u4ecd\u4e0d\u53ef\u66ff\u4ee3"}}
{"id": "2601.02364", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02364", "abs": "https://arxiv.org/abs/2601.02364", "authors": ["Chung Park", "Taesan Kim", "Hyeongjun Yun", "Dongjoon Hong", "Junui Hong", "Kijung Park", "MinCheol Cho", "Mira Myong", "Jihoon Oh", "Min sung Choi"], "title": "Towards Trustworthy LLM-Based Recommendation via Rationale Integration", "comment": "Accepted at RS4SD'25 (CIKM'25 Workshop)", "summary": "Traditional recommender systems (RS) have been primarily optimized for accuracy and short-term engagement, often overlooking transparency and trustworthiness. Recently, platforms such as Amazon and Instagram have begun providing recommendation rationales to users, acknowledging their critical role in fostering trust and enhancing engagement; however, most existing systems still treat them as post-hoc artifacts. We propose an LLM-based recommender (LLM-Rec) that not only predicts items but also generates logically grounded rationales. Our approach leverages a self-annotated rationale dataset and instruction tuning in a rationale-first format, where the model generates an explanation before outputting the recommended item. By adopting this strategy and representing rationales in a chain-of-thought (CoT) style, LLM-Rec strengthens both interpretability and recommendation performance. Experiments on the Fashion and Scientific domains of the Amazon Review dataset demonstrate significant improvements over well-established baselines. To encourage reproducibility and future research, we publicly release a rationale-augmented recommendation dataset containing user histories, rationales, and recommended items.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eLLM\u7684\u63a8\u8350\u7cfb\u7edfLLM-Rec\uff0c\u901a\u8fc7\u751f\u6210\u903b\u8f91\u5408\u7406\u7684\u63a8\u8350\u7406\u7531\u6765\u63d0\u5347\u900f\u660e\u5ea6\u548c\u63a8\u8350\u6027\u80fd\uff0c\u91c7\u7528\u7406\u7531\u4f18\u5148\u7684\u6307\u4ee4\u8c03\u4f18\u7b56\u7565", "motivation": "\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\u8fc7\u5ea6\u5173\u6ce8\u51c6\u786e\u6027\u548c\u77ed\u671f\u53c2\u4e0e\u5ea6\uff0c\u5ffd\u89c6\u4e86\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6\u3002\u867d\u7136\u4e9a\u9a6c\u900a\u3001Instagram\u7b49\u5e73\u53f0\u5f00\u59cb\u63d0\u4f9b\u63a8\u8350\u7406\u7531\uff0c\u4f46\u591a\u6570\u7cfb\u7edf\u4ecd\u5c06\u5176\u89c6\u4e3a\u4e8b\u540e\u4ea7\u7269\uff0c\u7f3a\u4e4f\u4e0e\u63a8\u8350\u8fc7\u7a0b\u7684\u6df1\u5ea6\u6574\u5408", "method": "\u63d0\u51faLLM-Rec\u63a8\u8350\u7cfb\u7edf\uff0c\u5229\u7528\u81ea\u6807\u6ce8\u7406\u7531\u6570\u636e\u96c6\u548c\u6307\u4ee4\u8c03\u4f18\uff0c\u91c7\u7528\u7406\u7531\u4f18\u5148\u683c\u5f0f\uff08\u5148\u751f\u6210\u89e3\u91ca\u518d\u8f93\u51fa\u63a8\u8350\u9879\uff09\uff0c\u5e76\u4ee5\u601d\u7ef4\u94fe\u98ce\u683c\u8868\u793a\u7406\u7531\uff0c\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u548c\u63a8\u8350\u6027\u80fd", "result": "\u5728Amazon Review\u6570\u636e\u96c6\u7684\u65f6\u5c1a\u548c\u79d1\u5b66\u9886\u57df\u5b9e\u9a8c\u4e2d\uff0c\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u5e76\u516c\u5f00\u53d1\u5e03\u4e86\u5305\u542b\u7528\u6237\u5386\u53f2\u3001\u7406\u7531\u548c\u63a8\u8350\u9879\u7684\u6570\u636e\u96c6", "conclusion": "LLM-Rec\u901a\u8fc7\u751f\u6210\u903b\u8f91\u5408\u7406\u7684\u63a8\u8350\u7406\u7531\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\uff0c\u8fd8\u589e\u5f3a\u4e86\u63a8\u8350\u6027\u80fd\uff0c\u4e3a\u53ef\u89e3\u91ca\u63a8\u8350\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411"}}
{"id": "2601.02365", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.02365", "abs": "https://arxiv.org/abs/2601.02365", "authors": ["Tushar Vatsa", "Vibha Belavadi", "Priya Shanmugasundaram", "Suhas Suresha", "Dewang Sultania"], "title": "FUSE : Failure-aware Usage of Subagent Evidence for MultiModal Search and Recommendation", "comment": "ICDM MMSR 2025: Workshop on Multimodal Search and Recommendations", "summary": "Multimodal creative assistants decompose user goals and route tasks to subagents for layout, styling, retrieval, and generation. Retrieval quality is pivotal, yet failures can arise at several stages: understanding user intent, choosing content types, finding candidates (recall), or ranking results. Meanwhile, sending and processing images is costly, making naive multimodal approaches impractical. We present FUSE: Failure-aware Usage of Subagent Evidence for MultiModal Search and Recommendation. FUSE replaces most raw-image prompting with a compact Grounded Design Representation (GDR): a selection aware JSON of canvas elements (image, text, shape, icon, video, logo), structure, styles, salient colors, and user selection provided by the Planner team. FUSE implements seven context budgeting strategies: comprehensive baseline prompting, context compression, chain-of-thought reasoning, mini-shot optimization, retrieval-augmented context, two-stage processing, and zero-shot minimalism. Finally, a pipeline attribution layer monitors system performance by converting subagent signals into simple checks: intent alignment, content-type/routing sanity, recall health (e.g., zero-hit and top-match strength), and ranking displacement analysis. We evaluate the seven context budgeting variants across 788 evaluation queries from diverse users and design templates (refer Figure 3). Our systematic evaluation reveals that Context Compression achieves optimal performance across all pipeline stages, with 93.3% intent accuracy, 86.8% routing success(with fallbacks), 99.4% recall, and 88.5% NDCG@5. This approach demonstrates that strategic context summarization outperforms both comprehensive and minimal contextualization strategies.", "AI": {"tldr": "FUSE\u63d0\u51fa\u4e86\u4e00\u79cd\u5931\u8d25\u611f\u77e5\u7684\u591a\u6a21\u6001\u641c\u7d22\u63a8\u8350\u7cfb\u7edf\uff0c\u901a\u8fc7\u7d27\u51d1\u7684GDR\u8868\u793a\u66ff\u4ee3\u539f\u59cb\u56fe\u50cf\uff0c\u91c7\u7528\u4e03\u79cd\u4e0a\u4e0b\u6587\u9884\u7b97\u7b56\u7565\uff0c\u5176\u4e2d\u4e0a\u4e0b\u6587\u538b\u7f29\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u591a\u6a21\u6001\u521b\u610f\u52a9\u624b\u4e2d\u68c0\u7d22\u8d28\u91cf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5b58\u5728\u7528\u6237\u610f\u56fe\u7406\u89e3\u3001\u5185\u5bb9\u7c7b\u578b\u9009\u62e9\u3001\u5019\u9009\u67e5\u627e\u548c\u7ed3\u679c\u6392\u5e8f\u7b49\u591a\u4e2a\u5931\u8d25\u70b9\uff0c\u540c\u65f6\u539f\u59cb\u56fe\u50cf\u5904\u7406\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "FUSE\u4f7f\u7528\u7d27\u51d1\u7684GDR\uff08\u57fa\u4e8e\u753b\u5e03\u5143\u7d20\u7684JSON\u8868\u793a\uff09\u66ff\u4ee3\u539f\u59cb\u56fe\u50cf\uff0c\u5b9e\u73b0\u4e03\u79cd\u4e0a\u4e0b\u6587\u9884\u7b97\u7b56\u7565\uff0c\u5e76\u5efa\u7acb\u7ba1\u9053\u5f52\u56e0\u5c42\u76d1\u63a7\u7cfb\u7edf\u6027\u80fd\u3002", "result": "\u5728788\u4e2a\u8bc4\u4f30\u67e5\u8be2\u4e2d\uff0c\u4e0a\u4e0b\u6587\u538b\u7f29\u7b56\u7565\u8868\u73b0\u6700\u4f18\uff1a\u610f\u56fe\u51c6\u786e\u738793.3%\uff0c\u8def\u7531\u6210\u529f\u738786.8%\uff08\u542b\u56de\u9000\uff09\uff0c\u53ec\u56de\u738799.4%\uff0cNDCG@5\u4e3a88.5%\u3002", "conclusion": "\u6218\u7565\u6027\u4e0a\u4e0b\u6587\u603b\u7ed3\u4f18\u4e8e\u5168\u9762\u548c\u6700\u5c0f\u5316\u4e0a\u4e0b\u6587\u7b56\u7565\uff0c\u8bc1\u660e\u4e86FUSE\u5728\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u63d0\u5347\u591a\u6a21\u6001\u68c0\u7d22\u6027\u80fd\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.02366", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02366", "abs": "https://arxiv.org/abs/2601.02366", "authors": ["Yiwen Chen", "Yiqing Wu", "Huishi Luo", "Fuzhen Zhuang", "Deqing Wang"], "title": "TextBridgeGNN: Pre-training Graph Neural Network for Cross-Domain Recommendation via Text-Guided Transfer", "comment": null, "summary": "Graph-based recommendation has achieved great success in recent years. The classical graph recommendation model utilizes ID embedding to store essential collaborative information. However, this ID-based paradigm faces challenges in transferring to a new domain, making it hard to build a pre-trained graph recommendation model. This phenomenon primarily stems from two inherent challenges: (1) the non-transferability of ID embeddings due to isolated domain-specific ID spaces, and (2) structural incompatibility between heterogeneous interaction graphs across domains.\n  To address these issues, we propose TextBridgeGNN, a pre-training and fine-tuning framework that can effectively transfer knowledge from a pre-trained GNN to downstream tasks. We believe the key lies in how to build the relationship between domains. Specifically, TextBridgeGNN uses text as a semantic bridge to connect domains through multi-level graph propagation. During the pre-training stage, textual information is utilized to break the data islands formed by multiple domains, and hierarchical GNNs are designed to learn both domain-specific and domain-global knowledge with text features, ensuring the retention of collaborative signals and the enhancement of semantics. During the fine-tuning stage, a similarity transfer mechanism is proposed. This mechanism initializes ID embeddings in the target domain by transferring from semantically related nodes, successfully transferring the ID embeddings and graph pattern.\n  Experiments demonstrate that TextBridgeGNN outperforms existing methods in cross-domain, multi-domain, and training-free settings, highlighting its ability to integrate Pre-trained Language Model (PLM)-driven semantics with graph-based collaborative filtering without costly language model fine-tuning or real-time inference overhead.", "AI": {"tldr": "TextBridgeGNN\uff1a\u5229\u7528\u6587\u672c\u4f5c\u4e3a\u8bed\u4e49\u6865\u6881\u7684\u56fe\u63a8\u8350\u9884\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u7ea7\u56fe\u4f20\u64ad\u8fde\u63a5\u4e0d\u540c\u9886\u57df\uff0c\u89e3\u51b3ID\u5d4c\u5165\u4e0d\u53ef\u8fc1\u79fb\u548c\u5f02\u6784\u56fe\u7ed3\u6784\u4e0d\u517c\u5bb9\u95ee\u9898", "motivation": "\u4f20\u7edf\u57fa\u4e8eID\u5d4c\u5165\u7684\u56fe\u63a8\u8350\u6a21\u578b\u96be\u4ee5\u8fc1\u79fb\u5230\u65b0\u9886\u57df\uff0c\u4e3b\u8981\u9762\u4e34\u4e24\u4e2a\u6311\u6218\uff1a1) ID\u5d4c\u5165\u56e0\u9886\u57df\u7279\u5b9aID\u7a7a\u95f4\u9694\u79bb\u800c\u4e0d\u53ef\u8fc1\u79fb\uff1b2) \u8de8\u9886\u57df\u5f02\u6784\u4ea4\u4e92\u56fe\u7ed3\u6784\u4e0d\u517c\u5bb9\u3002\u8fd9\u963b\u788d\u4e86\u9884\u8bad\u7ec3\u56fe\u63a8\u8350\u6a21\u578b\u7684\u6784\u5efa\u3002", "method": "\u63d0\u51faTextBridgeGNN\u9884\u8bad\u7ec3-\u5fae\u8c03\u6846\u67b6\uff1a1) \u4f7f\u7528\u6587\u672c\u4f5c\u4e3a\u8bed\u4e49\u6865\u6881\u8fde\u63a5\u4e0d\u540c\u9886\u57df\uff1b2) \u9884\u8bad\u7ec3\u9636\u6bb5\u5229\u7528\u6587\u672c\u4fe1\u606f\u6253\u7834\u6570\u636e\u5b64\u5c9b\uff0c\u8bbe\u8ba1\u5206\u5c42GNN\u5b66\u4e60\u9886\u57df\u7279\u5b9a\u548c\u5168\u5c40\u77e5\u8bc6\uff1b3) \u5fae\u8c03\u9636\u6bb5\u63d0\u51fa\u76f8\u4f3c\u6027\u8fc1\u79fb\u673a\u5236\uff0c\u901a\u8fc7\u8bed\u4e49\u76f8\u5173\u8282\u70b9\u521d\u59cb\u5316\u76ee\u6807\u9886\u57dfID\u5d4c\u5165\u3002", "result": "\u5b9e\u9a8c\u8868\u660eTextBridgeGNN\u5728\u8de8\u9886\u57df\u3001\u591a\u9886\u57df\u548c\u65e0\u8bad\u7ec3\u8bbe\u7f6e\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u6574\u5408\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u8bed\u4e49\u4e0e\u57fa\u4e8e\u56fe\u7684\u534f\u540c\u8fc7\u6ee4\uff0c\u65e0\u9700\u6602\u8d35\u7684\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u6216\u5b9e\u65f6\u63a8\u7406\u5f00\u9500\u3002", "conclusion": "TextBridgeGNN\u6210\u529f\u89e3\u51b3\u4e86\u56fe\u63a8\u8350\u6a21\u578b\u7684\u9886\u57df\u8fc1\u79fb\u95ee\u9898\uff0c\u901a\u8fc7\u6587\u672c\u8bed\u4e49\u6865\u6881\u548c\u591a\u7ea7\u56fe\u4f20\u64ad\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u77e5\u8bc6\u4ece\u9884\u8bad\u7ec3GNN\u5230\u4e0b\u6e38\u4efb\u52a1\u7684\u6709\u6548\u8fc1\u79fb\uff0c\u4e3a\u6784\u5efa\u901a\u7528\u9884\u8bad\u7ec3\u56fe\u63a8\u8350\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2601.02368", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02368", "abs": "https://arxiv.org/abs/2601.02368", "authors": ["Ruibing Wang", "Shuhan Guo", "Haotong Du", "Quanming Yao"], "title": "Distillation-based Scenario-Adaptive Mixture-of-Experts for the Matching Stage of Multi-scenario Recommendation", "comment": null, "summary": "Multi-scenario recommendation is pivotal for optimizing user experience across diverse contexts. While Multi-gate Mixture-of-Experts (MMOE) thrives in ranking, its transfer to the matching stage is hindered by the blind optimization inherent to independent two-tower architectures and the parameter dominance of head scenarios. To address these structural and distributional bottlenecks, we propose Distillation-based Scenario-Adaptive Mixture-of-Experts (DSMOE). Specially, we devise a Scenario-Adaptive Projection (SAP) module to generate lightweight, context-specific parameters, effectively preventing expert collapse in long-tail scenarios. Concurrently, we introduce a cross-architecture knowledge distillation framework, where an interaction-aware teacher guides the two-tower student to capture complex matching patterns. Extensive experiments on real-world datasets demonstrate DSMOE's superiority, particularly in significantly improving retrieval quality for under-represented, data-sparse scenarios.", "AI": {"tldr": "DSMOE\uff1a\u57fa\u4e8e\u84b8\u998f\u7684\u573a\u666f\u81ea\u9002\u5e94\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\uff0c\u89e3\u51b3\u591a\u573a\u666f\u63a8\u8350\u4e2d\u5339\u914d\u9636\u6bb5\u7684\u4e13\u5bb6\u5d29\u6e83\u548c\u53c2\u6570\u4e3b\u5bfc\u95ee\u9898\uff0c\u63d0\u5347\u957f\u5c3e\u573a\u666f\u68c0\u7d22\u8d28\u91cf", "motivation": "\u591a\u573a\u666f\u63a8\u8350\u4e2d\uff0cMMOE\u5728\u6392\u5e8f\u9636\u6bb5\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5339\u914d\u9636\u6bb5\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u72ec\u7acb\u53cc\u5854\u67b6\u6784\u7684\u76f2\u76ee\u4f18\u5316\uff1b2\uff09\u5934\u90e8\u573a\u666f\u53c2\u6570\u4e3b\u5bfc\u5bfc\u81f4\u957f\u5c3e\u573a\u666f\u4e13\u5bb6\u5d29\u6e83", "method": "\u63d0\u51faDSMOE\u6846\u67b6\uff1a1\uff09\u573a\u666f\u81ea\u9002\u5e94\u6295\u5f71\u6a21\u5757\u751f\u6210\u8f7b\u91cf\u7ea7\u3001\u573a\u666f\u7279\u5b9a\u53c2\u6570\uff1b2\uff09\u8de8\u67b6\u6784\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u8ba9\u4ea4\u4e92\u611f\u77e5\u7684\u6559\u5e08\u6a21\u578b\u6307\u5bfc\u53cc\u5854\u5b66\u751f\u6a21\u578b\u5b66\u4e60\u590d\u6742\u5339\u914d\u6a21\u5f0f", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660eDSMOE\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u7a00\u758f\u3001\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u957f\u5c3e\u573a\u666f\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u8d28\u91cf", "conclusion": "DSMOE\u901a\u8fc7\u573a\u666f\u81ea\u9002\u5e94\u53c2\u6570\u751f\u6210\u548c\u77e5\u8bc6\u84b8\u998f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u573a\u666f\u63a8\u8350\u5339\u914d\u9636\u6bb5\u7684\u7ed3\u6784\u548c\u5206\u5e03\u74f6\u9888\uff0c\u4e3a\u957f\u5c3e\u573a\u666f\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u63a8\u8350\u6548\u679c"}}
{"id": "2601.02372", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.02372", "abs": "https://arxiv.org/abs/2601.02372", "authors": ["Eunice Kingenga", "Mike Wa Nkongolo"], "title": "Improving News Recommendations through Hybrid Sentiment Modelling and Reinforcement Learning", "comment": "Masters in information technology, University of Pretoria", "summary": "News recommendation systems rely on automated sentiment analysis to personalise content and enhance user engagement. Conventional approaches often struggle with ambiguity, lexicon inconsistencies, and limited contextual understanding, particularly in multi-source news environments. Existing models typically treat sentiment as a secondary feature, reducing their ability to adapt to users' affective preferences. To address these limitations, this study develops an adaptive, sentiment-aware news recommendation framework by integrating hybrid sentiment analysis with reinforcement learning. Using the BBC News dataset, a hybrid sentiment model combines VADER, AFINN, TextBlob, and SentiWordNet scores to generate robust article-level sentiment estimates. Articles are categorised as positive, negative, or neutral, and these sentiment states are embedded within a Q-learning architecture to guide the agent in learning optimal recommendation policies. The proposed system effectively identifies and recommends articles with aligned emotional profiles while continuously improving personalisation through iterative Q-learning updates. The results demonstrate that coupling hybrid sentiment modelling with reinforcement learning provides a feasible, interpretable, and adaptive approach for user-centred news recommendation.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6df7\u5408\u60c5\u611f\u5206\u6790\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u9002\u5e94\u60c5\u611f\u611f\u77e5\u65b0\u95fb\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7Q-learning\u5b66\u4e60\u6700\u4f18\u63a8\u8350\u7b56\u7565\uff0c\u63d0\u9ad8\u4e2a\u6027\u5316\u63a8\u8350\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u65b0\u95fb\u63a8\u8350\u7cfb\u7edf\u5728\u60c5\u611f\u5206\u6790\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff1a\u5904\u7406\u6b67\u4e49\u6027\u3001\u8bcd\u5178\u4e0d\u4e00\u81f4\u6027\u3001\u4e0a\u4e0b\u6587\u7406\u89e3\u4e0d\u8db3\uff0c\u4e14\u901a\u5e38\u5c06\u60c5\u611f\u4f5c\u4e3a\u6b21\u8981\u7279\u5f81\uff0c\u96be\u4ee5\u9002\u5e94\u7528\u6237\u7684\u60c5\u611f\u504f\u597d\u3002", "method": "\u5f00\u53d1\u81ea\u9002\u5e94\u60c5\u611f\u611f\u77e5\u65b0\u95fb\u63a8\u8350\u6846\u67b6\uff0c\u6574\u5408\u6df7\u5408\u60c5\u611f\u5206\u6790\u548c\u5f3a\u5316\u5b66\u4e60\u3002\u4f7f\u7528BBC News\u6570\u636e\u96c6\uff0c\u7ed3\u5408VADER\u3001AFINN\u3001TextBlob\u548cSentiWordNet\u56db\u79cd\u60c5\u611f\u5206\u6790\u5de5\u5177\u751f\u6210\u7a33\u5065\u7684\u6587\u7ae0\u7ea7\u60c5\u611f\u4f30\u8ba1\uff0c\u5c06\u6587\u7ae0\u5206\u7c7b\u4e3a\u79ef\u6781\u3001\u6d88\u6781\u6216\u4e2d\u6027\uff0c\u5e76\u5c06\u8fd9\u4e9b\u60c5\u611f\u72b6\u6001\u5d4c\u5165Q-learning\u67b6\u6784\u4e2d\u6307\u5bfc\u667a\u80fd\u4f53\u5b66\u4e60\u6700\u4f18\u63a8\u8350\u7b56\u7565\u3002", "result": "\u8be5\u7cfb\u7edf\u80fd\u6709\u6548\u8bc6\u522b\u5e76\u63a8\u8350\u60c5\u611f\u7279\u5f81\u5339\u914d\u7684\u6587\u7ae0\uff0c\u901a\u8fc7\u8fed\u4ee3Q-learning\u66f4\u65b0\u6301\u7eed\u6539\u8fdb\u4e2a\u6027\u5316\u63a8\u8350\u3002\u7ed3\u679c\u8868\u660e\uff0c\u6df7\u5408\u60c5\u611f\u5efa\u6a21\u4e0e\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u4e3a\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u65b0\u95fb\u63a8\u8350\u63d0\u4f9b\u4e86\u53ef\u884c\u3001\u53ef\u89e3\u91ca\u4e14\u81ea\u9002\u5e94\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u5c06\u6df7\u5408\u60c5\u611f\u5efa\u6a21\u4e0e\u5f3a\u5316\u5b66\u4e60\u8026\u5408\uff0c\u4e3a\u65b0\u95fb\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u3001\u53ef\u89e3\u91ca\u4e14\u81ea\u9002\u5e94\u7684\u7528\u6237\u4e2d\u5fc3\u5316\u65b9\u6cd5\uff0c\u80fd\u591f\u66f4\u597d\u5730\u7406\u89e3\u548c\u9002\u5e94\u7528\u6237\u7684\u60c5\u611f\u504f\u597d\u3002"}}
{"id": "2601.02374", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.02374", "abs": "https://arxiv.org/abs/2601.02374", "authors": ["Melissa Tessa", "Diderot D. Cidjeu", "Rachele Carli", "Sarah Abchiche", "Ahmad Aldarwishd", "Igor Tchappi", "Amro Najjar"], "title": "A Lay User Explainable Food Recommendation System Based on Hybrid Feature Importance Extraction and Large Language Models", "comment": null, "summary": "Large Language Models (LLM) have experienced strong development in recent years, with varied applications. This paper uses LLMs to develop a post-hoc process that provides more elaborated explanations of the results of food recommendation systems. By combining LLM with a hybrid extraction of key variables using SHAP, we obtain dynamic, convincing and more comprehensive explanations to lay user, compared to those in the literature. This approach enhances user trust and transparency by making complex recommendation outcomes easier to understand for a lay user.", "AI": {"tldr": "\u4f7f\u7528LLM\u548cSHAP\u5f00\u53d1\u540e\u5904\u7406\u6d41\u7a0b\uff0c\u4e3a\u98df\u54c1\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u66f4\u8be6\u7ec6\u7684\u89e3\u91ca\uff0c\u589e\u5f3a\u7528\u6237\u4fe1\u4efb\u548c\u900f\u660e\u5ea6", "motivation": "\u867d\u7136LLM\u53d1\u5c55\u8fc5\u901f\uff0c\u4f46\u73b0\u6709\u98df\u54c1\u63a8\u8350\u7cfb\u7edf\u7684\u89e3\u91ca\u4e0d\u591f\u8be6\u7ec6\uff0c\u7528\u6237\u96be\u4ee5\u7406\u89e3\u590d\u6742\u63a8\u8350\u7ed3\u679c\uff0c\u9700\u8981\u66f4\u5168\u9762\u3001\u52a8\u6001\u7684\u89e3\u91ca\u6765\u589e\u5f3a\u7528\u6237\u4fe1\u4efb", "method": "\u7ed3\u5408LLM\u548cSHAP\u7684\u6df7\u5408\u5173\u952e\u53d8\u91cf\u63d0\u53d6\u65b9\u6cd5\uff0c\u5f00\u53d1\u540e\u5904\u7406\u6d41\u7a0b\uff0c\u4e3a\u63a8\u8350\u7ed3\u679c\u751f\u6210\u52a8\u6001\u3001\u6709\u8bf4\u670d\u529b\u7684\u89e3\u91ca", "result": "\u76f8\u6bd4\u6587\u732e\u4e2d\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u80fd\u4e3a\u666e\u901a\u7528\u6237\u63d0\u4f9b\u66f4\u5168\u9762\u3001\u66f4\u4ee4\u4eba\u4fe1\u670d\u7684\u89e3\u91ca\uff0c\u4f7f\u590d\u6742\u63a8\u8350\u7ed3\u679c\u66f4\u6613\u7406\u89e3", "conclusion": "LLM\u4e0eSHAP\u7ed3\u5408\u7684\u540e\u5904\u7406\u6d41\u7a0b\u80fd\u6709\u6548\u63d0\u5347\u98df\u54c1\u63a8\u8350\u7cfb\u7edf\u7684\u89e3\u91ca\u8d28\u91cf\uff0c\u589e\u5f3a\u7528\u6237\u4fe1\u4efb\u548c\u7cfb\u7edf\u900f\u660e\u5ea6"}}
{"id": "2601.02381", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.02381", "abs": "https://arxiv.org/abs/2601.02381", "authors": ["Zhexiang Li"], "title": "TAG-HGT: A Scalable and Cost-Effective Framework for Inductive Cold-Start Academic Recommendation", "comment": "8pages", "summary": "Inductive cold-start recommendation remains the \"Achilles' Heel\" of industrial academic platforms, where thousands of new scholars join daily without historical interaction records. While recent Generative Graph Models (e.g., HiGPT, OFA) demonstrate promising semantic capabilities, their prohibitive inference latency (often exceeding 13 minutes per 1,000 requests) and massive computational costs render them practically undeployable for real-time, million-scale applications. To bridge this gap between generative quality and industrial scalability, we propose TAG-HGT, a cost-effective neuro-symbolic framework. Adopting a decoupled \"Semantics-First, Structure-Refined\" paradigm, TAG-HGT utilizes a frozen Large Language Model (DeepSeek-V3) as an offline semantic factory and distills its knowledge into a lightweight Heterogeneous Graph Transformer (HGT) via Cross-View Contrastive Learning (CVCL). We present a key insight: while LLM semantics provide necessary global recall, structural signals offer the critical local discrimination needed to distinguish valid collaborators from semantically similar but socially unreachable strangers in dense embedding spaces. Validated under a strict Time-Machine Protocol on the massive OpenAlex dataset, TAG-HGT achieves a SOTA System Recall@10 of 91.97%, outperforming structure-only baselines by 20.7%. Most significantly, from an industrial perspective, TAG-HGT reduces inference latency by five orders of magnitude ($4.5 \\times 10^{5}\\times$) compared to generative baselines (from 780s down to 1.73 ms), and slashes inference costs from $\\sim$$1.50 to $<$$0.001 per 1k queries. This 99.9% cost reduction democratizes high-precision academic recommendation.", "AI": {"tldr": "TAG-HGT\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u901a\u8fc7\"\u8bed\u4e49\u4f18\u5148\u3001\u7ed3\u6784\u7cbe\u70bc\"\u7684\u89e3\u8026\u8303\u5f0f\uff0c\u5c06\u51bb\u7ed3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u77e5\u8bc6\u84b8\u998f\u5230\u8f7b\u91cf\u7ea7\u5f02\u6784\u56feTransformer\u4e2d\uff0c\u89e3\u51b3\u4e86\u5b66\u672f\u5e73\u53f0\u51b7\u542f\u52a8\u63a8\u8350\u4e2d\u751f\u6210\u6a21\u578b\u63a8\u7406\u5ef6\u8fdf\u9ad8\u3001\u8ba1\u7b97\u6210\u672c\u5927\u7684\u95ee\u9898\u3002", "motivation": "\u5de5\u4e1a\u5b66\u672f\u5e73\u53f0\u6bcf\u5929\u6709\u5927\u91cf\u65b0\u5b66\u8005\u52a0\u5165\uff0c\u7f3a\u4e4f\u5386\u53f2\u4ea4\u4e92\u8bb0\u5f55\uff0c\u9762\u4e34\u51b7\u542f\u52a8\u63a8\u8350\u6311\u6218\u3002\u73b0\u6709\u751f\u6210\u56fe\u6a21\u578b\u867d\u7136\u8bed\u4e49\u80fd\u529b\u5f3a\uff0c\u4f46\u63a8\u7406\u5ef6\u8fdf\u9ad8\uff08\u6bcf1000\u4e2a\u8bf7\u6c42\u8d85\u8fc713\u5206\u949f\uff09\u3001\u8ba1\u7b97\u6210\u672c\u5927\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5b9e\u65f6\u3001\u767e\u4e07\u7ea7\u89c4\u6a21\u5e94\u7528\u7684\u9700\u6c42\u3002", "method": "\u91c7\u7528\"\u8bed\u4e49\u4f18\u5148\u3001\u7ed3\u6784\u7cbe\u70bc\"\u7684\u89e3\u8026\u8303\u5f0f\uff1a1\uff09\u4f7f\u7528\u51bb\u7ed3\u7684DeepSeek-V3\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u79bb\u7ebf\u8bed\u4e49\u5de5\u5382\uff1b2\uff09\u901a\u8fc7\u8de8\u89c6\u56fe\u5bf9\u6bd4\u5b66\u4e60\u5c06\u8bed\u4e49\u77e5\u8bc6\u84b8\u998f\u5230\u8f7b\u91cf\u7ea7\u5f02\u6784\u56feTransformer\u4e2d\uff1b3\uff09\u7ed3\u5408LLM\u63d0\u4f9b\u7684\u5168\u5c40\u53ec\u56de\u80fd\u529b\u548c\u7ed3\u6784\u4fe1\u53f7\u63d0\u4f9b\u7684\u5c40\u90e8\u5224\u522b\u80fd\u529b\u3002", "result": "\u5728OpenAlex\u6570\u636e\u96c6\u4e0a\uff0cTAG-HGT\u8fbe\u523091.97%\u7684SOTA\u7cfb\u7edf\u53ec\u56de\u7387@10\uff0c\u6bd4\u7eaf\u7ed3\u6784\u57fa\u7ebf\u63d0\u534720.7%\u3002\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e5\u4e2a\u6570\u91cf\u7ea7\uff08\u4ece780\u79d2\u964d\u81f31.73\u6beb\u79d2\uff09\uff0c\u63a8\u7406\u6210\u672c\u4ece\u6bcf1000\u67e5\u8be2\u7ea61.50\u7f8e\u5143\u964d\u81f3<0.001\u7f8e\u5143\uff0c\u6210\u672c\u964d\u4f4e99.9%\u3002", "conclusion": "TAG-HGT\u5728\u4fdd\u6301\u751f\u6210\u6a21\u578b\u8bed\u4e49\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u5de5\u4e1a\u7ea7\u53ef\u6269\u5c55\u6027\uff0c\u5927\u5e45\u964d\u4f4e\u4e86\u63a8\u7406\u5ef6\u8fdf\u548c\u6210\u672c\uff0c\u4f7f\u9ad8\u7cbe\u5ea6\u5b66\u672f\u63a8\u8350\u6c11\u4e3b\u5316\uff0c\u4e3a\u5de5\u4e1a\u51b7\u542f\u52a8\u63a8\u8350\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.02386", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02386", "abs": "https://arxiv.org/abs/2601.02386", "authors": ["Hanyang Yuan", "Ning Tang", "Tongya Zheng", "Jiarong Xu", "Xintong Hu", "Renhong Huang", "Shunyu Liu", "Jiacong Hu", "Jiawei Chen", "Mingli Song"], "title": "Tree of Preferences for Diversified Recommendation", "comment": null, "summary": "Diversified recommendation has attracted increasing attention from both researchers and practitioners, which can effectively address the homogeneity of recommended items. Existing approaches predominantly aim to infer the diversity of user preferences from observed user feedback. Nonetheless, due to inherent data biases, the observed data may not fully reflect user interests, where underexplored preferences can be overwhelmed or remain unmanifested. Failing to capture these preferences can lead to suboptimal diversity in recommendations. To fill this gap, this work aims to study diversified recommendation from a data-bias perspective. Inspired by the outstanding performance of large language models (LLMs) in zero-shot inference leveraging world knowledge, we propose a novel approach that utilizes LLMs' expertise to uncover underexplored user preferences from observed behavior, ultimately providing diverse and relevant recommendations. To achieve this, we first introduce Tree of Preferences (ToP), an innovative structure constructed to model user preferences from coarse to fine. ToP enables LLMs to systematically reason over the user's rationale behind their behavior, thereby uncovering their underexplored preferences. To guide diversified recommendations using uncovered preferences, we adopt a data-centric approach, identifying candidate items that match user preferences and generating synthetic interactions that reflect underexplored preferences. These interactions are integrated to train a general recommender for diversification. Moreover, we scale up overall efficiency by dynamically selecting influential users during optimization. Extensive evaluations of both diversity and relevance show that our approach outperforms existing methods in most cases and achieves near-optimal performance in others, with reasonable inference latency.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6837\u5316\u63a8\u8350\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u504f\u597d\u6811\u6316\u6398\u7528\u6237\u672a\u5145\u5206\u63a2\u7d22\u7684\u5174\u8da3\uff0c\u751f\u6210\u5408\u6210\u4ea4\u4e92\u6570\u636e\u8bad\u7ec3\u63a8\u8350\u6a21\u578b\uff0c\u63d0\u5347\u63a8\u8350\u7684\u591a\u6837\u6027\u548c\u76f8\u5173\u6027\u3002", "motivation": "\u73b0\u6709\u591a\u6837\u5316\u63a8\u8350\u65b9\u6cd5\u4e3b\u8981\u4ece\u89c2\u5bdf\u5230\u7684\u7528\u6237\u53cd\u9988\u63a8\u65ad\u7528\u6237\u504f\u597d\u591a\u6837\u6027\uff0c\u4f46\u7531\u4e8e\u6570\u636e\u504f\u5dee\uff0c\u89c2\u5bdf\u6570\u636e\u53ef\u80fd\u65e0\u6cd5\u5b8c\u5168\u53cd\u6620\u7528\u6237\u5174\u8da3\uff0c\u672a\u5145\u5206\u63a2\u7d22\u7684\u504f\u597d\u53ef\u80fd\u88ab\u63a9\u76d6\u6216\u672a\u663e\u73b0\uff0c\u5bfc\u81f4\u63a8\u8350\u591a\u6837\u6027\u4e0d\u8db3\u3002", "method": "1. \u5f15\u5165\u504f\u597d\u6811(ToP)\u7ed3\u6784\uff0c\u4ece\u7c97\u5230\u7ec6\u5efa\u6a21\u7528\u6237\u504f\u597d\uff1b2. \u5229\u7528LLM\u7684\u96f6\u6837\u672c\u63a8\u7406\u80fd\u529b\uff0c\u57fa\u4e8e\u4e16\u754c\u77e5\u8bc6\u7cfb\u7edf\u63a8\u7406\u7528\u6237\u884c\u4e3a\u80cc\u540e\u7684\u903b\u8f91\uff0c\u6316\u6398\u672a\u5145\u5206\u63a2\u7d22\u7684\u504f\u597d\uff1b3. \u91c7\u7528\u6570\u636e\u4e3a\u4e2d\u5fc3\u7684\u65b9\u6cd5\uff0c\u8bc6\u522b\u5339\u914d\u7528\u6237\u504f\u597d\u7684\u5019\u9009\u7269\u54c1\uff0c\u751f\u6210\u53cd\u6620\u672a\u63a2\u7d22\u504f\u597d\u7684\u5408\u6210\u4ea4\u4e92\uff1b4. \u6574\u5408\u8fd9\u4e9b\u4ea4\u4e92\u8bad\u7ec3\u901a\u7528\u63a8\u8350\u5668\u5b9e\u73b0\u591a\u6837\u5316\uff1b5. \u901a\u8fc7\u52a8\u6001\u9009\u62e9\u6709\u5f71\u54cd\u529b\u7684\u7528\u6237\u4f18\u5316\u6574\u4f53\u6548\u7387\u3002", "result": "\u5728\u591a\u6837\u6027\u548c\u76f8\u5173\u6027\u65b9\u9762\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u5176\u4ed6\u60c5\u51b5\u4e0b\u8fbe\u5230\u63a5\u8fd1\u6700\u4f18\u7684\u6027\u80fd\uff0c\u4e14\u63a8\u7406\u5ef6\u8fdf\u5408\u7406\u3002", "conclusion": "\u4ece\u6570\u636e\u504f\u5dee\u89d2\u5ea6\u7814\u7a76\u591a\u6837\u5316\u63a8\u8350\uff0c\u5229\u7528LLM\u7684\u4e13\u4e1a\u77e5\u8bc6\u6316\u6398\u672a\u5145\u5206\u63a2\u7d22\u7684\u7528\u6237\u504f\u597d\uff0c\u901a\u8fc7\u504f\u597d\u6811\u7ed3\u6784\u548c\u6570\u636e\u4e3a\u4e2d\u5fc3\u7684\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u63a8\u8350\u591a\u6837\u6027\u548c\u76f8\u5173\u6027\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.02412", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02412", "abs": "https://arxiv.org/abs/2601.02412", "authors": ["Lukas Sch\u00fcepp", "Carmen Amo Alonso", "Florian D\u00f6rfler", "Giulia De Pasquale"], "title": "Socially-Aware Recommender Systems Mitigate Opinion Clusterization", "comment": null, "summary": "Recommender systems shape online interactions by matching users with creators content to maximize engagement. Creators, in turn, adapt their content to align with users preferences and enhance their popularity. At the same time, users preferences evolve under the influence of both suggested content from the recommender system and content shared within their social circles. This feedback loop generates a complex interplay between users, creators, and recommender algorithms, which is the key cause of filter bubbles and opinion polarization. We develop a social network-aware recommender system that explicitly accounts for this user-creators feedback interaction and strategically exploits the topology of the user's own social network to promote diversification. Our approach highlights how accounting for and exploiting user's social network in the recommender system design is crucial to mediate filter bubble effects while balancing content diversity with personalization. Provably, opinion clusterization is positively correlated with the influence of recommended content on user opinions. Ultimately, the proposed approach shows the power of socially-aware recommender systems in combating opinion polarization and clusterization phenomena.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8003\u8651\u7528\u6237\u793e\u4ea4\u7f51\u7edc\u7684\u63a8\u8350\u7cfb\u7edf\uff0c\u901a\u8fc7\u5229\u7528\u793e\u4ea4\u7f51\u7edc\u62d3\u6251\u6765\u5e73\u8861\u4e2a\u6027\u5316\u4e0e\u591a\u6837\u6027\uff0c\u4ee5\u7f13\u89e3\u8fc7\u6ee4\u6c14\u6ce1\u548c\u610f\u89c1\u6781\u5316\u95ee\u9898\u3002", "motivation": "\u63a8\u8350\u7cfb\u7edf\u3001\u5185\u5bb9\u521b\u4f5c\u8005\u548c\u7528\u6237\u4e4b\u95f4\u5f62\u6210\u4e86\u590d\u6742\u7684\u53cd\u9988\u5faa\u73af\uff1a\u63a8\u8350\u7cfb\u7edf\u6839\u636e\u7528\u6237\u504f\u597d\u5339\u914d\u5185\u5bb9\uff0c\u521b\u4f5c\u8005\u4e3a\u63d0\u5347\u53d7\u6b22\u8fce\u5ea6\u800c\u8c03\u6574\u5185\u5bb9\uff0c\u7528\u6237\u504f\u597d\u53c8\u53d7\u5230\u63a8\u8350\u5185\u5bb9\u548c\u793e\u4ea4\u5708\u7684\u53cc\u91cd\u5f71\u54cd\u3002\u8fd9\u79cd\u5faa\u73af\u662f\u5bfc\u81f4\u8fc7\u6ee4\u6c14\u6ce1\u548c\u610f\u89c1\u6781\u5316\u7684\u5173\u952e\u539f\u56e0\uff0c\u9700\u8981\u8bbe\u8ba1\u80fd\u591f\u7f13\u89e3\u8fd9\u4e9b\u95ee\u9898\u7684\u63a8\u8350\u7cfb\u7edf\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u793e\u4ea4\u7f51\u7edc\u611f\u77e5\u7684\u63a8\u8350\u7cfb\u7edf\uff0c\u660e\u786e\u8003\u8651\u7528\u6237\u4e0e\u521b\u4f5c\u8005\u4e4b\u95f4\u7684\u53cd\u9988\u4e92\u52a8\uff0c\u5e76\u6218\u7565\u6027\u5730\u5229\u7528\u7528\u6237\u81ea\u8eab\u793e\u4ea4\u7f51\u7edc\u7684\u62d3\u6251\u7ed3\u6784\u6765\u4fc3\u8fdb\u5185\u5bb9\u591a\u6837\u5316\u3002\u8be5\u65b9\u6cd5\u5728\u63a8\u8350\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u5145\u5206\u8003\u8651\u5e76\u5229\u7528\u7528\u6237\u7684\u793e\u4ea4\u7f51\u7edc\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u610f\u89c1\u805a\u7c7b\u4e0e\u63a8\u8350\u5185\u5bb9\u5bf9\u7528\u6237\u610f\u89c1\u7684\u5f71\u54cd\u529b\u5448\u6b63\u76f8\u5173\u3002\u63d0\u51fa\u7684\u65b9\u6cd5\u5c55\u793a\u4e86\u793e\u4ea4\u611f\u77e5\u63a8\u8350\u7cfb\u7edf\u5728\u5bf9\u6297\u610f\u89c1\u6781\u5316\u548c\u805a\u7c7b\u73b0\u8c61\u65b9\u9762\u7684\u80fd\u529b\u3002", "conclusion": "\u5728\u63a8\u8350\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u8003\u8651\u5e76\u5229\u7528\u7528\u6237\u7684\u793e\u4ea4\u7f51\u7edc\u5bf9\u4e8e\u8c03\u89e3\u8fc7\u6ee4\u6c14\u6ce1\u6548\u5e94\u81f3\u5173\u91cd\u8981\uff0c\u80fd\u591f\u5728\u5185\u5bb9\u591a\u6837\u6027\u548c\u4e2a\u6027\u5316\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002\u793e\u4ea4\u611f\u77e5\u63a8\u8350\u7cfb\u7edf\u662f\u5e94\u5bf9\u610f\u89c1\u6781\u5316\u548c\u805a\u7c7b\u73b0\u8c61\u7684\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2601.02428", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02428", "abs": "https://arxiv.org/abs/2601.02428", "authors": ["Okan Bursa"], "title": "A Dynamic Retrieval-Augmented Generation System with Selective Memory and Remembrance", "comment": "6 Pages, 2 figures", "summary": "We introduce \\emph{Adaptive RAG Memory} (ARM), a retrieval-augmented generation (RAG) framework that replaces a static vector index with a \\emph{dynamic} memory substrate governed by selective remembrance and decay. Frequently retrieved items are consolidated and protected from forgetting, while rarely used items gradually decay, inspired by cognitive consolidation and forgetting principles. On a lightweight retrieval benchmark, ARM reaches near state-of-the-art performance (e.g., NDCG@5 $\\approx$ 0.940, Recall@5 $=1.000$) with only $\\sim$22M parameters in the embedding layer, achieving the best efficiency among ultra-efficient models ($<$25M parameters). In addition, we compare static vs. dynamic RAG combinations across Llama 3.1 and GPT-4o. Llama 3.1 with static RAG achieves the highest key-term coverage (67.2\\%) at moderate latency, while GPT-4o with a dynamic selective retrieval policy attains the fastest responses (8.2s on average) with competitive coverage (58.7\\%). We further present an engineering optimization of the DynamicRAG implementation, making embedding weights configurable, adjustable at runtime, and robust to invalid settings.\n  ARM yields competitive accuracy, self-regularizing memory growth, and interpretable retention dynamics without retraining the generator\\color{black} and provides practical trade-off between quality, latency and memory efficiency for production and research RAG system.", "AI": {"tldr": "ARM\u662f\u4e00\u4e2a\u52a8\u6001\u8bb0\u5fc6RAG\u6846\u67b6\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u8bb0\u5fc6\u548c\u9057\u5fd8\u673a\u5236\u66ff\u4ee3\u9759\u6001\u5411\u91cf\u7d22\u5f15\uff0c\u5b9e\u73b0\u9ad8\u6548\u68c0\u7d22\u589e\u5f3a\u751f\u6210", "motivation": "\u4f20\u7edfRAG\u4f7f\u7528\u9759\u6001\u5411\u91cf\u7d22\u5f15\u5b58\u5728\u6548\u7387\u95ee\u9898\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u8bb0\u5fc6\u7ba1\u7406\u673a\u5236\u6765\u5e73\u8861\u6027\u80fd\u3001\u5ef6\u8fdf\u548c\u5185\u5b58\u6548\u7387", "method": "\u91c7\u7528\u52a8\u6001\u8bb0\u5fc6\u57fa\u677f\uff0c\u57fa\u4e8e\u8ba4\u77e5\u5de9\u56fa\u548c\u9057\u5fd8\u539f\u7406\uff1a\u9891\u7e41\u68c0\u7d22\u7684\u9879\u76ee\u88ab\u5de9\u56fa\u4fdd\u62a4\uff0c\u5f88\u5c11\u4f7f\u7528\u7684\u9879\u76ee\u9010\u6e10\u8870\u51cf", "result": "\u5728\u8f7b\u91cf\u7ea7\u68c0\u7d22\u57fa\u51c6\u4e0a\u8fbe\u5230\u63a5\u8fd1SOTA\u6027\u80fd\uff08NDCG@5\u22480.940\uff0cRecall@5=1.000\uff09\uff0c\u4ec5\u9700\u7ea622M\u53c2\u6570\uff0c\u5728\u8d85\u9ad8\u6548\u6a21\u578b\u4e2d\u6548\u7387\u6700\u4f73", "conclusion": "ARM\u5728\u8d28\u91cf\u3001\u5ef6\u8fdf\u548c\u5185\u5b58\u6548\u7387\u4e4b\u95f4\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6743\u8861\uff0c\u9002\u7528\u4e8e\u751f\u4ea7\u548c\u7814\u7a76RAG\u7cfb\u7edf\uff0c\u5177\u6709\u81ea\u6b63\u5219\u5316\u5185\u5b58\u589e\u957f\u548c\u53ef\u89e3\u91ca\u7684\u4fdd\u7559\u52a8\u6001"}}
{"id": "2601.02708", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02708", "abs": "https://arxiv.org/abs/2601.02708", "authors": ["HuiJeong Son", "Hyeongu Kang", "Sunho Kim", "Subeen Ho", "SeongKu Kang", "Dongha Lee", "Susik Yoon"], "title": "CREAM: Continual Retrieval on Dynamic Streaming Corpora with Adaptive Soft Memory", "comment": "Accepted to KDD 2026", "summary": "Information retrieval (IR) in dynamic data streams is emerging as a challenging task, as shifts in data distribution degrade the performance of AI-powered IR systems. To mitigate this issue, memory-based continual learning has been widely adopted for IR. However, existing methods rely on a fixed set of queries with ground-truth relevant documents, which limits generalization to unseen queries and documents, making them impractical for real-world applications. To enable more effective learning with unseen topics of a new corpus without ground-truth labels, we propose CREAM, a self-supervised framework for memory-based continual retrieval. CREAM captures the evolving semantics of streaming queries and documents into dynamically structured soft memory and leverages it to adapt to both seen and unseen topics in an unsupervised setting. We realize this through three key techniques: fine-grained similarity estimation, regularized cluster prototyping, and stratified coreset sampling. Experiments on two benchmark datasets demonstrate that CREAM exhibits superior adaptability and retrieval accuracy, outperforming the strongest method in a label-free setting by 27.79\\% in Success@5 and 44.5\\% in Recall@10 on average, and achieving performance comparable to or even exceeding that of supervised methods.", "AI": {"tldr": "CREAM\u662f\u4e00\u4e2a\u7528\u4e8e\u52a8\u6001\u6570\u636e\u6d41\u4fe1\u606f\u68c0\u7d22\u7684\u81ea\u76d1\u7763\u6301\u7eed\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u7ed3\u6784\u5316\u8f6f\u8bb0\u5fc6\u6355\u83b7\u6d41\u5f0f\u67e5\u8be2\u548c\u6587\u6863\u7684\u8bed\u4e49\u6f14\u5316\uff0c\u65e0\u9700\u771f\u5b9e\u6807\u7b7e\u5373\u53ef\u9002\u5e94\u65b0\u65e7\u4e3b\u9898\u3002", "motivation": "\u52a8\u6001\u6570\u636e\u6d41\u4e2d\u7684\u4fe1\u606f\u68c0\u7d22\u9762\u4e34\u6570\u636e\u5206\u5e03\u6f02\u79fb\u7684\u6311\u6218\uff0c\u73b0\u6709\u57fa\u4e8e\u8bb0\u5fc6\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u67e5\u8be2\u96c6\u548c\u771f\u5b9e\u76f8\u5173\u6587\u6863\uff0c\u9650\u5236\u4e86\u5411\u672a\u89c1\u67e5\u8be2\u548c\u6587\u6863\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u96be\u4ee5\u5e94\u7528\u4e8e\u5b9e\u9645\u573a\u666f\u3002", "method": "\u63d0\u51faCREAM\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u6280\u672f\uff1a\u7ec6\u7c92\u5ea6\u76f8\u4f3c\u5ea6\u4f30\u8ba1\u3001\u6b63\u5219\u5316\u805a\u7c7b\u539f\u578b\u548c\u5206\u5c42\u6838\u5fc3\u96c6\u91c7\u6837\uff0c\u901a\u8fc7\u52a8\u6001\u7ed3\u6784\u5316\u8f6f\u8bb0\u5fc6\u6355\u83b7\u6d41\u5f0f\u67e5\u8be2\u548c\u6587\u6863\u7684\u8bed\u4e49\u6f14\u5316\uff0c\u5728\u65e0\u76d1\u7763\u8bbe\u7f6e\u4e0b\u9002\u5e94\u5df2\u89c1\u548c\u672a\u89c1\u4e3b\u9898\u3002", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCREAM\u5728\u65e0\u6807\u7b7e\u8bbe\u7f6e\u4e0b\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u9002\u5e94\u6027\u548c\u68c0\u7d22\u51c6\u786e\u6027\uff0c\u5728Success@5\u548cRecall@10\u6307\u6807\u4e0a\u5e73\u5747\u6bd4\u6700\u5f3a\u65b9\u6cd5\u5206\u522b\u63d0\u534727.79%\u548c44.5%\uff0c\u6027\u80fd\u8fbe\u5230\u751a\u81f3\u8d85\u8fc7\u76d1\u7763\u65b9\u6cd5\u3002", "conclusion": "CREAM\u901a\u8fc7\u81ea\u76d1\u7763\u6846\u67b6\u89e3\u51b3\u4e86\u52a8\u6001\u6570\u636e\u6d41\u4fe1\u606f\u68c0\u7d22\u4e2d\u7684\u5206\u5e03\u6f02\u79fb\u95ee\u9898\uff0c\u65e0\u9700\u771f\u5b9e\u6807\u7b7e\u5373\u53ef\u6709\u6548\u9002\u5e94\u65b0\u65e7\u4e3b\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.02750", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.02750", "abs": "https://arxiv.org/abs/2601.02750", "authors": ["Bincheng Gu", "Min Gao", "Junliang Yu", "Zongwei Wang", "Zhiyi Liu", "Kai Shu", "Hongyu Zhang"], "title": "Ahead of the Spread: Agent-Driven Virtual Propagation for Early Fake News Detection", "comment": null, "summary": "Early detection of fake news is critical for mitigating its rapid dissemination on social media, which can severely undermine public trust and social stability. Recent advancements show that incorporating propagation dynamics can significantly enhance detection performance compared to previous content-only approaches. However, this remains challenging at early stages due to the absence of observable propagation signals. To address this limitation, we propose AVOID, an \\underline{a}gent-driven \\underline{v}irtual pr\\underline{o}pagat\\underline{i}on for early fake news \\underline{d}etection. AVOID reformulates early detection as a new paradigm of evidence generation, where propagation signals are actively simulated rather than passively observed. Leveraging LLM-powered agents with differentiated roles and data-driven personas, AVOID realistically constructs early-stage diffusion behaviors without requiring real propagation data. The resulting virtual trajectories provide complementary social evidence that enriches content-based detection, while a denoising-guided fusion strategy aligns simulated propagation with content semantics. Extensive experiments on benchmark datasets demonstrate that AVOID consistently outperforms state-of-the-art baselines, highlighting the effectiveness and practical value of virtual propagation augmentation for early fake news detection. The code and data are available at https://github.com/Ironychen/AVOID.", "AI": {"tldr": "AVOID\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u667a\u80fd\u4f53\u7684\u865a\u62df\u4f20\u64ad\u6a21\u62df\u65b9\u6cd5\uff0c\u7528\u4e8e\u65e9\u671f\u5047\u65b0\u95fb\u68c0\u6d4b\uff0c\u901a\u8fc7\u4e3b\u52a8\u751f\u6210\u4f20\u64ad\u4fe1\u53f7\u800c\u975e\u88ab\u52a8\u89c2\u5bdf\u6765\u89e3\u51b3\u65e9\u671f\u4f20\u64ad\u6570\u636e\u7f3a\u5931\u7684\u95ee\u9898\u3002", "motivation": "\u65e9\u671f\u5047\u65b0\u95fb\u68c0\u6d4b\u9762\u4e34\u4f20\u64ad\u4fe1\u53f7\u7f3a\u5931\u7684\u6311\u6218\uff0c\u4f20\u7edf\u57fa\u4e8e\u4f20\u64ad\u52a8\u6001\u7684\u65b9\u6cd5\u5728\u65e9\u671f\u9636\u6bb5\u65e0\u6cd5\u83b7\u5f97\u8db3\u591f\u7684\u4f20\u64ad\u6570\u636e\uff0c\u5bfc\u81f4\u68c0\u6d4b\u6027\u80fd\u53d7\u9650\u3002", "method": "AVOID\u5c06\u65e9\u671f\u68c0\u6d4b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u8bc1\u636e\u751f\u6210\u8303\u5f0f\uff0c\u4f7f\u7528\u5177\u6709\u5dee\u5f02\u5316\u89d2\u8272\u548c\u6570\u636e\u9a71\u52a8\u4eba\u8bbe\u7684LLM\u667a\u80fd\u4f53\uff0c\u5728\u6ca1\u6709\u771f\u5b9e\u4f20\u64ad\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u6a21\u62df\u65e9\u671f\u6269\u6563\u884c\u4e3a\uff0c\u751f\u6210\u865a\u62df\u4f20\u64ad\u8f68\u8ff9\u4f5c\u4e3a\u8865\u5145\u793e\u4ea4\u8bc1\u636e\uff0c\u5e76\u901a\u8fc7\u53bb\u566a\u5f15\u5bfc\u7684\u878d\u5408\u7b56\u7565\u5c06\u6a21\u62df\u4f20\u64ad\u4e0e\u5185\u5bb9\u8bed\u4e49\u5bf9\u9f50\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cAVOID\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u865a\u62df\u4f20\u64ad\u589e\u5f3a\u5bf9\u65e9\u671f\u5047\u65b0\u95fb\u68c0\u6d4b\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u4ef7\u503c\u3002", "conclusion": "AVOID\u901a\u8fc7\u4e3b\u52a8\u6a21\u62df\u4f20\u64ad\u52a8\u6001\u800c\u975e\u88ab\u52a8\u89c2\u5bdf\uff0c\u4e3a\u65e9\u671f\u5047\u65b0\u95fb\u68c0\u6d4b\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u865a\u62df\u4f20\u64ad\u589e\u5f3a\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.02764", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02764", "abs": "https://arxiv.org/abs/2601.02764", "authors": ["Hyunji Nam", "Sejoon Oh", "Emma Kong", "Yesu Feng", "Moumita Bhattacharya"], "title": "Netflix Artwork Personalization via LLM Post-training", "comment": "6 pages", "summary": "Large language models (LLMs) have demonstrated success in various applications of user recommendation and personalization across e-commerce and entertainment. On many entertainment platforms such as Netflix, users typically interact with a wide range of titles, each represented by an artwork. Since users have diverse preferences, an artwork that appeals to one type of user may not resonate with another with different preferences. Given this user heterogeneity, our work explores the novel problem of personalized artwork recommendations according to diverse user preferences. Similar to the multi-dimensional nature of users' tastes, titles contain different themes and tones that may appeal to different viewers. For example, the same title might feature both heartfelt family drama and intense action scenes. Users who prefer romantic content may like the artwork emphasizing emotional warmth between the characters, while those who prefer action thrillers may find high-intensity action scenes more intriguing. Rather than a one-size-fits-all approach, we conduct post-training of pre-trained LLMs to make personalized artwork recommendations, selecting the most preferred visual representation of a title for each user and thereby improving user satisfaction and engagement. Our experimental results with Llama 3.1 8B models (trained on a dataset of 110K data points and evaluated on 5K held-out user-title pairs) show that the post-trained LLMs achieve 3-5\\% improvements over the Netflix production model, suggesting a promising direction for granular personalized recommendations using LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528LLM\u8fdb\u884c\u4e2a\u6027\u5316\u827a\u672f\u54c1\u63a8\u8350\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u540e\u8bad\u7ec3\u4f7f\u6a21\u578b\u80fd\u6839\u636e\u7528\u6237\u504f\u597d\u9009\u62e9\u6700\u5408\u9002\u7684\u89c6\u89c9\u5448\u73b0\uff0c\u5728Netflix\u6570\u636e\u96c6\u4e0a\u6bd4\u73b0\u6709\u751f\u4ea7\u6a21\u578b\u63d0\u53473-5%\u3002", "motivation": "\u7528\u6237\u5bf9\u5a31\u4e50\u5185\u5bb9\uff08\u5982Netflix\u4e0a\u7684\u6807\u9898\uff09\u7684\u504f\u597d\u5177\u6709\u591a\u6837\u6027\uff0c\u540c\u4e00\u6807\u9898\u7684\u4e0d\u540c\u89c6\u89c9\u5448\u73b0\uff08\u827a\u672f\u54c1\uff09\u53ef\u80fd\u5438\u5f15\u4e0d\u540c\u7c7b\u578b\u7684\u7528\u6237\u3002\u73b0\u6709\u7684\u4e00\u5200\u5207\u63a8\u8350\u65b9\u6cd5\u65e0\u6cd5\u6ee1\u8db3\u8fd9\u79cd\u4e2a\u6027\u5316\u9700\u6c42\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u80fd\u591f\u6839\u636e\u7528\u6237\u504f\u597d\u63a8\u8350\u6700\u5408\u9002\u827a\u672f\u54c1\u7684\u4e2a\u6027\u5316\u7cfb\u7edf\u3002", "method": "\u5bf9\u9884\u8bad\u7ec3\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08Llama 3.1 8B\uff09\u8fdb\u884c\u540e\u8bad\u7ec3\uff0c\u4f7f\u5176\u80fd\u591f\u6839\u636e\u7528\u6237\u504f\u597d\u4e3a\u6bcf\u4e2a\u7528\u6237-\u6807\u9898\u5bf9\u63a8\u8350\u6700\u5408\u9002\u7684\u89c6\u89c9\u5448\u73b0\u3002\u4f7f\u7528\u5305\u542b110K\u6570\u636e\u70b9\u7684\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u57285K\u4fdd\u7559\u7684\u7528\u6237-\u6807\u9898\u5bf9\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u540e\u8bad\u7ec3\u7684LLM\u5728\u4e2a\u6027\u5316\u827a\u672f\u54c1\u63a8\u8350\u4efb\u52a1\u4e0a\u6bd4Netflix\u751f\u4ea7\u6a21\u578b\u63d0\u5347\u4e863-5%\u7684\u6027\u80fd\uff0c\u8868\u660e\u4f7f\u7528LLM\u8fdb\u884c\u7ec6\u7c92\u5ea6\u4e2a\u6027\u5316\u63a8\u8350\u662f\u4e00\u4e2a\u6709\u524d\u666f\u7684\u65b9\u5411\u3002", "conclusion": "LLM\u80fd\u591f\u6709\u6548\u5904\u7406\u7528\u6237\u504f\u597d\u7684\u591a\u6837\u6027\uff0c\u4e3a\u4e2a\u6027\u5316\u827a\u672f\u54c1\u63a8\u8350\u63d0\u4f9b\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002\u901a\u8fc7\u540e\u8bad\u7ec3\u9884\u8bad\u7ec3LLM\uff0c\u53ef\u4ee5\u5b9e\u73b0\u6bd4\u73b0\u6709\u751f\u4ea7\u6a21\u578b\u66f4\u597d\u7684\u63a8\u8350\u6548\u679c\uff0c\u63d0\u5347\u7528\u6237\u6ee1\u610f\u5ea6\u548c\u53c2\u4e0e\u5ea6\u3002"}}
{"id": "2601.02807", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.02807", "abs": "https://arxiv.org/abs/2601.02807", "authors": ["Sohini Roychowdhury", "Doris Wang", "Qian Ge", "Joy Mu", "Srihari Reddy"], "title": "COFFEE: COdesign Framework for Feature Enriched Embeddings in Ads-Ranking Systems", "comment": "4 pages, 5 figures, 1 table", "summary": "Diverse and enriched data sources are essential for commercial ads-recommendation models to accurately assess user interest both before and after engagement with content. While extended user-engagement histories can improve the prediction of user interests, it is equally important to embed activity sequences from multiple sources to ensure freshness of user and ad-representations, following scaling law principles. In this paper, we present a novel three-dimensional framework for enhancing user-ad representations without increasing model inference or serving complexity. The first dimension examines the impact of incorporating diverse event sources, the second considers the benefits of longer user histories, and the third focuses on enriching data with additional event attributes and multi-modal embeddings. We assess the return on investment (ROI) of our source enrichment framework by comparing organic user engagement sources, such as content viewing, with ad-impression sources. The proposed method can boost the area under curve (AUC) and the slope of scaling curves for ad-impression sources by 1.56 to 2 times compared to organic usage sources even for short online-sequence lengths of 100 to 10K. Additionally, click-through rate (CTR) prediction improves by 0.56% AUC over the baseline production ad-recommendation system when using enriched ad-impression event sources, leading to improved sequence scaling resolutions for longer and offline user-ad representations.", "AI": {"tldr": "\u63d0\u51fa\u4e09\u7ef4\u6846\u67b6\u589e\u5f3a\u7528\u6237-\u5e7f\u544a\u8868\u793a\uff0c\u901a\u8fc7\u6574\u5408\u591a\u6e90\u4e8b\u4ef6\u3001\u5ef6\u957f\u7528\u6237\u5386\u53f2\u3001\u4e30\u5bcc\u4e8b\u4ef6\u5c5e\u6027\u548c\u591a\u6a21\u6001\u5d4c\u5165\uff0c\u63d0\u5347\u5e7f\u544a\u63a8\u8350\u6548\u679c\uff0cAUC\u63d0\u53471.56-2\u500d\uff0cCTR\u9884\u6d4b\u63d0\u53470.56% AUC\u3002", "motivation": "\u5546\u4e1a\u5e7f\u544a\u63a8\u8350\u6a21\u578b\u9700\u8981\u591a\u6837\u5316\u548c\u4e30\u5bcc\u7684\u6570\u636e\u6e90\u6765\u51c6\u786e\u8bc4\u4f30\u7528\u6237\u5174\u8da3\u3002\u867d\u7136\u6269\u5c55\u7684\u7528\u6237\u53c2\u4e0e\u5386\u53f2\u53ef\u4ee5\u6539\u5584\u7528\u6237\u5174\u8da3\u9884\u6d4b\uff0c\u4f46\u540c\u6837\u91cd\u8981\u7684\u662f\u5d4c\u5165\u6765\u81ea\u591a\u4e2a\u6765\u6e90\u7684\u6d3b\u52a8\u5e8f\u5217\uff0c\u4ee5\u786e\u4fdd\u7528\u6237\u548c\u5e7f\u544a\u8868\u793a\u7684\u65b0\u9c9c\u5ea6\uff0c\u9075\u5faa\u6269\u5c55\u6cd5\u5219\u539f\u5219\u3002", "method": "\u63d0\u51fa\u65b0\u9896\u7684\u4e09\u7ef4\u6846\u67b6\uff1a\u7b2c\u4e00\u7ef4\u7814\u7a76\u6574\u5408\u4e0d\u540c\u4e8b\u4ef6\u6765\u6e90\u7684\u5f71\u54cd\uff1b\u7b2c\u4e8c\u7ef4\u8003\u8651\u66f4\u957f\u7528\u6237\u5386\u53f2\u7684\u597d\u5904\uff1b\u7b2c\u4e09\u7ef4\u4e13\u6ce8\u4e8e\u7528\u989d\u5916\u4e8b\u4ef6\u5c5e\u6027\u548c\u591a\u6a21\u6001\u5d4c\u5165\u4e30\u5bcc\u6570\u636e\u3002\u901a\u8fc7\u6bd4\u8f83\u6709\u673a\u7528\u6237\u53c2\u4e0e\u6765\u6e90\uff08\u5982\u5185\u5bb9\u6d4f\u89c8\uff09\u4e0e\u5e7f\u544a\u5c55\u793a\u6765\u6e90\u6765\u8bc4\u4f30\u6295\u8d44\u56de\u62a5\u7387\u3002", "result": "\u5e7f\u544a\u5c55\u793a\u6765\u6e90\u7684AUC\u548c\u6269\u5c55\u66f2\u7ebf\u659c\u7387\u6bd4\u6709\u673a\u4f7f\u7528\u6765\u6e90\u63d0\u53471.56\u52302\u500d\uff0c\u5373\u4f7f\u5728\u7ebf\u5e8f\u5217\u957f\u5ea6\u4ec5\u4e3a100\u523010K\u3002\u4f7f\u7528\u4e30\u5bcc\u7684\u5e7f\u544a\u5c55\u793a\u4e8b\u4ef6\u6765\u6e90\u65f6\uff0cCTR\u9884\u6d4b\u6bd4\u57fa\u7ebf\u751f\u4ea7\u5e7f\u544a\u63a8\u8350\u7cfb\u7edf\u63d0\u53470.56% AUC\uff0c\u6539\u5584\u4e86\u66f4\u957f\u548c\u79bb\u7ebf\u7528\u6237-\u5e7f\u544a\u8868\u793a\u7684\u5e8f\u5217\u6269\u5c55\u5206\u8fa8\u7387\u3002", "conclusion": "\u4e09\u7ef4\u6570\u636e\u6e90\u4e30\u5bcc\u6846\u67b6\u80fd\u663e\u8457\u63d0\u5347\u5e7f\u544a\u63a8\u8350\u6027\u80fd\uff0c\u901a\u8fc7\u591a\u6e90\u4e8b\u4ef6\u6574\u5408\u3001\u5ef6\u957f\u7528\u6237\u5386\u53f2\u548c\u4e30\u5bcc\u4e8b\u4ef6\u5c5e\u6027\uff0c\u5728\u4e0d\u589e\u52a0\u6a21\u578b\u63a8\u7406\u6216\u670d\u52a1\u590d\u6742\u5ea6\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u6548\u6539\u5584\u7528\u6237-\u5e7f\u544a\u8868\u793a\u8d28\u91cf\u3002"}}
{"id": "2601.02955", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.02955", "abs": "https://arxiv.org/abs/2601.02955", "authors": ["Boyang Xia", "Zhou Yu", "Zhiliang Zhu", "Hanxiao Sun", "Biyun Han", "Jun Wang", "Runnan Liu", "Wenwu Ou"], "title": "HarmonRank: Ranking-aligned Multi-objective Ensemble for Live-streaming E-commerce Recommendation", "comment": "11 pages, 5 figures", "summary": "Recommendation for live-streaming e-commerce is gaining increasing attention due to the explosive growth of the live streaming economy. Different from traditional e-commerce, live-streaming e-commerce shifts the focus from products to streamers, which requires ranking mechanism to balance both purchases and user-streamer interactions for long-term ecology. To trade off multiple objectives, a popular solution is to build an ensemble model to integrate multi-objective scores into a unified score. The ensemble model is usually supervised by multiple independent binary classification losses of all objectives. However, this paradigm suffers from two inherent limitations. First, the optimization direction of the binary classification task is misaligned with the ranking task (evaluated by AUC). Second, this paradigm overlooks the alignment between objectives, e.g., comment and buy behaviors are partially dependent which can be revealed in labels correlations. The model can achieve better trade-offs if it learns the aligned parts of ranking abilities among different objectives.\n  To mitigate these limitations, we propose a novel multi-objective ensemble framework HarmonRank to fulfill both alignment to the ranking task and alignment among objectives. For alignment to ranking, we formulate ranking metric AUC as a rank-sum problem and utilize differentiable ranking techniques for ranking-oriented optimization. For inter-objective alignment, we change the original one-step ensemble paradigm to a two-step relation-aware ensemble scheme.\n  Extensive offline experiments results on two industrial datasets and online experiments demonstrate that our approach significantly outperforms existing state-of-the-art methods. The proposed method has been fully deployed in Kuaishou's live-streaming e-commerce recommendation platform with 400 million DAUs, contributing over 2% purchase gain.", "AI": {"tldr": "\u63d0\u51faHarmonRank\u6846\u67b6\uff0c\u901a\u8fc7\u6392\u540d\u5bf9\u9f50\u548c\u8de8\u76ee\u6807\u5bf9\u9f50\u89e3\u51b3\u76f4\u64ad\u7535\u5546\u63a8\u8350\u4e2d\u7684\u591a\u76ee\u6807\u6392\u5e8f\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u8d2d\u4e70\u8f6c\u5316\u7387\u3002", "motivation": "\u76f4\u64ad\u7535\u5546\u63a8\u8350\u9700\u8981\u5e73\u8861\u8d2d\u4e70\u548c\u7528\u6237-\u4e3b\u64ad\u4e92\u52a8\u7b49\u591a\u4e2a\u76ee\u6807\u3002\u73b0\u6709\u96c6\u6210\u6a21\u578b\u4f7f\u7528\u591a\u4e2a\u72ec\u7acb\u7684\u4e8c\u5206\u7c7b\u635f\u5931\uff0c\u5b58\u5728\u4e24\u4e2a\u95ee\u9898\uff1a1\uff09\u4e8c\u5206\u7c7b\u4f18\u5316\u65b9\u5411\u4e0e\u6392\u540d\u4efb\u52a1\uff08AUC\u8bc4\u4f30\uff09\u4e0d\u5bf9\u9f50\uff1b2\uff09\u5ffd\u7565\u4e86\u76ee\u6807\u95f4\u7684\u76f8\u5173\u6027\uff08\u5982\u8bc4\u8bba\u548c\u8d2d\u4e70\u884c\u4e3a\u7684\u90e8\u5206\u4f9d\u8d56\u6027\uff09\u3002", "method": "\u63d0\u51faHarmonRank\u6846\u67b6\uff1a1\uff09\u6392\u540d\u5bf9\u9f50\uff1a\u5c06AUC\u6392\u540d\u6307\u6807\u516c\u5f0f\u5316\u4e3a\u79e9\u548c\u95ee\u9898\uff0c\u4f7f\u7528\u53ef\u5fae\u5206\u6392\u540d\u6280\u672f\u8fdb\u884c\u6392\u540d\u5bfc\u5411\u4f18\u5316\uff1b2\uff09\u8de8\u76ee\u6807\u5bf9\u9f50\uff1a\u5c06\u539f\u59cb\u7684\u4e00\u6b65\u96c6\u6210\u8303\u5f0f\u6539\u4e3a\u4e24\u6b65\u5173\u7cfb\u611f\u77e5\u96c6\u6210\u65b9\u6848\u3002", "result": "\u5728\u4e24\u4e2a\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u7684\u79bb\u7ebf\u5b9e\u9a8c\u548c\u5728\u7ebf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709SOTA\u65b9\u6cd5\u3002\u5df2\u5728\u5feb\u624b\u76f4\u64ad\u7535\u5546\u63a8\u8350\u5e73\u53f0\uff084\u4ebfDAU\uff09\u5168\u9762\u90e8\u7f72\uff0c\u8d21\u732e\u8d85\u8fc72%\u7684\u8d2d\u4e70\u589e\u76ca\u3002", "conclusion": "HarmonRank\u901a\u8fc7\u540c\u65f6\u5b9e\u73b0\u6392\u540d\u4efb\u52a1\u5bf9\u9f50\u548c\u76ee\u6807\u95f4\u5bf9\u9f50\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u76f4\u64ad\u7535\u5546\u63a8\u8350\u4e2d\u7684\u591a\u76ee\u6807\u6392\u5e8f\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u957f\u671f\u751f\u6001\u6548\u76ca\u3002"}}
{"id": "2601.02962", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.02962", "abs": "https://arxiv.org/abs/2601.02962", "authors": ["Fabian Haak", "Philipp Schaer"], "title": "Auditing Search Query Suggestion Bias Through Recursive Algorithm Interrogation", "comment": null, "summary": "Despite their important role in online information search, search query suggestions have not been researched as much as most other aspects of search engines. Although reasons for this are multi-faceted, the sparseness of context and the limited data basis of up to ten suggestions per search query pose the most significant problem in identifying bias in search query suggestions. The most proven method to reduce sparseness and improve the validity of bias identification of search query suggestions so far is to consider suggestions from subsequent searches over time for the same query. This work presents a new, alternative approach to search query bias identification that includes less high-level suggestions to deepen the data basis of bias analyses. We employ recursive algorithm interrogation techniques and create suggestion trees that enable access to more subliminal search query suggestions. Based on these suggestions, we investigate topical group bias in person-related searches in the political domain.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7\u9012\u5f52\u7b97\u6cd5\u8be2\u95ee\u6784\u5efa\u5efa\u8bae\u6811\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc6\u522b\u641c\u7d22\u67e5\u8be2\u5efa\u8bae\u4e2d\u7684\u504f\u89c1\uff0c\u7279\u522b\u9488\u5bf9\u653f\u6cbb\u9886\u57df\u4eba\u7269\u76f8\u5173\u641c\u7d22\u7684\u4e3b\u9898\u7fa4\u4f53\u504f\u89c1\u3002", "motivation": "\u641c\u7d22\u67e5\u8be2\u5efa\u8bae\u5728\u5728\u7ebf\u4fe1\u606f\u641c\u7d22\u4e2d\u626e\u6f14\u91cd\u8981\u89d2\u8272\uff0c\u4f46\u76f8\u5173\u7814\u7a76\u8f83\u5c11\u3002\u4e3b\u8981\u6311\u6218\u5728\u4e8e\u4e0a\u4e0b\u6587\u7a00\u758f\u6027\u548c\u6570\u636e\u57fa\u7840\u6709\u9650\uff08\u6bcf\u4e2a\u67e5\u8be2\u6700\u591a10\u4e2a\u5efa\u8bae\uff09\uff0c\u8fd9\u7ed9\u8bc6\u522b\u641c\u7d22\u67e5\u8be2\u5efa\u8bae\u4e2d\u7684\u504f\u89c1\u5e26\u6765\u4e86\u663e\u8457\u95ee\u9898\u3002", "method": "\u91c7\u7528\u9012\u5f52\u7b97\u6cd5\u8be2\u95ee\u6280\u672f\uff0c\u521b\u5efa\u5efa\u8bae\u6811\uff0c\u4ece\u800c\u8bbf\u95ee\u66f4\u591a\u6f5c\u610f\u8bc6\u7684\u641c\u7d22\u67e5\u8be2\u5efa\u8bae\u3002\u57fa\u4e8e\u8fd9\u4e9b\u5efa\u8bae\uff0c\u7814\u7a76\u653f\u6cbb\u9886\u57df\u4eba\u7269\u76f8\u5173\u641c\u7d22\u4e2d\u7684\u4e3b\u9898\u7fa4\u4f53\u504f\u89c1\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6df1\u5316\u504f\u89c1\u5206\u6790\u7684\u6570\u636e\u57fa\u7840\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u8bc6\u522b\u641c\u7d22\u67e5\u8be2\u5efa\u8bae\u504f\u89c1\u7684\u65b0\u66ff\u4ee3\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u9012\u5f52\u7b97\u6cd5\u8be2\u95ee\u6784\u5efa\u5efa\u8bae\u6811\u7684\u65b9\u6cd5\uff0c\u4e3a\u89e3\u51b3\u641c\u7d22\u67e5\u8be2\u5efa\u8bae\u504f\u89c1\u8bc6\u522b\u4e2d\u7684\u6570\u636e\u7a00\u758f\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\uff0c\u7279\u522b\u9002\u7528\u4e8e\u653f\u6cbb\u9886\u57df\u4eba\u7269\u76f8\u5173\u641c\u7d22\u7684\u504f\u89c1\u5206\u6790\u3002"}}
{"id": "2601.03153", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.03153", "abs": "https://arxiv.org/abs/2601.03153", "authors": ["Jiakai Tang", "Xu Chen", "Wen Chen", "Jian Wu", "Yuning Jiang", "Bo Zheng"], "title": "Parallel Latent Reasoning for Sequential Recommendation", "comment": null, "summary": "Capturing complex user preferences from sparse behavioral sequences remains a fundamental challenge in sequential recommendation. Recent latent reasoning methods have shown promise by extending test-time computation through multi-step reasoning, yet they exclusively rely on depth-level scaling along a single trajectory, suffering from diminishing returns as reasoning depth increases. To address this limitation, we propose \\textbf{Parallel Latent Reasoning (PLR)}, a novel framework that pioneers width-level computational scaling by exploring multiple diverse reasoning trajectories simultaneously. PLR constructs parallel reasoning streams through learnable trigger tokens in continuous latent space, preserves diversity across streams via global reasoning regularization, and adaptively synthesizes multi-stream outputs through mixture-of-reasoning-streams aggregation. Extensive experiments on three real-world datasets demonstrate that PLR substantially outperforms state-of-the-art baselines while maintaining real-time inference efficiency. Theoretical analysis further validates the effectiveness of parallel reasoning in improving generalization capability. Our work opens new avenues for enhancing reasoning capacity in sequential recommendation beyond existing depth scaling.", "AI": {"tldr": "PLR\u63d0\u51fa\u5e76\u884c\u6f5c\u5728\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u540c\u65f6\u63a2\u7d22\u591a\u4e2a\u4e0d\u540c\u7684\u63a8\u7406\u8f68\u8ff9\u6765\u89e3\u51b3\u5e8f\u5217\u63a8\u8350\u4e2d\u7a00\u758f\u884c\u4e3a\u5e8f\u5217\u7684\u590d\u6742\u7528\u6237\u504f\u597d\u5efa\u6a21\u95ee\u9898\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u6df1\u5ea6\u7ea7\u6269\u5c55\u7684\u9650\u5236\u3002", "motivation": "\u73b0\u6709\u6f5c\u5728\u63a8\u7406\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u5355\u4e00\u8f68\u8ff9\u7684\u6df1\u5ea6\u7ea7\u6269\u5c55\uff0c\u968f\u7740\u63a8\u7406\u6df1\u5ea6\u589e\u52a0\u4f1a\u51fa\u73b0\u6536\u76ca\u9012\u51cf\u95ee\u9898\uff0c\u9650\u5236\u4e86\u4ece\u7a00\u758f\u884c\u4e3a\u5e8f\u5217\u4e2d\u6355\u6349\u590d\u6742\u7528\u6237\u504f\u597d\u7684\u80fd\u529b\u3002", "method": "PLR\u6846\u67b6\u901a\u8fc7\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\u5b9e\u73b0\uff1a1) \u5728\u8fde\u7eed\u6f5c\u5728\u7a7a\u95f4\u4e2d\u4f7f\u7528\u53ef\u5b66\u4e60\u7684\u89e6\u53d1\u4ee4\u724c\u6784\u5efa\u5e76\u884c\u63a8\u7406\u6d41\uff1b2) \u901a\u8fc7\u5168\u5c40\u63a8\u7406\u6b63\u5219\u5316\u4fdd\u6301\u6d41\u95f4\u7684\u591a\u6837\u6027\uff1b3) \u901a\u8fc7\u6df7\u5408\u63a8\u7406\u6d41\u805a\u5408\u81ea\u9002\u5e94\u5408\u6210\u591a\u6d41\u8f93\u51fa\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPLR\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5b9e\u65f6\u63a8\u7406\u6548\u7387\u3002\u7406\u8bba\u5206\u6790\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u5e76\u884c\u63a8\u7406\u5728\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "PLR\u4e3a\u5e8f\u5217\u63a8\u8350\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u589e\u5f3a\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u6df1\u5ea6\u6269\u5c55\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bbd\u5ea6\u7ea7\u8ba1\u7b97\u6269\u5c55\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2601.03211", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.03211", "abs": "https://arxiv.org/abs/2601.03211", "authors": ["Yue Kang", "Zhuoyi Huang", "Benji Schussheim", "Diana Licon", "Dina Atia", "Shixing Cao", "Jacob Danovitch", "Kunho Kim", "Billy Norcilien", "Jonah Karpman", "Mahmound Sayed", "Mike Taylor", "Tao Sun", "Pavel Metrikov", "Vipul Agarwal", "Chris Quirk", "Ye-Yi Wang", "Nick Craswell", "Irene Shaffer", "Tianwei Chen", "Sulaiman Vesal", "Soundar Srinivasan"], "title": "Fine-tuning Small Language Models as Efficient Enterprise Search Relevance Labelers", "comment": null, "summary": "In enterprise search, building high-quality datasets at scale remains a central challenge due to the difficulty of acquiring labeled data. To resolve this challenge, we propose an efficient approach to fine-tune small language models (SLMs) for accurate relevance labeling, enabling high-throughput, domain-specific labeling comparable or even better in quality to that of state-of-the-art large language models (LLMs). To overcome the lack of high-quality and accessible datasets in the enterprise domain, our method leverages on synthetic data generation. Specifically, we employ an LLM to synthesize realistic enterprise queries from a seed document, apply BM25 to retrieve hard negatives, and use a teacher LLM to assign relevance scores. The resulting dataset is then distilled into an SLM, producing a compact relevance labeler. We evaluate our approach on a high-quality benchmark consisting of 923 enterprise query-document pairs annotated by trained human annotators, and show that the distilled SLM achieves agreement with human judgments on par with or better than the teacher LLM. Furthermore, our fine-tuned labeler substantially improves throughput, achieving 17 times increase while also being 19 times more cost-effective. This approach enables scalable and cost-effective relevance labeling for enterprise-scale retrieval applications, supporting rapid offline evaluation and iteration in real-world settings.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9ad8\u6548\u65b9\u6cd5\uff0c\u901a\u8fc7\u5408\u6210\u6570\u636e\u751f\u6210\u548c\u77e5\u8bc6\u84b8\u998f\uff0c\u5c06\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u4e3a\u4f01\u4e1a\u641c\u7d22\u4e2d\u7684\u76f8\u5173\u6027\u6807\u6ce8\u5668\uff0c\u5728\u4fdd\u6301\u8d28\u91cf\u7684\u540c\u65f6\u5927\u5e45\u63d0\u5347\u541e\u5410\u91cf\u548c\u6210\u672c\u6548\u76ca\u3002", "motivation": "\u4f01\u4e1a\u641c\u7d22\u4e2d\u6784\u5efa\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u9762\u4e34\u6838\u5fc3\u6311\u6218\uff1a\u96be\u4ee5\u83b7\u53d6\u6807\u6ce8\u6570\u636e\u3002\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6807\u6ce8\u6210\u672c\u9ad8\u3001\u901f\u5ea6\u6162\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "1) \u4f7f\u7528LLM\u4ece\u79cd\u5b50\u6587\u6863\u5408\u6210\u771f\u5b9e\u4f01\u4e1a\u67e5\u8be2\uff1b2) \u5e94\u7528BM25\u68c0\u7d22\u56f0\u96be\u8d1f\u6837\u672c\uff1b3) \u4f7f\u7528\u6559\u5e08LLM\u5206\u914d\u76f8\u5173\u6027\u5206\u6570\uff1b4) \u5c06\u5408\u6210\u6570\u636e\u96c6\u84b8\u998f\u5230\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u751f\u6210\u7d27\u51d1\u7684\u76f8\u5173\u6027\u6807\u6ce8\u5668\u3002", "result": "\u5728923\u4e2a\u4f01\u4e1a\u67e5\u8be2-\u6587\u6863\u5bf9\u7684\u4eba\u5de5\u6807\u6ce8\u57fa\u51c6\u4e0a\uff0c\u84b8\u998f\u540e\u7684\u5c0f\u578b\u6a21\u578b\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u4e00\u81f4\u6027\u8fbe\u5230\u6216\u8d85\u8fc7\u6559\u5e08LLM\u6c34\u5e73\u3002\u541e\u5410\u91cf\u63d0\u534717\u500d\uff0c\u6210\u672c\u6548\u76ca\u63d0\u9ad819\u500d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u3001\u6210\u672c\u6548\u76ca\u9ad8\u7684\u4f01\u4e1a\u7ea7\u76f8\u5173\u6027\u6807\u6ce8\uff0c\u652f\u6301\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5feb\u901f\u79bb\u7ebf\u8bc4\u4f30\u548c\u8fed\u4ee3\uff0c\u4e3a\u4f01\u4e1a\u641c\u7d22\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
