<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 5]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [BookRAG: A Hierarchical Structure-aware Index-based Approach for Retrieval-Augmented Generation on Complex Documents](https://arxiv.org/abs/2512.03413)
*Shu Wang,Yingli Zhou,Yixiang Fang*

Main category: cs.IR

TL;DR: BookRAG：针对具有层次结构的文档（如书籍、手册等）提出的新型检索增强生成方法，通过构建层次化索引和实体关系图来提升问答性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法通常处理一般文档，忽略了现实世界中许多文档（如书籍、手册等）具有层次结构的特点，导致在问答任务上表现不佳。

Method: 1. 构建BookIndex：从文档中提取层次树（作为目录），用图捕捉实体间复杂关系，并将实体映射到树节点；2. 基于信息觅食理论的智能体查询方法：动态分类查询并采用定制化的检索工作流。

Result: 在三个广泛采用的基准测试中，BookRAG实现了最先进的性能，在检索召回率和问答准确性方面显著优于基线方法，同时保持竞争性的效率。

Conclusion: BookRAG是针对层次结构文档的有效RAG方法，通过利用逻辑层次和实体关系显著提升了问答任务的性能。

Abstract: As an effective method to boost the performance of Large Language Models (LLMs) on the question answering (QA) task, Retrieval-Augmented Generation (RAG), which queries highly relevant information from external complex documents, has attracted tremendous attention from both industry and academia. Existing RAG approaches often focus on general documents, and they overlook the fact that many real-world documents (such as books, booklets, handbooks, etc.) have a hierarchical structure, which organizes their content from different granularity levels, leading to poor performance for the QA task. To address these limitations, we introduce BookRAG, a novel RAG approach targeted for documents with a hierarchical structure, which exploits logical hierarchies and traces entity relations to query the highly relevant information. Specifically, we build a novel index structure, called BookIndex, by extracting a hierarchical tree from the document, which serves as the role of its table of contents, using a graph to capture the intricate relationships between entities, and mapping entities to tree nodes. Leveraging the BookIndex, we then propose an agent-based query method inspired by the Information Foraging Theory, which dynamically classifies queries and employs a tailored retrieval workflow. Extensive experiments on three widely adopted benchmarks demonstrate that BookRAG achieves state-of-the-art performance, significantly outperforming baselines in both retrieval recall and QA accuracy while maintaining competitive efficiency.

</details>


### [2] [LLM as Explainable Re-Ranker for Recommendation System](https://arxiv.org/abs/2512.03439)
*Yaqi Wang,Haojia Sun,Shuting Zhang*

Main category: cs.IR

TL;DR: 使用LLM作为可解释的重排序器，结合传统推荐模型提升准确性和可解释性


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统缺乏可解释性且存在流行度偏差问题，而LLM作为独立预测器无法达到传统模型的准确性

Method: 提出混合方法：使用LLM作为可解释的重排序器，结合传统推荐模型；构建数据集训练重排序LLM，采用两阶段训练过程

Result: 模型显著提升了NDCG排名指标，重排序器在排名准确性和可解释性上均优于零样本基线

Conclusion: 结合传统推荐模型与LLM能够解决现有系统的局限性，为更可解释和公平的推荐框架铺平道路

Abstract: The application of large language models (LLMs) in recommendation systems has recently gained traction. Traditional recommendation systems often lack explainability and suffer from issues such as popularity bias. Previous research has also indicated that LLMs, when used as standalone predictors, fail to achieve accuracy comparable to traditional models. To address these challenges, we propose to use LLM as an explainable re-ranker, a hybrid approach that combines traditional recommendation models with LLMs to enhance both accuracy and interpretability. We constructed a dataset to train the re-ranker LLM and evaluated the alignment between the generated dataset and human expectations. Leveraging a two-stage training process, our model significantly improved NDCG, a key ranking metric. Moreover, the re-ranker outperformed a zero-shot baseline in ranking accuracy and interpretability. These results highlight the potential of integrating traditional recommendation models with LLMs to address limitations in existing systems and pave the way for more explainable and fair recommendation frameworks.

</details>


### [3] [M3DR: Towards Universal Multilingual Multimodal Document Retrieval](https://arxiv.org/abs/2512.03514)
*Adithya S Kolavi,Vyoman Jain*

Main category: cs.IR

TL;DR: M3DR是一个多语言多模态文档检索框架，通过合成多语言数据和对比训练，在22种语言上实现了跨语言和跨模态对齐，性能提升约150%。


<details>
  <summary>Details</summary>
Motivation: 现有多模态文档检索系统主要针对英语，在多语言环境中效果有限，需要开发能够适应不同语言和文化背景的框架。

Method: 利用合成多语言文档数据，采用对比训练学习文本和文档图像的统一表示，支持不同视觉-语言架构和模型大小，涵盖密集向量和ColBERT式多向量检索范式。

Result: 在22种类型多样的语言上验证了性能，NetraEmbed和ColNetraEmbed模型在跨语言检索上实现了约150%的相对改进，达到最先进水平。

Conclusion: M3DR框架成功解决了多语言多模态文档检索的挑战，能够有效处理语言和文字变体，为实际多语言场景提供了强大的解决方案。

Abstract: Multimodal document retrieval systems have shown strong progress in aligning visual and textual content for semantic search. However, most existing approaches remain heavily English-centric, limiting their effectiveness in multilingual contexts. In this work, we present M3DR (Multilingual Multimodal Document Retrieval), a framework designed to bridge this gap across languages, enabling applicability across diverse linguistic and cultural contexts. M3DR leverages synthetic multilingual document data and generalizes across different vision-language architectures and model sizes, enabling robust cross-lingual and cross-modal alignment. Using contrastive training, our models learn unified representations for text and document images that transfer effectively across languages. We validate this capability on 22 typologically diverse languages, demonstrating consistent performance and adaptability across linguistic and script variations. We further introduce a comprehensive benchmark that captures real-world multilingual scenarios, evaluating models under monolingual, multilingual, and mixed-language settings. M3DR generalizes across both single dense vector and ColBERT-style token-level multi-vector retrieval paradigms. Our models, NetraEmbed and ColNetraEmbed achieve state-of-the-art performance with ~150% relative improvements on cross-lingual retrieval.

</details>


### [4] [Algorithms for Boolean Matrix Factorization using Integer Programming and Heuristics](https://arxiv.org/abs/2512.03807)
*Christos Kolomvakis,Thomas Bobille,Arnaud Vandaele,Nicolas Gillis*

Main category: cs.IR

TL;DR: 本文提出布尔矩阵分解(BMF)的新算法，包括交替优化、整数规划、贪心和局部搜索启发式方法，以及高效的C++数据结构，显著提升了BMF在真实数据集上的性能和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 布尔矩阵分解(BMF)使用布尔OR和AND运算进行矩阵分解，相比基于标准算术的二进制矩阵分解，能提高可解释性并减少近似误差。然而现有方法在可扩展性方面存在限制，需要更高效的算法来处理大规模数据集。

Method: 1. 提出基于交替优化(AO)的算法，每个子问题通过整数规划(IP)求解；2. 设计从多次运行中选择最优秩-1因子子集的方法来增强AO算法；3. 针对IP方法的可扩展性限制，引入新的贪心和局部搜索启发式方法；4. 构建新的C++数据结构，显著加速布尔向量和矩阵运算。

Result: 提出的方法在各种真实数据集上（包括有缺失数据和无缺失数据的情况）表现出色，在主题建模和图像处理等应用中超越了现有技术水平。新的C++数据结构使启发式方法能够扩展到大规模数据集。

Conclusion: 本文开发了一套完整的BMF算法框架，结合了精确优化方法和启发式方法，通过高效的数据结构实现可扩展性，为布尔矩阵分解提供了实用的解决方案，适用于各种实际应用场景。

Abstract: Boolean matrix factorization (BMF) approximates a given binary input matrix as the product of two smaller binary factors. Unlike binary matrix factorization based on standard arithmetic, BMF employs the Boolean OR and AND operations for the matrix product, which improves interpretability and reduces the approximation error. It is also used in role mining and computer vision. In this paper, we first propose algorithms for BMF that perform alternating optimization (AO) of the factor matrices, where each subproblem is solved via integer programming (IP). We then design different approaches to further enhance AO-based algorithms by selecting an optimal subset of rank-one factors from multiple runs. To address the scalability limits of IP-based methods, we introduce new greedy and local-search heuristics. We also construct a new C++ data structure for Boolean vectors and matrices that is significantly faster than existing ones and is of independent interest, allowing our heuristics to scale to large datasets. We illustrate the performance of all our proposed methods and compare them with the state of the art on various real datasets, both with and without missing data, including applications in topic modeling and imaging.

</details>


### [5] [Learning to Comparison-Shop](https://arxiv.org/abs/2512.04009)
*Jie Tang,Daochen Zha,Xin Liu,Huiji Gao,Liwei He,Stephanie Moyerman,Sanjeev Katariya*

Main category: cs.IR

TL;DR: 提出LTCS系统，通过显式建模用户比较购物行为来改进电商搜索排名，在Airbnb等平台实现NDCG提升1.7%，预订转化率提升0.6%。


<details>
  <summary>Details</summary>
Motivation: 当前电商搜索引擎与用户比较购物需求存在脱节，传统排名模型孤立评估商品，忽视用户在搜索结果页面对多个商品进行比较的上下文环境。

Method: 提出Learning-to-Comparison-Shop (LTCS)系统架构，显式建模和学习用户的比较购物行为，通过离线实验和在线A/B测试验证效果。

Result: NDCG提升1.7%，预订转化率提升0.6%，在A/B测试中取得统计显著提升，且优于现有先进方法。

Conclusion: LTCS系统能有效建模用户比较购物行为，显著提升搜索排名效果和业务指标，同时改善用户体验。

Abstract: In online marketplaces like Airbnb, users frequently engage in comparison shopping before making purchase decisions. Despite the prevalence of this behavior, a significant disconnect persists between mainstream e-commerce search engines and users' comparison needs. Traditional ranking models often evaluate items in isolation, disregarding the context in which users compare multiple items on a search results page. While recent advances in deep learning have sought to improve ranking accuracy, diversity, and fairness by encoding listwise context, the challenge of aligning search rankings with user comparison shopping behavior remains inadequately addressed. In this paper, we propose a novel ranking architecture - Learning-to-Comparison-Shop (LTCS) System - that explicitly models and learns users' comparison shopping behaviors. Through extensive offline and online experiments, we demonstrate that our approach yields statistically significant gains in key business metrics - improving NDCG by 1.7% and boosting booking conversion rate by 0.6% in A/B testing - while also enhancing user experience. We also compare our model against state-of-the-art approaches and demonstrate that LTCS significantly outperforms them.

</details>
