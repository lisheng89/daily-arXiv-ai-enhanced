{"id": "2512.23961", "categories": ["cs.IR", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.23961", "abs": "https://arxiv.org/abs/2512.23961", "authors": ["Junjie H. Xu"], "title": "An Comparative Analysis about KYC on a Recommendation System Toward Agentic Recommendation System", "comment": "5 pages, 1 figure", "summary": "This research presents a cutting-edge recommendation system utilizing agentic AI for KYC (Know Your Customer in the financial domain), and its evaluation across five distinct content verticals: Advertising (Ad), News, Gossip, Sharing (User-Generated Content), and Technology (Tech). The study compares the performance of four experimental groups, grouping by the intense usage of KYC, benchmarking them against the Normalized Discounted Cumulative Gain (nDCG) metric at truncation levels of $k=1$, $k=3$, and $k=5$. By synthesizing experimental data with theoretical frameworks and industry benchmarks from platforms such as Baidu and Xiaohongshu, this research provides insight by showing experimental results for engineering a large-scale agentic recommendation system."}
{"id": "2512.24246", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.24246", "abs": "https://arxiv.org/abs/2512.24246", "authors": ["Jie Luo", "Wenyu Zhang", "Xinming Zhang", "Yuan Fang"], "title": "Time-Aware Adaptive Side Information Fusion for Sequential Recommendation", "comment": "10 pages. Accepted by WSDM'26", "summary": "Incorporating item-side information, such as category and brand, into sequential recommendation is a well-established and effective approach for improving performance. However, despite significant advancements, current models are generally limited by three key challenges: they often overlook the fine-grained temporal dynamics inherent in timestamps, exhibit vulnerability to noise in user interaction sequences, and rely on computationally expensive fusion architectures. To systematically address these challenges, we propose the Time-Aware Adaptive Side Information Fusion (TASIF) framework. TASIF integrates three synergistic components: (1) a simple, plug-and-play time span partitioning mechanism to capture global temporal patterns; (2) an adaptive frequency filter that leverages a learnable gate to denoise feature sequences adaptively, thereby providing higher-quality inputs for subsequent fusion modules; and (3) an efficient adaptive side information fusion layer, this layer employs a \"guide-not-mix\" architecture, where attributes guide the attention mechanism without being mixed into the content-representing item embeddings, ensuring deep interaction while ensuring computational efficiency. Extensive experiments on four public datasets demonstrate that TASIF significantly outperforms state-of-the-art baselines while maintaining excellent efficiency in training. Our source code is available at https://github.com/jluo00/TASIF."}
{"id": "2512.24268", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.24268", "abs": "https://arxiv.org/abs/2512.24268", "authors": ["Pankayaraj Pathmanathan", "Michael-Andrei Panaitescu-Liess", "Cho-Yu Jason Chiang", "Furong Huang"], "title": "RAGPart & RAGMask: Retrieval-Stage Defenses Against Corpus Poisoning in Retrieval-Augmented Generation", "comment": "Published at AAAI 2026 Workshop on New Frontiers in Information Retrieval [Oral]", "summary": "Retrieval-Augmented Generation (RAG) has emerged as a promising paradigm to enhance large language models (LLMs) with external knowledge, reducing hallucinations and compensating for outdated information. However, recent studies have exposed a critical vulnerability in RAG pipelines corpus poisoning where adversaries inject malicious documents into the retrieval corpus to manipulate model outputs. In this work, we propose two complementary retrieval-stage defenses: RAGPart and RAGMask. Our defenses operate directly on the retriever, making them computationally lightweight and requiring no modification to the generation model. RAGPart leverages the inherent training dynamics of dense retrievers, exploiting document partitioning to mitigate the effect of poisoned points. In contrast, RAGMask identifies suspicious tokens based on significant similarity shifts under targeted token masking. Across two benchmarks, four poisoning strategies, and four state-of-the-art retrievers, our defenses consistently reduce attack success rates while preserving utility under benign conditions. We further introduce an interpretable attack to stress-test our defenses. Our findings highlight the potential and limitations of retrieval-stage defenses, providing practical insights for robust RAG deployments."}
{"id": "2512.24325", "categories": ["cs.IR", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.24325", "abs": "https://arxiv.org/abs/2512.24325", "authors": ["Wan Jiang", "Xinyi Zang", "Yudong Zhao", "Yusi Zou", "Yunfei Lu", "Junbo Tong", "Yang Liu", "Ming Li", "Jiani Shi", "Xin Yang"], "title": "MaRCA: Multi-Agent Reinforcement Learning for Dynamic Computation Allocation in Large-Scale Recommender Systems", "comment": "12 pages, 5 figures", "summary": "Modern recommender systems face significant computational challenges due to growing model complexity and traffic scale, making efficient computation allocation critical for maximizing business revenue. Existing approaches typically simplify multi-stage computation resource allocation, neglecting inter-stage dependencies, thus limiting global optimality. In this paper, we propose MaRCA, a multi-agent reinforcement learning framework for end-to-end computation resource allocation in large-scale recommender systems. MaRCA models the stages of a recommender system as cooperative agents, using Centralized Training with Decentralized Execution (CTDE) to optimize revenue under computation resource constraints. We introduce an AutoBucket TestBench for accurate computation cost estimation, and a Model Predictive Control (MPC)-based Revenue-Cost Balancer to proactively forecast traffic loads and adjust the revenue-cost trade-off accordingly. Since its end-to-end deployment in the advertising pipeline of a leading global e-commerce platform in November 2024, MaRCA has consistently handled hundreds of billions of ad requests per day and has delivered a 16.67% revenue uplift using existing computation resources."}
{"id": "2512.24366", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.24366", "abs": "https://arxiv.org/abs/2512.24366", "authors": ["Ben Kabongo", "Vincent Guigue"], "title": "On the Factual Consistency of Text-based Explainable Recommendation Models", "comment": "13 pages, 2 figures, 4 tables", "summary": "Text-based explainable recommendation aims to generate natural-language explanations that justify item recommendations, to improve user trust and system transparency. Although recent advances leverage LLMs to produce fluent outputs, a critical question remains underexplored: are these explanations factually consistent with the available evidence? We introduce a comprehensive framework for evaluating the factual consistency of text-based explainable recommenders. We design a prompting-based pipeline that uses LLMs to extract atomic explanatory statements from reviews, thereby constructing a ground truth that isolates and focuses on their factual content. Applying this pipeline to five categories from the Amazon Reviews dataset, we create augmented benchmarks for fine-grained evaluation of explanation quality. We further propose statement-level alignment metrics that combine LLM- and NLI-based approaches to assess both factual consistency and relevance of generated explanations. Across extensive experiments on six state-of-the-art explainable recommendation models, we uncover a critical gap: while models achieve high semantic similarity scores (BERTScore F1: 0.81-0.90), all our factuality metrics reveal alarmingly low performance (LLM-based statement-level precision: 4.38%-32.88%). These findings underscore the need for factuality-aware evaluation in explainable recommendation and provide a foundation for developing more trustworthy explanation systems."}
{"id": "2512.24711", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.24711", "abs": "https://arxiv.org/abs/2512.24711", "authors": ["Kangyang Luo", "Shuzheng Si", "Yuzhuo Bai", "Cheng Gao", "Zhitong Wang", "Cheng Huang", "Yingli Shen", "Yufeng Han", "Wenhao Li", "Cunliang Kong", "Maosong Sun"], "title": "MEIC-DT: Memory-Efficient Incremental Clustering for Long-Text Coreference Resolution with Dual-Threshold Constraints", "comment": null, "summary": "In the era of large language models (LLMs), supervised neural methods remain the state-of-the-art (SOTA) for Coreference Resolution. Yet, their full potential is underexplored, particularly in incremental clustering, which faces the critical challenge of balancing efficiency with performance for long texts. To address the limitation, we propose \\textbf{MEIC-DT}, a novel dual-threshold, memory-efficient incremental clustering approach based on a lightweight Transformer. MEIC-DT features a dual-threshold constraint mechanism designed to precisely control the Transformer's input scale within a predefined memory budget. This mechanism incorporates a Statistics-Aware Eviction Strategy (\\textbf{SAES}), which utilizes distinct statistical profiles from the training and inference phases for intelligent cache management. Furthermore, we introduce an Internal Regularization Policy (\\textbf{IRP}) that strategically condenses clusters by selecting the most representative mentions, thereby preserving semantic integrity. Extensive experiments on common benchmarks demonstrate that MEIC-DT achieves highly competitive coreference performance under stringent memory constraints."}
{"id": "2512.24715", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.24715", "abs": "https://arxiv.org/abs/2512.24715", "authors": ["Kang Fu", "Honglei Zhang", "Xuechao Zou", "Yidong Li"], "title": "MDiffFR: Modality-Guided Diffusion Generation for Cold-start Items in Federated Recommendation", "comment": null, "summary": "Federated recommendations (FRs) provide personalized services while preserving user privacy by keeping user data on local clients, which has attracted significant attention in recent years. However, due to the strict privacy constraints inherent in FRs, access to user-item interaction data and user profiles across clients is highly restricted, making it difficult to learn globally effective representations for new (cold-start) items. Consequently, the item cold-start problem becomes even more challenging in FRs. Existing solutions typically predict embeddings for new items through the attribute-to-embedding mapping paradigm, which establishes a fixed one-to-one correspondence between item attributes and their embeddings. However, this one-to-one mapping paradigm often fails to model varying data distributions and tends to cause embedding misalignment, as verified by our empirical studies. To this end, we propose MDiffFR, a novel generation-based modality-guided diffusion method for cold-start items in FRs. In this framework, we employ a tailored diffusion model on the server to generate embeddings for new items, which are then distributed to clients for cold-start inference. To align item semantics, we deploy a pre-trained modality encoder to extract modality features as conditional signals to guide the reverse denoising process. Furthermore, our theoretical analysis verifies that the proposed method achieves stronger privacy guarantees compared to existing mapping-based approaches. Extensive experiments on four real datasets demonstrate that our method consistently outperforms all baselines in FRs."}
{"id": "2512.24762", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.24762", "abs": "https://arxiv.org/abs/2512.24762", "authors": ["Guorui Zhou", "Honghui Bao", "Jiaming Huang", "Jiaxin Deng", "Jinghao Zhang", "Junda She", "Kuo Cai", "Lejian Ren", "Lu Ren", "Qiang Luo", "Qianqian Wang", "Qigen Hu", "Rongzhou Zhang", "Ruiming Tang", "Shiyao Wang", "Wuchao Li", "Xiangyu Wu", "Xinchen Luo", "Xingmei Wang", "Yifei Hu", "Yunfan Wu", "Zhanyu Liu", "Zhiyang Zhang", "Zixing Zhang", "Bo Chen", "Bin Wen", "Chaoyi Ma", "Chengru Song", "Chenglong Chu", "Defu Lian", "Fan Yang", "Feng Jiang", "Hongtao Cheng", "Huanjie Wang", "Kun Gai", "Pengfei Zheng", "Qiang Wang", "Rui Huang", "Siyang Mao", "Tingting Gao", "Wei Yuan", "Yan Wang", "Yang Zhou", "Yi Su", "Zexuan Cheng", "Zhixin Ling", "Ziming Li"], "title": "OpenOneRec Technical Report", "comment": null, "summary": "While the OneRec series has successfully unified the fragmented recommendation pipeline into an end-to-end generative framework, a significant gap remains between recommendation systems and general intelligence. Constrained by isolated data, they operate as domain specialists-proficient in pattern matching but lacking world knowledge, reasoning capabilities, and instruction following. This limitation is further compounded by the lack of a holistic benchmark to evaluate such integrated capabilities. To address this, our contributions are: 1) RecIF Bench & Open Data: We propose RecIF-Bench, a holistic benchmark covering 8 diverse tasks that thoroughly evaluate capabilities from fundamental prediction to complex reasoning. Concurrently, we release a massive training dataset comprising 96 million interactions from 160,000 users to facilitate reproducible research. 2) Framework & Scaling: To ensure full reproducibility, we open-source our comprehensive training pipeline, encompassing data processing, co-pretraining, and post-training. Leveraging this framework, we demonstrate that recommendation capabilities can scale predictably while mitigating catastrophic forgetting of general knowledge. 3) OneRec-Foundation: We release OneRec Foundation (1.7B and 8B), a family of models establishing new state-of-the-art (SOTA) results across all tasks in RecIF-Bench. Furthermore, when transferred to the Amazon benchmark, our models surpass the strongest baselines with an average 26.8% improvement in Recall@10 across 10 diverse datasets (Figure 1). This work marks a step towards building truly intelligent recommender systems. Nonetheless, realizing this vision presents significant technical and theoretical challenges, highlighting the need for broader research engagement in this promising direction."}
{"id": "2512.24787", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.24787", "abs": "https://arxiv.org/abs/2512.24787", "authors": ["Yunsheng Pang", "Zijian Liu", "Yudong Li", "Shaojie Zhu", "Zijian Luo", "Chenyun Yu", "Sikai Wu", "Shichen Shen", "Cong Xu", "Bin Wang", "Kai Jiang", "Hongyong Yu", "Chengxiang Zhuo", "Zang Li"], "title": "HiGR: Efficient Generative Slate Recommendation via Hierarchical Planning and Multi-Objective Preference Alignment", "comment": null, "summary": "Slate recommendation, where users are presented with a ranked list of items simultaneously, is widely adopted in online platforms. Recent advances in generative models have shown promise in slate recommendation by modeling sequences of discrete semantic IDs autoregressively. However, existing autoregressive approaches suffer from semantically entangled item tokenization and inefficient sequential decoding that lacks holistic slate planning. To address these limitations, we propose HiGR, an efficient generative slate recommendation framework that integrates hierarchical planning with listwise preference alignment. First, we propose an auto-encoder utilizing residual quantization and contrastive constraints to tokenize items into semantically structured IDs for controllable generation. Second, HiGR decouples generation into a list-level planning stage for global slate intent, followed by an item-level decoding stage for specific item selection. Third, we introduce a listwise preference alignment objective to directly optimize slate quality using implicit user feedback. Experiments on our large-scale commercial media platform demonstrate that HiGR delivers consistent improvements in both offline evaluations and online deployment. Specifically, it outperforms state-of-the-art methods by over 10% in offline recommendation quality with a 5x inference speedup, while further achieving a 1.22% and 1.73% increase in Average Watch Time and Average Video Views in online A/B tests."}
{"id": "2512.24943", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24943", "abs": "https://arxiv.org/abs/2512.24943", "authors": ["Chenji Lu", "Zhuo Chen", "Hui Zhao", "Zhenyi Wang", "Pengjie Wang", "Jian Xu", "Bo Zheng"], "title": "RAIR: A Rule-Aware Benchmark Uniting Challenging Long-Tail and Visual Salience Subset for E-commerce Relevance Assessment", "comment": null, "summary": "Search relevance plays a central role in web e-commerce. While large language models (LLMs) have shown significant results on relevance task, existing benchmarks lack sufficient complexity for comprehensive model assessment, resulting in an absence of standardized relevance evaluation metrics across the industry. To address this limitation, we propose Rule-Aware benchmark with Image for Relevance assessment(RAIR), a Chinese dataset derived from real-world scenarios. RAIR established a standardized framework for relevance assessment and provides a set of universal rules, which forms the foundation for standardized evaluation. Additionally, RAIR analyzes essential capabilities required for current relevance models and introduces a comprehensive dataset consists of three subset: (1) a general subset with industry-balanced sampling to evaluate fundamental model competencies; (2) a long-tail hard subset focus on challenging cases to assess performance limits; (3) a visual salience subset for evaluating multimodal understanding capabilities. We conducted experiments on RAIR using 14 open and closed-source models. The results demonstrate that RAIR presents sufficient challenges even for GPT-5, which achieved the best performance. RAIR data are now available, serving as an industry benchmark for relevance assessment while providing new insights into general LLM and Visual Language Model(VLM) evaluation."}
