<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 9]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Legal Retrieval for Public Defenders](https://arxiv.org/abs/2601.14348)
*Dominik Stammbach,Kylie Zhang,Patty Liu,Nimra Nadeem,Lucia Zheng,Peter Henderson*

Main category: cs.IR

TL;DR: 开发NJ BriefBank检索工具，帮助公设辩护人快速查找相关上诉状，改进法律检索基准


<details>
  <summary>Details</summary>
Motivation: 公设辩护机构面临案件量大、资源有限的挑战，AI工具可能提供帮助，但目前缺乏AI如何有效支持辩护人日常工作的证据

Method: 与纽泽西公设辩护办公室合作开发NJ BriefBank检索工具，通过添加领域知识（法律推理查询扩展、领域特定数据、精心设计的合成示例）改进检索质量

Result: 现有法律检索基准无法直接应用于公设辩护检索，但添加领域知识能显著提升检索质量；提供了现实辩护人查询分类和手动标注的公设辩护检索数据集

Conclusion: 为构建实用可靠的法律检索AI工具提供了起点，并为更现实的法律检索基准奠定了基础

Abstract: AI tools are increasingly suggested as solutions to assist public agencies with heavy workloads. In public defense, where a constitutional right to counsel meets the complexities of law, overwhelming caseloads and constrained resources, practitioners face especially taxing conditions. Yet, there is little evidence of how AI could meaningfully support defenders' day-to-day work. In partnership with the New Jersey Office of the Public Defender, we develop the NJ BriefBank, a retrieval tool which surfaces relevant appellate briefs to streamline legal research and writing. We show that existing legal retrieval benchmarks fail to transfer to public defense search, however adding domain knowledge improves retrieval quality. This includes query expansion with legal reasoning, domain-specific data and curated synthetic examples. To facilitate further research, we provide a taxonomy of realistic defender search queries and release a manually annotated public defense retrieval dataset. Together, our work offers starting points towards building practical, reliable retrieval AI tools for public defense, and towards more realistic legal retrieval benchmarks.

</details>


### [2] [Trust Me on This: A User Study of Trustworthiness for RAG Responses](https://arxiv.org/abs/2601.14460)
*Weronika Łajewska,Krisztian Balog*

Main category: cs.IR

TL;DR: 研究探讨了不同解释类型如何影响用户对检索增强生成系统响应的信任，发现解释能引导用户选择更高质量回答，但信任还受响应清晰度、可操作性和用户先验知识影响。


<details>
  <summary>Details</summary>
Motivation: 生成式AI集成到信息访问系统时，常提供缺乏透明度的合成答案，需要研究不同类型的解释如何影响用户对检索增强生成系统响应的信任。

Method: 进行受控的两阶段用户研究，参与者从一对响应中选择更可信的响应（一个客观质量更高），比较三种解释类型：来源归属、事实基础、信息覆盖度，以及无解释情况。

Result: 解释显著引导用户选择更高质量的响应，但信任不完全由客观质量决定，还受响应清晰度、可操作性和用户先验知识的强烈影响。

Conclusion: 解释设计在增强AI系统透明度方面至关重要，需要平衡客观质量与用户感知因素（如清晰度和可操作性），才能有效建立用户信任。

Abstract: The integration of generative AI into information access systems often presents users with synthesized answers that lack transparency. This study investigates how different types of explanations can influence user trust in responses from retrieval-augmented generation systems. We conducted a controlled, two-stage user study where participants chose the more trustworthy response from a pair-one objectively higher quality than the other-both with and without one of three explanation types: (1) source attribution, (2) factual grounding, and (3) information coverage. Our results show that while explanations significantly guide users toward selecting higher quality responses, trust is not dictated by objective quality alone: Users' judgments are also heavily influenced by response clarity, actionability, and their own prior knowledge.

</details>


### [3] [Predicting Retrieval Utility and Answer Quality in Retrieval-Augmented Generation](https://arxiv.org/abs/2601.14546)
*Fangzheng Tian,Debasis Ganguly,Craig Macdonald*

Main category: cs.IR

TL;DR: 本文提出在检索增强生成(RAG)中预测检索文档效用和最终答案质量的方法，通过结合检索器中心特征、阅读器中心特征和文档质量特征来提升预测准确性。


<details>
  <summary>Details</summary>
Motivation: RAG中生成答案的质量受检索文档上下文信息影响很大，但缺乏有效方法来预测检索文档的效用和最终答案的质量，这限制了RAG性能的进一步提升。

Method: 定义两个预测任务：检索性能预测(RPP)和生成性能预测(GPP)。提出三类预测特征：1)基于查询性能预测(QPP)的检索器中心特征；2)基于LLM困惑度的阅读器中心特征；3)查询无关的文档质量和可读性特征。使用线性回归模型进行预测。

Result: 在Natural Questions数据集上的实验表明，结合多个特征类别的预测器能够最准确地估计RAG性能，验证了所提方法的有效性。

Conclusion: 通过系统性地整合检索器中心、阅读器中心和文档质量特征，可以有效地预测RAG中的检索文档效用和最终答案质量，为RAG性能优化提供了重要工具。

Abstract: The quality of answers generated by large language models (LLMs) in retrieval-augmented generation (RAG) is largely influenced by the contextual information contained in the retrieved documents. A key challenge for improving RAG is to predict both the utility of retrieved documents -- quantified as the performance gain from using context over generation without context -- and the quality of the final answers in terms of correctness and relevance. In this paper, we define two prediction tasks within RAG. The first is retrieval performance prediction (RPP), which estimates the utility of retrieved documents. The second is generation performance prediction (GPP), which estimates the final answer quality. We hypothesise that in RAG, the topical relevance of retrieved documents correlates with their utility, suggesting that query performance prediction (QPP) approaches can be adapted for RPP and GPP. Beyond these retriever-centric signals, we argue that reader-centric features, such as the LLM's perplexity of the retrieved context conditioned on the input query, can further enhance prediction accuracy for both RPP and GPP. Finally, we propose that features reflecting query-agnostic document quality and readability can also provide useful signals to the predictions. We train linear regression models with the above categories of predictors for both RPP and GPP. Experiments on the Natural Questions (NQ) dataset show that combining predictors from multiple feature categories yields the most accurate estimates of RAG performance.

</details>


### [4] [When Text-as-Vision Meets Semantic IDs in Generative Recommendation: An Empirical Study](https://arxiv.org/abs/2601.14697)
*Shutong Qiao,Wei Yuan,Tong Chen,Xiangyu Zhao,Quoc Viet Hung Nguyen,Hongzhi Yin*

Main category: cs.IR

TL;DR: 该论文提出将文本作为视觉信号处理，使用OCR模型编码商品描述图像，在生成式推荐中显著提升语义ID学习效果


<details>
  <summary>Details</summary>
Motivation: 传统文本编码器主要针对自然语言优化，但在推荐系统中商品描述常包含数字、单位、缩写等符号化内容，导致语义碎片化。在多模态生成式推荐中，文本和图像嵌入的几何结构不匹配进一步影响跨模态融合效果。

Method: 将商品描述渲染为图像，使用基于视觉的OCR模型进行编码，获得OCR文本表示。在四个数据集和两种生成式骨干网络上进行系统性实验验证。

Result: OCR文本表示在单模态和多模态设置下均能匹配或超越标准文本嵌入的语义ID学习效果。即使在极端空间分辨率压缩下，OCR语义ID仍保持鲁棒性。

Conclusion: 将文本作为视觉信号处理，通过OCR模型编码商品描述图像，能够有效解决传统文本编码器在推荐系统中的局限性，提供更鲁棒高效的语义ID学习方案。

Abstract: Semantic ID learning is a key interface in Generative Recommendation (GR) models, mapping items to discrete identifiers grounded in side information, most commonly via a pretrained text encoder. However, these text encoders are primarily optimized for well-formed natural language. In real-world recommendation data, item descriptions are often symbolic and attribute-centric, containing numerals, units, and abbreviations. These text encoders can break these signals into fragmented tokens, weakening semantic coherence and distorting relationships among attributes. Worse still, when moving to multimodal GR, relying on standard text encoders introduces an additional obstacle: text and image embeddings often exhibit mismatched geometric structures, making cross-modal fusion less effective and less stable.
  In this paper, we revisit representation design for Semantic ID learning by treating text as a visual signal. We conduct a systematic empirical study of OCR-based text representations, obtained by rendering item descriptions into images and encoding them with vision-based OCR models. Experiments across four datasets and two generative backbones show that OCR-text consistently matches or surpasses standard text embeddings for Semantic ID learning in both unimodal and multimodal settings. Furthermore, we find that OCR-based Semantic IDs remain robust under extreme spatial-resolution compression, indicating strong robustness and efficiency in practical deployments.

</details>


### [5] [Unified Multimodal and Multilingual Retrieval via Multi-Task Learning with NLU Integration](https://arxiv.org/abs/2601.14714)
*Xinyuan Zhang,Lina Zhang,Lisung Chen,Guangyao Liu,Shuai Nie,Jiaming Xu,Runyu Shi,Ying Huang,Guoquan Zhang*

Main category: cs.IR

TL;DR: 提出统一多模态检索框架，首次联合优化多语言图像检索、文本检索和自然语言理解任务，使用共享文本编码器提升意图理解和检索准确性


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在文本检索任务上表现不佳，添加额外文本编码器会增加存储和推理开销，在多语言环境下检索效率问题更严重

Method: 采用多任务学习框架，统一图像、长短文本和意图丰富查询的特征表示，集成图像和文本检索，使用共享文本编码器并通过NLU特征增强

Result: 这是首个在单一框架内联合优化多语言图像检索、文本检索和自然语言理解任务的工作

Conclusion: 提出的方法解决了多模态检索系统的局限性，通过统一表示和共享编码器提高了检索效率和准确性

Abstract: Multimodal retrieval systems typically employ Vision Language Models (VLMs) that encode images and text independently into vectors within a shared embedding space. Despite incorporating text encoders, VLMs consistently underperform specialized text models on text-only retrieval tasks. Moreover, introducing additional text encoders increases storage, inference overhead, and exacerbates retrieval inefficiencies, especially in multilingual settings. To address these limitations, we propose a multi-task learning framework that unifies the feature representation across images, long and short texts, and intent-rich queries. To our knowledge, this is the first work to jointly optimize multilingual image retrieval, text retrieval, and natural language understanding (NLU) tasks within a single framework. Our approach integrates image and text retrieval with a shared text encoder that is enhanced by NLU features for intent understanding and retrieval accuracy.

</details>


### [6] [PULSE: Socially-Aware User Representation Modeling Toward Parameter-Efficient Graph Collaborative Filtering](https://arxiv.org/abs/2601.14720)
*Doyun Choi,Cheonwoo Lee,Biniyam Aschalew Tolera,Taewook Ham,Chanyoung Park,Jaemin Yoo*

Main category: cs.IR

TL;DR: 提出PULSE框架，通过从社交信号构建用户表示而非显式学习嵌入，减少参数达50%，在稀疏交互场景下超越13个基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的社交推荐方法面临计算成本高、可扩展性有限的问题，因为需要为所有用户和物品分配显式嵌入参数。

Method: 提出PULSE框架，从社交有意义的信号构建用户表示，而不为每个用户创建显式可学习嵌入，实现参数高效的用户表示学习。

Result: 相比最轻量级GCF基线减少参数达50%，在13个GCF和基于图的社交推荐基线上实现SOTA性能，在从冷启动到高活跃用户的不同交互稀疏度场景中均表现优异。

Conclusion: PULSE通过参数高效的用户表示学习方法，解决了现有图社交推荐方法的计算和可扩展性限制，在保持高性能的同时显著减少模型参数。

Abstract: Graph-based social recommendation (SocialRec) has emerged as a powerful extension of graph collaborative filtering (GCF), which leverages graph neural networks (GNNs) to capture multi-hop collaborative signals from user-item interactions. These methods enrich user representations by incorporating social network information into GCF, thereby integrating additional collaborative signals from social relations. However, existing GCF and graph-based SocialRec approaches face significant challenges: they incur high computational costs and suffer from limited scalability due to the large number of parameters required to assign explicit embeddings to all users and items. In this work, we propose PULSE (Parameter-efficient User representation Learning with Social Knowledge), a framework that addresses this limitation by constructing user representations from socially meaningful signals without creating an explicit learnable embedding for each user. PULSE reduces the parameter size by up to 50% compared to the most lightweight GCF baseline. Beyond parameter efficiency, our method achieves state-of-the-art performance, outperforming 13 GCF and graph-based social recommendation baselines across varying levels of interaction sparsity, from cold-start to highly active users, through a time- and memory-efficient modeling process.

</details>


### [7] [What Should I Cite? A RAG Benchmark for Academic Citation Prediction](https://arxiv.org/abs/2601.14949)
*Leqi Zheng,Jiajun Zhang,Canzhi Chen,Chaokun Wang,Hongwei Li,Yuying Li,Yaoxin Mao,Shannan Yan,Zixin Song,Zhiyuan Feng,Zhaolu Kang,Zirong Chen,Hang Zhang,Qiang Liu,Liang Wang,Ziyang Liu*

Main category: cs.IR

TL;DR: CiteRAG是首个集成检索增强生成（RAG）的学术引用预测基准，包含多级检索策略、专用检索器和生成器，提供全面评估框架。


<details>
  <summary>Details</summary>
Motivation: 随着网络学术出版物快速增长，每年发表的论文数量激增，学者越来越难找到相关前期工作。引用预测旨在自动推荐合适参考文献，帮助学者在扩展的科学文献中导航。

Method: 提出多级混合RAG方法用于引用预测：1）建立两个不同粒度的引用预测任务实例；2）构建包含554k论文的三级大规模语料库；3）通过对比学习微调嵌入模型捕捉复杂引用关系；4）结合专用生成模型。

Result: 构建了包含7,267个实例的任务1数据集和8,541个实例的任务2数据集，在包括闭源API、开源模型和微调生成器在内的最先进语言模型上进行了广泛实验，证明了框架的有效性。

Conclusion: CiteRAG提供了首个全面的引用预测评估框架，可作为其他科学领域的方法模板，开源工具包支持可重复评估并专注于学术文献。

Abstract: With the rapid growth of Web-based academic publications, more and more papers are being published annually, making it increasingly difficult to find relevant prior work. Citation prediction aims to automatically suggest appropriate references, helping scholars navigate the expanding scientific literature. Here we present \textbf{CiteRAG}, the first comprehensive retrieval-augmented generation (RAG)-integrated benchmark for evaluating large language models on academic citation prediction, featuring a multi-level retrieval strategy, specialized retrievers, and generators. Our benchmark makes four core contributions: (1) We establish two instances of the citation prediction task with different granularity. Task 1 focuses on coarse-grained list-specific citation prediction, while Task 2 targets fine-grained position-specific citation prediction. To enhance these two tasks, we build a dataset containing 7,267 instances for Task 1 and 8,541 instances for Task 2, enabling comprehensive evaluation of both retrieval and generation. (2) We construct a three-level large-scale corpus with 554k papers spanning many major subfields, using an incremental pipeline. (3) We propose a multi-level hybrid RAG approach for citation prediction, fine-tuning embedding models with contrastive learning to capture complex citation relationships, paired with specialized generation models. (4) We conduct extensive experiments across state-of-the-art language models, including closed-source APIs, open-source models, and our fine-tuned generators, demonstrating the effectiveness of our framework. Our open-source toolkit enables reproducible evaluation and focuses on academic literature, providing the first comprehensive evaluation framework for citation prediction and serving as a methodological template for other scientific domains. Our source code and data are released at https://github.com/LQgdwind/CiteRAG.

</details>


### [8] [From Insight to Intervention: Interpretable Neuron Steering for Controlling Popularity Bias in Recommender Systems](https://arxiv.org/abs/2601.15122)
*Parviz Ahmadov,Masoud Mansoury*

Main category: cs.IR

TL;DR: PopSteer：一种基于稀疏自编码器的后处理方法，用于解释和缓解推荐系统中的流行度偏差，通过识别编码流行度信号的神经元并调整其激活来实现公平性控制。


<details>
  <summary>Details</summary>
Motivation: 推荐系统中普遍存在流行度偏差问题，少数热门物品占据大部分注意力，而多数非热门物品曝光不足。现有缓解方法往往缺乏透明度，无法解释其工作原理。

Method: 提出PopSteer方法：1）使用稀疏自编码器（SAE）复制已训练推荐模型的行为，实现神经元级可解释性；2）创建偏好热门或非热门物品的合成用户，通过激活模式识别编码流行度信号的神经元；3）通过调整最偏置神经元的激活来引导推荐结果。

Result: 在三个公开数据集上的顺序推荐模型实验中，PopSteer显著提高了公平性，同时对准确性影响最小，提供了可解释的洞察和细粒度的公平性-准确性权衡控制。

Conclusion: PopSteer提供了一种透明、可解释的后处理方法，有效缓解推荐系统中的流行度偏差问题，在保持推荐准确性的同时提升公平性，并允许细粒度的公平性-准确性权衡控制。

Abstract: Popularity bias is a pervasive challenge in recommender systems, where a few popular items dominate attention while the majority of less popular items remain underexposed. This imbalance can reduce recommendation quality and lead to unfair item exposure. Although existing mitigation methods address this issue to some extent, they often lack transparency in how they operate. In this paper, we propose a post-hoc approach, PopSteer, that leverages a Sparse Autoencoder (SAE) to both interpret and mitigate popularity bias in recommendation models. The SAE is trained to replicate a trained model's behavior while enabling neuron-level interpretability. By introducing synthetic users with strong preferences for either popular or unpopular items, we identify neurons encoding popularity signals through their activation patterns. We then steer recommendations by adjusting the activations of the most biased neurons. Experiments on three public datasets with a sequential recommendation model demonstrate that PopSteer significantly enhances fairness with minimal impact on accuracy, while providing interpretable insights and fine-grained control over the fairness-accuracy trade-off.

</details>


### [9] [Beyond the Geometric Curse: High-Dimensional N-Gram Hashing for Dense Retrieval](https://arxiv.org/abs/2601.15205)
*Sangeet Sharma*

Main category: cs.IR

TL;DR: NUMEN使用确定性字符哈希将文本直接投影到高维向量，无需训练，突破了密集检索中的维度瓶颈，首次在LIMIT基准上超越BM25基线。


<details>
  <summary>Details</summary>
Motivation: 当前强大的7B参数嵌入模型在简单检索任务上表现不如几十年前的BM25，理论表明这是由于维度瓶颈问题——将无限的语言细微差别压缩到固定长度的小向量中。

Method: NUMEN采用确定性字符哈希方法，完全移除学习过程，直接将语言投影到高维向量。这种方法无需训练，支持无限词汇表，几何容量可按需扩展。

Result: 在LIMIT基准测试中，NUMEN在32,768维度下达到93.90%的Recall@100，首次使密集检索模型正式超越稀疏BM25基线（93.6%）。

Conclusion: 密集检索的真正问题不在于架构，而在于嵌入层本身。解决方案不一定是更智能的训练，而是为表示提供更多空间。

Abstract: Why do even the most powerful 7B-parameter embedding models struggle with simple retrieval tasks that the decades old BM25 handles with ease? Recent theory suggests that this happens because of a dimensionality bottleneck. This occurs when we force infinite linguistic nuances into small, fixed-length learned vectors. We developed NUMEN to break this bottleneck by removing the learning process entirely. Instead of training heavy layers to map text to a constrained space, NUMEN uses deterministic character hashing to project language directly onto high-dimensional vectors. This approach requires no training, supports an unlimited vocabulary, and allows the geometric capacity scale as needed. On the LIMIT benchmark, NUMEN achieves 93.90 % Recall@100 at 32,768 dimensions. This makes it the first dense retrieval model to officially surpass the sparse BM25 baseline 93.6 %. Our findings show that the real problem in dense retrieval isn't the architecture, but the embedding layer itself. The solution isn't necessarily smarter training, but simply providing more room to breathe.

</details>
