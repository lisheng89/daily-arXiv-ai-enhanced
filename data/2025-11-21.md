<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 7]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [QueryGym: A Toolkit for Reproducible LLM-Based Query Reformulation](https://arxiv.org/abs/2511.15996)
*Amin Bigdeli,Radin Hamidi Rad,Mert Incesu,Negar Arabzadeh,Charles L. A. Clarke,Ebrahim Bagheri*

Main category: cs.IR

TL;DR: QueryGym是一个轻量级、可扩展的Python工具包，为基于大语言模型的查询重构提供统一框架，解决现有方法实现分散、难以公平比较的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的查询重构方法虽然能显著提升检索效果，但各方法的实现分散在不同作者手中，缺乏统一工具包，阻碍了公平比较、快速实验、一致基准测试和可靠部署。

Method: 提供Python API支持多种LLM方法应用、检索无关的接口支持Pyserini和PyTerrier等后端集成、集中式提示管理系统、内置BEIR和MS MARCO基准支持，以及完全开源的扩展实现。

Result: 开发了QueryGym工具包，为LLM查询重构方法提供了统一的实现、执行和比较框架。

Conclusion: QueryGym填补了LLM查询重构领域缺乏统一工具包的空白，促进了该领域研究的公平比较和快速发展。

Abstract: We present QueryGym, a lightweight, extensible Python toolkit that supports large language model (LLM)-based query reformulation. This is an important tool development since recent work on llm-based query reformulation has shown notable increase in retrieval effectiveness. However, while different authors have sporadically shared the implementation of their methods, there is no unified toolkit that provides a consistent implementation of such methods, which hinders fair comparison, rapid experimentation, consistent benchmarking and reliable deployment. QueryGym addresses this gap by providing a unified framework for implementing, executing, and comparing llm-based reformulation methods. The toolkit offers: (1) a Python API for applying diverse LLM-based methods, (2) a retrieval-agnostic interface supporting integration with backends such as Pyserini and PyTerrier, (3) a centralized prompt management system with versioning and metadata tracking, (4) built-in support for benchmarks like BEIR and MS MARCO, and (5) a completely open-source extensible implementation available to all researchers. QueryGym is publicly available at https://github.com/radinhamidi/QueryGym.

</details>


### [2] [Incorporating Token Importance in Multi-Vector Retrieval](https://arxiv.org/abs/2511.16106)
*Archish S,Ankit Garg,Kirankumar Shiragur,Neeraj Kayal*

Main category: cs.IR

TL;DR: 本文提出了对ColBERT中Chamfer距离函数的改进，通过计算查询令牌贡献的加权和来增强表达性，其中权重反映令牌重要性。


<details>
  <summary>Details</summary>
Motivation: 探索增强Chamfer距离函数的方法，通过考虑令牌重要性来提升多向量表示机制的表达能力。

Method: 在保持多向量表示固定的情况下，仅训练令牌权重，计算查询令牌贡献的加权和。

Result: 在BEIR基准测试中，零样本设置下使用基于IDF的权重实现了Recall@10平均提升1.28%，通过少量样本微调实现了3.66%的提升。

Conclusion: 这种简单的扩展方法有效增强了后期交互多向量机制的表达能力。

Abstract: ColBERT introduced a late interaction mechanism that independently encodes queries and documents using BERT, and computes similarity via fine-grained interactions over token-level vector representations. This design enables expressive matching while allowing efficient computation of scores, as the multi-vector document representations could be pre-computed offline. ColBERT models distance using a Chamfer-style function: for each query token, it selects the closest document token and sums these distances across all query tokens.
  In our work, we explore enhancements to the Chamfer distance function by computing a weighted sum over query token contributions, where weights reflect the token importance. Empirically, we show that this simple extension, requiring only token-weight training while keeping the multi-vector representations fixed, further enhances the expressiveness of late interaction multi-vector mechanism. In particular, on the BEIR benchmark, our method achieves an average improvement of 1.28\% in Recall@10 in the zero-shot setting using IDF-based weights, and 3.66\% through few-shot fine-tuning.

</details>


### [3] [ARK: Answer-Centric Retriever Tuning via KG-augmented Curriculum Learning](https://arxiv.org/abs/2511.16326)
*Jiawei Zhou,Hang Ding,Haiyun Jiang*

Main category: cs.IR

TL;DR: 提出了一种针对检索增强生成(RAG)的答案对齐微调框架，通过识别高质量正样本块和基于知识图谱的课程对比学习，优化检索器在长上下文场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 标准检索器在长上下文场景中难以区分稀疏但关键的证据，且其查询-文档相似性优化与生成精确答案的下游目标不一致。

Method: 首先评估文本块生成正确答案的充分性来识别高质量正样本，然后使用基于LLM构建知识图谱的课程对比学习方案，生成增强查询并挖掘渐进式困难负样本。

Result: 在Ultradomain和LongBench基准的10个数据集上实现最先进性能，相比基础模型提升14.5%，同时保持长上下文RAG的高效性。

Conclusion: 该方法为构建真正以答案为中心的检索器提供了稳健有效的解决方案。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful framework for knowledge-intensive tasks, yet its effectiveness in long-context scenarios is often bottlenecked by the retriever's inability to distinguish sparse yet crucial evidence. Standard retrievers, optimized for query-document similarity, frequently fail to align with the downstream goal of generating a precise answer. To bridge this gap, we propose a novel fine-tuning framework that optimizes the retriever for Answer Alignment. Specifically, we first identify high-quality positive chunks by evaluating their sufficiency to generate the correct answer. We then employ a curriculum-based contrastive learning scheme to fine-tune the retriever. This curriculum leverages LLM-constructed Knowledge Graphs (KGs) to generate augmented queries, which in turn mine progressively challenging hard negatives. This process trains the retriever to distinguish the answer-sufficient positive chunks from these nuanced distractors, enhancing its generalization. Extensive experiments on 10 datasets from the Ultradomain and LongBench benchmarks demonstrate that our fine-tuned retriever achieves state-of-the-art performance, improving 14.5% over the base model without substantial architectural modifications and maintaining strong efficiency for long-context RAG. Our work presents a robust and effective methodology for building truly answer-centric retrievers.

</details>


### [4] [An Efficient LLM-based Evolutional Recommendation with Locate-Forget-Update Paradigm](https://arxiv.org/abs/2511.16414)
*Hao Liu,Le Wu,Min Hou,Han Wu,Kun Zhang,Xin Li,Si Wei*

Main category: cs.IR

TL;DR: EvoRec是一个高效的定位-遗忘-更新框架，专门为基于LLM的推荐系统设计，用于建模用户偏好的演化，通过精确更新少量参数来节省计算资源并保持推荐性能。


<details>
  <summary>Details</summary>
Motivation: LLM-based推荐系统难以适应随时间变化的用户偏好，因为LLM参数量大，传统重训练或微调方法要么计算成本过高，要么会导致非活跃用户偏好遗忘。

Method: 提出EvoRec框架，通过识别与偏好变化相关的小参数集并进行精确更新，仅修改30%的LoRA适配器参数，不引入额外参数。

Result: 在两个真实数据集上的实验表明，EvoRec能有效演化LLMRec以适应活跃用户偏好，同时保护非活跃用户的兴趣在演化过程中不受干扰。

Conclusion: EvoRec为LLM-based推荐系统提供了一种高效的演化方法，在节省计算资源的同时保持了强大的推荐性能。

Abstract: Nowadays, Large Language Models (LLMs) have shown exceptional performance in sequential recommendations, and the adoption of LLM-based recommender systems (LLMRec) is becoming increasingly widespread in existing e-commerce platforms. Despite the impressive performance, the constant high volume of new user-item interactions makes it difficult to adapt to the evolution of user preference over time, especially for LLM-based recommender systems. The challenge arises from the large number of parameters in LLMs, which makes traditional evolution methods (i.e., Re-training or Fine-tuning) impractical. Specifically, Re-training with all interactions results in prohibitively high computational costs. On the other hand, fine-tuning with only new interactions leads to preference forgetting among inactive users, ultimately compromising overall performance. To tackle this problem, we propose EvoRec, an efficient Locate-Forget-Update framework designed for LLM-based recommender systems to model the evolution of user preferences. EvoRec identifies a small set of parameters associated with preference changes and updates them precisely, thereby saving computational resources while maintaining strong recommendation performance. Notably, the modified parameters account for only 30\% of LoRA adapter parameters, with no additional parameters introduced. Extensive experiments on two real-world datasets demonstrate that, compared to existing methods, EvoRec not only efficiently evolves LLMRec to adapt to the preferences of active users, but also preserves the interests of inactive users from being disturbed during evolution.

</details>


### [5] [Music Recommendation with Large Language Models: Challenges, Opportunities, and Evaluation](https://arxiv.org/abs/2511.16478)
*Elena V. Epure,Yashar Deldjoo,Bruno Sguerra,Markus Schedl,Manuel Moussallam*

Main category: cs.IR

TL;DR: 论文主张LLM驱动的音乐推荐系统需要重新思考评估方法，分析了LLM如何重塑用户建模、物品建模和自然语言推荐，并提出了结构化的成功和风险维度评估框架。


<details>
  <summary>Details</summary>
Motivation: 传统音乐推荐系统基于信息检索框架，主要关注检索准确性，但难以回答"什么是好的推荐"这一根本问题。LLM的出现打破了这一框架，需要重新思考评估方法。

Method: 首先回顾LLM如何重塑音乐推荐的用户建模、物品建模和自然语言推荐；然后借鉴NLP领域的评估实践；最后通过LLM提示技术提出结构化的成功和风险维度评估框架。

Result: 提出了一个更新的、教学性的、跨学科的评估视角，为MRS社区提供了应对LLM时代挑战的评估方法论。

Conclusion: LLM驱动的音乐推荐系统需要根本性地重新思考评估范式，传统基于准确性的指标不再适用，需要建立更全面的评估框架来应对LLM带来的机遇和挑战。

Abstract: Music Recommender Systems (MRS) have long relied on an information-retrieval framing, where progress is measured mainly through accuracy on retrieval-oriented subtasks. While effective, this reductionist paradigm struggles to address the deeper question of what makes a good recommendation, and attempts to broaden evaluation, through user studies or fairness analyses, have had limited impact. The emergence of Large Language Models (LLMs) disrupts this framework: LLMs are generative rather than ranking-based, making standard accuracy metrics questionable. They also introduce challenges such as hallucinations, knowledge cutoffs, non-determinism, and opaque training data, rendering traditional train/test protocols difficult to interpret. At the same time, LLMs create new opportunities, enabling natural-language interaction and even allowing models to act as evaluators.
  This work argues that the shift toward LLM-driven MRS requires rethinking evaluation. We first review how LLMs reshape user modeling, item modeling, and natural-language recommendation in music. We then examine evaluation practices from NLP, highlighting methodologies and open challenges relevant to MRS. Finally, we synthesize insights-focusing on how LLM prompting applies to MRS, to outline a structured set of success and risk dimensions. Our goal is to provide the MRS community with an updated, pedagogical, and cross-disciplinary perspective on evaluation.

</details>


### [6] [The Oracle and The Prism: A Decoupled and Efficient Framework for Generative Recommendation Explanation](https://arxiv.org/abs/2511.16543)
*Jiaheng Zhang,Daqiang Zhang*

Main category: cs.IR

TL;DR: Prism是一个解耦的框架，将推荐系统分为专门的排序阶段和解释生成阶段，通过知识蒸馏使用教师LLM生成高质量解释知识，学生模型专门合成个性化解释，在保持高质量的同时显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在可解释推荐系统中端到端架构存在的性能-效率权衡问题，避免排序和解释联合优化导致的次优妥协。

Method: 采用解耦框架，使用强大的教师LLM（如FLAN-T5-XXL）作为Oracle生成高保真解释知识，然后由精调的紧凑学生模型（如BART-Base）专门合成个性化解释。

Result: 140M参数的Prism模型在忠实度和个性化的人类评估中显著优于11B参数的教师模型，推理速度提升24倍，内存消耗减少10倍。

Conclusion: 解耦结合有针对性的蒸馏为高质量可解释推荐提供了高效有效的途径。

Abstract: The integration of Large Language Models (LLMs) into explainable recommendation systems often leads to a performance-efficiency trade-off in end-to-end architectures, where joint optimization of ranking and explanation can result in suboptimal compromises. To resolve this, we propose Prism, a novel decoupled framework that rigorously separates the recommendation process into a dedicated ranking stage and an explanation generation stage.
  Inspired by knowledge distillation, Prism leverages a powerful teacher LLM (e.g., FLAN-T5-XXL) as an Oracle to produce high-fidelity explanatory knowledge. A compact, fine-tuned student model (e.g., BART-Base), the Prism, then specializes in synthesizing this knowledge into personalized explanations. This decomposition ensures that each component is optimized for its specific objective, eliminating inherent conflicts in coupled models.
  Extensive experiments on benchmark datasets demonstrate that our 140M-parameter Prism model significantly outperforms its 11B-parameter teacher in human evaluations of faithfulness and personalization, while achieving a 24 times speedup and a 10 times reduction in memory consumption during inference. These results validate that decoupling, coupled with targeted distillation, provides an efficient and effective pathway to high-quality explainable recommendation.

</details>


### [7] [PolyMinHash: Efficient Area-Based MinHashing of Polygons for Approximate Nearest Neighbor Search](https://arxiv.org/abs/2511.16576)
*Alima Subedi,Sankalpa Pokharel,Satish Puri*

Main category: cs.IR

TL;DR: PolyMinHash是一个用于多边形近似相似性搜索的系统，通过将MinHashing适配为2D多边形哈希方案，生成保持相似性的短签名，显著减少候选处理数量。


<details>
  <summary>Details</summary>
Motivation: 随着数据集增大，精确最近邻搜索变得不可行，而现有ANN系统主要针对文本、图像和轨迹数据，缺乏针对多边形数据的ANN系统。

Method: 通过计算随机采样点落入多边形内部区域所需的点数来生成MinHash值，该方法保持基于面积的Jaccard相似性。

Result: 与暴力算法相比，哈希机制在查询细化阶段处理的候选数量减少了高达98%。

Conclusion: PolyMinHash系统在多边形相似性搜索中实现了搜索精度与运行时间之间的良好权衡，显著提高了搜索效率。

Abstract: Similarity searches are a critical task in data mining. As data sets grow larger, exact nearest neighbor searches quickly become unfeasible, leading to the adoption of approximate nearest neighbor (ANN) searches. ANN has been studied for text data, images, and trajectories. However, there has been little effort to develop ANN systems for polygons in spatial database systems and geographic information systems. We present PolyMinHash, a system for approximate polygon similarity search that adapts MinHashing into a novel 2D polygon-hashing scheme to generate short, similarity-preserving signatures of input polygons. Minhash is generated by counting the number of randomly sampled points needed before the sampled point lands within the polygon's interior area, yielding hash values that preserve area-based Jaccard similarity. We present the tradeoff between search accuracy and runtime of our PolyMinHash system. Our hashing mechanism reduces the number of candidates to be processed in the query refinement phase by up to 98% compared to the number of candidates processed by the brute-force algorithm.

</details>
