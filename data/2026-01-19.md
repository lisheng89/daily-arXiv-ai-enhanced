<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 13]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Tail-Aware Data Augmentation for Long-Tail Sequential Recommendation](https://arxiv.org/abs/2601.10933)
*Yizhou Dang,Zhifu Wei,Minhan Huang,Lianbo Ma,Jianzhe Zhao,Guibing Guo,Xingwei Wang*

Main category: cs.IR

TL;DR: 提出TADA方法，通过尾部感知的数据增强解决序列推荐中的长尾问题，在保持头部性能的同时提升尾部用户/物品的推荐效果。


<details>
  <summary>Details</summary>
Motivation: 现实场景中大多数用户只能与少量物品交互，而大多数物品很少被消费，这种普遍的长尾问题限制了模型学习用户偏好的能力。现有方法在改善尾部性能时往往会损害整体或头部性能。

Method: 提出尾部感知数据增强(TADA)：1) 用线性模型捕捉低流行度物品的共现和相关性；2) 设计T-Substitute（用相关物品替换头部物品）和T-Insert（利用共现关系扩展序列）两种增强操作；3) 在表示层混合增强和原始序列以保留偏好知识；4) 跨不同尾部用户序列和增强序列扩展混合操作以生成更丰富的增强样本。

Result: 综合实验证明了该方法的优越性，能够在保持头部性能的同时提升尾部用户/物品的推荐效果。

Conclusion: TADA方法通过尾部感知的数据增强有效解决了序列推荐中的长尾问题，在提升尾部性能的同时不损害头部性能，从而改善了整体用户体验。

Abstract: Sequential recommendation (SR) learns user preferences based on their historical interaction sequences and provides personalized suggestions. In real-world scenarios, most users can only interact with a handful of items, while the majority of items are seldom consumed. This pervasive long-tail challenge limits the model's ability to learn user preferences. Despite previous efforts to enrich tail items/users with knowledge from head parts or improve tail learning through additional contextual information, they still face the following issues: 1) They struggle to improve the situation where interactions of tail users/items are scarce, leading to incomplete preferences learning for the tail parts. 2) Existing methods often degrade overall or head parts performance when improving accuracy for tail users/items, thereby harming the user experience. We propose Tail-Aware Data Augmentation (TADA) for long-tail sequential recommendation, which enhances the interaction frequency for tail items/users while maintaining head performance, thereby promoting the model's learning capabilities for the tail. Specifically, we first capture the co-occurrence and correlation among low-popularity items by a linear model. Building upon this, we design two tail-aware augmentation operators, T-Substitute and T-Insert. The former replaces the head item with a relevant item, while the latter utilizes co-occurrence relationships to extend the original sequence by incorporating both head and tail items. The augmented and original sequences are mixed at the representation level to preserve preference knowledge. We further extend the mix operation across different tail-user sequences and augmented sequences to generate richer augmented samples, thereby improving tail performance. Comprehensive experiments demonstrate the superiority of our method. The codes are provided at https://github.com/KingGugu/TADA.

</details>


### [2] [Can Instructed Retrieval Models Really Support Exploration?](https://arxiv.org/abs/2601.10936)
*Piyush Maheshwari,Sheshera Mysore,Hamed Zamani*

Main category: cs.IR

TL;DR: 评估指令跟随检索模型在方面条件种子引导探索任务中的表现，发现其在排名相关性上有改进，但在指令跟随能力上存在不足。


<details>
  <summary>Details</summary>
Motivation: 探索性搜索具有目标不明确和查询意图不断演化的特点，需要能够捕捉用户指定意图细微差别并相应调整结果的检索模型。指令跟随检索模型承诺具备这种能力，但尚未在方面条件种子引导探索这一普遍但未充分探索的应用中得到充分评估。

Method: 使用专家标注的测试集合，评估专门为指令跟随检索微调的LLM和使用Pairwise Ranking Prompting进行排名的通用LLM。比较指令跟随检索模型与指令无关方法的性能。

Result: 最佳指令跟随检索器在排名相关性方面优于指令无关方法，但指令跟随性能（对用户体验至关重要）并未反映排名相关性的改进，且对指令表现出不敏感或反直觉的行为。

Conclusion: 虽然用户可能从使用当前指令跟随检索器中获益（相比指令无关模型），但对于需要更高指令敏感度的长期探索性会话，用户可能无法从中受益。需要进一步改进指令跟随能力。

Abstract: Exploratory searches are characterized by under-specified goals and evolving query intents. In such scenarios, retrieval models that can capture user-specified nuances in query intent and adapt results accordingly are desirable -- instruction-following retrieval models promise such a capability. In this work, we evaluate instructed retrievers for the prevalent yet under-explored application of aspect-conditional seed-guided exploration using an expert-annotated test collection. We evaluate both recent LLMs fine-tuned for instructed retrieval and general-purpose LLMs prompted for ranking with the highly performant Pairwise Ranking Prompting. We find that the best instructed retrievers improve on ranking relevance compared to instruction-agnostic approaches. However, we also find that instruction following performance, crucial to the user experience of interacting with models, does not mirror ranking relevance improvements and displays insensitivity or counter-intuitive behavior to instructions. Our results indicate that while users may benefit from using current instructed retrievers over instruction-agnostic models, they may not benefit from using them for long-running exploratory sessions requiring greater sensitivity to instructions.

</details>


### [3] [PRISM: Personalized Recommendation via Information Synergy Module](https://arxiv.org/abs/2601.10944)
*Xinyi Zhang,Yutong Li,Peijie Sun,Letian Sha,Zhongxuan Han*

Main category: cs.IR

TL;DR: PRISM是一个用于多模态序列推荐的即插即用框架，通过信息理论方法将多模态信息分解为独特、冗余和协同组件，并根据用户偏好动态融合


<details>
  <summary>Details</summary>
Motivation: 现有MSR模型往往忽视仅通过模态组合出现的协同信息，并且通常假设不同模态交互对所有用户具有固定重要性，这限制了推荐效果

Method: 提出PRISM框架，通过交互专家层将多模态信息分解为独特、冗余和协同组件，再通过自适应融合层根据用户偏好动态加权融合

Result: 在四个数据集和三个序列推荐骨干网络上进行了广泛实验，证明了PRISM的有效性和通用性

Conclusion: PRISM通过信息理论设计实现了多模态信号的细粒度解耦和个性化融合，提高了多模态序列推荐的准确性和适应性

Abstract: Multimodal sequential recommendation (MSR) leverages diverse item modalities to improve recommendation accuracy, while achieving effective and adaptive fusion remains challenging. Existing MSR models often overlook synergistic information that emerges only through modality combinations. Moreover, they typically assume a fixed importance for different modality interactions across users. To address these limitations, we propose \textbf{P}ersonalized \textbf{R}ecommend-ation via \textbf{I}nformation \textbf{S}ynergy \textbf{M}odule (PRISM), a plug-and-play framework for sequential recommendation (SR). PRISM explicitly decomposes multimodal information into unique, redundant, and synergistic components through an Interaction Expert Layer and dynamically weights them via an Adaptive Fusion Layer guided by user preferences. This information-theoretic design enables fine-grained disentanglement and personalized fusion of multimodal signals. Extensive experiments on four datasets and three SR backbones demonstrate its effectiveness and versatility. The code is available at https://github.com/YutongLi2024/PRISM.

</details>


### [4] [PruneRAG: Confidence-Guided Query Decomposition Trees for Efficient Retrieval-Augmented Generation](https://arxiv.org/abs/2601.11024)
*Shuguang Jiao,Xinyu Xiao,Yunfan Wei,Shuhan Qi,Chengkai Huang,Quan Z. Michael Sheng,Lina Yao*

Main category: cs.IR

TL;DR: PruneRAG：基于置信度引导的查询分解框架，通过结构化查询分解树解决RAG中的证据遗忘和效率问题，实现稳定高效的多跳推理。


<details>
  <summary>Details</summary>
Motivation: 当前RAG系统在多跳推理中存在两个主要问题：证据遗忘（检索到的知识未被有效利用）和效率低下（查询扩展失控和冗余检索），这揭示了检索与证据利用之间的关键差距。

Method: 提出PruneRAG框架，包含三个关键机制：1）自适应节点扩展调节树宽度和深度；2）置信度引导决策接受可靠答案并剪枝不确定分支；3）细粒度检索提取实体级锚点提高检索精度。

Result: 在多个多跳QA基准测试中，PruneRAG在准确性和效率方面均优于现有最先进基线方法，同时显著降低了检索开销。

Conclusion: PruneRAG通过结构化查询分解树和置信度引导机制，有效解决了RAG中的证据遗忘和效率问题，为知识密集型推理任务提供了稳定高效的解决方案。

Abstract: Retrieval-augmented generation (RAG) has become a powerful framework for enhancing large language models in knowledge-intensive and reasoning tasks. However, as reasoning chains deepen or search trees expand, RAG systems often face two persistent failures: evidence forgetting, where retrieved knowledge is not effectively used, and inefficiency, caused by uncontrolled query expansions and redundant retrieval. These issues reveal a critical gap between retrieval and evidence utilization in current RAG architectures. We propose PruneRAG, a confidence-guided query decomposition framework that builds a structured query decomposition tree to perform stable and efficient reasoning. PruneRAG introduces three key mechanisms: adaptive node expansion that regulates tree width and depth, confidence-guided decisions that accept reliable answers and prune uncertain branches, and fine-grained retrieval that extracts entity-level anchors to improve retrieval precision. Together, these components preserve salient evidence throughout multi-hop reasoning while significantly reducing retrieval overhead. To better analyze evidence misuse, we define the Evidence Forgetting Rate as a metric to quantify cases where golden evidence is retrieved but not correctly used. Extensive experiments across various multi-hop QA benchmarks show that PruneRAG achieves superior accuracy and efficiency over state-of-the-art baselines.

</details>


### [5] [Learn Before Represent: Bridging Generative and Contrastive Learning for Domain-Specific LLM Embeddings](https://arxiv.org/abs/2601.11124)
*Xiaoyu Liang,Yuchen Peng,Jiale Luo,Wenhao Wang,Haoji Hu,Xincheng Zhou*

Main category: cs.IR

TL;DR: LBR框架通过两阶段学习解决LLM在垂直领域知识不足问题：先注入领域知识，再进行表征对齐


<details>
  <summary>Details</summary>
Motivation: 当前基于对比学习的LLM在通用表征学习表现出色，但在化学、法律等垂直领域表现不佳，主要原因是缺乏领域特定知识。现有"LLM+CL"范式只关注语义对齐，无法进行知识获取，导致在专业术语上失败。

Method: 提出Learn Before Represent (LBR)两阶段框架：1) 信息瓶颈约束的生成学习阶段，通过保持LLM的因果注意力来最大化知识获取，同时压缩语义；2) 在压缩表征上进行生成精炼的对比学习以实现对齐。该方法保持架构一致性，解决生成学习和对比学习之间的目标冲突。

Result: 在医疗、化学和代码检索任务上的大量实验表明，LBR显著优于强基线方法。

Conclusion: LBR为在垂直领域构建准确且鲁棒的表征建立了新范式。

Abstract: Large Language Models (LLMs) adapted via contrastive learning excel in general representation learning but struggle in vertical domains like chemistry and law, primarily due to a lack of domain-specific knowledge. This work identifies a core bottleneck: the prevailing ``LLM+CL'' paradigm focuses on semantic alignment but cannot perform knowledge acquisition, leading to failures on specialized terminology. To bridge this gap, we propose Learn Before Represent (LBR), a novel two-stage framework. LBR first injects domain knowledge via an Information Bottleneck-Constrained Generative Learning stage, preserving the LLM's causal attention to maximize knowledge acquisition while compressing semantics. It then performs Generative-Refined Contrastive Learning on the compressed representations for alignment. This approach maintains architectural consistency and resolves the objective conflict between generative and contrastive learning. Extensive experiments on medical, chemistry, and code retrieval tasks show that LBR significantly outperforms strong baselines. Our work establishes a new paradigm for building accurate and robust representations in vertical domains.

</details>


### [6] [Deep GraphRAG: A Balanced Approach to Hierarchical Retrieval and Adaptive Integration](https://arxiv.org/abs/2601.11144)
*Yuejie Li,Ke Yang,Tao Wang,Bolin Chen,Bowen Li,Chengjun Mao*

Main category: cs.IR

TL;DR: Deep GraphRAG提出分层全局-局部检索策略，结合三阶段检索过程和动态重排序模块，以及使用动态加权奖励GRPO训练的紧凑LLM知识集成模块，显著提升图检索的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有GraphRAG框架在全局搜索全面性和局部搜索效率之间存在权衡，面临大规模分层图导航、检索路径优化、探索-利用平衡等挑战，且缺乏鲁棒的多阶段重排序机制。

Method: 1) 分层全局-局部检索策略：三阶段过程（社区间过滤、社区级细化、实体级细粒度搜索）；2) 波束搜索优化的动态重排序模块；3) 知识集成模块使用动态加权奖励GRPO训练紧凑LLM，平衡相关性、忠实性和简洁性。

Result: 在Natural Questions和HotpotQA上的评估表明，Deep GraphRAG在准确性和效率方面显著优于基线图检索方法，紧凑模型(1.5B)在集成任务中接近大模型(70B)的性能。

Conclusion: Deep GraphRAG通过分层检索策略和动态加权奖励训练，有效解决了GraphRAG框架中的权衡问题，实现了准确性和效率的平衡，为大规模图检索提供了有效解决方案。

Abstract: Graph-based Retrieval-Augmented Generation (GraphRAG) frameworks face a trade-off between the comprehensiveness of global search and the efficiency of local search. Existing methods are often challenged by navigating large-scale hierarchical graphs, optimizing retrieval paths, and balancing exploration-exploitation dynamics, frequently lacking robust multi-stage re-ranking. To overcome these deficits, we propose Deep GraphRAG, a framework designed for a balanced approach to hierarchical retrieval and adaptive integration. It introduces a hierarchical global-to-local retrieval strategy that integrates macroscopic inter-community and microscopic intra-community contextual relations. This strategy employs a three-stage process: (1) inter-community filtering, which prunes the search space using local context; (2) community-level refinement, which prioritizes relevant subgraphs via entity-interaction analysis; and (3) entity-level fine-grained search within target communities. A beam search-optimized dynamic re-ranking module guides this process, continuously filtering candidates to balance efficiency and global comprehensiveness. Deep GraphRAG also features a Knowledge Integration Module leveraging a compact LLM, trained with Dynamic Weighting Reward GRPO (DW-GRPO). This novel reinforcement learning approach dynamically adjusts reward weights to balance three key objectives: relevance, faithfulness, and conciseness. This training enables compact models (1.5B) to approach the performance of large models (70B) in the integration task. Evaluations on Natural Questions and HotpotQA demonstrate that Deep GraphRAG significantly outperforms baseline graph retrieval methods in both accuracy and efficiency.

</details>


### [7] [Cross-Modal Attention Network with Dual Graph Learning in Multimodal Recommendation](https://arxiv.org/abs/2601.11151)
*Ji Dai,Quan Fang,Jun Hu,Desheng Cai,Yang Yang,Can Zhao*

Main category: cs.IR

TL;DR: CRANE：一种通过递归跨模态注意力机制和双图嵌入的多媒体推荐系统，解决浅层模态融合和不对称特征处理问题，在四个真实数据集上平均提升关键指标5%。


<details>
  <summary>Details</summary>
Motivation: 现有多媒体推荐系统存在两个关键局限：1）浅层模态融合通常依赖简单拼接，未能充分利用模态内和模态间的协同关系；2）不对称特征处理（用户仅用交互ID表征，而物品受益于丰富的多模态内容）阻碍了共享语义空间的学习。

Method: 提出CRANE框架：1）核心递归跨模态注意力机制，在联合潜在空间中基于跨模态相关性迭代精炼模态特征；2）通过聚合用户交互物品的特征显式构建用户多模态画像；3）对称双图框架（异构用户-物品交互图和同构物品-物品语义图），通过自监督对比学习目标融合行为和语义信号。

Result: 在四个公开真实世界数据集上验证，相比最先进基线方法，关键指标平均提升5%。理论分析和实证表明其具有可扩展性和高实际效率，在小数据集上收敛更快，在大规模数据集上达到更优性能上限。

Conclusion: CRANE通过递归跨模态注意力和对称双图嵌入，有效解决了多媒体推荐中的模态融合和特征不对称问题，在保持高计算效率的同时实现了显著的性能提升。

Abstract: Multimedia recommendation systems leverage user-item interactions and multimodal information to capture user preferences, enabling more accurate and personalized recommendations. Despite notable advancements, existing approaches still face two critical limitations: first, shallow modality fusion often relies on simple concatenation, failing to exploit rich synergic intra- and inter-modal relationships; second, asymmetric feature treatment-where users are only characterized by interaction IDs while items benefit from rich multimodal content-hinders the learning of a shared semantic space. To address these issues, we propose a Cross-modal Recursive Attention Network with dual graph Embedding (CRANE). To tackle shallow fusion, we design a core Recursive Cross-Modal Attention (RCA) mechanism that iteratively refines modality features based on cross-correlations in a joint latent space, effectively capturing high-order intra- and inter-modal dependencies. For symmetric multimodal learning, we explicitly construct users' multimodal profiles by aggregating features of their interacted items. Furthermore, CRANE integrates a symmetric dual-graph framework-comprising a heterogeneous user-item interaction graph and a homogeneous item-item semantic graph-unified by a self-supervised contrastive learning objective to fuse behavioral and semantic signals. Despite these complex modeling capabilities, CRANE maintains high computational efficiency. Theoretical and empirical analyses confirm its scalability and high practical efficiency, achieving faster convergence on small datasets and superior performance ceilings on large-scale ones. Comprehensive experiments on four public real-world datasets validate an average 5% improvement in key metrics over state-of-the-art baselines.

</details>


### [8] [From Knots to Knobs: Towards Steerable Collaborative Filtering Using Sparse Autoencoders](https://arxiv.org/abs/2601.11182)
*Martin Spišák,Ladislav Peška,Petr Škoda,Vojtěch Vančura,Rodrigo Alves*

Main category: cs.IR

TL;DR: 将稀疏自编码器应用于协同过滤，在协同自编码器中插入SAE层，提取可解释的单语义特征，实现可控推荐


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器在大型语言模型中已证明能提取高质量可解释特征，但尚未应用于协同过滤领域。本文旨在将SAE方法引入协同过滤，从纯交互信号中提取类似的可解释特征

Method: 在广泛使用的协同自编码器架构中，在编码器和解码器之间插入稀疏自编码器层，并提出语义概念与单个神经元之间的映射函数

Result: 证明这种表示主要具有单语义特性，能够提取可解释特征，并提出简单有效的利用这种表示来引导推荐方向的方法

Conclusion: 首次将稀疏自编码器成功应用于协同过滤，实现了从交互信号中提取可解释特征，为可控推荐提供了新方法

Abstract: Sparse autoencoders (SAEs) have recently emerged as pivotal tools for introspection into large language models. SAEs can uncover high-quality, interpretable features at different levels of granularity and enable targeted steering of the generation process by selectively activating specific neurons in their latent activations. Our paper is the first to apply this approach to collaborative filtering, aiming to extract similarly interpretable features from representations learned purely from interaction signals. In particular, we focus on a widely adopted class of collaborative autoencoders (CFAEs) and augment them by inserting an SAE between their encoder and decoder networks. We demonstrate that such representation is largely monosemantic and propose suitable mapping functions between semantic concepts and individual neurons. We also evaluate a simple yet effective method that utilizes this representation to steer the recommendations in a desired direction.

</details>


### [9] [LLM-Assisted Pseudo-Relevance Feedback](https://arxiv.org/abs/2601.11238)
*David Otero,Javier Parapar*

Main category: cs.IR

TL;DR: 提出一种结合传统伪相关反馈和LLM的混合方法，在RM3估计前加入LLM过滤阶段，只使用被判定为相关的文档进行查询扩展，提升检索效果


<details>
  <summary>Details</summary>
Motivation: 传统伪相关反馈方法（如RM3）容易受到主题漂移影响，而基于LLM的查询扩展方法存在幻觉和术语不匹配问题，需要一种结合两者优点的混合方案

Method: 在RM3估计前加入LLM过滤阶段：LLM对初始排名前k的文档进行相关性判断，只使用被接受为相关的文档进行RM3查询扩展估计

Result: 该方法在多个数据集和指标上优于盲目的伪相关反馈和强基线方法，提升了检索效果

Conclusion: 提出的混合方法既保留了传统伪相关反馈的鲁棒性和可解释性，又利用了LLM的语义判断能力，有效解决了查询扩展中的主题漂移问题

Abstract: Query expansion is a long-standing technique to mitigate vocabulary mismatch in ad hoc Information Retrieval. Pseudo-relevance feedback methods, such as RM3, estimate an expanded query model from the top-ranked documents, but remain vulnerable to topic drift when early results include noisy or tangential content. Recent approaches instead prompt Large Language Models to generate synthetic expansions or query variants. While effective, these methods risk hallucinations and misalignment with collection-specific terminology. We propose a hybrid alternative that preserves the robustness and interpretability of classical PRF while leveraging LLM semantic judgement. Our method inserts an LLM-based filtering stage prior to RM3 estimation: the LLM judges the documents in the initial top-$k$ ranking, and RM3 is computed only over those accepted as relevant. This simple intervention improves over blind PRF and a strong baseline across several datasets and metrics.

</details>


### [10] [Rank4Gen: RAG-Preference-Aligned Document Set Selection and Ranking](https://arxiv.org/abs/2601.11273)
*Yongqi Fan,Yuxiang Chu,Zhentao Xia,Xiaoyang Chen,Jie Liu,Haijin Liang,Jin Ma,Ben He,Yingfei Sun,Dezhi Ye,Tong Ruan*

Main category: cs.IR

TL;DR: Rank4Gen是一个为RAG系统设计的生成器感知排序器，通过优化排序以提升下游响应质量而非传统查询-文档相关性，并建模不同生成器的特定偏好，显著提升RAG性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统中的排序模型主要优化查询-文档相关性，与生成器在证据选择和引用方面的偏好存在偏差，限制了其对响应质量的提升效果。此外，大多数方法未考虑不同生成器之间的偏好差异，导致跨生成器性能不稳定。

Method: 提出Rank4Gen排序器，采用两种关键偏好建模策略：1) 从排序相关性到响应质量：优化排序以提升下游响应质量而非查询-文档相关性；2) 生成器特定偏好建模：使单个排序器能够根据不同生成器调整以捕捉其独特的排序偏好。为此构建了PRISM数据集，包含多个开源语料库和多样化下游生成器。

Result: 在五个具有挑战性的最新RAG基准测试中，Rank4Gen在RAG的复杂证据组合方面实现了强大且具有竞争力的性能。

Conclusion: Rank4Gen通过将排序优化目标从查询-文档相关性转向下游响应质量，并建模生成器特定偏好，有效解决了现有RAG排序模型与生成器偏好不匹配的问题，显著提升了跨生成器的RAG性能。

Abstract: In the RAG paradigm, the information retrieval module provides context for generators by retrieving and ranking multiple documents to support the aggregation of evidence. However, existing ranking models are primarily optimized for query--document relevance, which often misaligns with generators' preferences for evidence selection and citation, limiting their impact on response quality. Moreover, most approaches do not account for preference differences across generators, resulting in unstable cross-generator performance. We propose \textbf{Rank4Gen}, a generator-aware ranker for RAG that targets the goal of \emph{Ranking for Generators}. Rank4Gen introduces two key preference modeling strategies: (1) \textbf{From Ranking Relevance to Response Quality}, which optimizes ranking with respect to downstream response quality rather than query--document relevance; and (2) \textbf{Generator-Specific Preference Modeling}, which conditions a single ranker on different generators to capture their distinct ranking preferences. To enable such modeling, we construct \textbf{PRISM}, a dataset built from multiple open-source corpora and diverse downstream generators. Experiments on five challenging and recent RAG benchmarks demonstrate that RRank4Gen achieves strong and competitive performance for complex evidence composition in RAG.

</details>


### [11] [From SERPs to Sound: How Search Engine Result Pages and AI-generated Podcasts Interact to Influence User Attitudes on Controversial Topics](https://arxiv.org/abs/2601.11282)
*Junjie Wang,Gaole He,Alisa Rieger,Ujwal Gadiraju*

Main category: cs.IR

TL;DR: 研究比较搜索引擎结果页面(SERPs)与AI生成播客对用户态度的影响，发现信息消费顺序和媒介形态会影响用户观点改变，特别是涉及争议性话题时。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成播客成为新兴的被动信息消费方式，且与SERPs在信息搜索行为中日益融合，需要了解这两种媒介如何相互作用影响用户态度，特别是在涉及争议性、价值导向性话题时。

Method: 通过受控用户研究(N=483)，调查用户通过SERPs和AI生成播客消费信息的态度效应，重点关注曝光顺序和媒介形态如何塑造用户观点。

Result: 多数用户出现态度改变，发现顺序效应对态度改变有影响。结果进一步显示观点偏见和话题争议程度在塑造态度改变中起作用，但未发现个体调节变量的影响。

Conclusion: 信息媒介(SERPs与AI播客)的交互作用会影响用户态度形成，特别是在争议性话题中，信息消费顺序和媒介形态是重要影响因素，这对设计信息呈现方式有重要意义。

Abstract: Compared to search engine result pages (SERPs), AI-generated podcasts represent a relatively new and relatively more passive modality of information consumption, delivering narratives in a naturally engaging format. As these two media increasingly converge in everyday information-seeking behavior, it is essential to explore how their interaction influences user attitudes, particularly in contexts involving controversial, value-laden, and often debated topics. Addressing this need, we aim to understand how information mediums of present-day SERPs and AI-generated podcasts interact to shape the opinions of users. To this end, through a controlled user study (N=483), we investigated user attitudinal effects of consuming information via SERPs and AI-generated podcasts, focusing on how the sequence and modality of exposure shape user opinions. A majority of users in our study corresponded to attitude change outcomes, and we found an effect of sequence on attitude change. Our results further revealed a role of viewpoint bias and the degree of topic controversiality in shaping attitude change, although we found no effect of individual moderators.

</details>


### [12] [Validating Search Query Simulations: A Taxonomy of Measures](https://arxiv.org/abs/2601.11412)
*Andreas Konstantin Kruff,Nolwenn Bernard,Philipp Schaer*

Main category: cs.IR

TL;DR: 本文对用户模拟器在信息检索系统评估中的有效性验证方法进行了全面综述，提出了验证措施的分类法，并通过实证分析验证了分类法的有效性，最后给出了不同情境下的验证措施选择建议。


<details>
  <summary>Details</summary>
Motivation: 用户模拟器在信息检索系统评估中的有效性验证仍然是一个开放性问题，这限制了其有效使用和基于模拟结果的可靠性。需要系统性地解决用户模拟查询与真实查询之间的验证问题。

Method: 1. 进行全面的文献综述，特别关注模拟用户查询与真实查询的验证方法；2. 基于综述开发验证措施的分类法；3. 通过分析四种不同搜索场景数据集上各验证措施之间的关系，实证验证分类法。

Result: 1. 开发了结构化当前可用验证措施的分类法；2. 通过实证分析验证了分类法的有效性；3. 提供了不同情境下应选择的验证措施或组合的具体建议；4. 发布了包含最常用验证措施的专用库以促进未来研究。

Conclusion: 本文通过系统性的综述和实证分析，为信息检索中用户模拟器的验证提供了结构化框架和实用指南，有助于提高模拟评估的可靠性，并通过开源库促进该领域的研究发展。

Abstract: Assessing the validity of user simulators when used for the evaluation of information retrieval systems remains an open question, constraining their effective use and the reliability of simulation-based results. To address this issue, we conduct a comprehensive literature review with a particular focus on methods for the validation of simulated user queries with regard to real queries. Based on the review, we develop a taxonomy that structures the current landscape of available measures. We empirically corroborate the taxonomy by analyzing the relationships between the different measures applied to four different datasets representing diverse search scenarios. Finally, we provide concrete recommendations on which measures or combinations of measures should be considered when validating user simulation in different contexts. Furthermore, we release a dedicated library with the most commonly used measures to facilitate future research.

</details>


### [13] [Isotropy-Optimized Contrastive Learning for Semantic Course Recommendation](https://arxiv.org/abs/2601.11427)
*Ali Khreis,Anthony Nasr,Yusuf Hilal*

Main category: cs.IR

TL;DR: 基于BERT的自监督对比学习语义课程推荐系统，通过数据增强和各向同性正则化解决传统BERT嵌入的各向异性问题，提高课程推荐准确性。


<details>
  <summary>Details</summary>
Motivation: 传统BERT嵌入存在各向异性表示空间问题，课程描述无论语义相关性如何都表现出高余弦相似度，这限制了课程推荐系统的准确性和区分能力。

Method: 提出基于BERT的自监督对比学习框架，结合数据增强和各向同性正则化技术，处理学生文本查询并从500多门工程课程数据集中推荐Top-N相关课程。

Result: 实验结果表明，微调后的模型相比原始BERT基线，实现了更好的嵌入分离效果和更准确的课程推荐性能。

Conclusion: 提出的对比学习框架有效解决了BERT嵌入的各向异性问题，能够生成更具区分性的嵌入表示，从而提升课程推荐系统的语义匹配能力。

Abstract: This paper presents a semantic course recommendation system for students using a self-supervised contrastive learning approach built upon BERT (Bidirectional Encoder Representations from Transformers). Traditional BERT embeddings suffer from anisotropic representation spaces, where course descriptions exhibit high cosine similarities regardless of semantic relevance. To address this limitation, we propose a contrastive learning framework with data augmentation and isotropy regularization that produces more discriminative embeddings. Our system processes student text queries and recommends Top-N relevant courses from a curated dataset of over 500 engineering courses across multiple faculties. Experimental results demonstrate that our fine-tuned model achieves improved embedding separation and more accurate course recommendations compared to vanilla BERT baselines.

</details>
