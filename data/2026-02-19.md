<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 8]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [FeDecider: An LLM-Based Framework for Federated Cross-Domain Recommendation](https://arxiv.org/abs/2602.16034)
*Xinrui He,Ting-Wei Li,Tianxin Wei,Xuying Ning,Xinyu He,Wenxuan Bao,Hanghang Tong,Jingrui He*

Main category: cs.IR

TL;DR: FeDecider是一个用于联邦跨域推荐的LLM框架，通过解耦低秩更新和个性化权重集成来解决领域过拟合和异构性挑战


<details>
  <summary>Details</summary>
Motivation: 在联邦跨域推荐中采用LLM模型面临两个主要挑战：1) 领域特定本地适配器容易过拟合，参数更新幅度差异导致聚合偏差；2) LLM通过自回归文本生成隐式编码知识，难以在异构环境下有效衡量跨域相似性

Method: FeDecider框架包含两个关键技术：1) 解耦每个客户端的低秩更新，只共享方向分量以处理尺度特定噪声；2) 每个客户端学习个性化权重，实现数据感知的跨域更新集成

Result: 在多个数据集上的广泛实验验证了FeDecider的有效性，能够有效解决LLM在联邦跨域推荐中的过拟合和异构性挑战

Conclusion: FeDecider成功解决了LLM在联邦跨域推荐中的关键挑战，通过解耦更新和个性化集成实现了更好的推荐性能，为LLM在隐私保护的跨域推荐场景中的应用提供了有效方案

Abstract: Federated cross-domain recommendation (Federated CDR) aims to collaboratively learn personalized recommendation models across heterogeneous domains while preserving data privacy. Recently, large language model (LLM)-based recommendation models have demonstrated impressive performance by leveraging LLMs' strong reasoning capabilities and broad knowledge. However, adopting LLM-based recommendation models in Federated CDR scenarios introduces new challenges. First, there exists a risk of overfitting with domain-specific local adapters. The magnitudes of locally optimized parameter updates often vary across domains, causing biased aggregation and overfitting toward domain-specific distributions. Second, unlike traditional recommendation models (e.g., collaborative filtering, bipartite graph-based methods) that learn explicit and comparable user/item representations, LLMs encode knowledge implicitly through autoregressive text generation training. This poses additional challenges for effectively measuring the cross-domain similarities under heterogeneity. To address these challenges, we propose an LLM-based framework for federated cross-domain recommendation, FeDecider. Specifically, FeDecider tackles the challenge of scale-specific noise by disentangling each client's low-rank updates and sharing only their directional components. To handle the need for flexible and effective integration, each client further learns personalized weights that achieve the data-aware integration of updates from other domains. Extensive experiments across diverse datasets validate the effectiveness of our proposed FeDecider.

</details>


### [2] [Rethinking ANN-based Retrieval: Multifaceted Learnable Index for Large-scale Recommendation System](https://arxiv.org/abs/2602.16124)
*Jiang Zhang,Yubo Wang,Wei Chang,Lu Han,Xingying Cheng,Feng Zhang,Min Li,Songhao Jiang,Wei Zheng,Harry Tran,Zhen Wang,Lei Chen,Yueming Wang,Benyu Zhang,Xiangjun Fan,Bi Xue,Qifan Wang*

Main category: cs.IR

TL;DR: MFLI提出统一学习嵌入和索引的多面可学习索引框架，消除服务时的ANN搜索，提升召回率和服务效率


<details>
  <summary>Details</summary>
Motivation: 传统ANN检索存在两个关键限制：1) 嵌入学习和索引构建分离，导致次优检索质量，尤其对新内容；2) ANN搜索需要为每个请求运行，在大规模工业场景下计算成本高

Method: 通过残差量化构建多面分层码本，与嵌入共同训练；设计高效多面索引结构和实时更新机制；服务时直接使用学习到的分层索引识别相关物品，避免ANN搜索

Result: 在数十亿用户真实数据上，相比SOTA方法：参与度任务召回率提升11.8%，冷内容分发提升57.29%，语义相关性提升13.5%；在线部署显示参与度提升、流行度偏差减少、服务效率更高

Conclusion: MFLI提供了一种可扩展的实时检索范式，统一学习嵌入和索引，消除服务时ANN搜索，显著提升检索质量和服务效率，特别适合大规模推荐系统

Abstract: Approximate nearest neighbor (ANN) search is widely used in the retrieval stage of large-scale recommendation systems. In this stage, candidate items are indexed using their learned embedding vectors, and ANN search is executed for each user (or item) query to retrieve a set of relevant items. However, ANN-based retrieval has two key limitations. First, item embeddings and their indices are typically learned in separate stages: indexing is often performed offline after embeddings are trained, which can yield suboptimal retrieval quality-especially for newly created items. Second, although ANN offers sublinear query time, it must still be run for every request, incurring substantial computation cost at industry scale. In this paper, we propose MultiFaceted Learnable Index (MFLI), a scalable, real-time retrieval paradigm that learns multifaceted item embeddings and indices within a unified framework and eliminates ANN search at serving time. Specifically, we construct a multifaceted hierarchical codebook via residual quantization of item embeddings and co-train the codebook with the embeddings. We further introduce an efficient multifaceted indexing structure and mechanisms that support real-time updates. At serving time, the learned hierarchical indices are used directly to identify relevant items, avoiding ANN search altogether. Extensive experiments on real-world data with billions of users show that MFLI improves recall on engagement tasks by up to 11.8\%, cold-content delivery by up to 57.29\%, and semantic relevance by 13.5\% compared with prior state-of-the-art methods. We also deploy MFLI in the system and report online experimental results demonstrating improved engagement, less popularity bias, and higher serving efficiency.

</details>


### [3] [Retrieval Collapses When AI Pollutes the Web](https://arxiv.org/abs/2602.16136)
*Hongyeon Yu,Dongchan Kim,Young-Bum Kim*

Main category: cs.IR

TL;DR: 检索崩溃：AI生成内容主导搜索结果导致信息检索系统质量下降的两阶段过程


<details>
  <summary>Details</summary>
Motivation: AI生成内容在Web上的快速扩散对信息检索构成结构性风险，搜索引擎和RAG系统越来越多地使用LLM生成的证据，可能导致生态系统级故障

Method: 通过控制实验分析检索崩溃动态，包括高质量SEO风格内容和对抗性内容两种场景，比较BM25和LLM排序器的表现

Result: SEO场景中67%的池污染导致超过80%的暴露污染，形成同质化但看似健康的状态；对抗性污染中BM25暴露约19%有害内容，LLM排序器有更强的抑制能力

Conclusion: 检索管道正悄然转向合成证据，需要检索感知策略来防止Web基础系统中质量下降的自我强化循环

Abstract: The rapid proliferation of AI-generated content on the Web presents a structural risk to information retrieval, as search engines and Retrieval-Augmented Generation (RAG) systems increasingly consume evidence produced by the Large Language Models (LLMs). We characterize this ecosystem-level failure mode as Retrieval Collapse, a two-stage process where (1) AI-generated content dominates search results, eroding source diversity, and (2) low-quality or adversarial content infiltrates the retrieval pipeline. We analyzed this dynamic through controlled experiments involving both high-quality SEO-style content and adversarially crafted content. In the SEO scenario, a 67\% pool contamination led to over 80\% exposure contamination, creating a homogenized yet deceptively healthy state where answer accuracy remains stable despite the reliance on synthetic sources. Conversely, under adversarial contamination, baselines like BM25 exposed $\sim$19\% of harmful content, whereas LLM-based rankers demonstrated stronger suppression capabilities. These findings highlight the risk of retrieval pipelines quietly shifting toward synthetic evidence and the need for retrieval-aware strategies to prevent a self-reinforcing cycle of quality decline in Web-grounded systems.

</details>


### [4] [MICE: Minimal Interaction Cross-Encoders for efficient Re-ranking](https://arxiv.org/abs/2602.16299)
*Mathias Vast,Victor Morand,Basile van Cooten,Laure Soulier,Josiane Mothe,Benjamin Piwowarski*

Main category: cs.IR

TL;DR: 提出MICE架构，通过精简交叉编码器的注意力交互，在保持检索效果的同时大幅降低推理延迟，实现交叉编码器效果与延迟交互模型效率的结合。


<details>
  <summary>Details</summary>
Motivation: 交叉编码器在信息检索中效果最好但推理成本高，无法作为第一级排序器使用。现有工作要么加速交叉编码器推理，要么用更复杂模型改进第一级检索，但这两个方向相对独立。本研究旨在结合这两个方向。

Method: 基于对交叉编码器内部机制的深入理解，从交叉编码器出发，通过仔细移除有害或不必要的交互，推导出新的类似延迟交互的架构MICE（最小交互交叉编码器）。

Result: MICE将推理延迟降低四倍，与ColBERT等延迟交互模型相当，同时保留了交叉编码器在域内的大部分效果，并在域外数据上表现出更好的泛化能力。

Conclusion: MICE成功桥接了交叉编码器的高效果和延迟交互模型的效率，为信息检索系统提供了既高效又有效的解决方案。

Abstract: Cross-encoders deliver state-of-the-art ranking effectiveness in information retrieval, but have a high inference cost. This prevents them from being used as first-stage rankers, but also incurs a cost when re-ranking documents. Prior work has addressed this bottleneck from two largely separate directions: accelerating cross-encoder inference by sparsifying the attention process or improving first-stage retrieval effectiveness using more complex models, e.g. late-interaction ones. In this work, we propose to bridge these two approaches, based on an in-depth understanding of the internal mechanisms of cross-encoders. Starting from cross-encoders, we show that it is possible to derive a new late-interaction-like architecture by carefully removing detrimental or unnecessary interactions. We name this architecture MICE (Minimal Interaction Cross-Encoders). We extensively evaluate MICE across both in-domain (ID) and out-of-domain (OOD) datasets. MICE decreases fourfold the inference latency compared to standard cross-encoders, matching late-interaction models like ColBERT while retaining most of cross-encoder ID effectiveness and demonstrating superior generalization abilities in OOD.

</details>


### [5] [The Diversity Paradox revisited: Systemic Effects of Feedback Loops in Recommender Systems](https://arxiv.org/abs/2602.16315)
*Gabriele Barlacchi,Margherita Lalli,Emanuele Ferragina,Fosca Giannotti,Dino Pedreschi,Luca Pappalardo*

Main category: cs.IR

TL;DR: 推荐系统通过反馈循环影响用户选择，但现有研究假设不现实。本文提出包含隐式反馈、定期重训练、概率采纳和异构推荐系统的反馈循环模型，发现在线零售和音乐流媒体中，采纳增加可能促进个体消费多样化，但集体需求重新分配常加剧流行度集中。时间分析显示静态评估中的个体多样性增加是假象。


<details>
  <summary>Details</summary>
Motivation: 推荐系统通过用户行为和算法推荐的共同演化反馈循环塑造个体选择，但这些循环的系统性影响仍不清楚，部分原因是现有模拟研究中的假设不现实。

Method: 提出一个反馈循环模型，捕捉隐式反馈、定期重训练、概率采纳推荐和异构推荐系统。将该框架应用于在线零售和音乐流媒体数据，分析反馈循环的系统性影响。

Result: 增加推荐采纳可能导致个体消费逐渐多样化，而集体需求以模型和领域依赖的方式重新分配，通常加剧流行度集中。时间分析进一步显示，静态评估中观察到的个体多样性增加是假象：当采纳固定且时间展开时，个体多样性在所有模型中持续下降。

Conclusion: 结果强调需要超越静态评估，在设计推荐系统时明确考虑反馈循环动态。

Abstract: Recommender systems shape individual choices through feedback loops in which user behavior and algorithmic recommendations coevolve over time. The systemic effects of these loops remain poorly understood, in part due to unrealistic assumptions in existing simulation studies. We propose a feedback-loop model that captures implicit feedback, periodic retraining, probabilistic adoption of recommendations, and heterogeneous recommender systems. We apply the framework on online retail and music streaming data and analyze systemic effects of the feedback loop. We find that increasing recommender adoption may lead to a progressive diversification of individual consumption, while collective demand is redistributed in model- and domain-dependent ways, often amplifying popularity concentration. Temporal analyses further reveal that apparent increases in individual diversity observed in static evaluations are illusory: when adoption is fixed and time unfolds, individual diversity consistently decreases across all models. Our results highlight the need to move beyond static evaluations and explicitly account for feedback-loop dynamics when designing recommender systems.

</details>


### [6] [Variable-Length Semantic IDs for Recommender Systems](https://arxiv.org/abs/2602.16375)
*Kirill Khrylchenko*

Main category: cs.IR

TL;DR: 提出一种变长语义标识符方法，通过离散变分自编码器学习自适应长度的物品表示，解决推荐系统中物品空间大、固定长度语义标识符效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 生成模型在推荐系统中应用面临物品空间基数极大的挑战，现有语义标识符方法使用固定长度表示所有物品，效率低下且不符合自然语言特性，忽略了热门物品和长尾物品的不同信息需求。

Method: 提出变长语义标识符方法，使用基于Gumbel-Softmax重参数化的离散变分自编码器，在概率框架下学习自适应长度的物品表示，避免了REINFORCE训练的不稳定性和先前固定长度方法的限制。

Result: 该方法能够为不同频率的物品生成不同长度的语义标识符，高频物品获得较短描述，低频物品获得较长描述，更符合自然语言通信原理和推荐系统的实际需求。

Conclusion: 将涌现通信理论引入推荐系统，提出的变长语义标识符方法解决了固定长度表示的效率问题，为大规模物品空间的生成推荐模型提供了更有效的表示学习框架。

Abstract: Generative models are increasingly used in recommender systems, both for modeling user behavior as event sequences and for integrating large language models into recommendation pipelines. A key challenge in this setting is the extremely large cardinality of item spaces, which makes training generative models difficult and introduces a vocabulary gap between natural language and item identifiers. Semantic identifiers (semantic IDs), which represent items as sequences of low-cardinality tokens, have recently emerged as an effective solution to this problem.
  However, existing approaches generate semantic identifiers of fixed length, assigning the same description length to all items. This is inefficient, misaligned with natural language, and ignores the highly skewed frequency structure of real-world catalogs, where popular items and rare long-tail items exhibit fundamentally different information requirements. In parallel, the emergent communication literature studies how agents develop discrete communication protocols, often producing variable-length messages in which frequent concepts receive shorter descriptions. Despite the conceptual similarity, these ideas have not been systematically adopted in recommender systems.
  In this work, we bridge recommender systems and emergent communication by introducing variable-length semantic identifiers for recommendation. We propose a discrete variational autoencoder with Gumbel-Softmax reparameterization that learns item representations of adaptive length under a principled probabilistic framework, avoiding the instability of REINFORCE-based training and the fixed-length constraints of prior semantic ID methods.

</details>


### [7] [From Latent to Observable Position-Based Click Models in Carousel Interfaces](https://arxiv.org/abs/2602.16541)
*Santiago de Leon-Martinez,Robert Moro,Branislav Kveton,Maria Bielikova*

Main category: cs.IR

TL;DR: 本文研究了轮播界面中的点击模型，提出了三种新的基于位置的轮播点击模型，包括首个无需隐变量且结合眼动追踪数据的观察检查模型（OEPBM）。实验表明基于梯度的优化方法效果最好，OEPBM在点击预测和用户行为对齐方面表现最佳，但也揭示了仅依赖点击数据的模型在复杂界面中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现代推荐系统越来越多地使用轮播等复杂界面，但现有点击模型主要针对单一排名列表设计，无法有效建模轮播界面中复杂的用户浏览行为。需要开发专门针对轮播界面的点击模型。

Method: 提出了三种针对轮播界面的基于位置点击模型，包括首个无需隐变量且结合眼动追踪观察检查信号的OEPBM模型。开发了通用的轮播点击模型实现框架，支持多种优化技术，包括基于梯度的方法与传统方法（期望最大化、最大似然估计）的比较。

Result: 基于梯度的优化方法在点击似然度方面表现最好。OEPBM模型在点击预测方面表现最强，产生的检查模式与用户行为最接近。但研究发现，良好的点击拟合并不等同于对用户检查和浏览模式的真实建模。

Conclusion: 仅依赖点击数据的模型在复杂界面中存在根本性局限性，为轮播推荐系统设计点击模型时需要结合额外的行为信号。OEPBM展示了结合观察检查信号的优势，但需要更多行为数据来准确建模用户行为。

Abstract: Click models are a central component of learning and evaluation in recommender systems, yet most existing models are designed for single ranked-list interfaces. In contrast, modern recommender platforms increasingly use complex interfaces such as carousels, which consist of multiple swipeable lists that enable complex user browsing behaviors.
  In this paper, we study position-based click models in carousel interfaces and examine optimization methods, model structure, and alignment with user behavior. We propose three novel position-based models tailored to carousels, including the first position-based model without latent variables that incorporates observed examination signals derived from eye tracking data, called the Observed Examination Position-Based Model (OEPBM). We develop a general implementation of these carousel click models, supporting multiple optimization techniques and conduct experiments comparing gradient-based methods with classical approaches, namely expectation-maximization and maximum likelihood estimation.
  Our results show that gradient-based optimization consistently achieve better click likelihoods. Among the evaluated models, the OEPBM achieves the strongest performance in click prediction and produces examination patterns that most closely align to user behavior. However, we also demonstrate that strong click fit does not imply realistic modeling of user examination and browsing patterns. This reveals a fundamental limitation of click-only models in complex interfaces and the need for incorporating additional behavioral signals when designing click models for carousel-based recommender systems.

</details>


### [8] [Why Thinking Hurts? Diagnosing and Rectifying the Reasoning Shift in Foundation Recommender Models](https://arxiv.org/abs/2602.16587)
*Luankang Zhang,Yonghao Huang,Hang Lv,Mingjia Yin,Liangyue Li,Zulong Chen,Hao Wang,Enhong Chen*

Main category: cs.IR

TL;DR: 论文提出推理时子空间对齐框架，解决CoT推理在基于语义ID的推荐基础模型中导致性能下降的问题


<details>
  <summary>Details</summary>
Motivation: 在基于语义ID的推荐基础模型（如OpenOneRec）中集成CoT推理会降低推荐性能，原因是通用子空间的文本惯性导致模型忽视关键语义ID

Method: 提出无需训练的推理时子空间对齐框架，通过压缩推理链和应用偏差减去的对比解码来缓解无根据的文本漂移

Result: 实验表明该方法有效校准推理，使基础模型能够利用推理能力而不牺牲基于ID的准确性

Conclusion: 推理时子空间对齐框架成功解决了CoT推理在语义ID推荐模型中的性能下降问题，实现了推理能力与ID准确性的平衡

Abstract: Integrating Chain-of-Thought (CoT) reasoning into Semantic ID-based recommendation foundation models (such as OpenOneRec) often paradoxically degrades recommendation performance. We identify the root cause as textual inertia from the General Subspace, where verbose reasoning dominates inference and causes the model to neglect critical Semantic ID. To address this, we propose a training-free Inference-Time Subspace Alignment framework. By compressing reasoning chains and applying bias-subtracted contrastive decoding, our approach mitigates ungrounded textual drift. Experiments show this effectively calibrates inference, allowing foundation models to leverage reasoning without sacrificing ID-grounded accuracy.

</details>
