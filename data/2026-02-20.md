<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 15]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [RankEvolve: Automating the Discovery of Retrieval Algorithms via LLM-Driven Evolution](https://arxiv.org/abs/2602.16932)
*Jinming Nian,Fangchen Li,Dae Hoon Park,Yi Fang*

Main category: cs.IR

TL;DR: 本文提出RankEvolve方法，利用大语言模型在评估器引导下通过进化搜索自动发现改进的词法检索算法，从BM25和查询似然等基础算法出发，进化出新颖有效的检索算法。


<details>
  <summary>Details</summary>
Motivation: 虽然BM25和带Dirichlet平滑的查询似然等检索算法仍然是强大高效的一阶段排序器，但改进主要依赖于参数调整和人类直觉。研究者希望探索是否可以利用大语言模型在评估器引导下通过进化搜索自动发现改进的词法检索算法。

Method: 提出RankEvolve方法，基于AlphaEvolve的程序进化框架，将候选排序算法表示为可执行代码，通过迭代变异、重组和基于检索性能的选择进行进化。从BM25和带Dirichlet平滑的查询似然两个种子程序开始，在12个IR数据集（来自BEIR和BRIGHT）上进行评估和进化。

Result: 进化出的算法具有新颖性和有效性，在完整的BEIR和BRIGHT基准测试以及TREC DL 19和20上展现出良好的迁移性能。结果表明评估器引导的LLM程序进化是自动发现新颖排序算法的实用路径。

Conclusion: 评估器引导的大语言模型程序进化是自动发现新颖排序算法的可行方法，能够从基础检索算法出发进化出性能更优的算法，并具有良好的泛化能力。

Abstract: Retrieval algorithms like BM25 and query likelihood with Dirichlet smoothing remain strong and efficient first-stage rankers, yet improvements have mostly relied on parameter tuning and human intuition. We investigate whether a large language model, guided by an evaluator and evolutionary search, can automatically discover improved lexical retrieval algorithms. We introduce RankEvolve, a program evolution setup based on AlphaEvolve, in which candidate ranking algorithms are represented as executable code and iteratively mutated, recombined, and selected based on retrieval performance across 12 IR datasets from BEIR and BRIGHT. RankEvolve starts from two seed programs: BM25 and query likelihood with Dirichlet smoothing. The evolved algorithms are novel, effective, and show promising transfer to the full BEIR and BRIGHT benchmarks as well as TREC DL 19 and 20. Our results suggest that evaluator-guided LLM program evolution is a practical path towards automatic discovery of novel ranking algorithms.

</details>


### [2] [SAGE: Structure Aware Graph Expansion for Retrieval of Heterogeneous Data](https://arxiv.org/abs/2602.16964)
*Prasham Titiya,Rohit Khoja,Tomer Wolfson,Vivek Gupta,Dan Roth*

Main category: cs.IR

TL;DR: SAGE框架通过构建块级图并进行在线检索扩展，在异构语料问答中提升检索效果


<details>
  <summary>Details</summary>
Motivation: 现有检索增强问答系统面临两个问题：基于实体的知识图谱构建和维护成本高、查询时遍历效率低；而标准检索器-阅读器管道使用扁平相似性搜索，无法捕捉跨模态的多跳证据链。

Method: SAGE框架包含两个阶段：离线阶段使用元数据驱动的相似性构建块级图并进行百分位剪枝；在线阶段先运行基线检索器获取k个种子块，扩展一跳邻居，然后使用密集+稀疏检索过滤邻居，选择k'个额外块。针对不同语料类型，分别使用混合密集+稀疏检索器（隐式跨模态语料）和SPARK智能体检索器（显式模式图）。

Result: 在OTT-QA和STaRK数据集上，SAGE相比基线方法分别提升了5.7和8.5个百分点的检索召回率。

Conclusion: SAGE框架通过构建块级图结构并执行智能检索扩展，能够有效捕捉跨模态的多跳证据链，在异构语料问答任务中显著提升检索性能。

Abstract: Retrieval-augmented question answering over heterogeneous corpora requires connected evidence across text, tables, and graph nodes. While entity-level knowledge graphs support structured access, they are costly to construct and maintain, and inefficient to traverse at query time. In contrast, standard retriever-reader pipelines use flat similarity search over independently chunked text, missing multi-hop evidence chains across modalities. We propose SAGE (Structure Aware Graph Expansion) framework that (i) constructs a chunk-level graph offline using metadata-driven similarities with percentile-based pruning, and (ii) performs online retrieval by running an initial baseline retriever to obtain k seed chunks, expanding first-hop neighbors, and then filtering the neighbors using dense+sparse retrieval, selecting k' additional chunks. We instantiate the initial retriever using hybrid dense+sparse retrieval for implicit cross-modal corpora and SPARK (Structure Aware Planning Agent for Retrieval over Knowledge Graphs) an agentic retriever for explicit schema graphs. On OTT-QA and STaRK, SAGE improves retrieval recall by 5.7 and 8.5 points over baselines.

</details>


### [3] [Beyond Chunk-Then-Embed: A Comprehensive Taxonomy and Evaluation of Document Chunking Strategies for Information Retrieval](https://arxiv.org/abs/2602.16974)
*Yongjie Zhou,Shuai Wang,Bevan Koopman,Guido Zuccon*

Main category: cs.IR

TL;DR: 本文系统评估了文档分块策略，发现最优方法因任务而异：简单结构方法在语料库检索中表现最佳，而LLM引导方法在文档内检索中表现最好。


<details>
  <summary>Details</summary>
Motivation: 文档分块是密集检索系统的关键预处理步骤，但现有分块策略研究分散且缺乏统一评估框架。不同方法在重叠度低的基准上独立评估，难以直接比较。

Method: 提出统一框架，从两个维度分类现有策略：(1) 分割方法（结构基、语义基、LLM引导）和(2) 嵌入范式（预嵌入分块 vs 上下文分块）。在两种检索设置下系统评估：文档内检索和语料库检索。

Result: 最优分块策略具有任务依赖性：简单结构方法在语料库检索中优于LLM引导方法，而LumberChunker在文档内检索中表现最佳。上下文分块提升语料库检索效果但降低文档内检索效果。分块大小与文档内检索效果中度相关，与语料库检索效果弱相关。

Conclusion: 文档分块策略的选择应基于具体检索任务，没有"一刀切"的最佳方法。研究提供了统一评估框架和公开代码，为未来研究奠定基础。

Abstract: Document chunking is a critical preprocessing step in dense retrieval systems, yet the design space of chunking strategies remains poorly understood. Recent research has proposed several concurrent approaches, including LLM-guided methods (e.g., DenseX and LumberChunker) and contextualized strategies(e.g., Late Chunking), which generate embeddings before segmentation to preserve contextual information. However, these methods emerged independently and were evaluated on benchmarks with minimal overlap, making direct comparisons difficult.
  This paper reproduces prior studies in document chunking and presents a systematic framework that unifies existing strategies along two key dimensions: (1) segmentation methods, including structure-based methods (fixed-size, sentence-based, and paragraph-based) as well as semantically-informed and LLM-guided methods; and (2) embedding paradigms, which determine the timing of chunking relative to embedding (pre-embedding chunking vs. contextualized chunking). Our reproduction evaluates these approaches in two distinct retrieval settings established in previous work: in-document retrieval (needle-in-a-haystack) and in-corpus retrieval (the standard information retrieval task).
  Our comprehensive evaluation reveals that optimal chunking strategies are task-dependent: simple structure-based methods outperform LLM-guided alternatives for in-corpus retrieval, while LumberChunker performs best for in-document retrieval. Contextualized chunking improves in-corpus effectiveness but degrades in-document retrieval. We also find that chunk size correlates moderately with in-document but weakly with in-corpus effectiveness, suggesting segmentation method differences are not purely driven by chunk size. Our code and evaluation benchmarks are publicly available at (Anonymoused).

</details>


### [4] [Bending the Scaling Law Curve in Large-Scale Recommendation Systems](https://arxiv.org/abs/2602.16986)
*Qin Ding,Kevin Course,Linjian Ma,Jianhui Sun,Rouchen Liu,Zhao Zhu,Chunxing Yin,Wei Li,Dai Li,Yu Shi,Xuan Cao,Ze Yang,Han Li,Xing Liu,Bi Xue,Hongwei Li,Rui Jian,Daisy Shi He,Jing Qian,Matt Ma,Qunshu Zhang,Rui Li*

Main category: cs.IR

TL;DR: ULTRA-HSTU是一个通过模型与系统协同设计的序列推荐模型，通过创新的输入序列设计、稀疏注意力机制和模型拓扑，在保持推荐质量的同时实现了5倍训练加速和21倍推理加速，已在生产环境大规模部署。


<details>
  <summary>Details</summary>
Motivation: 当前序列推荐模型主要依赖交叉注意力机制来解决二次计算瓶颈，但这限制了自注意力的表征能力。需要一种既能保持模型质量又能提升效率的解决方案。

Method: 采用端到端的模型与系统协同设计，创新性地设计输入序列、稀疏注意力机制和模型拓扑结构，优化计算效率同时保持表征能力。

Result: ULTRA-HSTU实现了显著的扩展效率提升：相比传统模型，训练扩展速度提升5倍以上，推理扩展速度提升21倍，同时提供更优的推荐质量。在生产环境中部署后，带来了4%到8%的消费和参与度提升。

Conclusion: ULTRA-HSTU通过创新的模型架构和系统设计，成功解决了序列推荐中的计算效率瓶颈问题，在保持推荐质量的同时实现了显著的性能提升，已在实际生产环境中验证了其有效性。

Abstract: Learning from user interaction history through sequential models has become a cornerstone of large-scale recommender systems. Recent advances in large language models have revealed promising scaling laws, sparking a surge of research into long-sequence modeling and deeper architectures for recommendation tasks. However, many recent approaches rely heavily on cross-attention mechanisms to address the quadratic computational bottleneck in sequential modeling, which can limit the representational power gained from self-attention. We present ULTRA-HSTU, a novel sequential recommendation model developed through end-to-end model and system co-design. By innovating in the design of input sequences, sparse attention mechanisms, and model topology, ULTRA-HSTU achieves substantial improvements in both model quality and efficiency. Comprehensive benchmarking demonstrates that ULTRA-HSTU achieves remarkable scaling efficiency gains -- over 5x faster training scaling and 21x faster inference scaling compared to conventional models -- while delivering superior recommendation quality. Our solution is fully deployed at scale, serving billions of users daily and driving significant 4% to 8% consumption and engagement improvements in real-world production environments.

</details>


### [5] [WSDM Cup 2026 Multilingual Retrieval: A Low-Cost Multi-Stage Retrieval Pipeline](https://arxiv.org/abs/2602.16989)
*Chentong Hao,Minmao Wang*

Main category: cs.IR

TL;DR: 提出一个低成本的多语言检索系统，在WSDM Cup 2026任务中，使用四阶段流水线结合查询扩展、BM25检索、稠密排序和重排序，在有限计算预算下实现高效检索。


<details>
  <summary>Details</summary>
Motivation: 针对WSDM Cup 2026多语言检索任务，需要从约1000万篇中文、波斯语和俄语新闻文章中检索相关文档，同时考虑计算成本限制，设计一个高效且低成本的检索系统。

Method: 采用四阶段流水线：1) 基于LLM的GRF风格查询扩展；2) BM25候选检索；3) 使用jina-embeddings-v4的长文本表示进行稠密排序；4) 对前20个候选使用Qwen3-Reranker-4B进行点式重排序，其余保持稠密排序顺序。

Result: 在官方评估中，系统达到nDCG@20为0.403，Judged@20为0.95。通过消融实验量化了各阶段的贡献，分析了在有限计算预算下查询扩展、稠密排序和重排序的有效性。

Conclusion: 提出的低成本四阶段检索系统在多语言新闻检索任务中表现良好，通过结合传统检索方法和现代深度学习技术，在有限计算资源下实现了高效的检索性能。

Abstract: We present a low-cost retrieval system for the WSDM Cup 2026 multilingual retrieval task, where English queries are used to retrieve relevant documents from a collection of approximately ten million news articles in Chinese, Persian, and Russian, and to output the top-1000 ranked results for each query. We follow a four-stage pipeline that combines LLM-based GRF-style query expansion with BM25 candidate retrieval, dense ranking using long-text representations from jina-embeddings-v4, and pointwise re-ranking of the top-20 candidates using Qwen3-Reranker-4B while preserving the dense order for the remaining results. On the official evaluation, the system achieves nDCG@20 of 0.403 and Judged@20 of 0.95. We further conduct extensive ablation experiments to quantify the contribution of each stage and to analyze the effectiveness of query expansion, dense ranking, and top-$k$ reranking under limited compute budgets.

</details>


### [6] [LiveGraph: Active-Structure Neural Re-ranking for Exercise Recommendation](https://arxiv.org/abs/2602.17036)
*Rong Fu,Zijian Zhang,Haiyun Wei,Jiekai Wu,Kun Liu,Xianda Li,Haoyu Zhao,Yang Li,Yongtai Liu,Ziming Wang,Rui Lu,Simon Fong*

Main category: cs.IR

TL;DR: LiveGraph是一个新颖的主动结构神经重排序框架，通过图表示增强和动态重排序机制解决个性化教育内容推荐中的长尾分布和学习轨迹适应问题。


<details>
  <summary>Details</summary>
Motivation: 数字学习环境的扩展需要智能系统提供个性化教育内容，但现有练习推荐框架面临学生参与度长尾分布和无法适应个性化学习轨迹的挑战。

Method: 采用基于图的表示增强策略来弥合活跃与非活跃学生之间的信息差距，并集成动态重排序机制以促进内容多样性，优先考虑学习历史中的结构关系。

Result: 在多个真实世界数据集上的实验评估表明，LiveGraph在预测准确性和练习多样性广度方面均优于现有基线方法。

Conclusion: LiveGraph通过平衡推荐精度与教学多样性，有效解决了教育推荐系统中的长尾分布和个性化适应问题，为个性化学习提供了更优的解决方案。

Abstract: The continuous expansion of digital learning environments has catalyzed the demand for intelligent systems capable of providing personalized educational content. While current exercise recommendation frameworks have made significant strides, they frequently encounter obstacles regarding the long-tailed distribution of student engagement and the failure to adapt to idiosyncratic learning trajectories. We present LiveGraph, a novel active-structure neural re-ranking framework designed to overcome these limitations. Our approach utilizes a graph-based representation enhancement strategy to bridge the information gap between active and inactive students while integrating a dynamic re-ranking mechanism to foster content diversity. By prioritizing the structural relationships within learning histories, the proposed model effectively balances recommendation precision with pedagogical variety. Comprehensive experimental evaluations conducted on multiple real-world datasets demonstrate that LiveGraph surpasses contemporary baselines in both predictive accuracy and the breadth of exercise diversity.

</details>


### [7] [A Long-term Value Prediction Framework In Video Ranking](https://arxiv.org/abs/2602.17058)
*Huabin Chen,Xinao Wang,Huiping Chu,Keqin Xu,Chenhao Zhai,Chenyi Wang,Kai Meng,Yuning Jiang*

Main category: cs.IR

TL;DR: 提出一个实用的排序阶段长期价值框架，解决位置偏差、归因模糊和时间限制三大挑战，已在淘宝生产系统中亿级规模部署


<details>
  <summary>Details</summary>
Motivation: 在短视频推荐的排序阶段准确建模长期价值面临挑战，现有方法在细粒度归因和亿级规模的位置归一化方面仍不完善

Method: 1. 位置偏差：提出位置感知去偏分位数模块，通过分位数分布归一化参与度；2. 归因模糊：提出多维度归因模块，学习跨上下文、行为和内容信号的连续归因强度；3. 时间限制：提出跨时间作者建模模块，构建审查感知的日级LTV目标

Result: 离线研究和在线A/B测试显示LTV指标显著改善，与短期目标的权衡稳定，已在淘宝生产系统亿级规模部署，带来持续参与度提升

Conclusion: 该框架作为现有排序模型的任务增强实现，支持高效训练和服务，在工业约束下提供实用的排序阶段LTV解决方案

Abstract: Accurately modeling long-term value (LTV) at the ranking stage of short-video recommendation remains challenging. While delayed feedback and extended engagement have been explored, fine-grained attribution and robust position normalization at billion-scale are still underdeveloped. We propose a practical ranking-stage LTV framework addressing three challenges: position bias, attribution ambiguity, and temporal limitations.
  (1) Position bias: We introduce a Position-aware Debias Quantile (PDQ) module that normalizes engagement via quantile-based distributions, enabling position-robust LTV estimation without architectural changes. (2) Attribution ambiguity: We propose a multi-dimensional attribution module that learns continuous attribution strengths across contextual, behavioral, and content signals, replacing static rules to capture nuanced inter-video influence. A customized hybrid loss with explicit noise filtering improves causal clarity. (3) Temporal limitations: We present a cross-temporal author modeling module that builds censoring-aware, day-level LTV targets to capture creator-driven re-engagement over longer horizons; the design is extensible to other dimensions (e.g., topics, styles).
  Offline studies and online A/B tests show significant improvements in LTV metrics and stable trade-offs with short-term objectives. Implemented as task augmentation within an existing ranking model, the framework supports efficient training and serving, and has been deployed at billion-scale in Taobao's production system, delivering sustained engagement gains while remaining compatible with industrial constraints.

</details>


### [8] [When LLM Judges Inflate Scores: Exploring Overrating in Relevance Assessment](https://arxiv.org/abs/2602.17170)
*Chuting Yu,Hang Li,Joel Mackenzie,Teerapong Leelanupab*

Main category: cs.IR

TL;DR: LLM作为相关性评估代理存在系统性高估偏差，对文本长度和表面词汇线索过度敏感，不能直接替代人工评估


<details>
  <summary>Details</summary>
Motivation: 人工相关性评估耗时耗力，限制了信息检索评估的可扩展性，因此研究者开始探索使用LLM作为人工评估的代理。但LLM评估的可靠性、稳定性和严谨性能否达到人类水平仍是未解问题。

Method: 系统研究LLM相关性评估中的高估行为，涵盖不同模型架构、评估范式（点式和配对式）以及文本修改策略。通过控制实验分析LLM评估对文本长度和表面词汇线索的敏感性。

Result: LLM一致性地给不真正满足信息需求的文本分配过高的相关性分数（通常置信度很高），显示出系统性偏差而非随机波动。LLM相关性评估对文本长度和表面词汇线索高度敏感。

Conclusion: LLM不能直接替代人工相关性评估者，使用LLM进行相关性评估时需要建立仔细的诊断评估框架。研究结果对LLM作为评估代理的可靠性提出了重要警示。

Abstract: Human relevance assessment is time-consuming and cognitively intensive, limiting the scalability of Information Retrieval evaluation. This has led to growing interest in using large language models (LLMs) as proxies for human judges. However, it remains an open question whether LLM-based relevance judgments are reliable, stable, and rigorous enough to match humans for relevance assessment. In this work, we conduct a systematic study of overrating behavior in LLM-based relevance judgments across model backbones, evaluation paradigms (pointwise and pairwise), and passage modification strategies. We show that models consistently assign inflated relevance scores -- often with high confidence -- to passages that do not genuinely satisfy the underlying information need, revealing a system-wide bias rather than random fluctuations in judgment. Furthermore, controlled experiments show that LLM-based relevance judgments can be highly sensitive to passage length and surface-level lexical cues. These results raise concerns about the usage of LLMs as drop-in replacements for human relevance assessors, and highlight the urgent need for careful diagnostic evaluation frameworks when applying LLMs for relevance assessments. Our code and results are publicly available.

</details>


### [9] [On the Reliability of User-Centric Evaluation of Conversational Recommender Systems](https://arxiv.org/abs/2602.17264)
*Michael Müller,Amir Reza Mohammadi,Andreas Peintner,Beatriz Barroso Gstrein,Günther Specht,Eva Zangerle*

Main category: cs.IR

TL;DR: 本文通过大规模实证研究发现，基于第三方标注的对话推荐系统用户中心评估存在可靠性问题，特别是社交维度可靠性较低，且存在明显的晕轮效应。


<details>
  <summary>Details</summary>
Motivation: 当前对话推荐系统（CRS）的用户中心评估越来越多地依赖第三方对静态对话日志的标注，但这种做法的可靠性尚未得到充分验证。本文旨在通过实证研究探讨这种评估方法的可靠性。

Method: 使用CRS-Que框架的18个维度，收集了124名众包工作者对200个ReDial对话的1,053个标注。采用随机效应可靠性模型和相关性分析来量化各维度的稳定性和相互依赖性。

Result: 功利性和结果导向的维度（如准确性、有用性、满意度）在聚合后达到中等可靠性，而社交基础维度（如人性化、融洽关系）的可靠性显著较低。许多维度会聚合成单一的全局质量信号，显示出强烈的晕轮效应。

Conclusion: 研究结果挑战了单一标注者和基于LLM的评估协议的有效性，强调了在离线CRS评估中需要多标注者聚合和维度简化的必要性。

Abstract: User-centric evaluation has become a key paradigm for assessing Conversational Recommender Systems (CRS), aiming to capture subjective qualities such as satisfaction, trust, and rapport. To enable scalable evaluation, recent work increasingly relies on third-party annotations of static dialogue logs by crowd workers or large language models. However, the reliability of this practice remains largely unexamined. In this paper, we present a large-scale empirical study investigating the reliability and structure of user-centric CRS evaluation on static dialogue transcripts. We collected 1,053 annotations from 124 crowd workers on 200 ReDial dialogues using the 18-dimensional CRS-Que framework. Using random-effects reliability models and correlation analysis, we quantify the stability of individual dimensions and their interdependencies. Our results show that utilitarian and outcome-oriented dimensions such as accuracy, usefulness, and satisfaction achieve moderate reliability under aggregation, whereas socially grounded constructs such as humanness and rapport are substantially less reliable. Furthermore, many dimensions collapse into a single global quality signal, revealing a strong halo effect in third-party judgments. These findings challenge the validity of single-annotator and LLM-based evaluation protocols and motivate the need for multi-rater aggregation and dimension reduction in offline CRS evaluation.

</details>


### [10] [WebFAQ 2.0: A Multilingual QA Dataset with Mined Hard Negatives for Dense Retrieval](https://arxiv.org/abs/2602.17327)
*Michael Dinzinger,Laura Caspari,Ali Salman,Irvin Topi,Jelena Mitrović,Michael Granitzer*

Main category: cs.IR

TL;DR: WebFAQ 2.0是一个包含1.98亿FAQ问答对的多语言数据集，覆盖108种语言，提供14.3M双语对齐问答对，并包含用于密集检索器训练的困难负样本数据集。


<details>
  <summary>Details</summary>
Motivation: 构建更大规模、更多样化的多语言FAQ资源，满足社区对高质量训练数据的需求，特别是为密集检索器提供困难负样本，促进多语言和跨语言信息检索研究。

Method: 采用新颖的数据收集策略：直接爬取和提取相关网页内容；使用两阶段检索管道挖掘困难负样本；通过Open Web Index定期发布结构化FAQ实现持续扩展。

Result: 创建了目前最大的FAQ资源，包含1.98亿问答对、108种语言、14.3M双语对齐对；提供1.25M查询的困难负样本数据集，支持密集检索器的对比学习和知识蒸馏训练。

Conclusion: WebFAQ 2.0是一个动态发展的多语言资源，通过公开数据集和训练脚本促进多语言信息检索研究，并计划通过Open Web Index持续扩展和优化。

Abstract: We introduce WebFAQ 2.0, a new version of the WebFAQ dataset, containing 198 million FAQ-based natural question-answer pairs across 108 languages. Compared to the previous version, it significantly expands multilingual coverage and the number of bilingual aligned QA pairs to over 14.3M, making it the largest FAQ-based resource. Unlike the original release, WebFAQ 2.0 uses a novel data collection strategy that directly crawls and extracts relevant web content, resulting in a substantially more diverse and multilingual dataset with richer context through page titles and descriptions. In response to community feedback, we also release a hard negatives dataset for training dense retrievers, with 1.25M queries across 20 languages. These hard negatives were mined using a two-stage retrieval pipeline and include cross-encoder scores for 200 negatives per query. We further show how this resource enables two primary fine-tuning strategies for dense retrievers: Contrastive Learning with MultipleNegativesRanking loss, and Knowledge Distillation with MarginMSE loss. WebFAQ 2.0 is not a static resource but part of a long-term effort. Since late 2025, structured FAQs are being regularly released through the Open Web Index, enabling continuous expansion and refinement. We publish the datasets and training scripts to facilitate further research in multilingual and cross-lingual IR. The dataset itself and all related resources are publicly available on GitHub and HuggingFace.

</details>


### [11] [Training-free Graph-based Imputation of Missing Modalities in Multimodal Recommendation](https://arxiv.org/abs/2602.17354)
*Daniele Malitesta,Emanuele Rossi,Claudio Pomo,Tommaso Di Noia,Fragkiskos D. Malliaros*

Main category: cs.IR

TL;DR: 该论文针对多模态推荐系统中模态缺失问题，提出基于图结构的特征插补方法，无需重新训练即可提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 多模态推荐系统常面临模态数据缺失问题，现有方法通常直接丢弃缺失模态的样本，导致数据浪费和性能下降。目前该问题在多模态推荐领域缺乏系统化研究。

Method: 1) 首次形式化多模态推荐中的模态缺失问题；2) 将缺失模态问题重构为项目-项目共购图上的特征插补问题；3) 提出四种无需训练的图传播方法，通过项目间关系传播可用模态特征来填补缺失特征。

Result: 实验表明：1) 方法可无缝集成到现有多模态推荐系统；2) 保持甚至扩大了多模态与传统推荐系统的性能差距；3) 图基方法优于传统机器学习插补；4) 首次分析了项目图上特征同质性对插补效果的影响。

Conclusion: 该研究为多模态推荐中的模态缺失问题提供了系统化解决方案，基于图结构的特征插补方法能有效处理缺失模态，提升推荐性能，且具有实际部署的便利性。

Abstract: Multimodal recommender systems (RSs) represent items in the catalog through multimodal data (e.g., product images and descriptions) that, in some cases, might be noisy or (even worse) missing. In those scenarios, the common practice is to drop items with missing modalities and train the multimodal RSs on a subsample of the original dataset. To date, the problem of missing modalities in multimodal recommendation has still received limited attention in the literature, lacking a precise formalisation as done with missing information in traditional machine learning. In this work, we first provide a problem formalisation for missing modalities in multimodal recommendation. Second, by leveraging the user-item graph structure, we re-cast the problem of missing multimodal information as a problem of graph features interpolation on the item-item co-purchase graph. On this basis, we propose four training-free approaches that propagate the available multimodal features throughout the item-item graph to impute the missing features. Extensive experiments on popular multimodal recommendation datasets demonstrate that our solutions can be seamlessly plugged into any existing multimodal RS and benchmarking framework while still preserving (or even widen) the performance gap between multimodal and traditional RSs. Moreover, we show that our graph-based techniques can perform better than traditional imputations in machine learning under different missing modalities settings. Finally, we analyse (for the first time in multimodal RSs) how feature homophily calculated on the item-item graph can influence our graph-based imputations.

</details>


### [12] [Improving LLM-based Recommendation with Self-Hard Negatives from Intermediate Layers](https://arxiv.org/abs/2602.17410)
*Bingqian Li,Bowen Zheng,Xiaolei Wang,Long Zhang,Jinpeng Wang,Sheng Chen,Wayne Xin Zhao,Ji-rong Wen*

Main category: cs.IR

TL;DR: ILRec提出了一种新的偏好微调框架，利用中间层提取的自硬负样本信号来改进LLM推荐系统的偏好学习，通过跨层偏好优化和蒸馏增强负样本质量。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推荐系统主要使用序列级、离线生成的负样本，这些负样本在大型负项目空间中区分性和信息性不足，限制了偏好学习的效果。

Method: 提出ILRec框架：1）从中间层识别自硬负样本token作为细粒度负监督；2）设计两阶段框架：跨层偏好优化和跨层偏好蒸馏；3）引入轻量级协同过滤模型为负信号分配token级奖励，避免过度惩罚假负样本。

Result: 在三个数据集上的广泛实验表明，ILRec能有效提升基于LLM的推荐系统性能。

Conclusion: ILRec通过利用中间层的自硬负样本信号，解决了现有方法在大型负项目空间中负样本区分性不足的问题，为LLM推荐系统的偏好学习提供了有效解决方案。

Abstract: Large language models (LLMs) have shown great promise in recommender systems, where supervised fine-tuning (SFT) is commonly used for adaptation. Subsequent studies further introduce preference learning to incorporate negative samples into the training process. However, existing methods rely on sequence-level, offline-generated negatives, making them less discriminative and informative when adapting LLMs to recommendation tasks with large negative item spaces. To address these challenges, we propose ILRec, a novel preference fine-tuning framework for LLM-based recommendation, leveraging self-hard negative signals extracted from intermediate layers to improve preference learning. Specifically, we identify self-hard negative tokens from intermediate layers as fine-grained negative supervision that dynamically reflects the model's preference learning process. To effectively integrate these signals into training, we design a two-stage framework comprising cross-layer preference optimization and cross-layer preference distillation, enabling the model to jointly discriminate informative negatives and enhance the quality of negative signals from intermediate layers. In addition, we introduce a lightweight collaborative filtering model to assign token-level rewards for negative signals, mitigating the risk of over-penalizing false negatives. Extensive experiments on three datasets demonstrate ILRec's effectiveness in enhancing the performance of LLM-based recommender systems.

</details>


### [13] [Beyond Pipelines: A Fundamental Study on the Rise of Generative-Retrieval Architectures in Web Research](https://arxiv.org/abs/2602.17450)
*Amirereza Abbasi,Mohsen Hooshmand*

Main category: cs.IR

TL;DR: 这篇综述论文探讨了大型语言模型（LLMs）特别是通过检索增强生成（RAG）对网络研究和行业的影响，分析了关键进展、开放挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的兴起，网络研究和实践正在经历深刻变革。LLMs已经渗透到科学技术的各个领域，正在重塑网络研究和开发，将传统流程转变为生成式解决方案，并催生了新的应用。需要系统性地探索LLMs对网络领域的影响。

Method: 采用综述研究方法，重点分析检索增强生成（RAG）在LLMs中的应用。通过系统梳理近期进展，讨论LLMs在网络研究中的关键发展、现有挑战和未来方向。

Result: LLMs正在深刻改变网络研究和行业实践，特别是在信息检索、问答系统、推荐系统和网络分析等任务中，将传统流程转变为生成式解决方案。RAG技术在这一转型中发挥了关键作用，同时催生了网络摘要和教育工具等新应用。

Conclusion: LLMs通过RAG等技术正在重塑网络研究和开发范式，但仍面临开放挑战。未来需要继续探索如何利用LLMs增强网络解决方案，推动该领域的进一步发展。

Abstract: Web research and practices have evolved significantly over time, offering users diverse and accessible solutions across a wide range of tasks. While advanced concepts such as Web 4.0 have emerged from mature technologies, the introduction of large language models (LLMs) has profoundly influenced both the field and its applications. This wave of LLMs has permeated science and technology so deeply that no area remains untouched. Consequently, LLMs are reshaping web research and development, transforming traditional pipelines into generative solutions for tasks like information retrieval, question answering, recommendation systems, and web analytics. They have also enabled new applications such as web-based summarization and educational tools. This survey explores recent advances in the impact of LLMs-particularly through the use of retrieval-augmented generation (RAG)-on web research and industry. It discusses key developments, open challenges, and future directions for enhancing web solutions with LLMs.

</details>


### [14] [A Picture of Agentic Search](https://arxiv.org/abs/2602.17518)
*Francesca Pezzuti,Ophir Frieder,Fabrizio Silvestri,Sean MacAvaney,Nicola Tonellotto*

Main category: cs.IR

TL;DR: 论文提出Agentic Search Queryset (ASQ)数据集，用于解决信息检索系统在自动化代理查询时代面临的挑战，包含代理搜索行为和推理过程数据。


<details>
  <summary>Details</summary>
Motivation: 随着自动化系统越来越多地与人类一起发出搜索查询，信息检索面临重大转变。当前IR系统仍以人为中心设计，假设已不再适用于实际场景，导致系统性能优化出现问题。缺乏捕捉代理搜索行为的数据集是IR领域的关键缺口。

Method: 开发了一种收集代理检索增强系统在回答查询时产生和消费的所有数据的方法论。发布了ASQ数据集，包含推理诱导的查询、检索文档和思考过程，覆盖HotpotQA、Researchy Questions和MS MARCO数据集，涉及3种不同代理和2种检索管道。配套工具包支持扩展到新代理、检索器和数据集。

Result: 创建了Agentic Search Queryset (ASQ)数据集，这是首个专门捕捉代理搜索行为的数据集，包含代理在回答查询过程中的完整数据流，为研究代理驱动的信息检索提供了基础资源。

Conclusion: 信息检索领域需要适应自动化代理查询的新现实，ASQ数据集填补了关键的数据缺口，为开发能够同时满足人类和代理需求的检索系统提供了必要的数据基础和研究工具。

Abstract: With automated systems increasingly issuing search queries alongside humans, Information Retrieval (IR) faces a major shift. Yet IR remains human-centred, with systems, evaluation metrics, user models, and datasets designed around human queries and behaviours. Consequently, IR operates under assumptions that no longer hold in practice, with changes to workload volumes, predictability, and querying behaviours. This misalignment affects system performance and optimisation: caching may lose effectiveness, query pre-processing may add overhead without improving results, and standard metrics may mismeasure satisfaction. Without adaptation, retrieval models risk satisfying neither humans, nor the emerging user segment of agents. However, datasets capturing agent search behaviour are lacking, which is a critical gap given IR's historical reliance on data-driven evaluation and optimisation. We develop a methodology for collecting all the data produced and consumed by agentic retrieval-augmented systems when answering queries, and we release the Agentic Search Queryset (ASQ) dataset. ASQ contains reasoning-induced queries, retrieved documents, and thoughts for queries in HotpotQA, Researchy Questions, and MS MARCO, for 3 diverse agents and 2 retrieval pipelines. The accompanying toolkit enables ASQ to be extended to new agents, retrievers, and datasets.

</details>


### [15] [Mine and Refine: Optimizing Graded Relevance in E-commerce Search Retrieval](https://arxiv.org/abs/2602.17654)
*Jiaqi Xi,Raghav Saboo,Luming Chen,Martin Wang,Sudeep Das*

Main category: cs.IR

TL;DR: 提出两阶段"挖掘与精炼"对比训练框架，用于增强多类别电商搜索的语义文本嵌入，通过策略一致的监督和边界清晰的相似度分层来提升检索效果。


<details>
  <summary>Details</summary>
Motivation: 大规模电商搜索需要能够泛化到长尾、噪声查询的嵌入表示，同时需要符合产品策略约束的可扩展监督。实际挑战在于相关性通常是分级的：用户接受替代品或互补品而非精确匹配，生产系统需要清晰的相似度分层来实现稳定的混合排序和阈值处理。

Method: 1. 使用轻量级LLM在三级相关性标注上进行微调，通过参与度驱动的审核减少噪声；2. 第一阶段：用标签感知的监督对比目标训练多语言孪生双塔检索器，构建鲁棒的全局语义空间；3. 第二阶段：通过ANN挖掘困难样本并用策略对齐的LLM重新标注，引入多类圆形损失扩展来明确锐化相关性层级间的相似度边界；4. 通过拼写增强和合成查询生成提升鲁棒性。

Result: 广泛的离线评估和生产A/B测试表明，该框架提高了检索相关性，并在用户参与度和业务影响方面取得了统计显著的提升。

Conclusion: 提出的两阶段"挖掘与精炼"对比训练框架能够有效提升电商搜索的语义嵌入质量，通过策略一致的监督和明确的相似度边界分层，实现了更好的检索效果和业务价值。

Abstract: We propose a two-stage "Mine and Refine" contrastive training framework for semantic text embeddings to enhance multi-category e-commerce search retrieval. Large scale e-commerce search demands embeddings that generalize to long tail, noisy queries while adhering to scalable supervision compatible with product and policy constraints. A practical challenge is that relevance is often graded: users accept substitutes or complements beyond exact matches, and production systems benefit from clear separation of similarity scores across these relevance strata for stable hybrid blending and thresholding. To obtain scalable policy consistent supervision, we fine-tune a lightweight LLM on human annotations under a three-level relevance guideline and further reduce residual noise via engagement driven auditing. In Stage 1, we train a multilingual Siamese two-tower retriever with a label aware supervised contrastive objective that shapes a robust global semantic space. In Stage 2, we mine hard samples via ANN and re-annotate them with the policy aligned LLM, and introduce a multi-class extension of circle loss that explicitly sharpens similarity boundaries between relevance levels, to further refine and enrich the embedding space. Robustness is additionally improved through additive spelling augmentation and synthetic query generation. Extensive offline evaluations and production A/B tests show that our framework improves retrieval relevance and delivers statistically significant gains in engagement and business impact.

</details>
