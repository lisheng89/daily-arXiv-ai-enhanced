<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 14]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Membership Inference Attack against Large Language Model-based Recommendation Systems: A New Distillation-based Paradigm](https://arxiv.org/abs/2511.14763)
*Li Cuihong,Huang Xiaowen,Yin Chuanhuan,Sang Jitao*

Main category: cs.IR

TL;DR: 提出一种基于知识蒸馏的成员推理攻击范式，通过知识蒸馏获得参考模型来增强对成员和非成员数据的区分能力，提高对基于大语言模型的推荐系统的攻击性能。


<details>
  <summary>Details</summary>
Motivation: 传统成员推理攻击通过影子模型获取目标模型特征，但大语言模型推荐系统的训练数据规模和复杂性使得影子模型难以构建。知识蒸馏能够增强模型对成员和非成员数据的区分能力。

Method: 引入知识蒸馏获得参考模型，在蒸馏过程中分别对成员和非成员数据进行蒸馏，从参考模型获取个体特征，使用融合特征训练攻击模型。

Result: 与基于影子模型的攻击相比，该范式提高了成员推理攻击的性能。

Conclusion: 基于知识蒸馏的成员推理攻击范式能够有效提升对大语言模型推荐系统的攻击效果。

Abstract: Membership Inference Attack (MIA) aims to determine if a data sample is used in the training dataset of a target model. Traditional MIA obtains feature of target model via shadow models and uses the feature to train attack model, but the scale and complexity of training or fine-tuning data for large language model (LLM)-based recommendation systems make shadow models difficult to construct. Knowledge distillation as a method for extracting knowledge contributes to construct a stronger reference model. Knowledge distillation enables separate distillation for member and non-member data during the distillation process, enhancing the model's discriminative capability between the two in MIA. This paper propose a knowledge distillation-based MIA paradigm to improve the performance of membership inference attacks on LLM-based recommendation systems. Our paradigm introduces knowledge distillation to obtain a reference model, which enhances the reference model's ability to distinguish between member and non-member data. We obtain individual features from the reference model and train our attack model with fused feature. Our paradigm improves the attack performance of MIA compared to shadow model-based attack.

</details>


### [2] [Image-Seeking Intent Prediction for Cross-Device Product Search](https://arxiv.org/abs/2511.14764)
*Mariya Hendriksen,Svitlana Vakulenko,Jordan Massiah,Gabriella Kazai,Emine Yilmaz*

Main category: cs.IR

TL;DR: 本文提出了图像寻求意图预测任务，利用LLM预测语音产品查询何时需要视觉增强和跨设备切换，以改善电商产品发现体验。


<details>
  <summary>Details</summary>
Motivation: 随着用户在多设备上购物，不同设备具有不同的输入输出能力。精准预测何时需要跨设备视觉增强可以显著提升用户体验，但需要高精度以避免不必要的摩擦。

Method: 使用来自多设备零售助手的90万条语音查询数据，训练IRP模型，该模型结合用户输入查询和检索到的产品元数据来预测视觉意图，并采用轻量级摘要和面向精度的可微分损失函数。

Result: 实验表明，结合查询语义和产品数据（特别是通过轻量级摘要改进后）能持续提高预测准确率，使用面向精度的损失函数进一步减少了误报。

Conclusion: LLM有潜力驱动智能跨设备购物助手，预测和适应用户需求，实现更无缝和个性化的电商体验。

Abstract: Large Language Models (LLMs) are transforming personalized search, recommendations, and customer interaction in e-commerce. Customers increasingly shop across multiple devices, from voice-only assistants to multimodal displays, each offering different input and output capabilities. A proactive suggestion to switch devices can greatly improve the user experience, but it must be offered with high precision to avoid unnecessary friction. We address the challenge of predicting when a query requires visual augmentation and a cross-device switch to improve product discovery. We introduce Image-Seeking Intent Prediction, a novel task for LLM-driven e-commerce assistants that anticipates when a spoken product query should proactively trigger a visual on a screen-enabled device. Using large-scale production data from a multi-device retail assistant, including 900K voice queries, associated product retrievals, and behavioral signals such as image carousel engagement, we train IRP (Image Request Predictor), a model that leverages user input query and corresponding retrieved product metadata to anticipate visual intent. Our experiments show that combining query semantics with product data, particularly when improved through lightweight summarization, consistently improves prediction accuracy. Incorporating a differentiable precision-oriented loss further reduces false positives. These results highlight the potential of LLMs to power intelligent, cross-device shopping assistants that anticipate and adapt to user needs, enabling more seamless and personalized e-commerce experiences.

</details>


### [3] [Optimizing Agricultural Research: A RAG-Based Approach to Mycorrhizal Fungi Information](https://arxiv.org/abs/2511.14765)
*Mohammad Usman Altam,Md Imtiaz Habib,Tuan Hoang*

Main category: cs.IR

TL;DR: 本研究开发了一个针对菌根真菌农业应用的RAG系统，通过语义检索和结构化数据提取相结合的方法，提高了农业领域知识问答的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型受限于静态训练语料，无法动态整合领域专业知识。本研究旨在通过RAG技术克服这一限制，为菌根真菌在可持续农业中的应用提供准确可靠的知识支持。

Method: 采用双层策略：1）使用向量嵌入从农学和生物技术语料库中进行语义检索和增强；2）结构化数据提取以捕获预定义的实验元数据（如接种方法、孢子密度、土壤参数和产量结果）。

Result: 实证评估表明，该管道能够检索和合成关于菌根真菌与作物系统（如番茄）相互作用的高度相关信息，支持近实时检索不断发展的文献库。

Conclusion: 该框架强调了AI驱动的知识发现在加速农业生态创新和增强可持续农业系统决策方面的潜力。

Abstract: Retrieval-Augmented Generation (RAG) represents a transformative approach within natural language processing (NLP), combining neural information retrieval with generative language modeling to enhance both contextual accuracy and factual reliability of responses. Unlike conventional Large Language Models (LLMs), which are constrained by static training corpora, RAG-powered systems dynamically integrate domain-specific external knowledge sources, thereby overcoming temporal and disciplinary limitations. In this study, we present the design and evaluation of a RAG-enabled system tailored for Mycophyto, with a focus on advancing agricultural applications related to arbuscular mycorrhizal fungi (AMF). These fungi play a critical role in sustainable agriculture by enhancing nutrient acquisition, improving plant resilience under abiotic and biotic stresses, and contributing to soil health. Our system operationalizes a dual-layered strategy: (i) semantic retrieval and augmentation of domain-specific content from agronomy and biotechnology corpora using vector embeddings, and (ii) structured data extraction to capture predefined experimental metadata such as inoculation methods, spore densities, soil parameters, and yield outcomes. This hybrid approach ensures that generated responses are not only semantically aligned but also supported by structured experimental evidence. To support scalability, embeddings are stored in a high-performance vector database, allowing near real-time retrieval from an evolving literature base. Empirical evaluation demonstrates that the proposed pipeline retrieves and synthesizes highly relevant information regarding AMF interactions with crop systems, such as tomato (Solanum lycopersicum). The framework underscores the potential of AI-driven knowledge discovery to accelerate agroecological innovation and enhance decision-making in sustainable farming systems.

</details>


### [4] [OTCR: Optimal Transmission, Compression and Representation for Multimodal Information Extraction](https://arxiv.org/abs/2511.14766)
*Yang Li,Yajiao Wang,Wenhao Hu,Zhixiong Zhang,Mengting Zhang*

Main category: cs.IR

TL;DR: OTCR是一个两阶段的多模态信息提取框架，通过跨模态最优传输和变分信息瓶颈实现文本主导、视觉选择支持的可控融合，在文档AI中取得竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常假设模态等价或采用统一融合方式，导致多模态信号的无差别融合和任务无关冗余，限制了泛化能力。需要从任务中心视角重新审视多模态信息提取。

Method: 两阶段框架：1) 跨模态最优传输产生文本token和视觉patch的稀疏概率对齐，通过上下文感知门控控制视觉注入；2) 变分信息瓶颈压缩融合特征，过滤任务无关噪声。

Result: 在FUNSD上达到91.95% SER和91.13% RE，在XFUND(ZH)上达到91.09% SER和94.20% RE，性能具有竞争力。特征分析确认减少了模态冗余并增强了任务信号。

Conclusion: 为文档AI中的可控多模态融合提供了一个可解释的、基于信息论的范式，实现了文本主导、视觉选择支持的有效融合。

Abstract: Multimodal Information Extraction (MIE) requires fusing text and visual cues from visually rich documents. While recent methods have advanced multimodal representation learning, most implicitly assume modality equivalence or treat modalities in a largely uniform manner, still relying on generic fusion paradigms. This often results in indiscriminate incorporation of multimodal signals and insufficient control over task-irrelevant redundancy, which may in turn limit generalization. We revisit MIE from a task-centric view: text should dominate, vision should selectively support. We present OTCR, a two-stage framework. First, Cross-modal Optimal Transport (OT) yields sparse, probabilistic alignments between text tokens and visual patches, with a context-aware gate controlling visual injection. Second, a Variational Information Bottleneck (VIB) compresses fused features, filtering task-irrelevant noise to produce compact, task-adaptive representations. On FUNSD, OTCR achieves 91.95% SER and 91.13% RE, while on XFUND (ZH), it reaches 91.09% SER and 94.20% RE, demonstrating competitive performance across datasets. Feature-level analyses further confirm reduced modality redundancy and strengthened task signals. This work offers an interpretable, information-theoretic paradigm for controllable multimodal fusion in document AI.

</details>


### [5] [An LLM-Powered Agent for Real-Time Analysis of the Vietnamese IT Job Market](https://arxiv.org/abs/2511.14767)
*Minh-Thuan Nguyen,Thien Vo-Thanh,Thai-Duy Dinh,Xuan-Quang Phan,Tan-Ha Mai,Lam-Son Lê*

Main category: cs.IR

TL;DR: 开发了一个基于AI的越南IT就业市场咨询系统，通过自动化数据收集和LLM处理，提供实时、数据驱动的职业指导


<details>
  <summary>Details</summary>
Motivation: 解决越南IT就业市场缺乏可靠职业指导的问题，现有市场报告过时且人工分析大量职位信息不现实

Method: 构建自动化数据收集管道爬取职位信息，使用LLM结构化非结构化数据，基于ReAct框架开发工具增强的AI代理，支持SQL查询、语义搜索和数据可视化

Result: 成功收集分析3,745个职位信息，能够回答复杂多步查询、生成可视化图表，并提供基于真实数据的个性化职业建议

Conclusion: 引入劳动力市场分析新范式，展示专业AI代理系统如何为新一代专业人士提供及时可信的职业智能服务

Abstract: Individuals entering Vietnam's dynamic Information Technology (IT) job market face a critical gap in reliable career guidance. Existing market reports are often outdated, while the manual analysis of thousands of job postings is impractical for most. To address this challenge, we present the AI Job Market Consultant, a novel conversational agent that delivers deep, data-driven insights directly from the labor market in real-time. The foundation of our system is a custom-built dataset created via an automated pipeline that crawls job portals using Playwright and leverages the Large Language Model (LLM) to intelligently structure unstructured posting data. The core of our system is a tool-augmented AI agent, based on the ReAct agentic framework, which enables the ability of autonomously reasoning, planning, and executing actions through a specialized toolbox for SQL queries, semantic search, and data visualization. Our prototype successfully collected and analyzed 3,745 job postings, demonstrating its ability to answer complex, multi-step queries, generate on-demand visualizations, and provide personalized career advice grounded in real-world data. This work introduces a new paradigm for labor market analysis, showcasing how specialized agentic AI systems can democratize access to timely, trustworthy career intelligence for the next generation of professionals.

</details>


### [6] [Causally-Informed Reinforcement Learning for Adaptive Emotion-Aware Social Media Recommendation](https://arxiv.org/abs/2511.14768)
*Bhavika Jain,Robert Pitsko,Ananya Drishti,Mahfuza Farooque*

Main category: cs.IR

TL;DR: 提出了一个情感感知的社交媒体推荐框架ESMR，通过结合Transformer情感预测器和混合推荐策略，在保持用户参与度的同时改善情感健康。


<details>
  <summary>Details</summary>
Motivation: 现有社交媒体推荐系统仅优化参与度指标，不考虑用户情感状态，而长期接触情绪化内容会对用户情感健康产生负面影响。

Method: ESMR框架整合基于Transformer的情感预测器与混合推荐策略：稳定期使用LightGBM模型，持续负面情绪时使用带因果奖励的强化学习代理。

Result: 基于30天交互轨迹的行为评估显示，ESMR改善了情感恢复、降低了情绪波动，同时保持了良好的参与度。

Conclusion: ESMR为在不损害参与度性能的前提下实现情感感知推荐提供了一条可行路径。

Abstract: Social media recommendation systems play a central role in shaping users' emotional experiences. However, most systems are optimized solely for engagement metrics, such as click rate, viewing time, or scrolling, without accounting for users' emotional states. Repeated exposure to emotionally charged content has been shown to negatively affect users' emotional well-being over time. We propose an Emotion-aware Social Media Recommendation (ESMR) framework that personalizes content based on users' evolving emotional trajectories. ESMR integrates a Transformer-based emotion predictor with a hybrid recommendation policy: a LightGBM model for engagement during stable periods and a reinforcement learning agent with causally informed rewards when negative emotional states persist. Through behaviorally grounded evaluation over 30-day interaction traces, ESMR demonstrates improved emotional recovery, reduced volatility, and strong engagement retention. ESMR offers a path toward emotionally aware recommendations without compromising engagement performance.

</details>


### [7] [Cluster-based Adaptive Retrieval: Dynamic Context Selection for RAG Applications](https://arxiv.org/abs/2511.14769)
*Yifan Xu,Vipul Gupta,Rohit Aggarwal,Varsha Mahadevan,Bhaskar Krishnamachari*

Main category: cs.IR

TL;DR: CAR算法通过分析查询-文档相似度距离的聚类模式，动态确定最佳文档检索数量，解决了传统静态top-k检索无法适应不同查询特性的问题。


<details>
  <summary>Details</summary>
Motivation: 传统静态top-k检索方法无法适应不同查询特性：窄范围查询需要少量高相关文档，而宽泛查询需要更多支持信息。静态方法导致要么上下文不足，要么信息冗余。

Method: 提出基于聚类的自适应检索(CAR)算法，通过分析有序查询-文档相似度距离的聚类模式，检测相似度距离中的转折点，确定从高度相关文档转向不太相关候选文档的临界点，建立随查询复杂度扩展的自适应截断机制。

Result: 在Coinbase的CDP语料库和公共MultiHop-RAG基准测试中，CAR始终选择最佳检索深度并获得最高TES分数，优于所有固定top-k基线。在下游RAG评估中，CAR将LLM令牌使用量减少60%，端到端延迟降低22%，幻觉减少10%，同时完全保持答案相关性。集成到Coinbase虚拟助手后，用户参与度提升了200%。

Conclusion: CAR算法通过动态确定检索文档数量，显著提升了RAG系统的效率和效果，在减少资源消耗的同时保持了答案质量，并大幅提升了用户体验。

Abstract: Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by pulling in external material, document, code, manuals, from vast and ever-growing corpora, to effectively answer user queries. The effectiveness of RAG depends significantly on aligning the number of retrieved documents with query characteristics: narrowly focused queries typically require fewer, highly relevant documents, whereas broader or ambiguous queries benefit from retrieving more extensive supporting information. However, the common static top-k retrieval approach fails to adapt to this variability, resulting in either insufficient context from too few documents or redundant information from too many. Motivated by these challenges, we introduce Cluster-based Adaptive Retrieval (CAR), an algorithm that dynamically determines the optimal number of documents by analyzing the clustering patterns of ordered query-document similarity distances. CAR detects the transition point within similarity distances, where tightly clustered, highly relevant documents shift toward less pertinent candidates, establishing an adaptive cut-off that scales with query complexity. On Coinbase's CDP corpus and the public MultiHop-RAG benchmark, CAR consistently picks the optimal retrieval depth and achieves the highest TES score, outperforming every fixed top-k baseline. In downstream RAG evaluations, CAR cuts LLM token usage by 60%, trims end-to-end latency by 22%, and reduces hallucinations by 10% while fully preserving answer relevance. Since integrating CAR into Coinbase's virtual assistant, we've seen user engagement jump by 200%.

</details>


### [8] [ExplainRec: Towards Explainable Multi-Modal Zero-Shot Recommendation with Preference Attribution and Large Language Models](https://arxiv.org/abs/2511.14770)
*Bo Ma,LuYao Liu,ZeHua Hu,Simon Lau*

Main category: cs.IR

TL;DR: ExplainRec是一个基于大语言模型的推荐系统框架，通过偏好归因、多模态融合和零样本迁移学习解决现有方法的可解释性和冷启动问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推荐方法如TALLRec在可解释性和冷启动场景下面临挑战，需要开发更有效的解决方案。

Method: 采用偏好归因调优实现可解释推荐、零样本偏好迁移处理冷启动、多模态增强利用视觉和文本内容、多任务协同优化。

Result: 在MovieLens-25M和Amazon数据集上，ExplainRec优于现有方法，电影推荐AUC提升0.7%，跨域任务提升0.9%，能生成可解释推荐并有效处理冷启动场景。

Conclusion: ExplainRec框架通过整合多种技术贡献，显著提升了LLM推荐系统的性能、可解释性和冷启动处理能力。

Abstract: Recent advances in Large Language Models (LLMs) have opened new possibilities for recommendation systems, though current approaches such as TALLRec face challenges in explainability and cold-start scenarios. We present ExplainRec, a framework that extends LLM-based recommendation capabilities through preference attribution, multi-modal fusion, and zero-shot transfer learning. The framework incorporates four technical contributions: preference attribution tuning for explainable recommendations, zero-shot preference transfer for cold-start users and items, multi-modal enhancement leveraging visual and textual content, and multi-task collaborative optimization. Experimental evaluation on MovieLens-25M and Amazon datasets shows that ExplainRec outperforms existing methods, achieving AUC improvements of 0.7\% on movie recommendation and 0.9\% on cross-domain tasks, while generating interpretable explanations and handling cold-start scenarios effectively.

</details>


### [9] [SilverTorch: A Unified Model-based System to Democratize Large-Scale Recommendation on GPUs](https://arxiv.org/abs/2511.14881)
*Bi Xue,Hong Wu,Lei Chen,Chao Yang,Yiming Ma,Fei Ding,Zhen Wang,Liang Wang,Xiaoheng Mao,Ke Huang,Xialu Li,Peng Xia,Rui Jian,Yanli Zhao,Yanzun Huang,Yijie Deng,Harry Tran,Ryan Chang,Min Yu,Eric Dong,Jiazhou Wang,Qianqian Zhang,Keke Zhai,Hongzhang Yin,Pawel Garbacki,Zheng Fang,Yiyi Pan,Min Ni,Yang Liu*

Main category: cs.IR

TL;DR: SilverTorch是一个基于GPU的推荐模型服务系统，通过统一模型服务、GPU上的Bloom索引和Int8 ANN内核，以及索引协同设计，显著提升了推荐系统的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于CPU的ANN索引和过滤服务存在显著成本问题，且无法支持更复杂的模型架构，如学习相似性和多任务检索。

Method: 提出SilverTorch系统，用模型层替换独立的索引和过滤服务，包括GPU上的Bloom索引算法、融合Int8 ANN内核、索引协同设计，以及OverArch评分层和Value模型。

Result: 在工业级数据集上，SilverTorch实现了5.6倍延迟降低和23.7倍吞吐量提升，成本效率比CPU方案高13.35倍，同时通过服务更复杂模型提高了准确性。

Conclusion: SilverTorch提供了一个高效、准确的推荐模型服务解决方案，支持数百个在线模型和数十亿日活用户的内容推荐。

Abstract: Serving deep learning based recommendation models (DLRM) at scale is challenging. Existing systems rely on CPU-based ANN indexing and filtering services, suffering from non-negligible costs and forgoing joint optimization opportunities. Such inefficiency makes them difficult to support more complex model architectures, such as learned similarities and multi-task retrieval.
  In this paper, we propose SilverTorch, a model-based system for serving recommendation models on GPUs. SilverTorch unifies model serving by replacing standalone indexing and filtering services with layers of served models. We propose a Bloom index algorithm on GPUs for feature filtering and a tensor-native fused Int8 ANN kernel on GPUs for nearest neighbor search. We further co-design the ANN search index and filtering index to reduce GPU memory utilization and eliminate unnecessary computation. Benefit from SilverTorch's serving paradigm, we introduce a OverArch scoring layer and a Value Model to aggregate results across multi-tasks. These advancements improve the accuracy for retrieval and enable future studies for serving more complex models. For ranking, SilverTorch's design accelerates item embedding calculation by caching the pre-calculated embeddings inside the serving model.
  Our evaluation on the industry-scale datasets show that SilverTorch achieves up to 5.6x lower latency and 23.7x higher throughput compared to the state-of-the-art approaches. We also demonstrate that SilverTorch's solution is 13.35x more cost-efficient than CPU-based solution while improving accuracy via serving more complex models. SilverTorch serves over hundreds of models online across major products and recommends contents for billions of daily active users.

</details>


### [10] [Multi-Aspect Cross-modal Quantization for Generative Recommendation](https://arxiv.org/abs/2511.15122)
*Fuwei Zhang,Xiaoyu Liu,Dongbo Xi,Jishen Yin,Huan Chen,Peng Yan,Fuzhen Zhuang,Zhao Zhang*

Main category: cs.IR

TL;DR: 提出MACRec方法，通过多模态交叉量化改进生成式推荐系统，降低冲突率并增强生成能力


<details>
  <summary>Details</summary>
Motivation: 当前生成式推荐方法在利用多模态信息和捕捉深度跨模态交互方面存在局限，无法有效学习高质量语义ID和训练生成模型

Method: 引入多模态交叉量化进行ID学习，结合隐式和显式跨模态对齐来增强生成能力

Result: 在三个知名推荐数据集上的实验证明了方法的有效性

Conclusion: MACRec通过多模态信息的互补整合，显著改善了生成式推荐的性能

Abstract: Generative Recommendation (GR) has emerged as a new paradigm in recommender systems. This approach relies on quantized representations to discretize item features, modeling users' historical interactions as sequences of discrete tokens. Based on these tokenized sequences, GR predicts the next item by employing next-token prediction methods. The challenges of GR lie in constructing high-quality semantic identifiers (IDs) that are hierarchically organized, minimally conflicting, and conducive to effective generative model training. However, current approaches remain limited in their ability to harness multimodal information and to capture the deep and intricate interactions among diverse modalities, both of which are essential for learning high-quality semantic IDs and for effectively training GR models. To address this, we propose Multi-Aspect Cross-modal quantization for generative Recommendation (MACRec), which introduces multimodal information and incorporates it into both semantic ID learning and generative model training from different aspects. Specifically, we first introduce cross-modal quantization during the ID learning process, which effectively reduces conflict rates and thus improves codebook usability through the complementary integration of multimodal information. In addition, to further enhance the generative ability of our GR model, we incorporate multi-aspect cross-modal alignments, including the implicit and explicit alignments. Finally, we conduct extensive experiments on three well-known recommendation datasets to demonstrate the effectiveness of our proposed method.

</details>


### [11] [ItemRAG: Item-Based Retrieval-Augmented Generation for LLM-Based Recommendation](https://arxiv.org/abs/2511.15141)
*Sunwoo Kim,Geon Lee,Kyungho Kim,Jaemin Yoo,Kijung Shin*

Main category: cs.IR

TL;DR: 提出了ItemRAG方法，一种基于物品的检索增强生成方法，通过检索物品间的共同购买历史来提升LLM推荐系统的性能，特别是在冷启动物品推荐方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数RAG方法都是基于用户的，检索相似用户的购买模式。本文提出基于物品的方法，旨在更好地捕捉物品间的共同购买模式，特别是对冷启动物品的处理。

Method: ItemRAG方法从物品-物品共同购买历史中检索相关物品，而非用户。检索策略结合了语义相似物品以处理冷启动物品，并使用共同购买频率来提高检索物品的相关性。

Result: 实验表明，ItemRAG将零样本LLM推荐器的Hit-Ratio-1提升了43%，并在标准推荐和冷启动物品推荐设置下均优于基于用户的RAG基线方法。

Conclusion: ItemRAG通过基于物品的检索策略有效提升了LLM推荐系统的性能，特别是在处理冷启动物品方面具有显著优势。

Abstract: Recently, large language models (LLMs) have been widely used as recommender systems, owing to their strong reasoning capability and their effectiveness in handling cold-start items. To better adapt LLMs for recommendation, retrieval-augmented generation (RAG) has been incorporated. Most existing RAG methods are user-based, retrieving purchase patterns of users similar to the target user and providing them to the LLM. In this work, we propose ItemRAG, an item-based RAG method for LLM-based recommendation that retrieves relevant items (rather than users) from item-item co-purchase histories. ItemRAG helps LLMs capture co-purchase patterns among items, which are beneficial for recommendations. Especially, our retrieval strategy incorporates semantically similar items to better handle cold-start items and uses co-purchase frequencies to improve the relevance of the retrieved items. Through extensive experiments, we demonstrate that ItemRAG consistently (1) improves the zero-shot LLM-based recommender by up to 43% in Hit-Ratio-1 and (2) outperforms user-based RAG baselines under both standard and cold-start item recommendation settings.

</details>


### [12] [Selective Mixup for Debiasing Question Selection in Computerized Adaptive Testing](https://arxiv.org/abs/2511.15241)
*Mi Tian,Kun Zhang,Fei Liu,Jinglong Li,Yuxin Liao,Chenxi Bai,Zhengtao Tan,Le Wu,Richang Hong*

Main category: cs.IR

TL;DR: 本文提出了一种用于计算机自适应测试(CAT)的去偏框架，通过跨属性考生检索和选择性混合正则化来解决选择偏差问题，显著提高了诊断模型的泛化能力和公平性。


<details>
  <summary>Details</summary>
Motivation: 现有CAT方法主要关注诊断准确性，但忽视了自适应过程中固有的选择偏差问题。这种偏差源于问题选择严重依赖能力估计，导致诊断模型出现偏差预测，且学习者历史交互的不平衡性会加剧这种偏差。

Method: 提出包含两个关键模块的去偏框架：1)跨属性考生检索模块，检索具有相对均衡正确/错误回答分布的平衡考生作为偏差考生的中性参考；2)选择性混合正则化模块，在标签一致性条件下对偏差考生与其匹配的平衡对应项进行混合，丰富偏差冲突样本的多样性并平滑选择边界。

Result: 在两个基准数据集上的广泛实验表明，该方法显著提高了CAT中问题选择的泛化能力和公平性，多个先进诊断模型都得到了实质性改进。

Conclusion: 该去偏框架有效解决了CAT中的选择偏差问题，通过平衡参考和混合正则化技术，提升了诊断模型的性能和公平性，为在线教育平台的个性化学习者建模提供了更可靠的解决方案。

Abstract: Computerized Adaptive Testing (CAT) is a widely used technology for evaluating learners' proficiency in online education platforms. By leveraging prior estimates of proficiency to select questions and updating the estimates iteratively based on responses, CAT enables personalized learner modeling and has attracted substantial attention. Despite this progress, most existing works focus primarily on improving diagnostic accuracy, while overlooking the selection bias inherent in the adaptive process. Selection Bias arises because the question selection is strongly influenced by the estimated proficiency, such as assigning easier questions to learners with lower proficiency and harder ones to learners with higher proficiency. Since the selection depends on prior estimation, this bias propagates into the diagnosis model, which is further amplified during iterative updates, leading to misalignment and biased predictions. Moreover, the imbalanced nature of learners' historical interactions often exacerbates the bias in diagnosis models. To address this issue, we propose a debiasing framework consisting of two key modules: Cross-Attribute Examinee Retrieval and Selective Mixup-based Regularization. First, we retrieve balanced examinees with relatively even distributions of correct and incorrect responses and use them as neutral references for biased examinees. Then, mixup is applied between each biased examinee and its matched balanced counterpart under label consistency. This augmentation enriches the diversity of bias-conflicting samples and smooths selection boundaries. Finally, extensive experiments on two benchmark datasets with multiple advanced diagnosis models demonstrate that our method substantially improves both the generalization ability and fairness of question selection in CAT.

</details>


### [13] [Unveiling Inference Scaling for Difference-Aware User Modeling in LLM Personalization](https://arxiv.org/abs/2511.15389)
*Suyu Chen,Yimeng Bai,Yulong Huang,Xiaoyan Zhao,Yang Zhang*

Main category: cs.IR

TL;DR: 提出了DRP框架，通过推理扩展重构差异提取机制，利用系统2思维增强LLM个性化能力，在个性化评论生成任务中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖用户自身历史，忽略了用户间差异对个性化的重要性，且特征提取过程依赖固定维度和快速直觉推理，限制了用户差异的覆盖范围和粒度。

Method: DRP框架自主识别相关差异特征维度，生成结构化定义和描述，实现对用户差异的慢速、深思熟虑的推理（系统2思维）。

Result: 在个性化评论生成实验中，DRP在多个指标上持续优于基线方法。

Conclusion: DRP通过重构差异提取机制并利用推理扩展，有效提升了LLM的个性化能力。

Abstract: Large Language Models (LLMs) are increasingly integrated into users' daily lives, driving a growing demand for personalized outputs. Prior work has primarily leveraged a user's own history, often overlooking inter-user differences that are critical for effective personalization. While recent methods have attempted to model such differences, their feature extraction processes typically rely on fixed dimensions and quick, intuitive inference (System-1 thinking), limiting both the coverage and granularity of captured user differences. To address these limitations, we propose Difference-aware Reasoning Personalization (DRP), a framework that reconstructs the difference extraction mechanism by leveraging inference scaling to enhance LLM personalization. DRP autonomously identifies relevant difference feature dimensions and generates structured definitions and descriptions, enabling slow, deliberate reasoning (System-2 thinking) over user differences. Experiments on personalized review generation demonstrate that DRP consistently outperforms baseline methods across multiple metrics.

</details>


### [14] [CroPS: Improving Dense Retrieval with Cross-Perspective Positive Samples in Short-Video Search](https://arxiv.org/abs/2511.15443)
*Ao Xie,Jiahui Chen,Quanzhi Zhu,Xiaoze Jiang,Zhiheng Qin,Enyun Yu,Han Li*

Main category: cs.IR

TL;DR: CroPS是一个新颖的检索数据引擎，通过从查询级、系统级和知识级引入多样化的正样本来缓解密集检索中的过滤气泡效应，在快手搜索平台上取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 解决工业检索系统中基于历史用户交互的自强化训练导致的过滤气泡效应，避免模型偏向于保守检索而排除潜在相关内容。

Method: 提出CroPS框架，从三个层面引入正样本：用户查询重构行为（查询级）、推荐流中的参与数据（系统级）、LLM合成的世界知识（知识级），并采用分层标签分配策略和H-InfoNCE损失函数。

Result: 在快手搜索平台上的大量实验表明，CroPS在离线和在线A/B测试中都显著优于强基线，提升了检索性能并降低了查询重构率。

Conclusion: CroPS已完全部署在快手搜索中，为数亿用户提供服务，证明了其在缓解过滤气泡效应和提升检索质量方面的有效性。

Abstract: Dense retrieval has become a foundational paradigm in modern search systems, especially on short-video platforms. However, most industrial systems adopt a self-reinforcing training pipeline that relies on historically exposed user interactions for supervision. This paradigm inevitably leads to a filter bubble effect, where potentially relevant but previously unseen content is excluded from the training signal, biasing the model toward narrow and conservative retrieval. In this paper, we present CroPS (Cross-Perspective Positive Samples), a novel retrieval data engine designed to alleviate this problem by introducing diverse and semantically meaningful positive examples from multiple perspectives. CroPS enhances training with positive signals derived from user query reformulation behavior (query-level), engagement data in recommendation streams (system-level), and world knowledge synthesized by large language models (knowledge-level). To effectively utilize these heterogeneous signals, we introduce a Hierarchical Label Assignment (HLA) strategy and a corresponding H-InfoNCE loss that together enable fine-grained, relevance-aware optimization. Extensive experiments conducted on Kuaishou Search, a large-scale commercial short-video search platform, demonstrate that CroPS significantly outperforms strong baselines both offline and in live A/B tests, achieving superior retrieval performance and reducing query reformulation rates. CroPS is now fully deployed in Kuaishou Search, serving hundreds of millions of users daily.

</details>
