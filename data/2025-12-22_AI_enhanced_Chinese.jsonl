{"id": "2512.17015", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.17015", "abs": "https://arxiv.org/abs/2512.17015", "authors": ["Domenico De Gioia", "Claudio Pomo", "Ludovico Boratto", "Tommaso Di Noia"], "title": "A Reproducible and Fair Evaluation of Partition-aware Collaborative Filtering", "comment": "accepted at ECIR 2026 reproducibility track", "summary": "Similarity-based collaborative filtering (CF) models have long demonstrated strong offline performance and conceptual simplicity. However, their scalability is limited by the quadratic cost of maintaining dense item-item similarity matrices. Partitioning-based paradigms have recently emerged as an effective strategy for balancing effectiveness and efficiency, enabling models to learn local similarities within coherent subgraphs while maintaining a limited global context. In this work, we focus on the Fine-tuning Partition-aware Similarity Refinement (FPSR) framework, a prominent representative of this family, as well as its extension, FPSR+. Reproducible evaluation of partition-aware collaborative filtering remains challenging, as prior FPSR/FPSR+ reports often rely on splits of unclear provenance and omit some similarity-based baselines, thereby complicating fair comparison. We present a transparent, fully reproducible benchmark of FPSR and FPSR+. Based on our results, the family of FPSR models does not consistently perform at the highest level. Overall, it remains competitive, validates its design choices, and shows significant advantages in long-tail scenarios. This highlights the accuracy-coverage trade-offs resulting from partitioning, global components, and hub design. Our investigation clarifies when partition-aware similarity modeling is most beneficial and offers actionable guidance for scalable recommender system design under reproducible protocols.", "AI": {"tldr": "\u672c\u6587\u5bf9FPSR/FPSR+\u5206\u533a\u611f\u77e5\u534f\u540c\u8fc7\u6ee4\u6a21\u578b\u8fdb\u884c\u4e86\u53ef\u590d\u73b0\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u8be5\u6a21\u578b\u7cfb\u5217\u867d\u5177\u7ade\u4e89\u529b\u4f46\u5e76\u975e\u59cb\u7ec8\u6700\u4f18\uff0c\u5728\u957f\u5c3e\u573a\u666f\u4f18\u52bf\u660e\u663e\uff0c\u63ed\u793a\u4e86\u5206\u533a\u3001\u5168\u5c40\u7ec4\u4ef6\u548c\u67a2\u7ebd\u8bbe\u8ba1\u5e26\u6765\u7684\u51c6\u786e\u7387-\u8986\u76d6\u7387\u6743\u8861\u3002", "motivation": "\u57fa\u4e8e\u76f8\u4f3c\u5ea6\u7684\u534f\u540c\u8fc7\u6ee4\u6a21\u578b\u867d\u7136\u79bb\u7ebf\u6027\u80fd\u5f3a\u4e14\u6982\u5ff5\u7b80\u5355\uff0c\u4f46\u7ef4\u62a4\u5bc6\u96c6\u7269\u54c1\u76f8\u4f3c\u5ea6\u77e9\u9635\u7684\u4e8c\u6b21\u6210\u672c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u3002\u5206\u533a\u611f\u77e5\u8303\u5f0f\u5728\u5e73\u8861\u6548\u679c\u548c\u6548\u7387\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u73b0\u6709FPSR/FPSR+\u8bc4\u4f30\u5b58\u5728\u53ef\u590d\u73b0\u6027\u95ee\u9898\uff0c\u5305\u62ec\u4f7f\u7528\u6765\u6e90\u4e0d\u660e\u7684\u6570\u636e\u5206\u5272\u548c\u9057\u6f0f\u57fa\u7ebf\u6a21\u578b\uff0c\u96be\u4ee5\u8fdb\u884c\u516c\u5e73\u6bd4\u8f83\u3002", "method": "\u5efa\u7acb\u900f\u660e\u3001\u5b8c\u5168\u53ef\u590d\u73b0\u7684FPSR\u548cFPSR+\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u5bf9\u5206\u533a\u611f\u77e5\u534f\u540c\u8fc7\u6ee4\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u6027\u8bc4\u4f30\u3002\u91cd\u70b9\u5173\u6ce8\u6a21\u578b\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u6027\u80fd\u8868\u73b0\uff0c\u7279\u522b\u662f\u957f\u5c3e\u63a8\u8350\u60c5\u51b5\uff0c\u5206\u6790\u5206\u533a\u7b56\u7565\u3001\u5168\u5c40\u7ec4\u4ef6\u548c\u67a2\u7ebd\u8bbe\u8ba1\u5bf9\u63a8\u8350\u6548\u679c\u7684\u5f71\u54cd\u3002", "result": "FPSR\u6a21\u578b\u7cfb\u5217\u5e76\u672a\u59cb\u7ec8\u8fbe\u5230\u6700\u9ad8\u6027\u80fd\u6c34\u5e73\uff0c\u4f46\u6574\u4f53\u4fdd\u6301\u7ade\u4e89\u529b\uff0c\u9a8c\u8bc1\u4e86\u5176\u8bbe\u8ba1\u9009\u62e9\u7684\u6709\u6548\u6027\u3002\u5728\u957f\u5c3e\u63a8\u8350\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\u3002\u7814\u7a76\u63ed\u793a\u4e86\u5206\u533a\u7b56\u7565\u3001\u5168\u5c40\u7ec4\u4ef6\u548c\u67a2\u7ebd\u8bbe\u8ba1\u5e26\u6765\u7684\u51c6\u786e\u7387-\u8986\u76d6\u7387\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u5206\u533a\u611f\u77e5\u76f8\u4f3c\u5ea6\u5efa\u6a21\u5728\u7279\u5b9a\u573a\u666f\u4e0b\u6700\u4e3a\u6709\u76ca\uff0c\u7279\u522b\u662f\u5728\u957f\u5c3e\u63a8\u8350\u4e2d\u5177\u6709\u4f18\u52bf\u3002\u7814\u7a76\u4e3a\u53ef\u6269\u5c55\u63a8\u8350\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\uff0c\u5e76\u5f3a\u8c03\u4e86\u5728\u53ef\u590d\u73b0\u534f\u8bae\u4e0b\u8fdb\u884c\u6a21\u578b\u8bc4\u4f30\u7684\u91cd\u8981\u6027\u3002\u51c6\u786e\u7387-\u8986\u76d6\u7387\u7684\u6743\u8861\u662f\u5206\u533a\u7b56\u7565\u8bbe\u8ba1\u4e2d\u7684\u5173\u952e\u8003\u91cf\u56e0\u7d20\u3002"}}
{"id": "2512.17027", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.17027", "abs": "https://arxiv.org/abs/2512.17027", "authors": ["Erica Coppolillo", "Simone Mungari"], "title": "Unexpected Knowledge: Auditing Wikipedia and Grokipedia Search Recommendations", "comment": null, "summary": "Encyclopedic knowledge platforms are key gateways through which users explore information online. The recent release of Grokipedia, a fully AI-generated encyclopedia, introduces a new alternative to traditional, well-established platforms like Wikipedia. In this context, search engine mechanisms play an important role in guiding users exploratory paths, yet their behavior across different encyclopedic systems remains underexplored. In this work, we address this gap by providing the first comparative analysis of search engine in Wikipedia and Grokipedia.\n  Using nearly 10,000 neutral English words and their substrings as queries, we collect over 70,000 search engine results and examine their semantic alignment, overlap, and topical structure. We find that both platforms frequently generate results that are weakly related to the original query and, in many cases, surface unexpected content starting from innocuous queries. Despite these shared properties, the two systems often produce substantially different recommendation sets for the same query. Through topical annotation and trajectory analysis, we further identify systematic differences in how content categories are surfaced and how search engine results evolve over multiple stages of exploration.\n  Overall, our findings show that unexpected search engine outcomes are a common feature of both the platforms, even though they exhibit discrepancies in terms of topical distribution and query suggestions.", "AI": {"tldr": "\u5bf9\u7ef4\u57fa\u767e\u79d1\u548cGrokipedia\u4e24\u5927\u767e\u79d1\u5e73\u53f0\u7684\u641c\u7d22\u5f15\u64ce\u8fdb\u884c\u9996\u6b21\u6bd4\u8f83\u5206\u6790\uff0c\u53d1\u73b0\u4e24\u8005\u90fd\u4f1a\u9891\u7e41\u4ea7\u751f\u4e0e\u67e5\u8be2\u5f31\u76f8\u5173\u7684\u7ed3\u679c\uff0c\u751a\u81f3\u4ece\u65e0\u5bb3\u67e5\u8be2\u4e2d\u5448\u73b0\u610f\u5916\u5185\u5bb9\uff0c\u4f46\u4e24\u4e2a\u7cfb\u7edf\u5bf9\u76f8\u540c\u67e5\u8be2\u7684\u63a8\u8350\u7ed3\u679c\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "motivation": "\u968f\u7740AI\u751f\u6210\u7684\u767e\u79d1\u5168\u4e66Grokipedia\u7684\u51fa\u73b0\uff0c\u641c\u7d22\u5f15\u64ce\u5728\u4e0d\u540c\u767e\u79d1\u7cfb\u7edf\u4e2d\u7684\u884c\u4e3a\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u9996\u6b21\u6bd4\u8f83\u5206\u6790\u7ef4\u57fa\u767e\u79d1\u548cGrokipedia\u7684\u641c\u7d22\u5f15\u64ce\u673a\u5236\u3002", "method": "\u4f7f\u7528\u8fd110,000\u4e2a\u4e2d\u6027\u82f1\u6587\u5355\u8bcd\u53ca\u5176\u5b50\u5b57\u7b26\u4e32\u4f5c\u4e3a\u67e5\u8be2\uff0c\u6536\u96c6\u8d85\u8fc770,000\u4e2a\u641c\u7d22\u5f15\u64ce\u7ed3\u679c\uff0c\u5206\u6790\u5b83\u4eec\u7684\u8bed\u4e49\u5bf9\u9f50\u5ea6\u3001\u91cd\u53e0\u5ea6\u548c\u4e3b\u9898\u7ed3\u6784\u3002\u901a\u8fc7\u4e3b\u9898\u6807\u6ce8\u548c\u8f68\u8ff9\u5206\u6790\uff0c\u8fdb\u4e00\u6b65\u7814\u7a76\u5185\u5bb9\u7c7b\u522b\u7684\u5448\u73b0\u65b9\u5f0f\u548c\u641c\u7d22\u7ed3\u679c\u5728\u591a\u9636\u6bb5\u63a2\u7d22\u4e2d\u7684\u6f14\u53d8\u3002", "result": "\u53d1\u73b0\u4e24\u4e2a\u5e73\u53f0\u90fd\u4f1a\u9891\u7e41\u4ea7\u751f\u4e0e\u539f\u59cb\u67e5\u8be2\u5f31\u76f8\u5173\u7684\u7ed3\u679c\uff0c\u4e14\u7ecf\u5e38\u4ece\u65e0\u5bb3\u67e5\u8be2\u4e2d\u5448\u73b0\u610f\u5916\u5185\u5bb9\u3002\u5c3d\u7ba1\u6709\u8fd9\u4e9b\u5171\u540c\u7279\u6027\uff0c\u4e24\u4e2a\u7cfb\u7edf\u5bf9\u76f8\u540c\u67e5\u8be2\u7684\u63a8\u8350\u7ed3\u679c\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u4e3b\u9898\u5206\u5e03\u548c\u67e5\u8be2\u5efa\u8bae\u65b9\u9762\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u5f02\u3002", "conclusion": "\u610f\u5916\u641c\u7d22\u7ed3\u679c\u5728\u7ef4\u57fa\u767e\u79d1\u548cGrokipedia\u4e2d\u90fd\u662f\u5e38\u89c1\u73b0\u8c61\uff0c\u4f46\u4e24\u4e2a\u5e73\u53f0\u5728\u4e3b\u9898\u5206\u5e03\u548c\u67e5\u8be2\u5efa\u8bae\u65b9\u9762\u5b58\u5728\u660e\u663e\u5dee\u5f02\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u767e\u79d1\u7cfb\u7edf\u641c\u7d22\u5f15\u64ce\u884c\u4e3a\u7684\u7cfb\u7edf\u6027\u533a\u522b\u3002"}}
{"id": "2512.17164", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.17164", "abs": "https://arxiv.org/abs/2512.17164", "authors": ["Yu Yang", "Feng Tian", "Ping Chen"], "title": "TCDE: Topic-Centric Dual Expansion of Queries and Documents with Large Language Models for Information Retrieval", "comment": null, "summary": "Query Expansion (QE) enriches queries and Document Expansion (DE) enriches documents, and these two techniques are often applied separately. However, such separate application may lead to semantic misalignment between the expanded queries (or documents) and their relevant documents (or queries). To address this serious issue, we propose TCDE, a dual expansion strategy that leverages large language models (LLMs) for topic-centric enrichment on both queries and documents. In TCDE, we design two distinct prompt templates for processing each query and document. On the query side, an LLM is guided to identify distinct sub-topics within each query and generate a focused pseudo-document for each sub-topic. On the document side, an LLM is guided to distill each document into a set of core topic sentences. The resulting outputs are used to expand the original query and document. This topic-centric dual expansion process establishes semantic bridges between queries and their relevant documents, enabling better alignment for downstream retrieval models. Experiments on two challenging benchmarks, TREC Deep Learning and BEIR, demonstrate that TCDE achieves substantial improvements over strong state-of-the-art expansion baselines. In particular, on dense retrieval tasks, it outperforms several state-of-the-art methods, with a relative improvement of 2.8\\% in NDCG@10 on the SciFact dataset. Experimental results validate the effectiveness of our topic-centric and dual expansion strategy.", "AI": {"tldr": "TCDE\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e3b\u9898\u4e2d\u5fc3\u53cc\u6269\u5c55\u7b56\u7565\uff0c\u540c\u65f6\u5728\u67e5\u8be2\u548c\u6587\u6863\u4e24\u7aef\u8fdb\u884c\u6269\u5c55\uff0c\u901a\u8fc7\u5efa\u7acb\u8bed\u4e49\u6865\u6881\u6765\u6539\u5584\u68c0\u7d22\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u7684\u67e5\u8be2\u6269\u5c55\u548c\u6587\u6863\u6269\u5c55\u901a\u5e38\u5355\u72ec\u5e94\u7528\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u6269\u5c55\u540e\u7684\u67e5\u8be2\uff08\u6216\u6587\u6863\uff09\u4e0e\u76f8\u5173\u6587\u6863\uff08\u6216\u67e5\u8be2\uff09\u4e4b\u95f4\u7684\u8bed\u4e49\u4e0d\u5bf9\u9f50\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u4e25\u91cd\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u8003\u8651\u67e5\u8be2\u548c\u6587\u6863\u6269\u5c55\u7684\u65b9\u6cd5\u3002", "method": "TCDE\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e3b\u9898\u4e2d\u5fc3\u7684\u53cc\u6269\u5c55\uff1a\u5728\u67e5\u8be2\u7aef\uff0cLLM\u8bc6\u522b\u67e5\u8be2\u4e2d\u7684\u4e0d\u540c\u5b50\u4e3b\u9898\u5e76\u4e3a\u6bcf\u4e2a\u5b50\u4e3b\u9898\u751f\u6210\u4f2a\u6587\u6863\uff1b\u5728\u6587\u6863\u7aef\uff0cLLM\u5c06\u6587\u6863\u63d0\u70bc\u4e3a\u4e00\u7ec4\u6838\u5fc3\u4e3b\u9898\u53e5\u3002\u8fd9\u4e9b\u8f93\u51fa\u7528\u4e8e\u6269\u5c55\u539f\u59cb\u67e5\u8be2\u548c\u6587\u6863\u3002", "result": "\u5728TREC Deep Learning\u548cBEIR\u4e24\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTCDE\u76f8\u6bd4\u73b0\u6709\u7684\u6269\u5c55\u57fa\u7ebf\u65b9\u6cd5\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002\u7279\u522b\u662f\u5728\u5bc6\u96c6\u68c0\u7d22\u4efb\u52a1\u4e2d\uff0c\u5728SciFact\u6570\u636e\u96c6\u4e0aNDCG@10\u76f8\u5bf9\u63d0\u5347\u4e862.8%\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e3b\u9898\u4e2d\u5fc3\u548c\u53cc\u6269\u5c55\u7b56\u7565\u662f\u6709\u6548\u7684\uff0c\u901a\u8fc7\u5efa\u7acb\u67e5\u8be2\u548c\u76f8\u5173\u6587\u6863\u4e4b\u95f4\u7684\u8bed\u4e49\u6865\u6881\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5bf9\u9f50\u4e0b\u6e38\u68c0\u7d22\u6a21\u578b\u3002"}}
{"id": "2512.17277", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17277", "abs": "https://arxiv.org/abs/2512.17277", "authors": ["Saeed Ebrahimi", "Weijie Jiang", "Jaewon Yang", "Olafur Gudmundsson", "Yucheng Tu", "Huizhong Duan"], "title": "Warmer for Less: A Cost-Efficient Strategy for Cold-Start Recommendations at Pinterest", "comment": "Submitted to the WWW'26", "summary": "Pinterest is a leading visual discovery platform where recommender systems (RecSys) are key to delivering relevant, engaging, and fresh content to our users. In this paper, we study the problem of improving RecSys model predictions for cold-start (CS) items, which appear infrequently in the training data. Although this problem is well-studied in academia, few studies have addressed its root causes effectively at the scale of a platform like Pinterest. By investigating live traffic data, we identified several challenges of the CS problem and developed a corresponding solution for each: First, industrial-scale RecSys models must operate under tight computational constraints. Since CS items are a minority, any related improvements must be highly cost-efficient. To address this, our solutions were designed to be lightweight, collectively increasing the total parameters by only 5%. Second, CS items are represented only by non-historical (e.g., content or attribute) features, which models often treat as less important. To elevate their significance, we introduce a residual connection for the non-historical features. Third, CS items tend to receive lower prediction scores compared to non-CS items, reducing their likelihood of being surfaced. We mitigate this by incorporating a score regularization term into the model. Fourth, the labels associated with CS items are sparse, making it difficult for the model to learn from them. We apply the manifold mixup technique to address this data sparsity. Implemented together, our methods increased fresh content engagement at Pinterest by 10% without negatively impacting overall engagement and cost, and have been deployed to serve over 570 million users on Pinterest.", "AI": {"tldr": "Pinterest\u63d0\u51fa\u4e86\u4e00\u5957\u8f7b\u91cf\u7ea7\u89e3\u51b3\u65b9\u6848\u6765\u6539\u5584\u51b7\u542f\u52a8\u7269\u54c1\u63a8\u8350\uff0c\u5305\u62ec\u6b8b\u5dee\u8fde\u63a5\u3001\u5206\u6570\u6b63\u5219\u5316\u548c\u6d41\u5f62\u6df7\u5408\u6280\u672f\uff0c\u5728\u4ec5\u589e\u52a05%\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u63d0\u5347\u4e8610%\u65b0\u9c9c\u5185\u5bb9\u53c2\u4e0e\u5ea6\u3002", "motivation": "Pinterest\u4f5c\u4e3a\u89c6\u89c9\u53d1\u73b0\u5e73\u53f0\uff0c\u63a8\u8350\u7cfb\u7edf\u5bf9\u7528\u6237\u4f53\u9a8c\u81f3\u5173\u91cd\u8981\u3002\u51b7\u542f\u52a8\u7269\u54c1\u7531\u4e8e\u8bad\u7ec3\u6570\u636e\u7a00\u5c11\uff0c\u5728\u5de5\u4e1a\u7ea7\u63a8\u8350\u7cfb\u7edf\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5f88\u5c11\u80fd\u6709\u6548\u89e3\u51b3\u5e73\u53f0\u89c4\u6a21\u4e0b\u7684\u6839\u672c\u95ee\u9898\u3002", "method": "\u9488\u5bf9\u51b7\u542f\u52a8\u7269\u54c1\u7684\u56db\u4e2a\u6838\u5fc3\u6311\u6218\u63d0\u51fa\u5bf9\u5e94\u89e3\u51b3\u65b9\u6848\uff1a1) \u8bbe\u8ba1\u8f7b\u91cf\u7ea7\u67b6\u6784\uff08\u4ec5\u589e\u52a05%\u53c2\u6570\uff09\uff1b2) \u4e3a\u975e\u5386\u53f2\u7279\u5f81\u5f15\u5165\u6b8b\u5dee\u8fde\u63a5\u63d0\u5347\u91cd\u8981\u6027\uff1b3) \u52a0\u5165\u5206\u6570\u6b63\u5219\u5316\u9879\u7f13\u89e3\u51b7\u542f\u52a8\u7269\u54c1\u5f97\u5206\u504f\u4f4e\u95ee\u9898\uff1b4) \u5e94\u7528\u6d41\u5f62\u6df7\u5408\u6280\u672f\u89e3\u51b3\u6807\u7b7e\u7a00\u758f\u6027\u3002", "result": "\u8be5\u65b9\u6848\u5728Pinterest\u5e73\u53f0\u4e0a\u90e8\u7f72\u540e\uff0c\u65b0\u9c9c\u5185\u5bb9\u53c2\u4e0e\u5ea6\u63d0\u5347\u4e8610%\uff0c\u540c\u65f6\u4e0d\u5f71\u54cd\u6574\u4f53\u53c2\u4e0e\u5ea6\u548c\u6210\u672c\uff0c\u5df2\u4e3a\u8d85\u8fc75.7\u4ebf\u7528\u6237\u63d0\u4f9b\u670d\u52a1\u3002", "conclusion": "\u901a\u8fc7\u9488\u5bf9\u51b7\u542f\u52a8\u7269\u54c1\u7684\u7cfb\u7edf\u6027\u89e3\u51b3\u65b9\u6848\uff0cPinterest\u6210\u529f\u63d0\u5347\u4e86\u63a8\u8350\u7cfb\u7edf\u4e2d\u65b0\u9c9c\u5185\u5bb9\u7684\u66dd\u5149\u548c\u53c2\u4e0e\u5ea6\uff0c\u8bc1\u660e\u4e86\u5728\u5de5\u4e1a\u89c4\u6a21\u4e0b\u6709\u6548\u5904\u7406\u51b7\u542f\u52a8\u95ee\u9898\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2512.17389", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.17389", "abs": "https://arxiv.org/abs/2512.17389", "authors": ["Guangneng Hu"], "title": "The Mental World of Large Language Models in Recommendation: A Benchmark on Association, Personalization, and Knowledgeability", "comment": "21 pages, 13 figures, 27 tables, submission to KDD 2025", "summary": "Large language models (LLMs) have shown potential in recommendation systems (RecSys) by using them as either knowledge enhancer or zero-shot ranker. A key challenge lies in the large semantic gap between LLMs and RecSys where the former internalizes language world knowledge while the latter captures personalized world of behaviors. Unfortunately, the research community lacks a comprehensive benchmark that evaluates the LLMs over their limitations and boundaries in RecSys so that we can draw a confident conclusion. To investigate this, we propose a benchmark named LRWorld containing over 38K high-quality samples and 23M tokens carefully compiled and generated from widely used public recommendation datasets. LRWorld categorizes the mental world of LLMs in RecSys as three main scales (association, personalization, and knowledgeability) spanned by ten factors with 31 measures (tasks). Based on LRWorld, comprehensive experiments on dozens of LLMs show that they are still not well capturing the deep neural personalized embeddings but can achieve good results on shallow memory-based item-item similarity. They are also good at perceiving item entity relations, entity hierarchical taxonomies, and item-item association rules when inferring user interests. Furthermore, LLMs show a promising ability in multimodal knowledge reasoning (movie poster and product image) and robustness to noisy profiles. None of them show consistently good performance over the ten factors. Model sizes, position bias, and more are ablated.", "AI": {"tldr": "LRWorld\u662f\u4e00\u4e2a\u5305\u542b38K\u6837\u672c\u300123M token\u7684\u63a8\u8350\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u63a8\u8350\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u8fb9\u754c\uff0c\u6db5\u76d6\u5173\u8054\u6027\u3001\u4e2a\u6027\u5316\u3001\u77e5\u8bc6\u6027\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u5305\u542b10\u4e2a\u56e0\u7d20\u548c31\u4e2a\u4efb\u52a1\u3002", "motivation": "LLM\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u4f5c\u4e3a\u77e5\u8bc6\u589e\u5f3a\u5668\u6216\u96f6\u6837\u672c\u6392\u5e8f\u5668\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46LLM\uff08\u8bed\u8a00\u4e16\u754c\u77e5\u8bc6\uff09\u4e0e\u63a8\u8350\u7cfb\u7edf\uff08\u4e2a\u6027\u5316\u884c\u4e3a\u4e16\u754c\uff09\u4e4b\u95f4\u5b58\u5728\u5de8\u5927\u8bed\u4e49\u9e3f\u6c9f\u3002\u7814\u7a76\u793e\u533a\u7f3a\u4e4f\u4e00\u4e2a\u5168\u9762\u7684\u57fa\u51c6\u6765\u8bc4\u4f30LLM\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u5c40\u9650\u6027\u548c\u8fb9\u754c\uff0c\u4ee5\u4fbf\u5f97\u51fa\u53ef\u9760\u7ed3\u8bba\u3002", "method": "\u63d0\u51faLRWorld\u57fa\u51c6\uff0c\u4ece\u5e7f\u6cdb\u4f7f\u7528\u7684\u516c\u5171\u63a8\u8350\u6570\u636e\u96c6\u4e2d\u7cbe\u5fc3\u7f16\u8bd1\u548c\u751f\u6210\u8d85\u8fc738K\u4e2a\u9ad8\u8d28\u91cf\u6837\u672c\u548c23M token\u3002\u5c06LLM\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u5fc3\u667a\u4e16\u754c\u5206\u4e3a\u4e09\u4e2a\u4e3b\u8981\u5c3a\u5ea6\uff08\u5173\u8054\u6027\u3001\u4e2a\u6027\u5316\u3001\u77e5\u8bc6\u6027\uff09\uff0c\u6db5\u76d610\u4e2a\u56e0\u7d20\u548c31\u4e2a\u6d4b\u91cf\u4efb\u52a1\u3002", "result": "\u5bf9\u6570\u5341\u4e2aLLM\u7684\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff1a1) LLM\u4ecd\u4e0d\u80fd\u5f88\u597d\u5730\u6355\u6349\u6df1\u5ea6\u795e\u7ecf\u4e2a\u6027\u5316\u5d4c\u5165\uff0c\u4f46\u5728\u6d45\u5c42\u57fa\u4e8e\u8bb0\u5fc6\u7684\u7269\u54c1\u76f8\u4f3c\u6027\u4e0a\u8868\u73b0\u826f\u597d\uff1b2) \u5728\u63a8\u65ad\u7528\u6237\u5174\u8da3\u65f6\uff0cLLM\u64c5\u957f\u611f\u77e5\u7269\u54c1\u5b9e\u4f53\u5173\u7cfb\u3001\u5b9e\u4f53\u5c42\u6b21\u5206\u7c7b\u548c\u7269\u54c1\u5173\u8054\u89c4\u5219\uff1b3) LLM\u5728\u591a\u6a21\u6001\u77e5\u8bc6\u63a8\u7406\uff08\u7535\u5f71\u6d77\u62a5\u548c\u4ea7\u54c1\u56fe\u50cf\uff09\u548c\u5bf9\u566a\u58f0\u914d\u7f6e\u6587\u4ef6\u7684\u9c81\u68d2\u6027\u65b9\u9762\u663e\u793a\u51fa\u6709\u524d\u666f\u7684\u80fd\u529b\uff1b4) \u6ca1\u6709LLM\u572810\u4e2a\u56e0\u7d20\u4e0a\u8868\u73b0\u4e00\u81f4\u826f\u597d\uff1b5) \u6a21\u578b\u5927\u5c0f\u3001\u4f4d\u7f6e\u504f\u5dee\u7b49\u56e0\u7d20\u88ab\u6d88\u878d\u5206\u6790\u3002", "conclusion": "LRWorld\u57fa\u51c6\u4e3a\u8bc4\u4f30LLM\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u5168\u9762\u6846\u67b6\uff0c\u63ed\u793a\u4e86LLM\u5728\u4e2a\u6027\u5316\u63a8\u8350\u65b9\u9762\u7684\u5f53\u524d\u5c40\u9650\u6027\u548c\u4f18\u52bf\u9886\u57df\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2512.17442", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.17442", "abs": "https://arxiv.org/abs/2512.17442", "authors": ["Jan Hutter", "Hua Chang Bakker", "Stan Fris", "Madelon Bernardy", "Yuanna Liu"], "title": "A Systematic Reproducibility Study of BSARec for Sequential Recommendation", "comment": "Jan Hutter, Hua Chang Bakker, Stan Fris, Madelon Bernardy contributed equally to this work", "summary": "In sequential recommendation (SR), the self-attention mechanism of Transformer-based models acts as a low-pass filter, limiting their ability to capture high-frequency signals that reflect short-term user interests. To overcome this, BSARec augments the Transformer encoder with a frequency layer that rescales high-frequency components using the Fourier transform. However, the overall effectiveness of BSARec and the roles of its individual components have yet to be systematically validated. We reproduce BSARec and show that it outperforms other SR methods on some datasets. To empirically assess whether BSARec improves performance on high-frequency signals, we propose a metric to quantify user history frequency and evaluate SR methods across different user groups. We compare digital signal processing (DSP) techniques and find that the discrete wavelet transform (DWT) offer only slight improvements over Fourier transforms, and DSP methods provide no clear advantage over simple residual connections. Finally, we explore padding strategies and find that non-constant padding significantly improves recommendation performance, whereas constant padding hinders the frequency rescaler's ability to capture high-frequency signals.", "AI": {"tldr": "BSARec\u901a\u8fc7\u5085\u91cc\u53f6\u53d8\u6362\u589e\u5f3aTransformer\u7684\u9ad8\u9891\u4fe1\u53f7\u6355\u6349\u80fd\u529b\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u5176\u6548\u679c\u6709\u9650\uff0c\u7b80\u5355\u6b8b\u5dee\u8fde\u63a5\u4e0e\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u65b9\u6cd5\u6548\u679c\u76f8\u5f53\uff0c\u975e\u6052\u5b9a\u586b\u5145\u7b56\u7565\u5bf9\u6027\u80fd\u63d0\u5347\u66f4\u5173\u952e\u3002", "motivation": "\u4f20\u7edfTransformer\u5728\u5e8f\u5217\u63a8\u8350\u4e2d\u4f5c\u4e3a\u4f4e\u901a\u6ee4\u6ce2\u5668\uff0c\u96be\u4ee5\u6355\u6349\u53cd\u6620\u7528\u6237\u77ed\u671f\u5174\u8da3\u7684\u9ad8\u9891\u4fe1\u53f7\uff0c\u9700\u8981\u6539\u8fdb\u6a21\u578b\u7684\u9ad8\u9891\u4fe1\u53f7\u5904\u7406\u80fd\u529b\u3002", "method": "1. \u590d\u73b0BSARec\u6a21\u578b\uff0c\u5728Transformer\u7f16\u7801\u5668\u4e2d\u52a0\u5165\u9891\u7387\u5c42\uff0c\u901a\u8fc7\u5085\u91cc\u53f6\u53d8\u6362\u91cd\u65b0\u7f29\u653e\u9ad8\u9891\u5206\u91cf\uff1b2. \u63d0\u51fa\u91cf\u5316\u7528\u6237\u5386\u53f2\u9891\u7387\u7684\u6307\u6807\uff0c\u8bc4\u4f30\u4e0d\u540c\u7528\u6237\u7ec4\u7684\u63a8\u8350\u6027\u80fd\uff1b3. \u6bd4\u8f83\u4e0d\u540c\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u6280\u672f\uff08\u5085\u91cc\u53f6\u53d8\u6362vs\u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\uff09\uff1b4. \u63a2\u7d22\u4e0d\u540c\u7684\u586b\u5145\u7b56\u7565\u3002", "result": "1. BSARec\u5728\u67d0\u4e9b\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u5176\u4ed6\u5e8f\u5217\u63a8\u8350\u65b9\u6cd5\uff1b2. \u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\u76f8\u6bd4\u5085\u91cc\u53f6\u53d8\u6362\u4ec5\u6709\u8f7b\u5fae\u6539\u8fdb\uff1b3. \u6570\u5b57\u4fe1\u53f7\u5904\u7406\u65b9\u6cd5\u76f8\u6bd4\u7b80\u5355\u6b8b\u5dee\u8fde\u63a5\u6ca1\u6709\u660e\u663e\u4f18\u52bf\uff1b4. \u975e\u6052\u5b9a\u586b\u5145\u7b56\u7565\u663e\u8457\u63d0\u5347\u63a8\u8350\u6027\u80fd\uff0c\u800c\u6052\u5b9a\u586b\u5145\u4f1a\u963b\u788d\u9891\u7387\u91cd\u7f29\u653e\u5668\u6355\u6349\u9ad8\u9891\u4fe1\u53f7\u3002", "conclusion": "BSARec\u7684\u9ad8\u9891\u589e\u5f3a\u673a\u5236\u6548\u679c\u6709\u9650\uff0c\u5b9e\u9645\u6027\u80fd\u63d0\u5347\u4e3b\u8981\u6765\u81ea\u975e\u6052\u5b9a\u586b\u5145\u7b56\u7565\u800c\u975e\u590d\u6742\u7684\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u6280\u672f\uff0c\u7b80\u5355\u6b8b\u5dee\u8fde\u63a5\u53ef\u80fd\u5df2\u8db3\u591f\u6355\u6349\u9ad8\u9891\u4fe1\u53f7\u3002"}}
{"id": "2512.17462", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17462", "abs": "https://arxiv.org/abs/2512.17462", "authors": ["Olivier Jeunen", "Schaun Wheeler"], "title": "Behavioural Effects of Agentic Messaging: A Case Study on a Financial Service Application", "comment": "To appear in the 48th European Conference on Information Retrieval (ECIR '26) Industry Track", "summary": "Marketing and product personalisation provide a prominent and visible use-case for the application of Information Retrieval methods across several business domains. Recently, agentic approaches to these problems have been gaining traction. This work evaluates the behavioural and retention effects of agentic personalisation on a financial service application's customer communication system during a 2025 national tax filing period. Through a two month-long randomised controlled trial, we compare an agentic messaging approach against a business-as-usual (BAU) rule-based campaign system, focusing on two primary outcomes: unsubscribe behaviour and conversion timing. Empirical results show that agent-led messaging reduced unsubscribe events by 21\\% ($\\pm 0.01$) relative to BAU and increased early filing behaviour in the weeks preceding the national deadline. These findings demonstrate how adaptive, user-level decision-making systems can modulate engagement intensity whilst improving long-term retention indicators.", "AI": {"tldr": "\u8bc4\u4f30\u91d1\u878d\u5e94\u7528\u4e2d\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u4e2a\u6027\u5316\u6d88\u606f\u7cfb\u7edf\u5728\u7a0e\u52a1\u7533\u62a5\u671f\u95f4\u5bf9\u7528\u6237\u9000\u8ba2\u884c\u4e3a\u548c\u8f6c\u5316\u65f6\u95f4\u7684\u5f71\u54cd\uff0c\u7ed3\u679c\u663e\u793a\u667a\u80fd\u4f53\u6d88\u606f\u4f7f\u9000\u8ba2\u4e8b\u4ef6\u51cf\u5c1121%\u5e76\u4fc3\u8fdb\u63d0\u524d\u7533\u62a5", "motivation": "\u8425\u9500\u548c\u4ea7\u54c1\u4e2a\u6027\u5316\u662f\u4fe1\u606f\u68c0\u7d22\u65b9\u6cd5\u5728\u5546\u4e1a\u9886\u57df\u7684\u91cd\u8981\u5e94\u7528\u573a\u666f\uff0c\u8fd1\u5e74\u6765\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u65b9\u6cd5\u9010\u6e10\u53d7\u5230\u5173\u6ce8\u3002\u672c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u667a\u80fd\u4f53\u4e2a\u6027\u5316\u5728\u91d1\u878d\u670d\u52a1\u5e94\u7528\u5ba2\u6237\u6c9f\u901a\u7cfb\u7edf\u4e2d\u7684\u884c\u4e3a\u548c\u7559\u5b58\u6548\u679c", "method": "\u57282025\u5e74\u5168\u56fd\u7a0e\u52a1\u7533\u62a5\u671f\u95f4\uff0c\u901a\u8fc7\u4e3a\u671f\u4e24\u4e2a\u6708\u7684\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\uff0c\u6bd4\u8f83\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u6d88\u606f\u65b9\u6cd5\u4e0e\u4f20\u7edf\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u8425\u9500\u7cfb\u7edf\uff0c\u91cd\u70b9\u5173\u6ce8\u9000\u8ba2\u884c\u4e3a\u548c\u8f6c\u5316\u65f6\u95f4\u4e24\u4e2a\u4e3b\u8981\u7ed3\u679c\u6307\u6807", "result": "\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\uff1a\u667a\u80fd\u4f53\u4e3b\u5bfc\u7684\u6d88\u606f\u4f7f\u9000\u8ba2\u4e8b\u4ef6\u76f8\u5bf9\u4e8e\u4f20\u7edf\u7cfb\u7edf\u51cf\u5c11\u4e8621%\uff08\u00b10.01\uff09\uff0c\u5e76\u5728\u56fd\u5bb6\u622a\u6b62\u65e5\u671f\u524d\u7684\u51e0\u5468\u5185\u589e\u52a0\u4e86\u63d0\u524d\u7533\u62a5\u884c\u4e3a", "conclusion": "\u81ea\u9002\u5e94\u3001\u7528\u6237\u7ea7\u522b\u7684\u51b3\u7b56\u7cfb\u7edf\u80fd\u591f\u8c03\u8282\u53c2\u4e0e\u5f3a\u5ea6\uff0c\u540c\u65f6\u6539\u5584\u957f\u671f\u7559\u5b58\u6307\u6807\uff0c\u8bc1\u660e\u4e86\u667a\u80fd\u4f53\u4e2a\u6027\u5316\u5728\u91d1\u878d\u670d\u52a1\u6c9f\u901a\u4e2d\u7684\u6709\u6548\u6027"}}
{"id": "2512.17733", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.17733", "abs": "https://arxiv.org/abs/2512.17733", "authors": ["Jingmao Zhang", "Zhiting Zhao", "Yunqi Lin", "Jianghong Ma", "Tianjun Wei", "Haijun Zhang", "Xiaofeng Zhang"], "title": "Diversity Recommendation via Causal Deconfounding of Co-purchase Relations and Counterfactual Exposure", "comment": null, "summary": "Beyond user-item modeling, item-to-item relationships are increasingly used to enhance recommendation. However, common methods largely rely on co-occurrence, making them prone to item popularity bias and user attributes, which degrades embedding quality and performance. Meanwhile, although diversity is acknowledged as a key aspect of recommendation quality, existing research offers limited attention to it, with a notable lack of causal perspectives and theoretical grounding. To address these challenges, we propose Cadence: Diversity Recommendation via Causal Deconfounding of Co-purchase Relations and Counterfactual Exposure - a plug-and-play framework built upon LightGCN as the backbone, primarily designed to enhance recommendation diversity while preserving accuracy. First, we compute the Unbiased Asymmetric Co-purchase Relationship (UACR) between items - excluding item popularity and user attributes - to construct a deconfounded directed item graph, with an aggregation mechanism to refine embeddings. Second, we leverage UACR to identify diverse categories of items that exhibit strong causal relevance to a user's interacted items but have not yet been engaged with. We then simulate their behavior under high-exposure scenarios, thereby significantly enhancing recommendation diversity while preserving relevance. Extensive experiments on real-world datasets demonstrate that our method consistently outperforms state-of-the-art diversity models in both diversity and accuracy, and further validates its effectiveness, transferability, and efficiency over baselines.", "AI": {"tldr": "\u63d0\u51faCadence\u6846\u67b6\uff0c\u901a\u8fc7\u56e0\u679c\u53bb\u6df7\u6dc6\u7684\u5171\u8d2d\u4e70\u5173\u7cfb\u548c\u53cd\u4e8b\u5b9e\u66dd\u5149\u6765\u589e\u5f3a\u63a8\u8350\u591a\u6837\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u5171\u73b0\u5173\u7cfb\uff0c\u5bb9\u6613\u53d7\u5230\u5546\u54c1\u6d41\u884c\u5ea6\u548c\u7528\u6237\u5c5e\u6027\u504f\u5dee\u7684\u5f71\u54cd\uff0c\u5bfc\u81f4\u5d4c\u5165\u8d28\u91cf\u548c\u6027\u80fd\u4e0b\u964d\u3002\u540c\u65f6\uff0c\u591a\u6837\u6027\u4f5c\u4e3a\u63a8\u8350\u8d28\u91cf\u7684\u5173\u952e\u65b9\u9762\uff0c\u73b0\u6709\u7814\u7a76\u5173\u6ce8\u6709\u9650\uff0c\u7f3a\u4e4f\u56e0\u679c\u89c6\u89d2\u548c\u7406\u8bba\u57fa\u7840\u3002", "method": "1) \u8ba1\u7b97\u65e0\u504f\u975e\u5bf9\u79f0\u5171\u8d2d\u4e70\u5173\u7cfb(UACR)\uff0c\u6392\u9664\u5546\u54c1\u6d41\u884c\u5ea6\u548c\u7528\u6237\u5c5e\u6027\u5f71\u54cd\uff0c\u6784\u5efa\u53bb\u6df7\u6dc6\u7684\u6709\u5411\u5546\u54c1\u56fe\uff1b2) \u5229\u7528UACR\u8bc6\u522b\u4e0e\u7528\u6237\u4ea4\u4e92\u5546\u54c1\u6709\u5f3a\u56e0\u679c\u76f8\u5173\u6027\u4f46\u5c1a\u672a\u63a5\u89e6\u7684\u591a\u6837\u5316\u5546\u54c1\u7c7b\u522b\uff0c\u5728\u9ad8\u66dd\u5149\u573a\u666f\u4e0b\u6a21\u62df\u5176\u884c\u4e3a", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u6837\u6027\u548c\u51c6\u786e\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u591a\u6837\u6027\u6a21\u578b\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3001\u53ef\u8fc1\u79fb\u6027\u548c\u6548\u7387", "conclusion": "Cadence\u6846\u67b6\u901a\u8fc7\u56e0\u679c\u53bb\u6df7\u6dc6\u548c\u53cd\u4e8b\u5b9e\u66dd\u5149\uff0c\u80fd\u591f\u663e\u8457\u589e\u5f3a\u63a8\u8350\u591a\u6837\u6027\u540c\u65f6\u4fdd\u6301\u76f8\u5173\u6027\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u56e0\u679c\u89c6\u89d2\u548c\u7406\u8bba\u57fa\u7840"}}
