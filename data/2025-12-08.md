<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 4]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [RAG-IGBench: Innovative Evaluation for RAG-based Interleaved Generation in Open-domain Question Answering](https://arxiv.org/abs/2512.05119)
*Rongyang Zhang,Yuqing Huang,Chengqiang Lu,Qimeng Wang,Yan Gao,Yi Wu,Yao Hu,Yin Xu,Wei Wang,Hao Wang,Enhong Chen*

Main category: cs.IR

TL;DR: 提出了RAG-IGBench基准，专门评估基于检索增强生成（RAG-IG）的交错图像-文本生成任务，包含新数据集和评估指标。


<details>
  <summary>Details</summary>
Motivation: 现实场景中视觉增强的回答能显著提升理解和记忆，但现有交错内容生成质量不高，且缺乏专门评估交错序列的基准，现有基准多使用单模态指标，无法充分评估图像-文本组合输出的复杂性。

Method: 构建RAG-IGBench基准，基于社交媒体最新公开内容创建数据集，引入创新评估指标衡量文本质量、图像质量及其一致性；将多模态大语言模型（MLLMs）与检索机制结合，使模型能访问外部图像-文本信息生成连贯的多模态内容。

Result: 在RAG-IGBench上对最先进MLLMs（开源和专有）进行广泛实验，深入分析模型能力和局限性；验证评估指标与人工评估高度相关；在训练集上微调的模型在多个基准上表现提升，证实数据集质量和实用价值。

Conclusion: RAG-IGBench为交错图像-文本生成任务提供了全面评估基准，包含高质量数据集和有效评估指标，有助于推动该领域研究发展，数据集已开源。

Abstract: In real-world scenarios, providing user queries with visually enhanced responses can considerably benefit understanding and memory, underscoring the great value of interleaved image-text generation. Despite recent progress, like the visual autoregressive model that unifies text and image processing in a single transformer architecture, generating high-quality interleaved content remains challenging. Moreover, evaluations of these interleaved sequences largely remain underexplored, with existing benchmarks often limited by unimodal metrics that inadequately assess the intricacies of combined image-text outputs. To address these issues, we present RAG-IGBench, a thorough benchmark designed specifically to evaluate the task of Interleaved Generation based on Retrieval-Augmented Generation (RAG-IG) in open-domain question answering. RAG-IG integrates multimodal large language models (MLLMs) with retrieval mechanisms, enabling the models to access external image-text information for generating coherent multimodal content. Distinct from previous datasets, RAG-IGBench draws on the latest publicly available content from social platforms and introduces innovative evaluation metrics that measure the quality of text and images, as well as their consistency. Through extensive experiments with state-of-the-art MLLMs (both open-source and proprietary) on RAG-IGBench, we provide an in-depth analysis examining the capabilities and limitations of these models. Additionally, we validate our evaluation metrics by demonstrating their high correlation with human assessments. Models fine-tuned on RAG-IGBench's training set exhibit improved performance across multiple benchmarks, confirming both the quality and practical utility of our dataset. Our benchmark is available at https://github.com/USTC-StarTeam/RAG-IGBench.

</details>


### [2] [The Effect of Document Summarization on LLM-Based Relevance Judgments](https://arxiv.org/abs/2512.05334)
*Samaneh Mohtadi,Kevin Roitero,Stefano Mizzaro,Gianluca Demartini*

Main category: cs.IR

TL;DR: 研究探索文本摘要如何影响基于LLM的检索相关性判断的可靠性及其对IR评估的影响，发现摘要判断在系统排序稳定性上与全文判断相当，但会引入系统性偏差。


<details>
  <summary>Details</summary>
Motivation: 人工相关性标注成本高且耗时，LLM作为自动评估器显示出潜力。现有研究大多将文档作为固定单元直接输入LLM，但未研究文本摘要对LLM判断可靠性的影响及其对IR评估的下游影响。

Method: 使用最先进的LLM在多个TREC数据集上，比较基于全文的LLM判断与基于不同长度LLM生成摘要的判断。分析它们与人工标注的一致性、对检索效果评估的影响，以及对IR系统排序稳定性的影响。

Result: 摘要判断在系统排序稳定性方面与全文判断相当，但会引入系统性标签分布偏移和偏差，这些偏差因模型和数据集而异。摘要判断与人工标注的一致性模式与全文判断相似。

Conclusion: 文本摘要既是实现更高效大规模IR评估的机会，也是一个具有重要方法论意义的选择，会影响自动判断的可靠性。研究人员需要权衡摘要带来的效率提升与可能引入的系统性偏差。

Abstract: Relevance judgments are central to the evaluation of Information Retrieval (IR) systems, but obtaining them from human annotators is costly and time-consuming. Large Language Models (LLMs) have recently been proposed as automated assessors, showing promising alignment with human annotations. Most prior studies have treated documents as fixed units, feeding their full content directly to LLM assessors. We investigate how text summarization affects the reliability of LLM-based judgments and their downstream impact on IR evaluation. Using state-of-the-art LLMs across multiple TREC collections, we compare judgments made from full documents with those based on LLM-generated summaries of different lengths. We examine their agreement with human labels, their effect on retrieval effectiveness evaluation, and their influence on IR systems' ranking stability. Our findings show that summary-based judgments achieve comparable stability in systems' ranking to full-document judgments, while introducing systematic shifts in label distributions and biases that vary by model and dataset. These results highlight summarization as both an opportunity for more efficient large-scale IR evaluation and a methodological choice with important implications for the reliability of automatic judgments.

</details>


### [3] [A Systematic Framework for Enterprise Knowledge Retrieval: Leveraging LLM-Generated Metadata to Enhance RAG Systems](https://arxiv.org/abs/2512.05411)
*Pranav Pushkar Mishra,Kranti Prakash Yeole,Ramyashree Keshavamurthy,Mokshit Bharat Surana,Fatemeh Sarayloo*

Main category: cs.IR

TL;DR: 使用LLM进行元数据增强的系统框架，通过三种分块策略提升RAG系统文档检索效果，递归分块+TF-IDF加权嵌入达到82.5%准确率。


<details>
  <summary>Details</summary>
Motivation: 在企业环境中，从大型复杂知识库中高效检索相关信息对运营生产力和决策制定至关重要。现有RAG系统在文档检索方面仍有优化空间，需要提升语义表示和检索准确性。

Method: 提出使用LLM进行元数据增强的系统框架，采用结构化流水线动态生成文档片段的元数据。比较三种分块策略（语义、递归、朴素），结合高级嵌入技术，使用交叉编码器重排序生成基准真值，通过命中率和元数据一致性指标进行评估。

Result: 元数据增强方法始终优于纯内容基线：递归分块+TF-IDF加权嵌入达到82.5%准确率（纯语义方法为73.3%）；朴素分块+前缀融合达到最高命中率@10为0.925。元数据增强提高了向量聚类质量，同时减少了检索延迟。

Conclusion: 元数据增强是提升RAG系统效果的关键优化方法，为企业环境部署高性能、可扩展的文档检索解决方案提供了实用见解，证明了元数据增强在增强RAG有效性方面的强大作用。

Abstract: In enterprise settings, efficiently retrieving relevant information from large and complex knowledge bases is essential for operational productivity and informed decision-making. This research presents a systematic framework for metadata enrichment using large language models (LLMs) to enhance document retrieval in Retrieval-Augmented Generation (RAG) systems. Our approach employs a comprehensive, structured pipeline that dynamically generates meaningful metadata for document segments, substantially improving their semantic representations and retrieval accuracy. Through extensive experiments, we compare three chunking strategies-semantic, recursive, and naive-and evaluate their effectiveness when combined with advanced embedding techniques. The results demonstrate that metadata-enriched approaches consistently outperform content-only baselines, with recursive chunking paired with TF-IDF weighted embeddings yielding an 82.5% precision rate compared to 73.3% for semantic content-only approaches. The naive chunking strategy with prefix-fusion achieved the highest Hit Rate@10 of 0.925. Our evaluation employs cross-encoder reranking for ground truth generation, enabling rigorous assessment via Hit Rate and Metadata Consistency metrics. These findings confirm that metadata enrichment enhances vector clustering quality while reducing retrieval latency, making it a key optimization for RAG systems across knowledge domains. This work offers practical insights for deploying high-performance, scalable document retrieval solutions in enterprise settings, demonstrating that metadata enrichment is a powerful approach for enhancing RAG effectiveness.

</details>


### [4] [Enhancing Retrieval-Augmented Generation with Entity Linking for Educational Platforms](https://arxiv.org/abs/2512.05967)
*Francesco Granata,Francesco Poggi,Misael Mongiovì*

Main category: cs.IR

TL;DR: 该研究提出了一种增强的RAG架构，通过整合实体链接的事实信号来提高意大利语教育问答系统的准确性，在特定领域数据集上取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 在LLM时代，基于语义相似度的RAG系统在专业领域中经常因术语歧义而无法保证事实准确性，需要改进教育问答系统的可靠性和事实精确性。

Method: 提出增强的RAG架构，整合基于Wikidata的实体链接模块，实现三种重排序策略：混合分数加权模型、互逆排名融合和交叉编码器重排序器。

Result: 在特定领域上下文中，基于互逆排名融合的混合方案显著优于基线和交叉编码器方法；在通用领域数据集上，交叉编码器表现最佳，证实了领域不匹配效应。

Conclusion: 研究强调了领域适应和混合排序策略对提高RAG事实精确性的重要性，展示了实体感知RAG系统在教育环境中的潜力，有助于开发自适应可靠的AI辅导工具。

Abstract: In the era of Large Language Models (LLMs), Retrieval-Augmented Generation (RAG) architectures are gaining significant attention for their ability to ground language generation in reliable knowledge sources. Despite their impressive effectiveness in many areas, RAG systems based solely on semantic similarity often fail to ensure factual accuracy in specialized domains, where terminological ambiguity can affect retrieval relevance. This study proposes an enhanced RAG architecture that integrates a factual signal derived from Entity Linking to improve the accuracy of educational question-answering systems in Italian. The system includes a Wikidata-based Entity Linking module and implements three re-ranking strategies to combine semantic and entity-based information: a hybrid score weighting model, reciprocal rank fusion, and a cross-encoder re-ranker. Experiments were conducted on two benchmarks: a custom academic dataset and the standard SQuAD-it dataset. Results show that, in domain-specific contexts, the hybrid schema based on reciprocal rank fusion significantly outperforms both the baseline and the cross-encoder approach, while the cross-encoder achieves the best results on the general-domain dataset. These findings confirm the presence of an effect of domain mismatch and highlight the importance of domain adaptation and hybrid ranking strategies to enhance factual precision and reliability in retrieval-augmented generation. They also demonstrate the potential of entity-aware RAG systems in educational environments, fostering adaptive and reliable AI-based tutoring tools.

</details>
