<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 4]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [STCRank: Spatio-temporal Collaborative Ranking for Interactive Recommender System at Kuaishou E-shop](https://arxiv.org/abs/2601.10027)
*Boyang Xia,Ruilin Bao,Hanjun Jiang,Jun Wang,Wenwu Ou*

Main category: cs.IR

TL;DR: 快手电商提出STCRank框架，通过时空协同排序解决全屏沉浸式UI下的多目标冲突和时序贪婪陷阱问题，实现购买和日活双增长。


<details>
  <summary>Details</summary>
Motivation: 快手电商平台需要应对全屏UI和沉浸式下滑功能带来的独特挑战：1）转化、浏览、下滑等多目标间存在显性干扰（重叠或冲突）；2）排序系统在连续推荐槽位转换中容易陷入时序贪婪陷阱。

Method: 提出时空协同排序（STCRank）框架，包含两个模块：1）多目标协同（MOC）模块，通过缓解目标重叠和冲突来推进帕累托前沿；2）多槽位协同（MSC）模块，通过双阶段前瞻排序机制实现整体序列槽位的全局最优。

Result: 实验表明该方法实现了购买和日活（DAU）的共同增长。该系统已于2025年6月在快手电商平台部署上线。

Conclusion: STCRank框架有效解决了全屏沉浸式电商推荐系统中的多目标冲突和时序贪婪问题，为类似场景的推荐系统设计提供了有价值的解决方案。

Abstract: As a popular e-commerce platform, Kuaishou E-shop provides precise personalized product recommendations to tens of millions of users every day. To better respond real-time user feedback, we have deployed an interactive recommender system (IRS) alongside our core homepage recommender system. This IRS is triggered by user click on homepage, and generates a series of highly relevant recommendations based on the clicked item to meet focused browsing demands. Different from traditional e-commerce RecSys, the full-screen UI and immersive swiping down functionality present two distinct challenges for regular ranking system. First, there exists explicit interference (overlap or conflicts) between ranking objectives, i.e., conversion, view and swipe down. This is because there are intrinsic behavioral co-occurrences under the premise of immersive browsing and swiping down functionality. Second, the ranking system is prone to temporal greedy traps in sequential recommendation slot transitions, which is caused by full-screen UI design. To alleviate these challenges, we propose a novel Spatio-temporal collaborative ranking (STCRank) framework to achieve collaboration between multi-objectives within one slot (spatial) and between multiple sequential recommondation slots. In multi-objective collaboration (MOC) module, we push Pareto frontier by mitigating the objective overlaps and conflicts. In multi-slot collaboration (MSC) module, we achieve global optima on overall sequential slots by dual-stage look-ahead ranking mechanism. Extensive experiments demonstrate our proposed method brings about purchase and DAU co-growth. The proposed system has been already deployed at Kuaishou E-shop since 2025.6.

</details>


### [2] [Development of Ontological Knowledge Bases by Leveraging Large Language Models](https://arxiv.org/abs/2601.10436)
*Le Ngoc Luyen,Marie-Hélène Abel,Philippe Gouspillou*

Main category: cs.IR

TL;DR: 本文提出了一种利用大语言模型（LLMs）优化本体知识库开发的迭代方法，通过车辆销售领域的用户上下文配置文件本体案例研究，展示了该方法能显著加速本体构建、提高一致性、减少偏见并增强透明度。


<details>
  <summary>Details</summary>
Motivation: 传统本体知识库（OKBs）的手动开发面临可扩展性、一致性和适应性方面的重大挑战。生成式AI特别是大语言模型的发展为自动化和增强OKB开发提供了有前景的解决方案。

Method: 提出了一种结构化、迭代的方法论，利用LLMs优化知识获取、自动化本体工件生成，并支持持续精炼循环。通过车辆销售领域的用户上下文配置文件本体案例研究来验证该方法。

Result: 该方法显著加速了本体构建过程，提高了本体一致性，有效缓解了偏见问题，并增强了本体工程过程的透明度。

Conclusion: 将LLMs集成到本体开发中具有变革性潜力，能够显著提高知识管理系统的可扩展性、集成能力和整体效率。

Abstract: Ontological Knowledge Bases (OKBs) play a vital role in structuring domain-specific knowledge and serve as a foundation for effective knowledge management systems. However, their traditional manual development poses significant challenges related to scalability, consistency, and adaptability. Recent advancements in Generative AI, particularly Large Language Models (LLMs), offer promising solutions for automating and enhancing OKB development. This paper introduces a structured, iterative methodology leveraging LLMs to optimize knowledge acquisition, automate ontology artifact generation, and enable continuous refinement cycles. We demonstrate this approach through a detailed case study focused on developing a user context profile ontology within the vehicle sales domain. Key contributions include significantly accelerated ontology construction processes, improved ontological consistency, effective bias mitigation, and enhanced transparency in the ontology engineering process. Our findings highlight the transformative potential of integrating LLMs into ontology development, notably improving scalability, integration capabilities, and overall efficiency in knowledge management systems.

</details>


### [3] [iTIMO: An LLM-empowered Synthesis Dataset for Travel Itinerary Modification](https://arxiv.org/abs/2601.10609)
*Zhuoxuan Huang,Yunshan Ma,Hongyu Zhang,Hua Ma,Zhu Sun*

Main category: cs.IR

TL;DR: 论文提出了iTIMO数据集，专门用于行程修改任务研究，通过意图驱动的扰动方法生成需要修改的行程数据，并设计了混合评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注固定行程规划，而行程修改在旅行中频繁发生但研究不足。缺乏"需要修改"的行程数据是阻碍该任务研究的关键瓶颈。

Method: 提出通用流水线，将数据生成视为意图驱动的扰动任务，使用大语言模型通过REPLACE、ADD、DELETE三种原子编辑操作对真实行程进行扰动，基于流行度、空间距离和类别多样性三种意图。

Result: 构建了iTIMO数据集，通过综合实验揭示了当前LLMs在行程修改任务上的局限性，为未来研究提供了有价值的方向。

Conclusion: 该研究填补了行程修改任务的空白，提出的数据集和方法为相关研究提供了基础，并指出了未来改进方向。

Abstract: Addressing itinerary modification is crucial for enhancing the travel experience as it is a frequent requirement during traveling. However, existing research mainly focuses on fixed itinerary planning, leaving modification underexplored. To bridge this gap, we formally define the itinerary modification task and introduce iTIMO, a dataset specifically tailored for this purpose. We identify the lack of {\itshape need-to-modify} itinerary data as the critical bottleneck hindering research on this task and propose a general pipeline to overcome it. This pipeline frames the generation of such data as an intent-driven perturbation task. It instructs large language models to perturb real world itineraries using three atomic editing operations: REPLACE, ADD, and DELETE. Each perturbation is grounded in three intents, including disruptions of popularity, spatial distance, and category diversity. Furthermore, a hybrid evaluation metric is designed to ensure perturbation effectiveness. We conduct comprehensive experiments on iTIMO, revealing the limitations of current LLMs and lead to several valuable directions for future research. Dataset and corresponding code are available at https://github.com/zelo2/iTIMO.

</details>


### [4] [RoutIR: Fast Serving of Retrieval Pipelines for Retrieval-Augmented Generation](https://arxiv.org/abs/2601.10644)
*Eugene Yang,Andrew Yates,Dawn Lawrie,James Mayfield,Trevor Adriaanse*

Main category: cs.IR

TL;DR: RoutIR是一个Python包，为检索模型提供HTTP API，支持动态RAG系统中的在线检索服务。


<details>
  <summary>Details</summary>
Motivation: 现有学术IR平台通常基于Cranfield范式设计，支持批量离线处理，但无法支持需要在线服务的动态RAG系统（如多轮检索、反馈循环、自组织代理等）。

Method: 开发RoutIR Python包，提供简单的HTTP API包装任意检索方法（包括一阶段检索、重排序、查询扩展、结果融合），通过JSON配置文件指定要服务的检索模型，支持动态构建检索管道。

Result: RoutIR支持异步查询批处理和默认缓存，已支持多种先进检索方法，且通过实现Engine抽象类易于扩展，已在GitHub开源。

Conclusion: RoutIR填补了学术检索模型与动态RAG应用之间的鸿沟，为构建在线检索服务提供了灵活、高效的解决方案。

Abstract: Retrieval models are key components of Retrieval-Augmented Generation (RAG) systems, which generate search queries, process the documents returned, and generate a response. RAG systems are often dynamic and may involve multiple rounds of retrieval. While many state-of-the-art retrieval methods are available through academic IR platforms, these platforms are typically designed for the Cranfield paradigm in which all queries are known up front and can be batch processed offline. This simplification accelerates research but leaves state-of-the-art retrieval models unable to support downstream applications that require online services, such as arbitrary dynamic RAG pipelines that involve looping, feedback, or even self-organizing agents. In this work, we introduce RoutIR, a Python package that provides a simple and efficient HTTP API that wraps arbitrary retrieval methods, including first stage retrieval, reranking, query expansion, and result fusion. By providing a minimal JSON configuration file specifying the retrieval models to serve, RoutIR can be used to construct and query retrieval pipelines on-the-fly using any permutation of available models (e.g., fusing the results of several first-stage retrieval methods followed by reranking). The API automatically performs asynchronous query batching and caches results by default. While many state-of-the-art retrieval methods are already supported by the package, RoutIR is also easily expandable by implementing the Engine abstract class. The package is open-sourced and publicly available on GitHub: http://github.com/hltcoe/routir.

</details>
