<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 20]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [GCRank: A Generative Contextual Comprehension Paradigm for Takeout Ranking Model](https://arxiv.org/abs/2601.02361)
*Ziheng Ni,Congcong Liu,Cai Shang,Yiming Sun,Junjie Li,Zhiwei Fang,Guangpeng Chen,Jian Li,Zehua Zhang,Changping Peng,Zhangang Lin,Ching Law,Jingping Shao*

Main category: cs.IR

TL;DR: 提出生成式上下文理解框架，将广告排序重构为上下文理解任务，通过统一架构建模异构信号，在食品配送广告平台中显著提升点击率和平台收入。


<details>
  <summary>Details</summary>
Motivation: 现有广告排序模型依赖碎片化模块和手工特征，难以理解复杂用户意图，特别是在食品配送等位置服务中，用户决策受动态空间、时间和个体上下文影响。

Method: 提出生成式框架，包含生成式上下文编码器(GCE)和生成式上下文融合(GCF)。GCE有三个专门模块：个性化上下文增强器(PCE)用于用户特定建模，集体上下文增强器(CCE)用于群体级模式，动态上下文增强器(DCE)用于实时情境适应。GCF通过低秩适应无缝整合这些上下文表示。

Result: 实验证实该方法在关键业务指标上取得显著提升，包括点击率和平台收入。已成功部署在大型食品配送广告平台，展示了实际应用价值。

Conclusion: 这项工作开创了生成式推荐的新视角，突出了其在工业广告系统中的实际潜力，为复杂上下文环境下的广告排序提供了有效解决方案。

Abstract: The ranking stage serves as the central optimization and allocation hub in advertising systems, governing economic value distribution through eCPM and orchestrating the user-centric blending of organic and advertising content. Prevailing ranking models often rely on fragmented modules and hand-crafted features, limiting their ability to interpret complex user intent. This challenge is further amplified in location-based services such as food delivery, where user decisions are shaped by dynamic spatial, temporal, and individual contexts. To address these limitations, we propose a novel generative framework that reframes ranking as a context comprehension task, modeling heterogeneous signals in a unified architecture. Our architecture consists of two core components: the Generative Contextual Encoder (GCE) and the Generative Contextual Fusion (GCF). The GCE comprises three specialized modules: a Personalized Context Enhancer (PCE) for user-specific modeling, a Collective Context Enhancer (CCE) for group-level patterns, and a Dynamic Context Enhancer (DCE) for real-time situational adaptation. The GCF module then seamlessly integrates these contextual representations through low-rank adaptation. Extensive experiments confirm that our method achieves significant gains in critical business metrics, including click-through rate and platform revenue. We have successfully deployed our method on a large-scale food delivery advertising platform, demonstrating its substantial practical impact. This work pioneers a new perspective on generative recommendation and highlights its practical potential in industrial advertising systems.

</details>


### [2] [The Impact of LLM-Generated Reviews on Recommender Systems: Textual Shifts, Performance Effects, and Strategic Platform Control](https://arxiv.org/abs/2601.02362)
*Itzhak Ziv,Moshe Unger,Hilah Geva*

Main category: cs.IR

TL;DR: 研究探讨AI生成评论对推荐系统的影响，发现人类评论质量优于AI评论，平台控制AI内容生成策略对推荐效果至关重要


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI技术的发展，推荐系统面临AI生成内容与人类创作内容并存的新环境，需要研究AI内容如何影响推荐系统性能和商业结果

Method: 使用TripAdvisor酒店评论数据集，通过LLM生成合成评论，分析用户中心（用户使用AI工具优化评论）和平台中心（平台从结构化元数据生成评论）两种AI内容引入途径，评估对推荐系统训练和部署阶段的影响

Result: AI生成评论在多个文本维度上与人类评论存在系统性差异；人类评论训练的模型表现最佳；人类模型能良好泛化到AI内容，而AI模型对两种内容类型都表现不佳；基于语调的框架策略（鼓励性、建设性或批判性）能显著提升平台生成评论的效果

Conclusion: 平台在控制AI生成评论的生成和整合方面具有战略重要性，需要确保合成内容能够补充推荐系统的稳健性和可持续商业价值，人类真实数据质量仍不可替代

Abstract: The rise of generative AI technologies is reshaping content-based recommender systems (RSes), which increasingly encounter AI-generated content alongside human-authored content. This study examines how the introduction of AI-generated reviews influences RS performance and business outcomes. We analyze two distinct pathways through which AI content can enter RSes: user-centric, in which individuals use AI tools to refine their reviews, and platform-centric, in which platforms generate synthetic reviews directly from structured metadata. Using a large-scale dataset of hotel reviews from TripAdvisor, we generate synthetic reviews using LLMs and evaluate their impact across the training and deployment phases of RSes. We find that AI-generated reviews differ systematically from human-authored reviews across multiple textual dimensions. Although both user- and platform-centric AI reviews enhance RS performance relative to models without textual data, models trained on human reviews consistently achieve superior performance, underscoring the quality of authentic human data. Human-trained models generalize robustly to AI content, whereas AI-trained models underperform on both content types. Furthermore, tone-based framing strategies (encouraging, constructive, or critical) substantially enhance platform-generated review effectiveness. Our findings highlight the strategic importance of platform control in governing the generation and integration of AI-generated reviews, ensuring that synthetic content complements recommendation robustness and sustainable business value.

</details>


### [3] [Towards Trustworthy LLM-Based Recommendation via Rationale Integration](https://arxiv.org/abs/2601.02364)
*Chung Park,Taesan Kim,Hyeongjun Yun,Dongjoon Hong,Junui Hong,Kijung Park,MinCheol Cho,Mira Myong,Jihoon Oh,Min sung Choi*

Main category: cs.IR

TL;DR: 提出基于LLM的推荐系统LLM-Rec，通过生成逻辑合理的推荐理由来提升透明度和推荐性能，采用理由优先的指令调优策略


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统过度关注准确性和短期参与度，忽视了透明度和可信度。虽然亚马逊、Instagram等平台开始提供推荐理由，但多数系统仍将其视为事后产物，缺乏与推荐过程的深度整合

Method: 提出LLM-Rec推荐系统，利用自标注理由数据集和指令调优，采用理由优先格式（先生成解释再输出推荐项），并以思维链风格表示理由，增强可解释性和推荐性能

Result: 在Amazon Review数据集的时尚和科学领域实验中，相比现有基线方法取得了显著改进，并公开发布了包含用户历史、理由和推荐项的数据集

Conclusion: LLM-Rec通过生成逻辑合理的推荐理由，不仅提升了推荐系统的透明度，还增强了推荐性能，为可解释推荐系统研究提供了新方向

Abstract: Traditional recommender systems (RS) have been primarily optimized for accuracy and short-term engagement, often overlooking transparency and trustworthiness. Recently, platforms such as Amazon and Instagram have begun providing recommendation rationales to users, acknowledging their critical role in fostering trust and enhancing engagement; however, most existing systems still treat them as post-hoc artifacts. We propose an LLM-based recommender (LLM-Rec) that not only predicts items but also generates logically grounded rationales. Our approach leverages a self-annotated rationale dataset and instruction tuning in a rationale-first format, where the model generates an explanation before outputting the recommended item. By adopting this strategy and representing rationales in a chain-of-thought (CoT) style, LLM-Rec strengthens both interpretability and recommendation performance. Experiments on the Fashion and Scientific domains of the Amazon Review dataset demonstrate significant improvements over well-established baselines. To encourage reproducibility and future research, we publicly release a rationale-augmented recommendation dataset containing user histories, rationales, and recommended items.

</details>


### [4] [FUSE : Failure-aware Usage of Subagent Evidence for MultiModal Search and Recommendation](https://arxiv.org/abs/2601.02365)
*Tushar Vatsa,Vibha Belavadi,Priya Shanmugasundaram,Suhas Suresha,Dewang Sultania*

Main category: cs.IR

TL;DR: FUSE提出了一种失败感知的多模态搜索推荐系统，通过紧凑的GDR表示替代原始图像，采用七种上下文预算策略，其中上下文压缩表现最佳。


<details>
  <summary>Details</summary>
Motivation: 多模态创意助手中检索质量至关重要，但存在用户意图理解、内容类型选择、候选查找和结果排序等多个失败点，同时原始图像处理成本高昂，需要更高效的解决方案。

Method: FUSE使用紧凑的GDR（基于画布元素的JSON表示）替代原始图像，实现七种上下文预算策略，并建立管道归因层监控系统性能。

Result: 在788个评估查询中，上下文压缩策略表现最优：意图准确率93.3%，路由成功率86.8%（含回退），召回率99.4%，NDCG@5为88.5%。

Conclusion: 战略性上下文总结优于全面和最小化上下文策略，证明了FUSE在降低计算成本的同时提升多模态检索性能的有效性。

Abstract: Multimodal creative assistants decompose user goals and route tasks to subagents for layout, styling, retrieval, and generation. Retrieval quality is pivotal, yet failures can arise at several stages: understanding user intent, choosing content types, finding candidates (recall), or ranking results. Meanwhile, sending and processing images is costly, making naive multimodal approaches impractical. We present FUSE: Failure-aware Usage of Subagent Evidence for MultiModal Search and Recommendation. FUSE replaces most raw-image prompting with a compact Grounded Design Representation (GDR): a selection aware JSON of canvas elements (image, text, shape, icon, video, logo), structure, styles, salient colors, and user selection provided by the Planner team. FUSE implements seven context budgeting strategies: comprehensive baseline prompting, context compression, chain-of-thought reasoning, mini-shot optimization, retrieval-augmented context, two-stage processing, and zero-shot minimalism. Finally, a pipeline attribution layer monitors system performance by converting subagent signals into simple checks: intent alignment, content-type/routing sanity, recall health (e.g., zero-hit and top-match strength), and ranking displacement analysis. We evaluate the seven context budgeting variants across 788 evaluation queries from diverse users and design templates (refer Figure 3). Our systematic evaluation reveals that Context Compression achieves optimal performance across all pipeline stages, with 93.3% intent accuracy, 86.8% routing success(with fallbacks), 99.4% recall, and 88.5% NDCG@5. This approach demonstrates that strategic context summarization outperforms both comprehensive and minimal contextualization strategies.

</details>


### [5] [TextBridgeGNN: Pre-training Graph Neural Network for Cross-Domain Recommendation via Text-Guided Transfer](https://arxiv.org/abs/2601.02366)
*Yiwen Chen,Yiqing Wu,Huishi Luo,Fuzhen Zhuang,Deqing Wang*

Main category: cs.IR

TL;DR: TextBridgeGNN：利用文本作为语义桥梁的图推荐预训练框架，通过多级图传播连接不同领域，解决ID嵌入不可迁移和异构图结构不兼容问题


<details>
  <summary>Details</summary>
Motivation: 传统基于ID嵌入的图推荐模型难以迁移到新领域，主要面临两个挑战：1) ID嵌入因领域特定ID空间隔离而不可迁移；2) 跨领域异构交互图结构不兼容。这阻碍了预训练图推荐模型的构建。

Method: 提出TextBridgeGNN预训练-微调框架：1) 使用文本作为语义桥梁连接不同领域；2) 预训练阶段利用文本信息打破数据孤岛，设计分层GNN学习领域特定和全局知识；3) 微调阶段提出相似性迁移机制，通过语义相关节点初始化目标领域ID嵌入。

Result: 实验表明TextBridgeGNN在跨领域、多领域和无训练设置下优于现有方法，能够有效整合预训练语言模型语义与基于图的协同过滤，无需昂贵的语言模型微调或实时推理开销。

Conclusion: TextBridgeGNN成功解决了图推荐模型的领域迁移问题，通过文本语义桥梁和多级图传播机制，实现了知识从预训练GNN到下游任务的有效迁移，为构建通用预训练图推荐模型提供了可行方案。

Abstract: Graph-based recommendation has achieved great success in recent years. The classical graph recommendation model utilizes ID embedding to store essential collaborative information. However, this ID-based paradigm faces challenges in transferring to a new domain, making it hard to build a pre-trained graph recommendation model. This phenomenon primarily stems from two inherent challenges: (1) the non-transferability of ID embeddings due to isolated domain-specific ID spaces, and (2) structural incompatibility between heterogeneous interaction graphs across domains.
  To address these issues, we propose TextBridgeGNN, a pre-training and fine-tuning framework that can effectively transfer knowledge from a pre-trained GNN to downstream tasks. We believe the key lies in how to build the relationship between domains. Specifically, TextBridgeGNN uses text as a semantic bridge to connect domains through multi-level graph propagation. During the pre-training stage, textual information is utilized to break the data islands formed by multiple domains, and hierarchical GNNs are designed to learn both domain-specific and domain-global knowledge with text features, ensuring the retention of collaborative signals and the enhancement of semantics. During the fine-tuning stage, a similarity transfer mechanism is proposed. This mechanism initializes ID embeddings in the target domain by transferring from semantically related nodes, successfully transferring the ID embeddings and graph pattern.
  Experiments demonstrate that TextBridgeGNN outperforms existing methods in cross-domain, multi-domain, and training-free settings, highlighting its ability to integrate Pre-trained Language Model (PLM)-driven semantics with graph-based collaborative filtering without costly language model fine-tuning or real-time inference overhead.

</details>


### [6] [Distillation-based Scenario-Adaptive Mixture-of-Experts for the Matching Stage of Multi-scenario Recommendation](https://arxiv.org/abs/2601.02368)
*Ruibing Wang,Shuhan Guo,Haotong Du,Quanming Yao*

Main category: cs.IR

TL;DR: DSMOE：基于蒸馏的场景自适应专家混合模型，解决多场景推荐中匹配阶段的专家崩溃和参数主导问题，提升长尾场景检索质量


<details>
  <summary>Details</summary>
Motivation: 多场景推荐中，MMOE在排序阶段表现良好，但在匹配阶段面临两个主要问题：1）独立双塔架构的盲目优化；2）头部场景参数主导导致长尾场景专家崩溃

Method: 提出DSMOE框架：1）场景自适应投影模块生成轻量级、场景特定参数；2）跨架构知识蒸馏框架，让交互感知的教师模型指导双塔学生模型学习复杂匹配模式

Result: 在真实数据集上的实验表明DSMOE显著优于现有方法，特别是在数据稀疏、代表性不足的长尾场景中显著提升了检索质量

Conclusion: DSMOE通过场景自适应参数生成和知识蒸馏，有效解决了多场景推荐匹配阶段的结构和分布瓶颈，为长尾场景提供了更好的推荐效果

Abstract: Multi-scenario recommendation is pivotal for optimizing user experience across diverse contexts. While Multi-gate Mixture-of-Experts (MMOE) thrives in ranking, its transfer to the matching stage is hindered by the blind optimization inherent to independent two-tower architectures and the parameter dominance of head scenarios. To address these structural and distributional bottlenecks, we propose Distillation-based Scenario-Adaptive Mixture-of-Experts (DSMOE). Specially, we devise a Scenario-Adaptive Projection (SAP) module to generate lightweight, context-specific parameters, effectively preventing expert collapse in long-tail scenarios. Concurrently, we introduce a cross-architecture knowledge distillation framework, where an interaction-aware teacher guides the two-tower student to capture complex matching patterns. Extensive experiments on real-world datasets demonstrate DSMOE's superiority, particularly in significantly improving retrieval quality for under-represented, data-sparse scenarios.

</details>


### [7] [Improving News Recommendations through Hybrid Sentiment Modelling and Reinforcement Learning](https://arxiv.org/abs/2601.02372)
*Eunice Kingenga,Mike Wa Nkongolo*

Main category: cs.IR

TL;DR: 本研究提出了一种结合混合情感分析和强化学习的自适应情感感知新闻推荐框架，通过Q-learning学习最优推荐策略，提高个性化推荐效果。


<details>
  <summary>Details</summary>
Motivation: 传统新闻推荐系统在情感分析方面存在局限性：处理歧义性、词典不一致性、上下文理解不足，且通常将情感作为次要特征，难以适应用户的情感偏好。

Method: 开发自适应情感感知新闻推荐框架，整合混合情感分析和强化学习。使用BBC News数据集，结合VADER、AFINN、TextBlob和SentiWordNet四种情感分析工具生成稳健的文章级情感估计，将文章分类为积极、消极或中性，并将这些情感状态嵌入Q-learning架构中指导智能体学习最优推荐策略。

Result: 该系统能有效识别并推荐情感特征匹配的文章，通过迭代Q-learning更新持续改进个性化推荐。结果表明，混合情感建模与强化学习结合为以用户为中心的新闻推荐提供了可行、可解释且自适应的解决方案。

Conclusion: 将混合情感建模与强化学习耦合，为新闻推荐系统提供了一种可行、可解释且自适应的用户中心化方法，能够更好地理解和适应用户的情感偏好。

Abstract: News recommendation systems rely on automated sentiment analysis to personalise content and enhance user engagement. Conventional approaches often struggle with ambiguity, lexicon inconsistencies, and limited contextual understanding, particularly in multi-source news environments. Existing models typically treat sentiment as a secondary feature, reducing their ability to adapt to users' affective preferences. To address these limitations, this study develops an adaptive, sentiment-aware news recommendation framework by integrating hybrid sentiment analysis with reinforcement learning. Using the BBC News dataset, a hybrid sentiment model combines VADER, AFINN, TextBlob, and SentiWordNet scores to generate robust article-level sentiment estimates. Articles are categorised as positive, negative, or neutral, and these sentiment states are embedded within a Q-learning architecture to guide the agent in learning optimal recommendation policies. The proposed system effectively identifies and recommends articles with aligned emotional profiles while continuously improving personalisation through iterative Q-learning updates. The results demonstrate that coupling hybrid sentiment modelling with reinforcement learning provides a feasible, interpretable, and adaptive approach for user-centred news recommendation.

</details>


### [8] [A Lay User Explainable Food Recommendation System Based on Hybrid Feature Importance Extraction and Large Language Models](https://arxiv.org/abs/2601.02374)
*Melissa Tessa,Diderot D. Cidjeu,Rachele Carli,Sarah Abchiche,Ahmad Aldarwishd,Igor Tchappi,Amro Najjar*

Main category: cs.IR

TL;DR: 使用LLM和SHAP开发后处理流程，为食品推荐系统提供更详细的解释，增强用户信任和透明度


<details>
  <summary>Details</summary>
Motivation: 虽然LLM发展迅速，但现有食品推荐系统的解释不够详细，用户难以理解复杂推荐结果，需要更全面、动态的解释来增强用户信任

Method: 结合LLM和SHAP的混合关键变量提取方法，开发后处理流程，为推荐结果生成动态、有说服力的解释

Result: 相比文献中的方法，该方法能为普通用户提供更全面、更令人信服的解释，使复杂推荐结果更易理解

Conclusion: LLM与SHAP结合的后处理流程能有效提升食品推荐系统的解释质量，增强用户信任和系统透明度

Abstract: Large Language Models (LLM) have experienced strong development in recent years, with varied applications. This paper uses LLMs to develop a post-hoc process that provides more elaborated explanations of the results of food recommendation systems. By combining LLM with a hybrid extraction of key variables using SHAP, we obtain dynamic, convincing and more comprehensive explanations to lay user, compared to those in the literature. This approach enhances user trust and transparency by making complex recommendation outcomes easier to understand for a lay user.

</details>


### [9] [TAG-HGT: A Scalable and Cost-Effective Framework for Inductive Cold-Start Academic Recommendation](https://arxiv.org/abs/2601.02381)
*Zhexiang Li*

Main category: cs.IR

TL;DR: TAG-HGT是一个神经符号框架，通过"语义优先、结构精炼"的解耦范式，将冻结大语言模型的语义知识蒸馏到轻量级异构图Transformer中，解决了学术平台冷启动推荐中生成模型推理延迟高、计算成本大的问题。


<details>
  <summary>Details</summary>
Motivation: 工业学术平台每天有大量新学者加入，缺乏历史交互记录，面临冷启动推荐挑战。现有生成图模型虽然语义能力强，但推理延迟高（每1000个请求超过13分钟）、计算成本大，无法满足实时、百万级规模应用的需求。

Method: 采用"语义优先、结构精炼"的解耦范式：1）使用冻结的DeepSeek-V3大语言模型作为离线语义工厂；2）通过跨视图对比学习将语义知识蒸馏到轻量级异构图Transformer中；3）结合LLM提供的全局召回能力和结构信号提供的局部判别能力。

Result: 在OpenAlex数据集上，TAG-HGT达到91.97%的SOTA系统召回率@10，比纯结构基线提升20.7%。推理延迟降低5个数量级（从780秒降至1.73毫秒），推理成本从每1000查询约1.50美元降至<0.001美元，成本降低99.9%。

Conclusion: TAG-HGT在保持生成模型语义质量的同时，实现了工业级可扩展性，大幅降低了推理延迟和成本，使高精度学术推荐民主化，为工业冷启动推荐提供了实用解决方案。

Abstract: Inductive cold-start recommendation remains the "Achilles' Heel" of industrial academic platforms, where thousands of new scholars join daily without historical interaction records. While recent Generative Graph Models (e.g., HiGPT, OFA) demonstrate promising semantic capabilities, their prohibitive inference latency (often exceeding 13 minutes per 1,000 requests) and massive computational costs render them practically undeployable for real-time, million-scale applications. To bridge this gap between generative quality and industrial scalability, we propose TAG-HGT, a cost-effective neuro-symbolic framework. Adopting a decoupled "Semantics-First, Structure-Refined" paradigm, TAG-HGT utilizes a frozen Large Language Model (DeepSeek-V3) as an offline semantic factory and distills its knowledge into a lightweight Heterogeneous Graph Transformer (HGT) via Cross-View Contrastive Learning (CVCL). We present a key insight: while LLM semantics provide necessary global recall, structural signals offer the critical local discrimination needed to distinguish valid collaborators from semantically similar but socially unreachable strangers in dense embedding spaces. Validated under a strict Time-Machine Protocol on the massive OpenAlex dataset, TAG-HGT achieves a SOTA System Recall@10 of 91.97%, outperforming structure-only baselines by 20.7%. Most significantly, from an industrial perspective, TAG-HGT reduces inference latency by five orders of magnitude ($4.5 \times 10^{5}\times$) compared to generative baselines (from 780s down to 1.73 ms), and slashes inference costs from $\sim$$1.50 to $<$$0.001 per 1k queries. This 99.9% cost reduction democratizes high-precision academic recommendation.

</details>


### [10] [Tree of Preferences for Diversified Recommendation](https://arxiv.org/abs/2601.02386)
*Hanyang Yuan,Ning Tang,Tongya Zheng,Jiarong Xu,Xintong Hu,Renhong Huang,Shunyu Liu,Jiacong Hu,Jiawei Chen,Mingli Song*

Main category: cs.IR

TL;DR: 提出基于大语言模型的多样化推荐方法，通过构建偏好树挖掘用户未充分探索的兴趣，生成合成交互数据训练推荐模型，提升推荐的多样性和相关性。


<details>
  <summary>Details</summary>
Motivation: 现有多样化推荐方法主要从观察到的用户反馈推断用户偏好多样性，但由于数据偏差，观察数据可能无法完全反映用户兴趣，未充分探索的偏好可能被掩盖或未显现，导致推荐多样性不足。

Method: 1. 引入偏好树(ToP)结构，从粗到细建模用户偏好；2. 利用LLM的零样本推理能力，基于世界知识系统推理用户行为背后的逻辑，挖掘未充分探索的偏好；3. 采用数据为中心的方法，识别匹配用户偏好的候选物品，生成反映未探索偏好的合成交互；4. 整合这些交互训练通用推荐器实现多样化；5. 通过动态选择有影响力的用户优化整体效率。

Result: 在多样性和相关性方面的广泛评估表明，该方法在大多数情况下优于现有方法，在其他情况下达到接近最优的性能，且推理延迟合理。

Conclusion: 从数据偏差角度研究多样化推荐，利用LLM的专业知识挖掘未充分探索的用户偏好，通过偏好树结构和数据为中心的方法有效提升推荐多样性和相关性，具有实际应用价值。

Abstract: Diversified recommendation has attracted increasing attention from both researchers and practitioners, which can effectively address the homogeneity of recommended items. Existing approaches predominantly aim to infer the diversity of user preferences from observed user feedback. Nonetheless, due to inherent data biases, the observed data may not fully reflect user interests, where underexplored preferences can be overwhelmed or remain unmanifested. Failing to capture these preferences can lead to suboptimal diversity in recommendations. To fill this gap, this work aims to study diversified recommendation from a data-bias perspective. Inspired by the outstanding performance of large language models (LLMs) in zero-shot inference leveraging world knowledge, we propose a novel approach that utilizes LLMs' expertise to uncover underexplored user preferences from observed behavior, ultimately providing diverse and relevant recommendations. To achieve this, we first introduce Tree of Preferences (ToP), an innovative structure constructed to model user preferences from coarse to fine. ToP enables LLMs to systematically reason over the user's rationale behind their behavior, thereby uncovering their underexplored preferences. To guide diversified recommendations using uncovered preferences, we adopt a data-centric approach, identifying candidate items that match user preferences and generating synthetic interactions that reflect underexplored preferences. These interactions are integrated to train a general recommender for diversification. Moreover, we scale up overall efficiency by dynamically selecting influential users during optimization. Extensive evaluations of both diversity and relevance show that our approach outperforms existing methods in most cases and achieves near-optimal performance in others, with reasonable inference latency.

</details>


### [11] [Socially-Aware Recommender Systems Mitigate Opinion Clusterization](https://arxiv.org/abs/2601.02412)
*Lukas Schüepp,Carmen Amo Alonso,Florian Dörfler,Giulia De Pasquale*

Main category: cs.IR

TL;DR: 该论文提出了一种考虑用户社交网络的推荐系统，通过利用社交网络拓扑来平衡个性化与多样性，以缓解过滤气泡和意见极化问题。


<details>
  <summary>Details</summary>
Motivation: 推荐系统、内容创作者和用户之间形成了复杂的反馈循环：推荐系统根据用户偏好匹配内容，创作者为提升受欢迎度而调整内容，用户偏好又受到推荐内容和社交圈的双重影响。这种循环是导致过滤气泡和意见极化的关键原因，需要设计能够缓解这些问题的推荐系统。

Method: 开发了一种社交网络感知的推荐系统，明确考虑用户与创作者之间的反馈互动，并战略性地利用用户自身社交网络的拓扑结构来促进内容多样化。该方法在推荐系统设计中充分考虑并利用用户的社交网络。

Result: 理论上证明了意见聚类与推荐内容对用户意见的影响力呈正相关。提出的方法展示了社交感知推荐系统在对抗意见极化和聚类现象方面的能力。

Conclusion: 在推荐系统设计中考虑并利用用户的社交网络对于调解过滤气泡效应至关重要，能够在内容多样性和个性化之间取得平衡。社交感知推荐系统是应对意见极化和聚类现象的有效工具。

Abstract: Recommender systems shape online interactions by matching users with creators content to maximize engagement. Creators, in turn, adapt their content to align with users preferences and enhance their popularity. At the same time, users preferences evolve under the influence of both suggested content from the recommender system and content shared within their social circles. This feedback loop generates a complex interplay between users, creators, and recommender algorithms, which is the key cause of filter bubbles and opinion polarization. We develop a social network-aware recommender system that explicitly accounts for this user-creators feedback interaction and strategically exploits the topology of the user's own social network to promote diversification. Our approach highlights how accounting for and exploiting user's social network in the recommender system design is crucial to mediate filter bubble effects while balancing content diversity with personalization. Provably, opinion clusterization is positively correlated with the influence of recommended content on user opinions. Ultimately, the proposed approach shows the power of socially-aware recommender systems in combating opinion polarization and clusterization phenomena.

</details>


### [12] [A Dynamic Retrieval-Augmented Generation System with Selective Memory and Remembrance](https://arxiv.org/abs/2601.02428)
*Okan Bursa*

Main category: cs.IR

TL;DR: ARM是一个动态记忆RAG框架，通过选择性记忆和遗忘机制替代静态向量索引，实现高效检索增强生成


<details>
  <summary>Details</summary>
Motivation: 传统RAG使用静态向量索引存在效率问题，需要更智能的记忆管理机制来平衡性能、延迟和内存效率

Method: 采用动态记忆基板，基于认知巩固和遗忘原理：频繁检索的项目被巩固保护，很少使用的项目逐渐衰减

Result: 在轻量级检索基准上达到接近SOTA性能（NDCG@5≈0.940，Recall@5=1.000），仅需约22M参数，在超高效模型中效率最佳

Conclusion: ARM在质量、延迟和内存效率之间提供了实用的权衡，适用于生产和研究RAG系统，具有自正则化内存增长和可解释的保留动态

Abstract: We introduce \emph{Adaptive RAG Memory} (ARM), a retrieval-augmented generation (RAG) framework that replaces a static vector index with a \emph{dynamic} memory substrate governed by selective remembrance and decay. Frequently retrieved items are consolidated and protected from forgetting, while rarely used items gradually decay, inspired by cognitive consolidation and forgetting principles. On a lightweight retrieval benchmark, ARM reaches near state-of-the-art performance (e.g., NDCG@5 $\approx$ 0.940, Recall@5 $=1.000$) with only $\sim$22M parameters in the embedding layer, achieving the best efficiency among ultra-efficient models ($<$25M parameters). In addition, we compare static vs. dynamic RAG combinations across Llama 3.1 and GPT-4o. Llama 3.1 with static RAG achieves the highest key-term coverage (67.2\%) at moderate latency, while GPT-4o with a dynamic selective retrieval policy attains the fastest responses (8.2s on average) with competitive coverage (58.7\%). We further present an engineering optimization of the DynamicRAG implementation, making embedding weights configurable, adjustable at runtime, and robust to invalid settings.
  ARM yields competitive accuracy, self-regularizing memory growth, and interpretable retention dynamics without retraining the generator\color{black} and provides practical trade-off between quality, latency and memory efficiency for production and research RAG system.

</details>


### [13] [CREAM: Continual Retrieval on Dynamic Streaming Corpora with Adaptive Soft Memory](https://arxiv.org/abs/2601.02708)
*HuiJeong Son,Hyeongu Kang,Sunho Kim,Subeen Ho,SeongKu Kang,Dongha Lee,Susik Yoon*

Main category: cs.IR

TL;DR: CREAM是一个用于动态数据流信息检索的自监督持续学习框架，通过动态结构化软记忆捕获流式查询和文档的语义演化，无需真实标签即可适应新旧主题。


<details>
  <summary>Details</summary>
Motivation: 动态数据流中的信息检索面临数据分布漂移的挑战，现有基于记忆的持续学习方法依赖固定查询集和真实相关文档，限制了向未见查询和文档的泛化能力，难以应用于实际场景。

Method: 提出CREAM框架，包含三个关键技术：细粒度相似度估计、正则化聚类原型和分层核心集采样，通过动态结构化软记忆捕获流式查询和文档的语义演化，在无监督设置下适应已见和未见主题。

Result: 在两个基准数据集上的实验表明，CREAM在无标签设置下表现出卓越的适应性和检索准确性，在Success@5和Recall@10指标上平均比最强方法分别提升27.79%和44.5%，性能达到甚至超过监督方法。

Conclusion: CREAM通过自监督框架解决了动态数据流信息检索中的分布漂移问题，无需真实标签即可有效适应新旧主题，为实际应用提供了可行的解决方案。

Abstract: Information retrieval (IR) in dynamic data streams is emerging as a challenging task, as shifts in data distribution degrade the performance of AI-powered IR systems. To mitigate this issue, memory-based continual learning has been widely adopted for IR. However, existing methods rely on a fixed set of queries with ground-truth relevant documents, which limits generalization to unseen queries and documents, making them impractical for real-world applications. To enable more effective learning with unseen topics of a new corpus without ground-truth labels, we propose CREAM, a self-supervised framework for memory-based continual retrieval. CREAM captures the evolving semantics of streaming queries and documents into dynamically structured soft memory and leverages it to adapt to both seen and unseen topics in an unsupervised setting. We realize this through three key techniques: fine-grained similarity estimation, regularized cluster prototyping, and stratified coreset sampling. Experiments on two benchmark datasets demonstrate that CREAM exhibits superior adaptability and retrieval accuracy, outperforming the strongest method in a label-free setting by 27.79\% in Success@5 and 44.5\% in Recall@10 on average, and achieving performance comparable to or even exceeding that of supervised methods.

</details>


### [14] [Ahead of the Spread: Agent-Driven Virtual Propagation for Early Fake News Detection](https://arxiv.org/abs/2601.02750)
*Bincheng Gu,Min Gao,Junliang Yu,Zongwei Wang,Zhiyi Liu,Kai Shu,Hongyu Zhang*

Main category: cs.IR

TL;DR: AVOID提出了一种基于LLM智能体的虚拟传播模拟方法，用于早期假新闻检测，通过主动生成传播信号而非被动观察来解决早期传播数据缺失的问题。


<details>
  <summary>Details</summary>
Motivation: 早期假新闻检测面临传播信号缺失的挑战，传统基于传播动态的方法在早期阶段无法获得足够的传播数据，导致检测性能受限。

Method: AVOID将早期检测重新定义为证据生成范式，使用具有差异化角色和数据驱动人设的LLM智能体，在没有真实传播数据的情况下模拟早期扩散行为，生成虚拟传播轨迹作为补充社交证据，并通过去噪引导的融合策略将模拟传播与内容语义对齐。

Result: 在基准数据集上的大量实验表明，AVOID持续优于最先进的基线方法，证明了虚拟传播增强对早期假新闻检测的有效性和实用价值。

Conclusion: AVOID通过主动模拟传播动态而非被动观察，为早期假新闻检测提供了新的解决方案，展示了虚拟传播增强在实际应用中的潜力。

Abstract: Early detection of fake news is critical for mitigating its rapid dissemination on social media, which can severely undermine public trust and social stability. Recent advancements show that incorporating propagation dynamics can significantly enhance detection performance compared to previous content-only approaches. However, this remains challenging at early stages due to the absence of observable propagation signals. To address this limitation, we propose AVOID, an \underline{a}gent-driven \underline{v}irtual pr\underline{o}pagat\underline{i}on for early fake news \underline{d}etection. AVOID reformulates early detection as a new paradigm of evidence generation, where propagation signals are actively simulated rather than passively observed. Leveraging LLM-powered agents with differentiated roles and data-driven personas, AVOID realistically constructs early-stage diffusion behaviors without requiring real propagation data. The resulting virtual trajectories provide complementary social evidence that enriches content-based detection, while a denoising-guided fusion strategy aligns simulated propagation with content semantics. Extensive experiments on benchmark datasets demonstrate that AVOID consistently outperforms state-of-the-art baselines, highlighting the effectiveness and practical value of virtual propagation augmentation for early fake news detection. The code and data are available at https://github.com/Ironychen/AVOID.

</details>


### [15] [Netflix Artwork Personalization via LLM Post-training](https://arxiv.org/abs/2601.02764)
*Hyunji Nam,Sejoon Oh,Emma Kong,Yesu Feng,Moumita Bhattacharya*

Main category: cs.IR

TL;DR: 本文提出使用LLM进行个性化艺术品推荐的新方法，通过后训练使模型能根据用户偏好选择最合适的视觉呈现，在Netflix数据集上比现有生产模型提升3-5%。


<details>
  <summary>Details</summary>
Motivation: 用户对娱乐内容（如Netflix上的标题）的偏好具有多样性，同一标题的不同视觉呈现（艺术品）可能吸引不同类型的用户。现有的一刀切推荐方法无法满足这种个性化需求，因此需要开发能够根据用户偏好推荐最合适艺术品的个性化系统。

Method: 对预训练的大语言模型（Llama 3.1 8B）进行后训练，使其能够根据用户偏好为每个用户-标题对推荐最合适的视觉呈现。使用包含110K数据点的数据集进行训练，并在5K保留的用户-标题对上进行评估。

Result: 后训练的LLM在个性化艺术品推荐任务上比Netflix生产模型提升了3-5%的性能，表明使用LLM进行细粒度个性化推荐是一个有前景的方向。

Conclusion: LLM能够有效处理用户偏好的多样性，为个性化艺术品推荐提供有前景的解决方案。通过后训练预训练LLM，可以实现比现有生产模型更好的推荐效果，提升用户满意度和参与度。

Abstract: Large language models (LLMs) have demonstrated success in various applications of user recommendation and personalization across e-commerce and entertainment. On many entertainment platforms such as Netflix, users typically interact with a wide range of titles, each represented by an artwork. Since users have diverse preferences, an artwork that appeals to one type of user may not resonate with another with different preferences. Given this user heterogeneity, our work explores the novel problem of personalized artwork recommendations according to diverse user preferences. Similar to the multi-dimensional nature of users' tastes, titles contain different themes and tones that may appeal to different viewers. For example, the same title might feature both heartfelt family drama and intense action scenes. Users who prefer romantic content may like the artwork emphasizing emotional warmth between the characters, while those who prefer action thrillers may find high-intensity action scenes more intriguing. Rather than a one-size-fits-all approach, we conduct post-training of pre-trained LLMs to make personalized artwork recommendations, selecting the most preferred visual representation of a title for each user and thereby improving user satisfaction and engagement. Our experimental results with Llama 3.1 8B models (trained on a dataset of 110K data points and evaluated on 5K held-out user-title pairs) show that the post-trained LLMs achieve 3-5\% improvements over the Netflix production model, suggesting a promising direction for granular personalized recommendations using LLMs.

</details>


### [16] [COFFEE: COdesign Framework for Feature Enriched Embeddings in Ads-Ranking Systems](https://arxiv.org/abs/2601.02807)
*Sohini Roychowdhury,Doris Wang,Qian Ge,Joy Mu,Srihari Reddy*

Main category: cs.IR

TL;DR: 提出三维框架增强用户-广告表示，通过整合多源事件、延长用户历史、丰富事件属性和多模态嵌入，提升广告推荐效果，AUC提升1.56-2倍，CTR预测提升0.56% AUC。


<details>
  <summary>Details</summary>
Motivation: 商业广告推荐模型需要多样化和丰富的数据源来准确评估用户兴趣。虽然扩展的用户参与历史可以改善用户兴趣预测，但同样重要的是嵌入来自多个来源的活动序列，以确保用户和广告表示的新鲜度，遵循扩展法则原则。

Method: 提出新颖的三维框架：第一维研究整合不同事件来源的影响；第二维考虑更长用户历史的好处；第三维专注于用额外事件属性和多模态嵌入丰富数据。通过比较有机用户参与来源（如内容浏览）与广告展示来源来评估投资回报率。

Result: 广告展示来源的AUC和扩展曲线斜率比有机使用来源提升1.56到2倍，即使在线序列长度仅为100到10K。使用丰富的广告展示事件来源时，CTR预测比基线生产广告推荐系统提升0.56% AUC，改善了更长和离线用户-广告表示的序列扩展分辨率。

Conclusion: 三维数据源丰富框架能显著提升广告推荐性能，通过多源事件整合、延长用户历史和丰富事件属性，在不增加模型推理或服务复杂度的情况下，有效改善用户-广告表示质量。

Abstract: Diverse and enriched data sources are essential for commercial ads-recommendation models to accurately assess user interest both before and after engagement with content. While extended user-engagement histories can improve the prediction of user interests, it is equally important to embed activity sequences from multiple sources to ensure freshness of user and ad-representations, following scaling law principles. In this paper, we present a novel three-dimensional framework for enhancing user-ad representations without increasing model inference or serving complexity. The first dimension examines the impact of incorporating diverse event sources, the second considers the benefits of longer user histories, and the third focuses on enriching data with additional event attributes and multi-modal embeddings. We assess the return on investment (ROI) of our source enrichment framework by comparing organic user engagement sources, such as content viewing, with ad-impression sources. The proposed method can boost the area under curve (AUC) and the slope of scaling curves for ad-impression sources by 1.56 to 2 times compared to organic usage sources even for short online-sequence lengths of 100 to 10K. Additionally, click-through rate (CTR) prediction improves by 0.56% AUC over the baseline production ad-recommendation system when using enriched ad-impression event sources, leading to improved sequence scaling resolutions for longer and offline user-ad representations.

</details>


### [17] [HarmonRank: Ranking-aligned Multi-objective Ensemble for Live-streaming E-commerce Recommendation](https://arxiv.org/abs/2601.02955)
*Boyang Xia,Zhou Yu,Zhiliang Zhu,Hanxiao Sun,Biyun Han,Jun Wang,Runnan Liu,Wenwu Ou*

Main category: cs.IR

TL;DR: 提出HarmonRank框架，通过排名对齐和跨目标对齐解决直播电商推荐中的多目标排序问题，显著提升购买转化率。


<details>
  <summary>Details</summary>
Motivation: 直播电商推荐需要平衡购买和用户-主播互动等多个目标。现有集成模型使用多个独立的二分类损失，存在两个问题：1）二分类优化方向与排名任务（AUC评估）不对齐；2）忽略了目标间的相关性（如评论和购买行为的部分依赖性）。

Method: 提出HarmonRank框架：1）排名对齐：将AUC排名指标公式化为秩和问题，使用可微分排名技术进行排名导向优化；2）跨目标对齐：将原始的一步集成范式改为两步关系感知集成方案。

Result: 在两个工业数据集上的离线实验和在线实验表明，该方法显著优于现有SOTA方法。已在快手直播电商推荐平台（4亿DAU）全面部署，贡献超过2%的购买增益。

Conclusion: HarmonRank通过同时实现排名任务对齐和目标间对齐，有效解决了直播电商推荐中的多目标排序问题，显著提升了推荐系统的长期生态效益。

Abstract: Recommendation for live-streaming e-commerce is gaining increasing attention due to the explosive growth of the live streaming economy. Different from traditional e-commerce, live-streaming e-commerce shifts the focus from products to streamers, which requires ranking mechanism to balance both purchases and user-streamer interactions for long-term ecology. To trade off multiple objectives, a popular solution is to build an ensemble model to integrate multi-objective scores into a unified score. The ensemble model is usually supervised by multiple independent binary classification losses of all objectives. However, this paradigm suffers from two inherent limitations. First, the optimization direction of the binary classification task is misaligned with the ranking task (evaluated by AUC). Second, this paradigm overlooks the alignment between objectives, e.g., comment and buy behaviors are partially dependent which can be revealed in labels correlations. The model can achieve better trade-offs if it learns the aligned parts of ranking abilities among different objectives.
  To mitigate these limitations, we propose a novel multi-objective ensemble framework HarmonRank to fulfill both alignment to the ranking task and alignment among objectives. For alignment to ranking, we formulate ranking metric AUC as a rank-sum problem and utilize differentiable ranking techniques for ranking-oriented optimization. For inter-objective alignment, we change the original one-step ensemble paradigm to a two-step relation-aware ensemble scheme.
  Extensive offline experiments results on two industrial datasets and online experiments demonstrate that our approach significantly outperforms existing state-of-the-art methods. The proposed method has been fully deployed in Kuaishou's live-streaming e-commerce recommendation platform with 400 million DAUs, contributing over 2% purchase gain.

</details>


### [18] [Auditing Search Query Suggestion Bias Through Recursive Algorithm Interrogation](https://arxiv.org/abs/2601.02962)
*Fabian Haak,Philipp Schaer*

Main category: cs.IR

TL;DR: 提出一种通过递归算法询问构建建议树的新方法，用于识别搜索查询建议中的偏见，特别针对政治领域人物相关搜索的主题群体偏见。


<details>
  <summary>Details</summary>
Motivation: 搜索查询建议在在线信息搜索中扮演重要角色，但相关研究较少。主要挑战在于上下文稀疏性和数据基础有限（每个查询最多10个建议），这给识别搜索查询建议中的偏见带来了显著问题。

Method: 采用递归算法询问技术，创建建议树，从而访问更多潜意识的搜索查询建议。基于这些建议，研究政治领域人物相关搜索中的主题群体偏见。

Result: 该方法能够深化偏见分析的数据基础，提供了一种识别搜索查询建议偏见的新替代方法。

Conclusion: 通过递归算法询问构建建议树的方法，为解决搜索查询建议偏见识别中的数据稀疏性问题提供了有效途径，特别适用于政治领域人物相关搜索的偏见分析。

Abstract: Despite their important role in online information search, search query suggestions have not been researched as much as most other aspects of search engines. Although reasons for this are multi-faceted, the sparseness of context and the limited data basis of up to ten suggestions per search query pose the most significant problem in identifying bias in search query suggestions. The most proven method to reduce sparseness and improve the validity of bias identification of search query suggestions so far is to consider suggestions from subsequent searches over time for the same query. This work presents a new, alternative approach to search query bias identification that includes less high-level suggestions to deepen the data basis of bias analyses. We employ recursive algorithm interrogation techniques and create suggestion trees that enable access to more subliminal search query suggestions. Based on these suggestions, we investigate topical group bias in person-related searches in the political domain.

</details>


### [19] [Parallel Latent Reasoning for Sequential Recommendation](https://arxiv.org/abs/2601.03153)
*Jiakai Tang,Xu Chen,Wen Chen,Jian Wu,Yuning Jiang,Bo Zheng*

Main category: cs.IR

TL;DR: PLR提出并行潜在推理框架，通过同时探索多个不同的推理轨迹来解决序列推荐中稀疏行为序列的复杂用户偏好建模问题，突破了传统深度级扩展的限制。


<details>
  <summary>Details</summary>
Motivation: 现有潜在推理方法仅依赖单一轨迹的深度级扩展，随着推理深度增加会出现收益递减问题，限制了从稀疏行为序列中捕捉复杂用户偏好的能力。

Method: PLR框架通过三个关键组件实现：1) 在连续潜在空间中使用可学习的触发令牌构建并行推理流；2) 通过全局推理正则化保持流间的多样性；3) 通过混合推理流聚合自适应合成多流输出。

Result: 在三个真实世界数据集上的实验表明，PLR显著优于最先进的基线方法，同时保持了实时推理效率。理论分析进一步验证了并行推理在提高泛化能力方面的有效性。

Conclusion: PLR为序列推荐中的推理能力增强开辟了新途径，超越了现有的深度扩展方法，通过宽度级计算扩展实现了更好的性能。

Abstract: Capturing complex user preferences from sparse behavioral sequences remains a fundamental challenge in sequential recommendation. Recent latent reasoning methods have shown promise by extending test-time computation through multi-step reasoning, yet they exclusively rely on depth-level scaling along a single trajectory, suffering from diminishing returns as reasoning depth increases. To address this limitation, we propose \textbf{Parallel Latent Reasoning (PLR)}, a novel framework that pioneers width-level computational scaling by exploring multiple diverse reasoning trajectories simultaneously. PLR constructs parallel reasoning streams through learnable trigger tokens in continuous latent space, preserves diversity across streams via global reasoning regularization, and adaptively synthesizes multi-stream outputs through mixture-of-reasoning-streams aggregation. Extensive experiments on three real-world datasets demonstrate that PLR substantially outperforms state-of-the-art baselines while maintaining real-time inference efficiency. Theoretical analysis further validates the effectiveness of parallel reasoning in improving generalization capability. Our work opens new avenues for enhancing reasoning capacity in sequential recommendation beyond existing depth scaling.

</details>


### [20] [Fine-tuning Small Language Models as Efficient Enterprise Search Relevance Labelers](https://arxiv.org/abs/2601.03211)
*Yue Kang,Zhuoyi Huang,Benji Schussheim,Diana Licon,Dina Atia,Shixing Cao,Jacob Danovitch,Kunho Kim,Billy Norcilien,Jonah Karpman,Mahmound Sayed,Mike Taylor,Tao Sun,Pavel Metrikov,Vipul Agarwal,Chris Quirk,Ye-Yi Wang,Nick Craswell,Irene Shaffer,Tianwei Chen,Sulaiman Vesal,Soundar Srinivasan*

Main category: cs.IR

TL;DR: 提出一种高效方法，通过合成数据生成和知识蒸馏，将小型语言模型微调为企业搜索中的相关性标注器，在保持质量的同时大幅提升吞吐量和成本效益。


<details>
  <summary>Details</summary>
Motivation: 企业搜索中构建高质量数据集面临核心挑战：难以获取标注数据。现有大型语言模型标注成本高、速度慢，需要更高效、可扩展的解决方案。

Method: 1) 使用LLM从种子文档合成真实企业查询；2) 应用BM25检索困难负样本；3) 使用教师LLM分配相关性分数；4) 将合成数据集蒸馏到小型语言模型，生成紧凑的相关性标注器。

Result: 在923个企业查询-文档对的人工标注基准上，蒸馏后的小型模型与人类判断的一致性达到或超过教师LLM水平。吞吐量提升17倍，成本效益提高19倍。

Conclusion: 该方法实现了可扩展、成本效益高的企业级相关性标注，支持实际应用中的快速离线评估和迭代，为企业搜索系统开发提供了实用解决方案。

Abstract: In enterprise search, building high-quality datasets at scale remains a central challenge due to the difficulty of acquiring labeled data. To resolve this challenge, we propose an efficient approach to fine-tune small language models (SLMs) for accurate relevance labeling, enabling high-throughput, domain-specific labeling comparable or even better in quality to that of state-of-the-art large language models (LLMs). To overcome the lack of high-quality and accessible datasets in the enterprise domain, our method leverages on synthetic data generation. Specifically, we employ an LLM to synthesize realistic enterprise queries from a seed document, apply BM25 to retrieve hard negatives, and use a teacher LLM to assign relevance scores. The resulting dataset is then distilled into an SLM, producing a compact relevance labeler. We evaluate our approach on a high-quality benchmark consisting of 923 enterprise query-document pairs annotated by trained human annotators, and show that the distilled SLM achieves agreement with human judgments on par with or better than the teacher LLM. Furthermore, our fine-tuned labeler substantially improves throughput, achieving 17 times increase while also being 19 times more cost-effective. This approach enables scalable and cost-effective relevance labeling for enterprise-scale retrieval applications, supporting rapid offline evaluation and iteration in real-world settings.

</details>
