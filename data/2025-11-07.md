<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 6]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Caption Injection for Optimization in Generative Search Engine](https://arxiv.org/abs/2511.04080)
*Xiaolu Chen,Yong Liao*

Main category: cs.IR

TL;DR: 提出了首个多模态生成搜索引擎优化方法Caption Injection，通过从图像中提取字幕并注入文本内容，在生成式搜索场景中提升内容的主观可见性。


<details>
  <summary>Details</summary>
Motivation: 现有G-SEO方法仅限于基于文本的优化，无法充分利用多模态数据。随着多模态检索增强生成技术的发展，需要解决文本优化方法的局限性。

Method: Caption Injection方法从图像中提取字幕并注入文本内容，整合视觉语义来增强生成式搜索场景中内容的主观可见性。

Result: 在MRAMG基准测试中，Caption Injection在G-Eval指标下显著优于仅文本的G-SEO基线方法，证明了多模态整合的必要性和有效性。

Conclusion: 多模态整合在G-SEO中对于提升用户感知的内容可见性是必要且有效的，Caption Injection方法为此提供了可行的解决方案。

Abstract: Generative Search Engines (GSEs) leverage Retrieval-Augmented Generation
(RAG) techniques and Large Language Models (LLMs) to integrate multi-source
information and provide users with accurate and comprehensive responses. Unlike
traditional search engines that present results in ranked lists, GSEs shift
users' attention from sequential browsing to content-driven subjective
perception, driving a paradigm shift in information retrieval. In this context,
enhancing the subjective visibility of content through Generative Search Engine
Optimization (G-SEO) methods has emerged as a new research focus. With the
rapid advancement of Multimodal Retrieval-Augmented Generation (MRAG)
techniques, GSEs can now efficiently integrate text, images, audio, and video,
producing richer responses that better satisfy complex information needs.
Existing G-SEO methods, however, remain limited to text-based optimization and
fail to fully exploit multimodal data. To address this gap, we propose Caption
Injection, the first multimodal G-SEO approach, which extracts captions from
images and injects them into textual content, integrating visual semantics to
enhance the subjective visibility of content in generative search scenarios. We
systematically evaluate Caption Injection on MRAMG, a benchmark for MRAG, under
both unimodal and multimodal settings. Experimental results show that Caption
Injection significantly outperforms text-only G-SEO baselines under the G-Eval
metric, demonstrating the necessity and effectiveness of multimodal integration
in G-SEO to improve user-perceived content visibility.

</details>


### [2] [E-CARE: An Efficient LLM-based Commonsense-Augmented Framework for E-Commerce](https://arxiv.org/abs/2511.04087)
*Ge Zhang,Rohan Deepak Ajwani,Tony Zheng,Hongjian Gu,Yaochen Hu,Wei Guo,Mark Coates,Yingxue Zhang*

Main category: cs.IR

TL;DR: 提出E-CARE方法，通过构建常识推理因子图来编码LLMs的推理模式，在电商推荐中仅需单次LLM前向传播即可获得常识推理能力，显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 解决电商平台中查询与产品相关性预测问题，现有基于LLM的方法存在实时推理成本高、需要人工标注和微调等问题。

Method: 构建常识推理因子图来编码LLMs的推理模式，在推理时仅需单次LLM前向传播即可获得常识推理能力，无需实时LLM推理。

Result: 在两个下游任务上实验显示，precision@5指标最高提升12.1%。

Conclusion: E-CARE方法能有效利用LLMs的常识推理能力，同时显著降低计算成本，为电商推荐任务提供高效解决方案。

Abstract: Finding relevant products given a user query plays a pivotal role in an
e-commerce platform, as it can spark shopping behaviors and result in revenue
gains. The challenge lies in accurately predicting the correlation between
queries and products. Recently, mining the cross-features between queries and
products based on the commonsense reasoning capacity of Large Language Models
(LLMs) has shown promising performance. However, such methods suffer from high
costs due to intensive real-time LLM inference during serving, as well as human
annotations and potential Supervised Fine Tuning (SFT). To boost efficiency
while leveraging the commonsense reasoning capacity of LLMs for various
e-commerce tasks, we propose the Efficient Commonsense-Augmented Recommendation
Enhancer (E-CARE). During inference, models augmented with E-CARE can access
commonsense reasoning with only a single LLM forward pass per query by
utilizing a commonsense reasoning factor graph that encodes most of the
reasoning schema from powerful LLMs. The experiments on 2 downstream tasks show
an improvement of up to 12.1% on precision@5.

</details>


### [3] [Transforming Mentorship: An AI Powered Chatbot Approach to University Guidance](https://arxiv.org/abs/2511.04172)
*Mashrur Rahman,Mantaqa abedin,Monowar Zamil Abir,Faizul Islam Ansari,Adib Reza,Farig Yousuf Sadeque,Niloy Farhan*

Main category: cs.IR

TL;DR: 开发了一个AI驱动的聊天机器人，作为BRAC大学学生的导师，通过混合检索方法和LLaMA-3.3-70B模型提供个性化指导。


<details>
  <summary>Details</summary>
Motivation: 大学生在本科生活中面临巨大挑战，缺乏个性化的按需指导，现有数字工具无法提供规模化定制化辅导。

Method: 构建数据摄取管道处理CSV文件和大学网页信息，采用BM25词汇排名与ChromaDB语义检索的混合方法，使用LLaMA-3.3-70B模型生成对话响应。

Result: 生成文本语义相关性高，BERTScore为0.831，METEOR得分为0.809；数据管道更新效率高，更新耗时106.82秒，新数据处理耗时368.62秒。

Conclusion: 该聊天机器人能够帮助学生解答疑问，更好地理解大学生活，并在开放学分制大学中协助规划学期日程。

Abstract: University students face immense challenges during their undergraduate lives,
often being deprived of personalized on-demand guidance that mentors fail to
provide at scale. Digital tools exist, but there is a serious lack of
customized coaching for newcomers. This paper presents an AI-powered chatbot
that will serve as a mentor for the students of BRAC University. The main
component is a data ingestion pipeline that efficiently processes and updates
information from diverse sources, such as CSV files and university webpages.
The chatbot retrieves information through a hybrid approach, combining BM25
lexical ranking with ChromaDB semantic retrieval, and uses a Large Language
Model, LLaMA-3.3-70B, to generate conversational responses. The generated text
was found to be semantically highly relevant, with a BERTScore of 0.831 and a
METEOR score of 0.809. The data pipeline was also very efficient, taking 106.82
seconds for updates, compared to 368.62 seconds for new data. This chatbot will
be able to help students by responding to their queries, helping them to get a
better understanding of university life, and assisting them to plan better
routines for their semester in the open-credit university.

</details>


### [4] [Coordination-Free Lane Partitioning for Convergent ANN Search](https://arxiv.org/abs/2511.04221)
*Carl Kugblenu,Petri Vuorimaa*

Main category: cs.IR

TL;DR: 提出了一个无协调的分区方法，将向量搜索系统中并行通道的重复计算转化为互补工作，在不增加成本或延长截止时间的情况下提高搜索覆盖率。


<details>
  <summary>Details</summary>
Motivation: 生产向量搜索系统通常通过并行通道（线程、副本或分片）来满足延迟SLO，但这些通道会重复发现相同的候选结果，额外的计算无法提高覆盖率。

Method: 为每个查询：(1)构建确定性的候选池，大小为总top-k预算；(2)应用每个查询的伪随机排列；(3)为每个通道分配不相交的位置切片。通道通过构造返回不同结果，无需运行时协调。

Result: 在4个通道（总候选预算64）下，SIFT1M数据集上recall@10从0.249提升到0.999，通道重叠从近100%降至0%；MS MARCO数据集上hit@10从0.200提升到0.601，MRR@10从0.133提升到0.330。

Conclusion: 提供了一个简单的操作指南：将每个查询池大小设为总预算，确定性地跨通道分区位置，在不改变预算或截止时间的情况下将冗余扇出转化为互补覆盖。

Abstract: Production vector search systems often fan out each query across parallel
lanes (threads, replicas, or shards) to meet latency service-level objectives
(SLOs). In practice, these lanes rediscover the same candidates, so extra
compute does not increase coverage. We present a coordination-free lane
partitioner that turns duplication into complementary work at the same cost and
deadline. For each query we (1) build a deterministic candidate pool sized to
the total top-k budget, (2) apply a per-query pseudorandom permutation, and (3)
assign each lane a disjoint slice of positions. Lanes then return different
results by construction, with no runtime coordination.
  At equal cost with four lanes (total candidate budget 64), on SIFT1M (1M SIFT
feature vectors) with Hierarchical Navigable Small World graphs (HNSW)
recall@10 rises from 0.249 to 0.999 while lane overlap falls from nearly 100%
to 0%. On MS MARCO (8.8M passages) with HNSW, hit@10 improves from 0.200 to
0.601 and Mean Reciprocal Rank at 10 (MRR@10) from 0.133 to 0.330. For inverted
file (IVF) indexes we see smaller but consistent gains (for example, +11% on MS
MARCO) by de-duplicating list routing. A microbenchmark shows planner overhead
of ~37 microseconds per query (mean at the main setting) with linear growth in
the number of merged candidates.
  These results yield a simple operational guideline: size the per-query pool
to the total budget, deterministically partition positions across lanes, and
turn redundant fan-out into complementary coverage without changing budget or
deadline.

</details>


### [5] [Denoised Recommendation Model with Collaborative Signal Decoupling](https://arxiv.org/abs/2511.04237)
*Zefeng Li,Ning Yang*

Main category: cs.IR

TL;DR: 提出DRCSD模型，通过协作信号解耦和分阶去噪来提升推荐系统性能，有效处理用户-物品交互矩阵中的噪声问题。


<details>
  <summary>Details</summary>
Motivation: 传统协同过滤算法因用户-物品交互矩阵中的噪声导致推荐性能不佳，现有去噪方法多在单一图上进行，可能削弱协作信号。

Method: DRCSD模型包含协作信号解耦模块（按结构特征分解信号为不同阶）和分阶去噪模块（对每阶进行针对性去噪），并改进GNN聚合机制避免交叉阶信号干扰。

Result: 在三个真实数据集上的实验表明，DRCSD对不稳定交互具有优越鲁棒性，在推荐准确性指标上相比最先进基线模型获得显著性能提升。

Conclusion: DRCSD通过解耦协作信号和分阶去噪，有效提升了推荐系统对噪声交互的鲁棒性和推荐准确性。

Abstract: Although the collaborative filtering (CF) algorithm has achieved remarkable
performance in recommendation systems, it suffers from suboptimal
recommendation performance due to noise in the user-item interaction matrix.
Numerous noise-removal studies have improved recommendation models, but most
existing approaches conduct denoising on a single graph. This may cause
attenuation of collaborative signals: removing edges between two nodes can
interrupt paths between other nodes, weakening path-dependent collaborative
information. To address these limitations, this study proposes a novel
GNN-based CF model called DRCSD for denoising unstable interactions. DRCSD
includes two core modules: a collaborative signal decoupling module (decomposes
signals into distinct orders by structural characteristics) and an order-wise
denoising module (performs targeted denoising on each order). Additionally, the
information aggregation mechanism of traditional GNN-based CF models is
modified to avoid cross-order signal interference until the final pooling
operation. Extensive experiments on three public real-world datasets show that
DRCSD has superior robustness against unstable interactions and achieves
statistically significant performance improvements in recommendation accuracy
metrics compared to state-of-the-art baseline models.

</details>


### [6] [LLM-as-a-Judge: Toward World Models for Slate Recommendation Systems](https://arxiv.org/abs/2511.04541)
*Baptiste Bonin,Maxime Heuillet,Audrey Durand*

Main category: cs.IR

TL;DR: 本文研究了大型语言模型如何通过slate推荐中的成对推理来建模用户跨域偏好，发现LLM在推荐系统中作为世界模型的潜力。


<details>
  <summary>Details</summary>
Motivation: 在slate推荐（推荐有序项目序列）中，建模用户跨域偏好仍然是一个关键挑战，需要探索LLM如何有效作为用户偏好的世界模型。

Method: 在三个不同数据集上对多个LLM进行实证研究，通过成对推理分析slate中的偏好函数特性。

Result: 研究结果揭示了任务性能与LLM捕获的偏好函数特性之间的关系，指出了改进方向。

Conclusion: LLM在推荐系统中作为世界模型具有潜力，研究为改进LLM在推荐任务中的应用提供了方向。

Abstract: Modeling user preferences across domains remains a key challenge in slate
recommendation (i.e. recommending an ordered sequence of items) research. We
investigate how Large Language Models (LLM) can effectively act as world models
of user preferences through pairwise reasoning over slates. We conduct an
empirical study involving several LLMs on three tasks spanning different
datasets. Our results reveal relationships between task performance and
properties of the preference function captured by LLMs, hinting towards areas
for improvement and highlighting the potential of LLMs as world models in
recommender systems.

</details>
