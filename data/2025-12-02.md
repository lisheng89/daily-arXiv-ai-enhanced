<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 9]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Selecting User Histories to Generate LLM Users for Cold-Start Item Recommendation](https://arxiv.org/abs/2511.21989)
*Nachiket Subbaraman,Jaskinder Sarai,Aniruddh Nath,Lichan Hong,Lukasz Heldt,Li Wei,Zhe Zhao*

Main category: cs.IR

TL;DR: 提出基于强化学习的用户选择框架，利用LLM模拟用户生成冷启动物品交互数据，优化传统推荐系统性能


<details>
  <summary>Details</summary>
Motivation: 现有方法使用LLM生成冷启动物品的增强数据时，仅使用部分用户历史且随机选择用户，无法充分发挥LLM模拟用户的能力，也不是最优的数据增强策略

Method: 将LLM作为用户模拟器，开发强化学习框架训练策略模型，基于用户行为特征和历史选择最适合的用户进行数据增强，使用策略梯度方法优化策略以获得更好的冷启动物品性能

Result: 在Amazon产品评论数据集上的实验显示，该方法在冷启动物品召回率方面取得显著提升，证明了其作为可扩展、服务高效的数据增强策略的有效性

Conclusion: 提出的强化学习用户选择框架能够优化LLM在推荐系统冷启动问题中的应用，通过智能选择用户进行数据增强，显著提升冷启动物品的推荐性能

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in reasoning, generalization, and simulating human-like behavior across a wide range of tasks. These strengths present new opportunities to enhance traditional recommendation systems (RS), especially in the cold-start item scenario where newly introduced items lack interactions. Existing works have used LLMs to address cold-start issues in traditional RS through data augmentation, but they have limitations. One recent work directly addresses this issue by prompting LLMs to generate augmented interaction data between randomly sampled users and cold-start items. Then, they train the traditional RS with augmented data, incorporating collaborative signals for cold-start items. Although they use LLMs to provide cold-start items with feedback, they use partial user histories, which does not allow the LLM to fully emulate the user. Furthermore, randomly selecting users is not optimal for augmentation. To address these challenges, we leverage the LLM as a user and develop a reinforcement learning (RL) framework that trains a policy to select users for augmentation, optimizing for cold-start item performance after augmented training. The policy model learns to select users for cold-start item data augmentation based on their behavioral features and histories. To optimize user selection for cold-start item performance, we employ a policy gradient method that updates the policy in the direction of actions that lead to high rewards. Experiments on Amazon Product Review datasets show substantial gains in cold-start item recall, demonstrating the effectiveness of our method as a scalable, serving-efficient augmentation strategy for modern RS.

</details>


### [2] [Evaluating Embedding Models and Pipeline Optimization for AI Search Quality](https://arxiv.org/abs/2511.22240)
*Philip Zhong,Kent Chen,Don Wang*

Main category: cs.IR

TL;DR: 评估不同文本嵌入模型和配置对AI搜索系统性能的影响，发现高维嵌入、神经重排器和细粒度分块能显著提升检索准确率。


<details>
  <summary>Details</summary>
Motivation: 评估不同文本嵌入模型和管道配置在AI驱动搜索系统中的性能，为实际应用提供最佳实践指导。

Method: 使用本地LLM从美国市议会会议记录合成11,975个查询-分块对数据集，比较不同嵌入模型（All-MPNet、BGE、GTE、Qwen）、维度、索引方法（Milvus HNSW/IVF）和分块策略，采用Top-K准确率和NDCG指标评估检索性能。

Result: 高维嵌入显著提升搜索质量（如Qwen3-Embedding-8B/4096的Top-3准确率约0.571 vs GTE-large/1024的0.412），神经重排器（如BGE交叉编码器）进一步提升排序准确率（Top-3达0.527），细粒度分块（512字符vs2000字符）也提高准确率。

Conclusion: 嵌入维度、重排模型和分块粒度是影响AI搜索系统性能的关键因素，未来需要进一步自动化管道和评估流程。

Abstract: We evaluate the performance of various text embedding models and pipeline configurations for AI-driven search systems. We compare sentence-transformer and generative embedding models (e.g., All-MPNet, BGE, GTE, and Qwen) at different dimensions, indexing methods (Milvus HNSW/IVF), and chunking strategies. A custom evaluation dataset of 11,975 query-chunk pairs was synthesized from US City Council meeting transcripts using a local large language model (LLM). The data pipeline includes preprocessing, automated question generation per chunk, manual validation, and continuous integration/continuous deployment (CI/CD) integration. We measure retrieval accuracy using reference-based metrics: Top-K Accuracy and Normalized Discounted Cumulative Gain (NDCG). Our results demonstrate that higher-dimensional embeddings significantly boost search quality (e.g., Qwen3-Embedding-8B/4096 achieves Top-3 accuracy about 0.571 versus 0.412 for GTE-large/1024), and that neural re-rankers (e.g., a BGE cross-encoder) further improve ranking accuracy (Top-3 up to 0.527). Finer-grained chunking (512 characters versus 2000 characters) also improves accuracy. We discuss the impact of these factors and outline future directions for pipeline automation and evaluation.

</details>


### [3] [FIGROTD: A Friendly-to-Handle Dataset for Image Guided Retrieval with Optional Text](https://arxiv.org/abs/2511.22247)
*Hoang-Bao Le,Allie Tran,Binh T. Nguyen,Liting Zhou,Cathal Gurrin*

Main category: cs.IR

TL;DR: IGROT统一了视觉检索和组合检索，但缺乏可访问的基准和平衡性能的方法。作者提出了轻量级高质量数据集FIGROTD和方差引导特征掩码VaGFeM，结合双损失设计，在多个基准上取得竞争性结果。


<details>
  <summary>Details</summary>
Motivation: IGROT（图像引导检索与可选文本）统一了视觉检索和组合检索，在Google Image和Bing等应用中很重要，但进展受限：缺乏可访问的基准，现有方法在视觉和组合查询之间性能不平衡，大规模数据集计算成本高。

Method: 1) 提出轻量级高质量数据集FIGROTD，包含16,474个训练三元组和1,262个测试三元组，涵盖CIR、SBIR和CSTBIR任务；2) 提出方差引导特征掩码(VaGFeM)，基于方差统计选择性增强判别性维度；3) 采用双损失设计(InfoNCE + Triplet)改善组合推理。

Result: 在FIGROTD上训练的VaGFeM在九个基准上取得竞争性结果：CIRCO上达到34.8 mAP@10，Sketchy上达到75.7 mAP@200，尽管使用更少的三元组，仍优于更强的基线。

Conclusion: 提出的FIGROTD数据集和VaGFeM方法有效解决了IGROT领域的基准和方法问题，在轻量级设置下实现了平衡且竞争性的性能，为图像引导检索与可选文本任务提供了实用解决方案。

Abstract: Image-Guided Retrieval with Optional Text (IGROT) unifies visual retrieval (without text) and composed retrieval (with text). Despite its relevance in applications like Google Image and Bing, progress has been limited by the lack of an accessible benchmark and methods that balance performance across subtasks. Large-scale datasets such as MagicLens are comprehensive but computationally prohibitive, while existing models often favor either visual or compositional queries. We introduce FIGROTD, a lightweight yet high-quality IGROT dataset with 16,474 training triplets and 1,262 test triplets across CIR, SBIR, and CSTBIR. To reduce redundancy, we propose the Variance Guided Feature Mask (VaGFeM), which selectively enhances discriminative dimensions based on variance statistics. We further adopt a dual-loss design (InfoNCE + Triplet) to improve compositional reasoning. Trained on FIGROTD, VaGFeM achieves competitive results on nine benchmarks, reaching 34.8 mAP@10 on CIRCO and 75.7 mAP@200 on Sketchy, outperforming stronger baselines despite fewer triplets.

</details>


### [4] [UNION: A Lightweight Target Representation for Efficient Zero-Shot Image-Guided Retrieval with Optional Textual Queries](https://arxiv.org/abs/2511.22253)
*Hoang-Bao Le,Allie Tran,Binh T. Nguyen,Liting Zhou,Cathal Gurrin*

Main category: cs.IR

TL;DR: UNION方法通过融合图像嵌入和空文本提示，在少量数据（5000样本）下实现图像引导检索，在CIR和SBIR任务上取得竞争性结果


<details>
  <summary>Details</summary>
Motivation: 解决IGROT（图像引导检索）在低数据监督下的挑战，统一CIR（组合图像检索）和SBIR（草图图像检索）两个主要任务，减少对大量标注数据的依赖

Method: 提出轻量级可泛化的目标表示UNION，将图像嵌入与空文本提示融合，无需修改预训练视觉语言模型架构，仅需少量训练样本

Result: 在CIRCO数据集上mAP@50达到38.5，Sketchy数据集上mAP@200达到82.7，超越许多需要大量监督的基线方法

Conclusion: UNION方法展示了在少量数据下通过融合视觉和语言信息实现跨模态检索的鲁棒性和效率，为图像引导检索提供了有效的低数据解决方案

Abstract: Image-Guided Retrieval with Optional Text (IGROT) is a general retrieval setting where a query consists of an anchor image, with or without accompanying text, aiming to retrieve semantically relevant target images. This formulation unifies two major tasks: Composed Image Retrieval (CIR) and Sketch-Based Image Retrieval (SBIR). In this work, we address IGROT under low-data supervision by introducing UNION, a lightweight and generalisable target representation that fuses the image embedding with a null-text prompt. Unlike traditional approaches that rely on fixed target features, UNION enhances semantic alignment with multimodal queries while requiring no architectural modifications to pretrained vision-language models. With only 5,000 training samples - from LlavaSCo for CIR and Training-Sketchy for SBIR - our method achieves competitive results across benchmarks, including CIRCO mAP@50 of 38.5 and Sketchy mAP@200 of 82.7, surpassing many heavily supervised baselines. This demonstrates the robustness and efficiency of UNION in bridging vision and language across diverse query types.

</details>


### [5] [Efficiency and Effectiveness of SPLADE Models on Billion-Scale Web Document Title](https://arxiv.org/abs/2511.22263)
*Taeryun Won,Tae Kwan Lee,Hiun Kim,Hyemin Lee*

Main category: cs.IR

TL;DR: 本文系统比较了BM25、SPLADE和Expanded-SPLADE在大规模网页文档检索中的表现，发现稀疏表示模型性能更优但计算成本更高，通过剪枝策略优化后，Expanded-SPLADE在效果与效率间达到最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 在大规模网页文档检索场景中，需要评估不同检索模型（传统词频统计模型BM25与基于稀疏表示的SPLADE系列）在效果与效率上的表现，为实际搜索引擎部署提供指导。

Method: 1. 在千万到百亿级网页文档标题数据集上对比BM25、SPLADE和Expanded-SPLADE模型；2. 提出文档中心剪枝、top-k查询词选择、带词项阈值的布尔查询等策略来优化计算效率；3. 系统评估模型检索效果与计算成本。

Result: 1. SPLADE和Expanded-SPLADE在检索效果上优于BM25，特别是复杂查询；2. 稀疏表示模型计算成本更高；3. 剪枝策略能显著提升效率而不明显损失性能；4. Expanded-SPLADE在效果与效率间达到最佳平衡，尤其适合大规模数据集。

Conclusion: Expanded-SPLADE在大规模网页文档检索中实现了效果与效率的最佳平衡，通过适当的剪枝策略可进一步优化部署成本，为搜索引擎稀疏检索模型的实际应用提供了重要参考。

Abstract: This paper presents a comprehensive comparison of BM25, SPLADE, and Expanded-SPLADE models in the context of large-scale web document retrieval. We evaluate the effectiveness and efficiency of these models on datasets spanning from tens of millions to billions of web document titles. SPLADE and Expanded-SPLADE, which utilize sparse lexical representations, demonstrate superior retrieval performance compared to BM25, especially for complex queries. However, these models incur higher computational costs. We introduce pruning strategies, including document-centric pruning and top-k query term selection, boolean query with term threshold to mitigate these costs and improve the models' efficiency without significantly sacrificing retrieval performance. The results show that Expanded-SPLADE strikes the best balance between effectiveness and efficiency, particularly when handling large datasets. Our findings offer valuable insights for deploying sparse retrieval models in large-scale search engines.

</details>


### [6] [CoFiRec: Coarse-to-Fine Tokenization for Generative Recommendation](https://arxiv.org/abs/2511.22707)
*Tianxin Wei,Xuying Ning,Xuxing Chen,Ruizhong Qiu,Yupeng Hou,Yan Xie,Shuang Yang,Zhigang Hua,Jingrui He*

Main category: cs.IR

TL;DR: CoFiRec是一个生成式推荐框架，通过粗粒度到细粒度的语义层次化tokenization来建模用户意图的渐进演化过程，提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐模型将异构属性压缩为单一嵌入，忽略了物品语义的层次结构和用户意图在网页交互中的渐进演化过程。

Method: 提出CoFiRec框架，将物品信息分解为多个语义层次（从高层类别到详细描述），独立tokenize每个层次并保持结构顺序，在自回归解码时指导语言模型从粗到细生成物品token。

Result: 在多个公共基准测试和骨干网络上，CoFiRec优于现有方法，理论证明结构化tokenization能降低生成物品与真实物品之间的差异。

Conclusion: CoFiRec通过显式建模物品语义的粗粒度到细粒度层次结构，为生成式推荐提供了新视角，能更好地捕捉用户意图的渐进演化。

Abstract: In web environments, user preferences are often refined progressively as users move from browsing broad categories to exploring specific items. However, existing generative recommenders overlook this natural refinement process. Generative recommendation formulates next-item prediction as autoregressive generation over tokenized user histories, where each item is represented as a sequence of discrete tokens. Prior models typically fuse heterogeneous attributes such as ID, category, title, and description into a single embedding before quantization, which flattens the inherent semantic hierarchy of items and fails to capture the gradual evolution of user intent during web interactions. To address this limitation, we propose CoFiRec, a novel generative recommendation framework that explicitly incorporates the Coarse-to-Fine nature of item semantics into the tokenization process. Instead of compressing all attributes into a single latent space, CoFiRec decomposes item information into multiple semantic levels, ranging from high-level categories to detailed descriptions and collaborative filtering signals. Based on this design, we introduce the CoFiRec Tokenizer, which tokenizes each level independently while preserving structural order. During autoregressive decoding, the language model is instructed to generate item tokens from coarse to fine, progressively modeling user intent from general interests to specific item-level interests. Experiments across multiple public benchmarks and backbones demonstrate that CoFiRec outperforms existing methods, offering a new perspective for generative recommendation. Theoretically, we prove that structured tokenization leads to lower dissimilarity between generated and ground truth items, supporting its effectiveness in generative recommendation. Our code is available at https://github.com/YennNing/CoFiRec.

</details>


### [7] [Two-Stage Distributionally Robust Optimization Framework for Secure Communications in Aerial-RIS Systems](https://arxiv.org/abs/2511.22855)
*Zhongming Feng,Qiling Gao,Zeping Sui,Yun Lin,Michail Matthaiou*

Main category: cs.IR

TL;DR: 提出一个两阶段分布鲁棒优化框架，用于空中可重构智能表面辅助毫米波系统的安全部署和波束成形，以应对多时间尺度不确定性。


<details>
  <summary>Details</summary>
Motivation: 空中可重构智能表面辅助毫米波系统面临用户移动性、不完美信道状态信息和硬件损伤等多时间尺度不确定性，需要一种鲁棒的安全部署和波束成形方案。

Method: 采用两阶段分布鲁棒优化框架，将长期无人机部署与每时隙波束成形设计解耦，使用条件风险价值作为分布无关风险度量，结合代理模型和交替优化方案。

Result: 仿真结果表明，所提出的DRO-CVaR框架显著提升了尾部保密频谱效率，并保持较低的中断概率，尤其在严重不确定性条件下优于基准方案。

Conclusion: 该两阶段分布鲁棒优化框架为空中可重构智能表面辅助毫米波系统提供了一种有效的鲁棒安全部署和波束成形解决方案，能够应对多时间尺度不确定性挑战。

Abstract: This letter proposes a two-stage distributionally robust optimization (DRO) framework for secure deployment and beamforming in an aerial reconfigurable intelligent surface (A-RIS) assisted millimeter-wave system. To account for multi-timescale uncertainties arising from user mobility, imperfect channel state information (CSI), and hardware impairments, our approach decouples the long-term unmanned aerial vehicle (UAV) placement from the per-slot beamforming design. By employing the conditional value-at-risk (CVaR) as a distribution-free risk metric, a low-complexity algorithm is developed, which combines a surrogate model for efficient deployment with an alternating optimization (AO) scheme for robust real-time beamforming. Simulation results validate that the proposed DRO-CVaR framework significantly enhances the tail-end secrecy spectral efficiency and maintains a lower outage probability compared to benchmark schemes, especially under severe uncertainty conditions.

</details>


### [8] [FedAU2: Attribute Unlearning for User-Level Federated Recommender Systems with Adaptive and Robust Adversarial Training](https://arxiv.org/abs/2511.22872)
*Yuyuan Li,Junjie Fang,Fengyuan Yu,Xichun Sheng,Tianyu Du,Xuyang Teng,Shaowei Jiang,Linbo Jiang,Jianan Lin,Chaochao Chen*

Main category: cs.IR

TL;DR: FedAU2：针对用户级联邦推荐系统的属性遗忘方法，通过自适应对抗训练和双随机变分自编码器解决训练不稳定性和梯度信息泄露问题


<details>
  <summary>Details</summary>
Motivation: 联邦推荐系统虽然保护用户隐私，但用户嵌入中仍包含敏感属性信息，易受属性推断攻击。用户级联邦推荐系统比组级更实用但更具挑战性，需要有效的属性遗忘方法

Method: 提出FedAU2方法：1）自适应对抗训练策略，根据本地优化行为调整训练动态；2）双随机变分自编码器扰动对抗模型，防止梯度信息泄露

Result: 在三个真实世界数据集上的实验表明，FedAU2在遗忘效果和推荐性能方面优于现有基线方法

Conclusion: FedAU2有效解决了用户级联邦推荐系统中的属性遗忘问题，平衡了隐私保护和推荐性能

Abstract: Federated Recommender Systems (FedRecs) leverage federated learning to protect user privacy by retaining data locally. However, user embeddings in FedRecs often encode sensitive attribute information, rendering them vulnerable to attribute inference attacks. Attribute unlearning has emerged as a promising approach to mitigate this issue. In this paper, we focus on user-level FedRecs, which is a more practical yet challenging setting compared to group-level FedRecs. Adversarial training emerges as the most feasible approach within this context. We identify two key challenges in implementing adversarial training-based attribute unlearning for user-level FedRecs: i) mitigating training instability caused by user data heterogeneity, and ii) preventing attribute information leakage through gradients. To address these challenges, we propose FedAU2, an attribute unlearning method for user-level FedRecs. For CH1, we propose an adaptive adversarial training strategy, where the training dynamics are adjusted in response to local optimization behavior. For CH2, we propose a dual-stochastic variational autoencoder to perturb the adversarial model, effectively preventing gradient-based information leakage. Extensive experiments on three real-world datasets demonstrate that our proposed FedAU2 achieves superior performance in unlearning effectiveness and recommendation performance compared to existing baselines.

</details>


### [9] [Do LLM-judges Align with Human Relevance in Cranfield-style Recommender Evaluation?](https://arxiv.org/abs/2511.23312)
*Gustavo Penha,Aleksandr V. Petrov,Claudia Hauff,Enrico Palumbo,Ali Vardasbi,Edoardo D'Amico,Francesco Fabbri,Alice Wang,Praveen Chandar,Henrik Lindstrom,Hugues Bouchard,Mounia Lalmas*

Main category: cs.IR

TL;DR: LLM可以作为推荐系统的可靠自动评估工具，替代传统人工标注，解决可扩展性问题


<details>
  <summary>Details</summary>
Motivation: 推荐系统评估面临挑战：离线方法存在曝光偏差、流行度偏差等问题，而Cranfield风格测试集合构建成本高、难以扩展。需要寻找可扩展的自动评估方法。

Method: 使用ML-32M-ext电影推荐数据集，研究LLM作为自动评估者的可行性。分析现有评估方法的局限性，探索LLM评估与人工标注的一致性，并在播客推荐领域进行工业案例研究。

Result: LLM评估与人工标注的排名一致性高（Kendall's tau = 0.87）。丰富的项目元数据和更长的用户历史记录能提高对齐度。工业案例证明LLM评估可用于模型选择。

Conclusion: LLM评估是推荐系统评估的可行且可扩展的方法，能够替代传统人工标注，解决评估的可扩展性挑战。

Abstract: Evaluating recommender systems remains a long-standing challenge, as offline methods based on historical user interactions and train-test splits often yield unstable and inconsistent results due to exposure bias, popularity bias, sampled evaluations, and missing-not-at-random patterns. In contrast, textual document retrieval benefits from robust, standardized evaluation via Cranfield-style test collections, which combine pooled relevance judgments with controlled setups. While recent work shows that adapting this methodology to recommender systems is feasible, constructing such collections remains costly due to the need for manual relevance judgments, thus limiting scalability. This paper investigates whether Large Language Models (LLMs) can serve as reliable automatic judges to address these scalability challenges. Using the ML-32M-ext Cranfield-style movie recommendation collection, we first examine the limitations of existing evaluation methodologies. Then we explore the alignment and the recommender systems ranking agreement between the LLM-judge and human provided relevance labels. We find that incorporating richer item metadata and longer user histories improves alignment, and that LLM-judge yields high agreement with human-based rankings (Kendall's tau = 0.87). Finally, an industrial case study in the podcast recommendation domain demonstrates the practical value of LLM-judge for model selection. Overall, our results show that LLM-judge is a viable and scalable approach for evaluating recommender systems.

</details>
