<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 2]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Q-BERT4Rec: Quantized Semantic-ID Representation Learning for Multimodal Recommendation](https://arxiv.org/abs/2512.02474)
*Haofeng Huang,Ling Gai*

Main category: cs.IR

TL;DR: Q-Bert4Rec是一个多模态序列推荐框架，通过语义量化和跨模态注入提升推荐性能，在Amazon基准上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer推荐方法（如BERT4Rec）依赖离散物品ID，缺乏语义信息且忽略多模态特征（文本、图像），导致泛化能力弱和可解释性差。

Method: 三阶段框架：1)跨模态语义注入，通过动态Transformer融合文本、视觉和结构特征；2)语义量化，通过残差向量量化将融合表示离散化为有意义的token；3)多掩码预训练和微调，使用span、tail和多区域掩码策略。

Result: 在公开Amazon基准测试中，Q-Bert4Rec显著优于许多现有强方法，验证了语义量化对多模态序列推荐的有效性。

Conclusion: Q-Bert4Rec通过统一语义表示和量化建模，解决了传统基于ID方法的局限性，为多模态序列推荐提供了更有效的解决方案。

Abstract: Sequential recommendation plays a critical role in modern online platforms such as e-commerce, advertising, and content streaming, where accurately predicting users' next interactions is essential for personalization. Recent Transformer-based methods like BERT4Rec have shown strong modeling capability, yet they still rely on discrete item IDs that lack semantic meaning and ignore rich multimodal information (e.g., text and image). This leads to weak generalization and limited interpretability. To address these challenges, we propose Q-Bert4Rec, a multimodal sequential recommendation framework that unifies semantic representation and quantized modeling. Specifically, Q-Bert4Rec consists of three stages: (1) cross-modal semantic injection, which enriches randomly initialized ID embeddings through a dynamic transformer that fuses textual, visual, and structural features; (2) semantic quantization, which discretizes fused representations into meaningful tokens via residual vector quantization; and (3) multi-mask pretraining and fine-tuning, which leverage diverse masking strategies -- span, tail, and multi-region -- to improve sequential understanding. We validate our model on public Amazon benchmarks and demonstrate that Q-Bert4Rec significantly outperforms many strong existing methods, confirming the effectiveness of semantic tokenization for multimodal sequential recommendation. Our source code will be publicly available on GitHub after publishing.

</details>


### [2] [AskNearby: An LLM-Based Application for Neighborhood Information Retrieval and Personalized Cognitive-Map Recommendations](https://arxiv.org/abs/2512.02502)
*Luyao Niu,Zhicheng Deng,Boyang Li,Nuoxian Huang,Ruiqi Liu,Wenjia Zhang*

Main category: cs.IR

TL;DR: AskNearby是一个AI驱动的社区应用，通过三层RAG管道和认知地图模型解决15分钟生活圈内的本地生活信息可及性问题，显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 15分钟城市愿景不仅需要物理接近性，还需要高效可靠地获取附近场所、服务和活动的信息。现有基于位置的系统主要关注城市级任务，忽视了影响本地化决策的空间、时间和认知因素，存在本地生活信息可及性(LLIA)问题。

Method: 提出AskNearby应用，整合：(1)三层检索增强生成(RAG)管道，结合基于图、语义向量和地理检索；(2)认知地图模型，编码每个用户对社区的熟悉度和偏好。

Result: 在真实社区数据集上的实验表明，AskNearby在检索准确性和推荐质量上显著优于基于LLM和基于地图的基线，在时空基础和认知感知排序方面表现出稳健性能。实际部署进一步验证了其有效性。

Conclusion: 通过解决LLIA挑战，AskNearby赋能居民更有效地发现本地资源、规划日常活动和参与社区生活，推动了15分钟城市愿景的实现。

Abstract: The "15-minute city" envisions neighborhoods where residents can meet daily needs via a short walk or bike ride. Realizing this vision requires not only physical proximity but also efficient and reliable access to information about nearby places, services, and events. Existing location-based systems, however, focus mainly on city-level tasks and neglect the spatial, temporal, and cognitive factors that shape localized decision-making. We conceptualize this gap as the Local Life Information Accessibility (LLIA) problem and introduce AskNearby, an AI-driven community application that unifies retrieval and recommendation within the 15-minute life circle. AskNearby integrates (i) a three-layer Retrieval-Augmented Generation (RAG) pipeline that synergizes graph-based, semantic-vector, and geographic retrieval with (ii) a cognitive-map model that encodes each user's neighborhood familiarity and preferences. Experiments on real-world community datasets demonstrate that AskNearby significantly outperforms LLM-based and map-based baselines in retrieval accuracy and recommendation quality, achieving robust performance in spatiotemporal grounding and cognitive-aware ranking. Real-world deployments further validate its effectiveness. By addressing the LLIA challenge, AskNearby empowers residents to more effectively discover local resources, plan daily activities, and engage in community life.

</details>
