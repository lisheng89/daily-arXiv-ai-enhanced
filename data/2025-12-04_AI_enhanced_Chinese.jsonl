{"id": "2512.03413", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03413", "abs": "https://arxiv.org/abs/2512.03413", "authors": ["Shu Wang", "Yingli Zhou", "Yixiang Fang"], "title": "BookRAG: A Hierarchical Structure-aware Index-based Approach for Retrieval-Augmented Generation on Complex Documents", "comment": null, "summary": "As an effective method to boost the performance of Large Language Models (LLMs) on the question answering (QA) task, Retrieval-Augmented Generation (RAG), which queries highly relevant information from external complex documents, has attracted tremendous attention from both industry and academia. Existing RAG approaches often focus on general documents, and they overlook the fact that many real-world documents (such as books, booklets, handbooks, etc.) have a hierarchical structure, which organizes their content from different granularity levels, leading to poor performance for the QA task. To address these limitations, we introduce BookRAG, a novel RAG approach targeted for documents with a hierarchical structure, which exploits logical hierarchies and traces entity relations to query the highly relevant information. Specifically, we build a novel index structure, called BookIndex, by extracting a hierarchical tree from the document, which serves as the role of its table of contents, using a graph to capture the intricate relationships between entities, and mapping entities to tree nodes. Leveraging the BookIndex, we then propose an agent-based query method inspired by the Information Foraging Theory, which dynamically classifies queries and employs a tailored retrieval workflow. Extensive experiments on three widely adopted benchmarks demonstrate that BookRAG achieves state-of-the-art performance, significantly outperforming baselines in both retrieval recall and QA accuracy while maintaining competitive efficiency.", "AI": {"tldr": "BookRAG\uff1a\u9488\u5bf9\u5177\u6709\u5c42\u6b21\u7ed3\u6784\u7684\u6587\u6863\uff08\u5982\u4e66\u7c4d\u3001\u624b\u518c\u7b49\uff09\u63d0\u51fa\u7684\u65b0\u578b\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u5c42\u6b21\u5316\u7d22\u5f15\u548c\u5b9e\u4f53\u5173\u7cfb\u56fe\u6765\u63d0\u5347\u95ee\u7b54\u6027\u80fd\u3002", "motivation": "\u73b0\u6709RAG\u65b9\u6cd5\u901a\u5e38\u5904\u7406\u4e00\u822c\u6587\u6863\uff0c\u5ffd\u7565\u4e86\u73b0\u5b9e\u4e16\u754c\u4e2d\u8bb8\u591a\u6587\u6863\uff08\u5982\u4e66\u7c4d\u3001\u624b\u518c\u7b49\uff09\u5177\u6709\u5c42\u6b21\u7ed3\u6784\u7684\u7279\u70b9\uff0c\u5bfc\u81f4\u5728\u95ee\u7b54\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "method": "1. \u6784\u5efaBookIndex\uff1a\u4ece\u6587\u6863\u4e2d\u63d0\u53d6\u5c42\u6b21\u6811\uff08\u4f5c\u4e3a\u76ee\u5f55\uff09\uff0c\u7528\u56fe\u6355\u6349\u5b9e\u4f53\u95f4\u590d\u6742\u5173\u7cfb\uff0c\u5e76\u5c06\u5b9e\u4f53\u6620\u5c04\u5230\u6811\u8282\u70b9\uff1b2. \u57fa\u4e8e\u4fe1\u606f\u89c5\u98df\u7406\u8bba\u7684\u667a\u80fd\u4f53\u67e5\u8be2\u65b9\u6cd5\uff1a\u52a8\u6001\u5206\u7c7b\u67e5\u8be2\u5e76\u91c7\u7528\u5b9a\u5236\u5316\u7684\u68c0\u7d22\u5de5\u4f5c\u6d41\u3002", "result": "\u5728\u4e09\u4e2a\u5e7f\u6cdb\u91c7\u7528\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cBookRAG\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5728\u68c0\u7d22\u53ec\u56de\u7387\u548c\u95ee\u7b54\u51c6\u786e\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u6027\u7684\u6548\u7387\u3002", "conclusion": "BookRAG\u662f\u9488\u5bf9\u5c42\u6b21\u7ed3\u6784\u6587\u6863\u7684\u6709\u6548RAG\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u903b\u8f91\u5c42\u6b21\u548c\u5b9e\u4f53\u5173\u7cfb\u663e\u8457\u63d0\u5347\u4e86\u95ee\u7b54\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2512.03439", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.03439", "abs": "https://arxiv.org/abs/2512.03439", "authors": ["Yaqi Wang", "Haojia Sun", "Shuting Zhang"], "title": "LLM as Explainable Re-Ranker for Recommendation System", "comment": null, "summary": "The application of large language models (LLMs) in recommendation systems has recently gained traction. Traditional recommendation systems often lack explainability and suffer from issues such as popularity bias. Previous research has also indicated that LLMs, when used as standalone predictors, fail to achieve accuracy comparable to traditional models. To address these challenges, we propose to use LLM as an explainable re-ranker, a hybrid approach that combines traditional recommendation models with LLMs to enhance both accuracy and interpretability. We constructed a dataset to train the re-ranker LLM and evaluated the alignment between the generated dataset and human expectations. Leveraging a two-stage training process, our model significantly improved NDCG, a key ranking metric. Moreover, the re-ranker outperformed a zero-shot baseline in ranking accuracy and interpretability. These results highlight the potential of integrating traditional recommendation models with LLMs to address limitations in existing systems and pave the way for more explainable and fair recommendation frameworks.", "AI": {"tldr": "\u4f7f\u7528LLM\u4f5c\u4e3a\u53ef\u89e3\u91ca\u7684\u91cd\u6392\u5e8f\u5668\uff0c\u7ed3\u5408\u4f20\u7edf\u63a8\u8350\u6a21\u578b\u63d0\u5347\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027", "motivation": "\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u4e14\u5b58\u5728\u6d41\u884c\u5ea6\u504f\u5dee\u95ee\u9898\uff0c\u800cLLM\u4f5c\u4e3a\u72ec\u7acb\u9884\u6d4b\u5668\u65e0\u6cd5\u8fbe\u5230\u4f20\u7edf\u6a21\u578b\u7684\u51c6\u786e\u6027", "method": "\u63d0\u51fa\u6df7\u5408\u65b9\u6cd5\uff1a\u4f7f\u7528LLM\u4f5c\u4e3a\u53ef\u89e3\u91ca\u7684\u91cd\u6392\u5e8f\u5668\uff0c\u7ed3\u5408\u4f20\u7edf\u63a8\u8350\u6a21\u578b\uff1b\u6784\u5efa\u6570\u636e\u96c6\u8bad\u7ec3\u91cd\u6392\u5e8fLLM\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u8fc7\u7a0b", "result": "\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86NDCG\u6392\u540d\u6307\u6807\uff0c\u91cd\u6392\u5e8f\u5668\u5728\u6392\u540d\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u4e0a\u5747\u4f18\u4e8e\u96f6\u6837\u672c\u57fa\u7ebf", "conclusion": "\u7ed3\u5408\u4f20\u7edf\u63a8\u8350\u6a21\u578b\u4e0eLLM\u80fd\u591f\u89e3\u51b3\u73b0\u6709\u7cfb\u7edf\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u66f4\u53ef\u89e3\u91ca\u548c\u516c\u5e73\u7684\u63a8\u8350\u6846\u67b6\u94fa\u5e73\u9053\u8def"}}
{"id": "2512.03514", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.03514", "abs": "https://arxiv.org/abs/2512.03514", "authors": ["Adithya S Kolavi", "Vyoman Jain"], "title": "M3DR: Towards Universal Multilingual Multimodal Document Retrieval", "comment": null, "summary": "Multimodal document retrieval systems have shown strong progress in aligning visual and textual content for semantic search. However, most existing approaches remain heavily English-centric, limiting their effectiveness in multilingual contexts. In this work, we present M3DR (Multilingual Multimodal Document Retrieval), a framework designed to bridge this gap across languages, enabling applicability across diverse linguistic and cultural contexts. M3DR leverages synthetic multilingual document data and generalizes across different vision-language architectures and model sizes, enabling robust cross-lingual and cross-modal alignment. Using contrastive training, our models learn unified representations for text and document images that transfer effectively across languages. We validate this capability on 22 typologically diverse languages, demonstrating consistent performance and adaptability across linguistic and script variations. We further introduce a comprehensive benchmark that captures real-world multilingual scenarios, evaluating models under monolingual, multilingual, and mixed-language settings. M3DR generalizes across both single dense vector and ColBERT-style token-level multi-vector retrieval paradigms. Our models, NetraEmbed and ColNetraEmbed achieve state-of-the-art performance with ~150% relative improvements on cross-lingual retrieval.", "AI": {"tldr": "M3DR\u662f\u4e00\u4e2a\u591a\u8bed\u8a00\u591a\u6a21\u6001\u6587\u6863\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u5408\u6210\u591a\u8bed\u8a00\u6570\u636e\u548c\u5bf9\u6bd4\u8bad\u7ec3\uff0c\u572822\u79cd\u8bed\u8a00\u4e0a\u5b9e\u73b0\u4e86\u8de8\u8bed\u8a00\u548c\u8de8\u6a21\u6001\u5bf9\u9f50\uff0c\u6027\u80fd\u63d0\u5347\u7ea6150%\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u6587\u6863\u68c0\u7d22\u7cfb\u7edf\u4e3b\u8981\u9488\u5bf9\u82f1\u8bed\uff0c\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u8bed\u8a00\u548c\u6587\u5316\u80cc\u666f\u7684\u6846\u67b6\u3002", "method": "\u5229\u7528\u5408\u6210\u591a\u8bed\u8a00\u6587\u6863\u6570\u636e\uff0c\u91c7\u7528\u5bf9\u6bd4\u8bad\u7ec3\u5b66\u4e60\u6587\u672c\u548c\u6587\u6863\u56fe\u50cf\u7684\u7edf\u4e00\u8868\u793a\uff0c\u652f\u6301\u4e0d\u540c\u89c6\u89c9-\u8bed\u8a00\u67b6\u6784\u548c\u6a21\u578b\u5927\u5c0f\uff0c\u6db5\u76d6\u5bc6\u96c6\u5411\u91cf\u548cColBERT\u5f0f\u591a\u5411\u91cf\u68c0\u7d22\u8303\u5f0f\u3002", "result": "\u572822\u79cd\u7c7b\u578b\u591a\u6837\u7684\u8bed\u8a00\u4e0a\u9a8c\u8bc1\u4e86\u6027\u80fd\uff0cNetraEmbed\u548cColNetraEmbed\u6a21\u578b\u5728\u8de8\u8bed\u8a00\u68c0\u7d22\u4e0a\u5b9e\u73b0\u4e86\u7ea6150%\u7684\u76f8\u5bf9\u6539\u8fdb\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "M3DR\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u591a\u8bed\u8a00\u591a\u6a21\u6001\u6587\u6863\u68c0\u7d22\u7684\u6311\u6218\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u8bed\u8a00\u548c\u6587\u5b57\u53d8\u4f53\uff0c\u4e3a\u5b9e\u9645\u591a\u8bed\u8a00\u573a\u666f\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.03807", "categories": ["cs.IR", "eess.SP", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.03807", "abs": "https://arxiv.org/abs/2512.03807", "authors": ["Christos Kolomvakis", "Thomas Bobille", "Arnaud Vandaele", "Nicolas Gillis"], "title": "Algorithms for Boolean Matrix Factorization using Integer Programming and Heuristics", "comment": "24 pages, 12 tables, 3 figures, code and data available from https://gitlab.com/ckolomvakis/boolean-matrix-factorization-ip-and-heuristics", "summary": "Boolean matrix factorization (BMF) approximates a given binary input matrix as the product of two smaller binary factors. Unlike binary matrix factorization based on standard arithmetic, BMF employs the Boolean OR and AND operations for the matrix product, which improves interpretability and reduces the approximation error. It is also used in role mining and computer vision. In this paper, we first propose algorithms for BMF that perform alternating optimization (AO) of the factor matrices, where each subproblem is solved via integer programming (IP). We then design different approaches to further enhance AO-based algorithms by selecting an optimal subset of rank-one factors from multiple runs. To address the scalability limits of IP-based methods, we introduce new greedy and local-search heuristics. We also construct a new C++ data structure for Boolean vectors and matrices that is significantly faster than existing ones and is of independent interest, allowing our heuristics to scale to large datasets. We illustrate the performance of all our proposed methods and compare them with the state of the art on various real datasets, both with and without missing data, including applications in topic modeling and imaging.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e03\u5c14\u77e9\u9635\u5206\u89e3(BMF)\u7684\u65b0\u7b97\u6cd5\uff0c\u5305\u62ec\u4ea4\u66ff\u4f18\u5316\u3001\u6574\u6570\u89c4\u5212\u3001\u8d2a\u5fc3\u548c\u5c40\u90e8\u641c\u7d22\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u4ee5\u53ca\u9ad8\u6548\u7684C++\u6570\u636e\u7ed3\u6784\uff0c\u663e\u8457\u63d0\u5347\u4e86BMF\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u5e03\u5c14\u77e9\u9635\u5206\u89e3(BMF)\u4f7f\u7528\u5e03\u5c14OR\u548cAND\u8fd0\u7b97\u8fdb\u884c\u77e9\u9635\u5206\u89e3\uff0c\u76f8\u6bd4\u57fa\u4e8e\u6807\u51c6\u7b97\u672f\u7684\u4e8c\u8fdb\u5236\u77e9\u9635\u5206\u89e3\uff0c\u80fd\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u5e76\u51cf\u5c11\u8fd1\u4f3c\u8bef\u5dee\u3002\u7136\u800c\u73b0\u6709\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5b58\u5728\u9650\u5236\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u7b97\u6cd5\u6765\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002", "method": "1. \u63d0\u51fa\u57fa\u4e8e\u4ea4\u66ff\u4f18\u5316(AO)\u7684\u7b97\u6cd5\uff0c\u6bcf\u4e2a\u5b50\u95ee\u9898\u901a\u8fc7\u6574\u6570\u89c4\u5212(IP)\u6c42\u89e3\uff1b2. \u8bbe\u8ba1\u4ece\u591a\u6b21\u8fd0\u884c\u4e2d\u9009\u62e9\u6700\u4f18\u79e9-1\u56e0\u5b50\u5b50\u96c6\u7684\u65b9\u6cd5\u6765\u589e\u5f3aAO\u7b97\u6cd5\uff1b3. \u9488\u5bf9IP\u65b9\u6cd5\u7684\u53ef\u6269\u5c55\u6027\u9650\u5236\uff0c\u5f15\u5165\u65b0\u7684\u8d2a\u5fc3\u548c\u5c40\u90e8\u641c\u7d22\u542f\u53d1\u5f0f\u65b9\u6cd5\uff1b4. \u6784\u5efa\u65b0\u7684C++\u6570\u636e\u7ed3\u6784\uff0c\u663e\u8457\u52a0\u901f\u5e03\u5c14\u5411\u91cf\u548c\u77e9\u9635\u8fd0\u7b97\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5404\u79cd\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff08\u5305\u62ec\u6709\u7f3a\u5931\u6570\u636e\u548c\u65e0\u7f3a\u5931\u6570\u636e\u7684\u60c5\u51b5\uff09\u8868\u73b0\u51fa\u8272\uff0c\u5728\u4e3b\u9898\u5efa\u6a21\u548c\u56fe\u50cf\u5904\u7406\u7b49\u5e94\u7528\u4e2d\u8d85\u8d8a\u4e86\u73b0\u6709\u6280\u672f\u6c34\u5e73\u3002\u65b0\u7684C++\u6570\u636e\u7ed3\u6784\u4f7f\u542f\u53d1\u5f0f\u65b9\u6cd5\u80fd\u591f\u6269\u5c55\u5230\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002", "conclusion": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u5957\u5b8c\u6574\u7684BMF\u7b97\u6cd5\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u7cbe\u786e\u4f18\u5316\u65b9\u6cd5\u548c\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u901a\u8fc7\u9ad8\u6548\u7684\u6570\u636e\u7ed3\u6784\u5b9e\u73b0\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u5e03\u5c14\u77e9\u9635\u5206\u89e3\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2512.04009", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.04009", "abs": "https://arxiv.org/abs/2512.04009", "authors": ["Jie Tang", "Daochen Zha", "Xin Liu", "Huiji Gao", "Liwei He", "Stephanie Moyerman", "Sanjeev Katariya"], "title": "Learning to Comparison-Shop", "comment": null, "summary": "In online marketplaces like Airbnb, users frequently engage in comparison shopping before making purchase decisions. Despite the prevalence of this behavior, a significant disconnect persists between mainstream e-commerce search engines and users' comparison needs. Traditional ranking models often evaluate items in isolation, disregarding the context in which users compare multiple items on a search results page. While recent advances in deep learning have sought to improve ranking accuracy, diversity, and fairness by encoding listwise context, the challenge of aligning search rankings with user comparison shopping behavior remains inadequately addressed. In this paper, we propose a novel ranking architecture - Learning-to-Comparison-Shop (LTCS) System - that explicitly models and learns users' comparison shopping behaviors. Through extensive offline and online experiments, we demonstrate that our approach yields statistically significant gains in key business metrics - improving NDCG by 1.7% and boosting booking conversion rate by 0.6% in A/B testing - while also enhancing user experience. We also compare our model against state-of-the-art approaches and demonstrate that LTCS significantly outperforms them.", "AI": {"tldr": "\u63d0\u51faLTCS\u7cfb\u7edf\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u7528\u6237\u6bd4\u8f83\u8d2d\u7269\u884c\u4e3a\u6765\u6539\u8fdb\u7535\u5546\u641c\u7d22\u6392\u540d\uff0c\u5728Airbnb\u7b49\u5e73\u53f0\u5b9e\u73b0NDCG\u63d0\u53471.7%\uff0c\u9884\u8ba2\u8f6c\u5316\u7387\u63d0\u53470.6%\u3002", "motivation": "\u5f53\u524d\u7535\u5546\u641c\u7d22\u5f15\u64ce\u4e0e\u7528\u6237\u6bd4\u8f83\u8d2d\u7269\u9700\u6c42\u5b58\u5728\u8131\u8282\uff0c\u4f20\u7edf\u6392\u540d\u6a21\u578b\u5b64\u7acb\u8bc4\u4f30\u5546\u54c1\uff0c\u5ffd\u89c6\u7528\u6237\u5728\u641c\u7d22\u7ed3\u679c\u9875\u9762\u5bf9\u591a\u4e2a\u5546\u54c1\u8fdb\u884c\u6bd4\u8f83\u7684\u4e0a\u4e0b\u6587\u73af\u5883\u3002", "method": "\u63d0\u51faLearning-to-Comparison-Shop (LTCS)\u7cfb\u7edf\u67b6\u6784\uff0c\u663e\u5f0f\u5efa\u6a21\u548c\u5b66\u4e60\u7528\u6237\u7684\u6bd4\u8f83\u8d2d\u7269\u884c\u4e3a\uff0c\u901a\u8fc7\u79bb\u7ebf\u5b9e\u9a8c\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u9a8c\u8bc1\u6548\u679c\u3002", "result": "NDCG\u63d0\u53471.7%\uff0c\u9884\u8ba2\u8f6c\u5316\u7387\u63d0\u53470.6%\uff0c\u5728A/B\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u7edf\u8ba1\u663e\u8457\u63d0\u5347\uff0c\u4e14\u4f18\u4e8e\u73b0\u6709\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "LTCS\u7cfb\u7edf\u80fd\u6709\u6548\u5efa\u6a21\u7528\u6237\u6bd4\u8f83\u8d2d\u7269\u884c\u4e3a\uff0c\u663e\u8457\u63d0\u5347\u641c\u7d22\u6392\u540d\u6548\u679c\u548c\u4e1a\u52a1\u6307\u6807\uff0c\u540c\u65f6\u6539\u5584\u7528\u6237\u4f53\u9a8c\u3002"}}
