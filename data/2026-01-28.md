<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 16]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [XProvence: Zero-Cost Multilingual Context Pruning for Retrieval-Augmented Generation](https://arxiv.org/abs/2601.18886)
*Youssef Mohamed,Mohamed Elhoseiny,Thibault Formal,Nadezhda Chirkova*

Main category: cs.IR

TL;DR: XProvence是一个多语言零成本上下文剪枝模型，用于检索增强生成(RAG)，支持16种语言训练和100+种语言跨语言迁移，在保持性能的同时有效剪枝RAG上下文。


<details>
  <summary>Details</summary>
Motivation: 随着RAG系统在多语言环境中的广泛应用，需要将原本仅支持英语的Provence框架扩展到多语言场景，以支持全球范围内的RAG应用。

Method: 基于Provence框架，通过多种策略实现多语言泛化，将高效的零成本上下文剪枝直接集成到重排序模型中，支持16种语言训练和100+种语言的跨语言迁移。

Result: 在四个多语言问答基准测试中，XProvence能够以最小到无性能损失的方式剪枝RAG上下文，并且优于强基线模型。

Conclusion: XProvence成功将零成本上下文剪枝扩展到多语言环境，为全球RAG应用提供了高效的多语言上下文管理解决方案。

Abstract: This paper introduces XProvence, a multilingual zero-cost context pruning model for retrieval-augmented generation (RAG), trained on 16 languages and supporting 100+ languages through effective cross-lingual transfer. Motivated by the growing use of RAG systems across diverse languages, we explore several strategies to generalize the Provence framework-which first integrated efficient zero-cost context pruning directly into the re-ranking model-beyond English. Across four multilingual question answering benchmarks, we show how XProvence can prune RAG contexts with minimal-to-no performance degradation and outperforms strong baselines. Our model is available at https://huggingface.co/naver/xprovence-reranker-bgem3-v2.

</details>


### [2] [Recommending Composite Items Using Multi-Level Preference Information: A Joint Interaction Modeling Approach](https://arxiv.org/abs/2601.19005)
*Xuan Bi,Yaqiong Wang,Gediminas Adomavicius,Shawn Curley*

Main category: cs.IR

TL;DR: JIMA是一个联合交互建模方法，使用单一模型整合不同粒度级别的数据，学习原子物品和复合物品用户偏好以及领域专业知识之间的复杂关系。


<details>
  <summary>Details</summary>
Motivation: 随着推荐系统应用场景变得更加多样化和复杂，需要更复杂的推荐技术。特别是在复合物品（如时尚搭配）推荐中，可能存在多个层次的用户偏好信息，需要有效利用这些不同粒度的数据。

Method: 提出JIMA联合交互建模方法，使用单一模型整合所有不同粒度级别的数据，通过学习低阶（原子物品）和高阶（复合物品）用户偏好以及领域专业知识（如风格搭配）之间的复杂关系。

Result: 通过多个模拟研究和真实数据的离线与在线评估，与先进基线方法比较，结果一致表明所提方法具有优越性能。

Conclusion: JIMA方法能够有效利用不同粒度级别的数据，学习复杂的用户偏好关系，在复合物品推荐任务中表现出色。

Abstract: With the advancement of machine learning and artificial intelligence technologies, recommender systems have been increasingly used across a vast variety of platforms to efficiently and effectively match users with items. As application contexts become more diverse and complex, there is a growing need for more sophisticated recommendation techniques. One example is the composite item (for example, fashion outfit) recommendation where multiple levels of user preference information might be available and relevant. In this study, we propose JIMA, a joint interaction modeling approach that uses a single model to take advantage of all data from different levels of granularity and incorporate interactions to learn the complex relationships among lower-order (atomic item) and higher-order (composite item) user preferences as well as domain expertise (e.g., on the stylistic fit). We comprehensively evaluate the proposed method and compare it with advanced baselines through multiple simulation studies as well as with real data in both offline and online settings. The results consistently demonstrate the superior performance of the proposed approach.

</details>


### [3] [RobustExplain: Evaluating Robustness of LLM-Based Explanation Agents for Recommendation](https://arxiv.org/abs/2601.19120)
*Guilin Zhang,Kai Zhao,Jeffrey Friedman,Xu Chu*

Main category: cs.IR

TL;DR: 本文提出了RobustExplain框架，首次系统评估LLM生成推荐解释在真实用户行为噪声下的鲁棒性，发现当前模型仅具中等鲁棒性，大模型稳定性提升有限。


<details>
  <summary>Details</summary>
Motivation: 真实推荐系统中用户行为历史存在多种噪声（误点击、时间不一致、缺失值、偏好演变），但现有研究主要关注解释的流畅性和相关性，对LLM生成解释在噪声下的鲁棒性缺乏系统评估，这影响解释稳定性和用户信任。

Method: 提出RobustExplain评估框架：1）定义五种真实用户行为扰动（在不同严重级别评估）；2）设计多维度鲁棒性指标，包括语义一致性、关键词一致性、结构一致性和长度一致性；3）在四个代表性LLM（7B-70B）上进行实验。

Result: 实验表明当前LLM仅具中等鲁棒性，大模型稳定性最多提升8%。建立了首个解释代理的鲁棒性基准，揭示了鲁棒性作为可信推荐系统关键维度的重要性。

Conclusion: 鲁棒性是可信代理驱动推荐系统的关键维度，当前LLM解释代理的鲁棒性仍有待提升。RobustExplain为系统评估解释鲁棒性提供了原则性框架和初始基准，而非全面的LLM排行榜。

Abstract: Large Language Models (LLMs) are increasingly used to generate natural-language explanations in recommender systems, acting as explanation agents that reason over user behavior histories. While prior work has focused on explanation fluency and relevance under fixed inputs, the robustness of LLM-generated explanations to realistic user behavior noise remains largely unexplored. In real-world web platforms, interaction histories are inherently noisy due to accidental clicks, temporal inconsistencies, missing values, and evolving preferences, raising concerns about explanation stability and user trust. We present RobustExplain, the first systematic evaluation framework for measuring the robustness of LLM-generated recommendation explanations. RobustExplain introduces five realistic user behavior perturbations evaluated across multiple severity levels and a multi-dimensional robustness metric capturing semantic, keyword, structural, and length consistency. Our goal is to establish a principled, task-level evaluation framework and initial robustness baselines, rather than to provide a comprehensive leaderboard across all available LLMs. Experiments on four representative LLMs (7B--70B) show that current models exhibit only moderate robustness, with larger models achieving up to 8% higher stability. Our results establish the first robustness benchmarks for explanation agents and highlight robustness as a critical dimension for trustworthy, agent-driven recommender systems at web scale.

</details>


### [4] [LLMs as Orchestrators: Constraint-Compliant Multi-Agent Optimization for Recommendation Systems](https://arxiv.org/abs/2601.19121)
*Guilin Zhang,Kai Zhao,Jeffrey Friedman,Xu Chu*

Main category: cs.IR

TL;DR: DualAgent-Rec：基于LLM协调的双智能体框架，用于约束多目标电商推荐，实现100%约束满足和帕累托超体积提升


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统在优化多目标时难以满足硬业务约束（如公平性、覆盖率），传统方法将约束视为软惩罚或仅关注项目评分，导致实际部署中频繁违反约束。LLM在协调推荐系统中的约束优化方面尚未充分探索。

Method: 提出DualAgent-Rec框架：1) 开发智能体在硬约束下优先考虑准确性；2) 探索智能体通过无约束帕累托搜索促进多样性；3) LLM协调器根据优化进度和约束满足情况自适应分配资源；4) 自适应epsilon松弛机制保证最终解的可行性。

Result: 在Amazon Reviews 2023数据集上的实验表明：DualAgent-Rec实现100%约束满足，帕累托超体积比强基线提升4-6%，同时保持竞争力的准确性-多样性权衡。

Conclusion: LLM可以作为有效的编排智能体，构建可部署且符合约束的推荐系统。该框架为实际生产环境中满足硬业务约束的多目标推荐提供了可行解决方案。

Abstract: Recommendation systems must optimize multiple objectives while satisfying hard business constraints such as fairness and coverage. For example, an e-commerce platform may require every recommendation list to include items from multiple sellers and at least one newly listed product; violating such constraints--even once--is unacceptable in production. Prior work on multi-objective recommendation and recent LLM-based recommender agents largely treat constraints as soft penalties or focus on item scoring and interaction, leading to frequent violations in real-world deployments. How to leverage LLMs for coordinating constrained optimization in recommendation systems remains underexplored. We propose DualAgent-Rec, an LLM-coordinated dual-agent framework for constrained multi-objective e-commerce recommendation. The framework separates optimization into an Exploitation Agent that prioritizes accuracy under hard constraints and an Exploration Agent that promotes diversity through unconstrained Pareto search. An LLM-based coordinator adaptively allocates resources between agents based on optimization progress and constraint satisfaction, while an adaptive epsilon-relaxation mechanism guarantees feasibility of final solutions. Experiments on the Amazon Reviews 2023 dataset demonstrate that DualAgent-Rec achieves 100% constraint satisfaction and improves Pareto hypervolume by 4-6% over strong baselines, while maintaining competitive accuracy-diversity trade-offs. These results indicate that LLMs can act as effective orchestration agents for deployable and constraint-compliant recommendation systems.

</details>


### [5] [Accelerating Generative Recommendation via Simple Categorical User Sequence Compression](https://arxiv.org/abs/2601.19158)
*Qijiong Liu,Lu Fan,Zhongzhou Liu,Xiaoyu Dong,Yuankai Luo,Guoyuan An,Nuo Chen,Wei Guo,Yong Liu,Xiao-Ming Wu*

Main category: cs.IR

TL;DR: 提出基于物品类别特征压缩用户历史序列的方法，在保持用户兴趣的同时显著降低计算成本，相比HSTU模型实现6倍计算成本降低和39%准确率提升


<details>
  <summary>Details</summary>
Motivation: 生成式推荐系统在长序列上性能更好，但实际部署面临巨大计算成本挑战，需要解决长序列处理效率问题

Method: 利用物品固有的类别特征来压缩长期用户历史序列，设计简单有效的压缩方法，在保持用户兴趣的同时提升效率

Result: 在两个大规模数据集上实验表明，相比有影响力的HSTU模型，该方法实现高达6倍计算成本降低，在相似序列长度下达到39%更高的准确率

Conclusion: 提出的基于类别特征的序列压缩方法能有效平衡生成式推荐系统的性能和效率，为实际部署提供了可行的解决方案

Abstract: Although generative recommenders demonstrate improved performance with longer sequences, their real-time deployment is hindered by substantial computational costs. To address this challenge, we propose a simple yet effective method for compressing long-term user histories by leveraging inherent item categorical features, thereby preserving user interests while enhancing efficiency. Experiments on two large-scale datasets demonstrate that, compared to the influential HSTU model, our approach achieves up to a 6x reduction in computational cost and up to 39% higher accuracy at comparable cost (i.e., similar sequence length).

</details>


### [6] [HELM: A Human-Centered Evaluation Framework for LLM-Powered Recommender Systems](https://arxiv.org/abs/2601.19197)
*Sushant Mehta*

Main category: cs.IR

TL;DR: HELM框架为LLM推荐系统提供多维度人本评估，超越传统准确率指标，揭示GPT-4等模型在解释质量、交互自然度方面的优势，但也暴露其流行度偏见问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推荐系统评估方法过度依赖传统准确率指标，无法全面衡量影响真实用户体验的多维度人本特性，需要更全面的评估框架。

Method: 提出HELM框架，从意图对齐、解释质量、交互自然度、信任与透明度、公平性与多样性五个维度系统评估LLM推荐系统。使用GPT-4、LLaMA-3.1和P5三种先进模型，在电影、书籍、餐厅三个领域，通过12位领域专家对847个推荐场景进行严格评估。

Result: HELM揭示了传统指标无法捕捉的关键质量维度：GPT-4在解释质量(4.21/5.0)和交互自然度(4.35/5.0)方面表现优异，但存在显著的流行度偏见(基尼系数0.73)，远高于传统协同过滤(0.58)。

Conclusion: HELM框架为LLM推荐系统提供了全面的人本评估方法，揭示了传统指标无法捕捉的重要质量维度，开源工具包将推动推荐系统社区的人本评估实践。

Abstract: The integration of Large Language Models (LLMs) into recommendation systems has introduced unprecedented capabilities for natural language understanding, explanation generation, and conversational interactions. However, existing evaluation methodologies focus predominantly on traditional accuracy metrics, failing to capture the multifaceted human-centered qualities that determine the real-world user experience. We introduce \framework{} (\textbf{H}uman-centered \textbf{E}valuation for \textbf{L}LM-powered reco\textbf{M}menders), a comprehensive evaluation framework that systematically assesses LLM-powered recommender systems across five human-centered dimensions: \textit{Intent Alignment}, \textit{Explanation Quality}, \textit{Interaction Naturalness}, \textit{Trust \& Transparency}, and \textit{Fairness \& Diversity}. Through extensive experiments involving three state-of-the-art LLM-based recommenders (GPT-4, LLaMA-3.1, and P5) across three domains (movies, books, and restaurants), and rigorous evaluation by 12 domain experts using 847 recommendation scenarios, we demonstrate that \framework{} reveals critical quality dimensions invisible to traditional metrics. Our results show that while GPT-4 achieves superior explanation quality (4.21/5.0) and interaction naturalness (4.35/5.0), it exhibits a significant popularity bias (Gini coefficient 0.73) compared to traditional collaborative filtering (0.58). We release \framework{} as an open-source toolkit to advance human-centered evaluation practices in the recommender systems community.

</details>


### [7] [Propagating Similarity, Mitigating Uncertainty: Similarity Propagation-enhanced Uncertainty for Multimodal Recommendation](https://arxiv.org/abs/2601.19198)
*Xinzhuo Wu,Hongbo Wang,Yuan Lin,Kan Xu,Liang Yang,Hongfei Lin*

Main category: cs.IR

TL;DR: SPUMR是一个新颖的多模态推荐框架，通过显式建模模态不确定性，利用相似性传播来精炼表示，并通过不确定性感知的偏好聚合自适应融合多模态特征。


<details>
  <summary>Details</summary>
Motivation: 现有多模态推荐系统存在两个主要问题：1）忽略了模态特征中固有的噪声和不确定性（如模糊图像、多样视觉外观或模糊文本）；2）未能充分利用用户和物品之间的丰富相似性模式来精炼表示和不确定性估计。

Method: SPUMR框架包含三个核心组件：1）构建模态相似性图和协同相似性图，从内容和行为角度精炼表示；2）不确定性感知的偏好聚合模块，自适应融合精炼后的多模态特征，为更可靠的模态分配更大权重。

Result: 在三个基准数据集上的广泛实验表明，SPUMR相比现有领先方法取得了显著改进。

Conclusion: SPUMR通过显式建模和缓解不确定性，并利用相似性传播来精炼表示，有效解决了多模态推荐中的噪声和不确定性挑战，显著提升了推荐性能。

Abstract: Multimodal Recommendation (MMR) systems are crucial for modern platforms but are often hampered by inherent noise and uncertainty in modal features, such as blurry images, diverse visual appearances, or ambiguous text. Existing methods often overlook this modality-specific uncertainty, leading to ineffective feature fusion. Furthermore, they fail to leverage rich similarity patterns among users and items to refine representations and their corresponding uncertainty estimates. To address these challenges, we propose a novel framework, Similarity Propagation-enhanced Uncertainty for Multimodal Recommendation (SPUMR). SPUMR explicitly models and mitigates uncertainty by first constructing the Modality Similarity Graph and the Collaborative Similarity Graph to refine representations from both content and behavioral perspectives. The Uncertainty-aware Preference Aggregation module then adaptively fuses the refined multimodal features, assigning greater weight to more reliable modalities. Extensive experiments on three benchmark datasets demonstrate that SPUMR achieves significant improvements over existing leading methods.

</details>


### [8] [Physics-Informed Neuro-Symbolic Recommender System: A Dual-Physics Approach for Personalized Nutrition](https://arxiv.org/abs/2601.19244)
*Chayan Banerjee*

Main category: cs.IR

TL;DR: 提出一种物理信息神经符号推荐系统，将营养科学直接整合到推荐流程中，确保食品推荐符合用户每日能量消耗和宏量营养素平衡的生理约束。


<details>
  <summary>Details</summary>
Motivation: 传统电商推荐系统主要优化用户参与度和购买可能性，忽视了人类健康所需的严格生理约束。标准协同过滤算法在结构上无法处理这些硬性限制，经常推荐不符合特定每日总能量消耗和宏量营养素平衡要求的食品组合。

Method: 采用双层次架构：1) 使用句子级编码器构建语义知识图谱，严格对齐商业产品和权威营养数据；2) 训练阶段使用隐式物理正则化器，应用可微分热力学损失函数，确保学习到的潜在嵌入反映营养合理性而非简单流行度；3) 推理阶段使用显式物理优化器，采用模拟退火和弹性数量优化生成严格符合用户蛋白质和热量目标的离散食品组合。

Result: 论文介绍了一个能够生成符合营养约束的食品推荐框架，但摘要中未提供具体的实验结果数据。

Conclusion: 提出的物理信息神经符号推荐系统成功地将营养科学整合到推荐流程中，解决了传统推荐系统忽视生理约束的问题，能够生成严格符合用户营养目标的食品组合。

Abstract: Traditional e-commerce recommender systems primarily optimize for user engagement and purchase likelihood, often neglecting the rigid physiological constraints required for human health. Standard collaborative filtering algorithms are structurally blind to these hard limits, frequently suggesting bundles that fail to meet specific total daily energy expenditure and macronutrient balance requirements. To address this disconnect, this paper introduces a Physics-Informed Neuro-Symbolic Recommender System that integrates nutritional science directly into the recommendation pipeline via a dual-layer architecture. The framework begins by constructing a semantic knowledge graph using sentence-level encoders to strictly align commercial products with authoritative nutritional data. During the training phase, an implicit physics regularizer applies a differentiable thermodynamic loss function, ensuring that learned latent embeddings reflect nutritional plausibility rather than simple popularity. Subsequently, during the inference phase, an explicit physics optimizer employs simulated annealing and elastic quantity optimization to generate discrete grocery bundles that strictly adhere to the user's protein and caloric targets.

</details>


### [9] [Talos: Optimizing Top-$K$ Accuracy in Recommender Systems](https://arxiv.org/abs/2601.19276)
*Shengjia Zhang,Weiqin Yang,Jiawei Chen,Peng Wu,Yuegang Sun,Gang Wang,Qihao Shi,Can Wang*

Main category: cs.IR

TL;DR: Talos是一个专门优化Top-K推荐准确率的损失函数，通过分位数技术将复杂的排序依赖操作简化为预测分数与学习阈值之间的比较，并采用采样回归算法进行高效阈值估计。


<details>
  <summary>Details</summary>
Motivation: 推荐系统主要关注Top-K结果质量，但估计Top-K准确率需要确定物品的排序位置，计算开销大且优化困难。此外，推荐系统常面临用户偏好演变或数据偏差导致的分布偏移问题。

Method: 提出Talos损失函数，利用分位数技术将排序依赖操作转换为预测分数与学习阈值之间的比较；开发采样回归算法进行高效阈值估计；引入约束项防止分数膨胀；设计定制化代理函数处理不连续性和增强对分布偏移的鲁棒性。

Result: 通过全面的理论分析和实证实验，证明了Talos在有效性、效率、收敛性和分布鲁棒性方面的优越性能。

Conclusion: Talos通过创新的分位数技术和采样回归算法，有效解决了Top-K推荐准确率优化的计算复杂性和分布偏移问题，为推荐系统提供了一种高效稳健的优化方法。

Abstract: Recommender systems (RS) aim to retrieve a small set of items that best match individual user preferences. Naturally, RS place primary emphasis on the quality of the Top-$K$ results rather than performance across the entire item set. However, estimating Top-$K$ accuracy (e.g., Precision@$K$, Recall@$K$) requires determining the ranking positions of items, which imposes substantial computational overhead and poses significant challenges for optimization. In addition, RS often suffer from distribution shifts due to evolving user preferences or data biases, further complicating the task.
  To address these issues, we propose Talos, a loss function that is specifically designed to optimize the Talos recommendation accuracy. Talos leverages a quantile technique that replaces the complex ranking-dependent operations into simpler comparisons between predicted scores and learned score thresholds. We further develop a sampling-based regression algorithm for efficient and accurate threshold estimation, and introduce a constraint term to maintain optimization stability by preventing score inflation. Additionally, we incorporate a tailored surrogate function to address discontinuity and enhance robustness against distribution shifts. Comprehensive theoretical analyzes and empirical experiments are conducted to demonstrate the effectiveness, efficiency, convergence, and distributional robustness of Talos. The code is available at https://github.com/cynthia-shengjia/WWW-2026-Talos.

</details>


### [10] [UniRec: Unified Multimodal Encoding for LLM-Based Recommendations](https://arxiv.org/abs/2601.19423)
*Zijie Lei,Tao Feng,Zhigang Hua,Yan Xie,Guanyu Lin,Shuang Yang,Ge Liu,Jiaxuan You*

Main category: cs.IR

TL;DR: UniRec：统一多模态编码器，解决LLM推荐中跨模态和模态内异质性挑战，通过特定模态编码、三元组表示和分层Q-Former建模用户交互的嵌套结构


<details>
  <summary>Details</summary>
Motivation: 现实世界推荐信号远超文本和图像，包含文本、图像、分类特征和数值属性四种模态。这些异质性模态给LLM带来挑战：不仅跨模态存在差异，同一模态内（如价格、评分、时间都是数值但语义不同）也存在模糊性。此外，推荐信号具有嵌套结构（用户历史是项目序列，每个项目有多个属性）。

Method: 提出UniRec统一多模态编码器：1) 使用模态特定编码器为异质信号生成一致嵌入；2) 采用三元组表示（属性名、类型、值）分离模式与原始输入，保持语义区分；3) 使用分层Q-Former建模用户交互的嵌套结构，同时保持分层组织。

Result: 在多个真实世界基准测试中，UniRec比最先进的多模态和LLM推荐器性能提升高达15%。广泛的消融研究进一步验证了每个组件的贡献。

Conclusion: UniRec通过统一框架有效解决了LLM推荐中的多模态异质性和嵌套结构挑战，显著提升了推荐性能，为处理复杂现实世界推荐信号提供了有效解决方案。

Abstract: Large language models have recently shown promise for multimodal recommendation, particularly with text and image inputs. Yet real-world recommendation signals extend far beyond these modalities. To reflect this, we formalize recommendation features into four modalities: text, images, categorical features, and numerical attributes, and highlight the unique challenges this heterogeneity poses for LLMs in understanding multimodal information. In particular, these challenges arise not only across modalities but also within them, as attributes such as price, rating, and time may all be numeric yet carry distinct semantic meanings. Beyond this intra-modality ambiguity, another major challenge is the nested structure of recommendation signals, where user histories are sequences of items, each associated with multiple attributes. To address these challenges, we propose UniRec, a unified multimodal encoder for LLM-based recommendation. UniRec first employs modality-specific encoders to produce consistent embeddings across heterogeneous signals. It then adopts a triplet representation, comprising attribute name, type, and value, to separate schema from raw inputs and preserve semantic distinctions. Finally, a hierarchical Q-Former models the nested structure of user interactions while maintaining their layered organization. Across multiple real-world benchmarks, UniRec outperforms state-of-the-art multimodal and LLM-based recommenders by up to 15%, and extensive ablation studies further validate the contributions of each component.

</details>


### [11] [Masked Diffusion Generative Recommendation](https://arxiv.org/abs/2601.19501)
*Lingyu Mu,Hao Deng,Haibo Xing,Jinxin Hu,Yu Zhang,Xiaoyi Zeng,Jing Zhang*

Main category: cs.IR

TL;DR: 提出MDGR框架，使用掩码扩散生成推荐，解决传统自回归解码的三个问题：全局依赖捕获不足、固定解码路径假设、推理效率低


<details>
  <summary>Details</summary>
Motivation: 传统生成式推荐采用自回归解码范式，存在三个关键限制：1) 难以联合捕获SID多维特征的全局依赖关系；2) 固定解码路径假设所有用户以相同顺序关注商品属性；3) 推理效率低，难以满足实时需求

Method: 提出MDGR掩码扩散生成推荐框架，从三个角度重塑GR流程：1) 采用并行码本为扩散基础；2) 训练时沿时间和样本维度自适应构建掩码监督信号；3) 推理时使用基于预热的两阶段并行解码策略

Result: 在多个公开和工业级数据集上，MDGR超越10个SOTA基线达10.78%；在大规模在线广告平台部署实现1.20%收入增长

Conclusion: MDGR通过掩码扩散方法有效解决了自回归解码的三个限制，在推荐性能和推理效率上均有显著提升，具有实际应用价值

Abstract: Generative recommendation (GR) typically first quantizes continuous item embeddings into multi-level semantic IDs (SIDs), and then generates the next item via autoregressive decoding. Although existing methods are already competitive in terms of recommendation performance, directly inheriting the autoregressive decoding paradigm from language models still suffers from three key limitations: (1) autoregressive decoding struggles to jointly capture global dependencies among the multi-dimensional features associated with different positions of SID; (2) using a unified, fixed decoding path for the same item implicitly assumes that all users attend to item attributes in the same order; (3) autoregressive decoding is inefficient at inference time and struggles to meet real-time requirements. To tackle these challenges, we propose MDGR, a Masked Diffusion Generative Recommendation framework that reshapes the GR pipeline from three perspectives: codebook, training, and inference. (1) We adopt a parallel codebook to provide a structural foundation for diffusion-based GR. (2) During training, we adaptively construct masking supervision signals along both the temporal and sample dimensions. (3) During inference, we develop a warm-up-based two-stage parallel decoding strategy for efficient generation of SIDs. Extensive experiments on multiple public and industrial-scale datasets show that MDGR outperforms ten state-of-the-art baselines by up to 10.78%. Furthermore, by deploying MDGR on a large-scale online advertising platform, we achieve a 1.20% increase in revenue, demonstrating its practical value. The code will be released upon acceptance.

</details>


### [12] [Enhancing Academic Paper Recommendations Using Fine-Grained Knowledge Entities and Multifaceted Document Embeddings](https://arxiv.org/abs/2601.19513)
*Haixu Xi,Heng Zhang,Chengzhi Zhang*

Main category: cs.IR

TL;DR: 提出一种新颖的学术论文推荐方法，通过整合细粒度知识实体、文档标题摘要和引用数据来嵌入多维信息，基于组合论文向量相似度进行推荐，在STM-KG数据集上优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 当前学术论文推荐系统主要基于宽泛的主题或领域相似性进行推荐，无法满足学者在特定研究方法、具体研究任务等细粒度需求。随着学术文献爆炸式增长，学者文献综述负担加重，需要更精准的推荐系统来提高研究效率和激发创新思维。

Method: 提出一种新颖的学术论文推荐方法，通过整合细粒度知识实体（如研究方法、研究任务）、文档标题摘要和引用数据来嵌入多维信息，然后计算组合论文向量之间的相似度来生成推荐。

Result: 在STM-KG数据集（包含十个不同领域科学概念的知识图谱）上评估，该方法在top-50推荐中平均精度达到27.3%，比现有方法提高了6.7%。

Conclusion: 该方法通过整合细粒度知识实体和多维信息，能够更好地满足学者在具体研究方法和任务方面的细粒度需求，显著提升了学术论文推荐的精度和实用性。

Abstract: In the era of explosive growth in academic literature, the burden of literature review on scholars are increasing. Proactively recommending academic papers that align with scholars' literature needs in the research process has become one of the crucial pathways to enhance research efficiency and stimulate innovative thinking. Current academic paper recommendation systems primarily focus on broad and coarse-grained suggestions based on general topic or field similarities. While these systems effectively identify related literature, they fall short in addressing scholars' more specific and fine-grained needs, such as locating papers that utilize particular research methods, or tackle distinct research tasks within the same topic. To meet the diverse and specific literature needs of scholars in the research process, this paper proposes a novel academic paper recommendation method. This approach embeds multidimensional information by integrating new types of fine-grained knowledge entities, title and abstract of document, and citation data. Recommendations are then generated by calculating the similarity between combined paper vectors. The proposed recommendation method was evaluated using the STM-KG dataset, a knowledge graph that incorporates scientific concepts derived from papers across ten distinct domains. The experimental results indicate that our method outperforms baseline models, achieving an average precision of 27.3% among the top 50 recommendations. This represents an improvement of 6.7% over existing approaches.

</details>


### [13] [LURE-RAG: Lightweight Utility-driven Reranking for Efficient RAG](https://arxiv.org/abs/2601.19535)
*Manish Chandra,Debasis Ganguly,Iadh Ounis*

Main category: cs.IR

TL;DR: LURE-RAG是一个轻量级效用驱动的重排序框架，通过LambdaMART重排序器和列表排序损失优化RAG中的文档排序，在保持高效的同时达到接近SOTA的性能。


<details>
  <summary>Details</summary>
Motivation: 传统RAG基于相关性的检索与下游任务的实际效用存在偏差，现有效用驱动检索方法存在两个主要问题：1) 资源密集需要查询编码，2) 训练中没有使用列表排序损失，而文档相对顺序直接影响RAG生成质量。

Method: 提出LURE-RAG框架，为任何黑盒检索器添加高效的LambdaMART重排序器，使用基于LLM效用的列表排序损失训练重排序器，直接优化检索文档的排序。还提出了其密集变体UR-RAG。

Result: 在两个标准数据集上的实验表明，LURE-RAG达到最佳密集神经基线97-98%的性能，同时在训练和推理中保持高效。其密集变体UR-RAG比现有最佳基线显著提升达3%。

Conclusion: LURE-RAG通过轻量级效用驱动重排序有效解决了传统RAG中相关性检索与任务效用不匹配的问题，在保持效率的同时实现了接近SOTA的性能，其密集变体进一步提升了性能表现。

Abstract: Most conventional Retrieval-Augmented Generation (RAG) pipelines rely on relevance-based retrieval, which often misaligns with utility -- that is, whether the retrieved passages actually improve the quality of the generated text specific to a downstream task such as question answering or query-based summarization. The limitations of existing utility-driven retrieval approaches for RAG are that, firstly, they are resource-intensive typically requiring query encoding, and that secondly, they do not involve listwise ranking loss during training. The latter limitation is particularly critical, as the relative order between documents directly affects generation in RAG. To address this gap, we propose Lightweight Utility-driven Reranking for Efficient RAG (LURE-RAG), a framework that augments any black-box retriever with an efficient LambdaMART-based reranker. Unlike prior methods, LURE-RAG trains the reranker with a listwise ranking loss guided by LLM utility, thereby directly optimizing the ordering of retrieved documents. Experiments on two standard datasets demonstrate that LURE-RAG achieves competitive performance, reaching 97-98% of the state-of-the-art dense neural baseline, while remaining efficient in both training and inference. Moreover, its dense variant, UR-RAG, significantly outperforms the best existing baseline by up to 3%.

</details>


### [14] [Comparing how Large Language Models perform against keyword-based searches for social science research data discovery](https://arxiv.org/abs/2601.19559)
*Mark Green,Maura Halstead,Caroline Jay,Richard Kingston,Alex Singleton,David Topping*

Main category: cs.IR

TL;DR: 该研究比较了基于大语言模型的语义搜索与传统关键词搜索在数据发现中的表现，发现语义搜索返回结果更多，对地点、拼写错误、复杂查询处理更好，虽然不完全替代但显著提升了数据发现效果。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型驱动的语义搜索工具相对于传统关键词搜索在数据发现中的性能差异，探索语义搜索在实际应用中的优势和局限性。

Method: 使用英国研究创新局数据服务的定制语义搜索系统与消费者数据研究中心的关键词搜索进行对比，基于2023年12月至2024年10月期间CDRC搜索日志中最常用的131个搜索词，通过描述性统计、定性检查和定量相似度测量（包括精确数据集重叠、Jaccard相似度和BERT嵌入的余弦相似度）评估返回数据集的差异。

Result: 语义搜索始终返回比关键词搜索更多的结果，在处理基于地点、拼写错误、晦涩或复杂查询时表现尤为出色。虽然语义搜索未能捕获所有基于关键词的结果，但返回的数据集在语义上高度相似，余弦相似度得分高而精确重叠率较低。两种工具的最相关结果排名存在显著差异，反映了不同的优先级策略。

Conclusion: 基于大语言模型的语义搜索为数据发现提供了实质性改进，特别是在处理拼写错误、解释地理和上下文相关性以及支持自然语言查询方面表现出色，它是对传统关键词搜索方法的补充而非完全替代。

Abstract: This paper evaluates the performance of a large language model (LLM) based semantic search tool relative to a traditional keyword-based search for data discovery. Using real-world search behaviour, we compare outputs from a bespoke semantic search system applied to UKRI data services with the Consumer Data Research Centre (CDRC) keyword search. Analysis is based on 131 of the most frequently used search terms extracted from CDRC search logs between December 2023 and October 2024. We assess differences in the volume, overlap, ranking, and relevance of returned datasets using descriptive statistics, qualitative inspection, and quantitative similarity measures, including exact dataset overlap, Jaccard similarity, and cosine similarity derived from BERT embeddings. Results show that the semantic search consistently returns a larger number of results than the keyword search and performs particularly well for place based, misspelled, obscure, or complex queries. While the semantic search does not capture all keyword based results, the datasets returned are overwhelmingly semantically similar, with high cosine similarity scores despite lower exact overlap. Rankings of the most relevant results differ substantially between tools, reflecting contrasting prioritisation strategies. Case studies demonstrate that the LLM based tool is robust to spelling errors, interprets geographic and contextual relevance effectively, and supports natural-language queries that keyword search fails to resolve. Overall, the findings suggest that LLM driven semantic search offers a substantial improvement for data discovery, complementing rather than fully replacing traditional keyword-based approaches.

</details>


### [15] [LLM-Enhanced Reinforcement Learning for Long-Term User Satisfaction in Interactive Recommendation](https://arxiv.org/abs/2601.19585)
*Chongjun Xia,Yanchun Peng,Xianzhi Wang*

Main category: cs.IR

TL;DR: LLM-增强强化学习（LERL）框架：结合LLM的语义规划能力和RL的细粒度适应性，通过分层设计解决推荐系统中的内容同质化和长期用户满意度问题。


<details>
  <summary>Details</summary>
Motivation: 当前交互式推荐系统存在内容同质化和过滤气泡问题，过度拟合短期用户偏好。现有多样性改进方法主要在静态或一次性设置中操作，忽略了用户兴趣的长期演化。强化学习虽然能优化长期满意度，但受限于稀疏的用户-物品交互和有限的语义规划能力。

Method: 提出LERL分层推荐框架：1）高层LLM规划器选择语义多样的内容类别；2）低层RL策略在选定语义空间内推荐个性化物品。这种设计缩小了动作空间，提高了规划效率，并减轻了冗余内容的过度曝光。

Result: 在真实世界数据集上的大量实验表明，与最先进的基线方法相比，LERL显著提高了长期用户满意度。

Conclusion: LERL成功整合了LLM的语义规划能力和RL的适应性，有效解决了推荐系统中的内容多样性和长期优化问题，为交互式推荐系统提供了新的解决方案。

Abstract: Interactive recommender systems can dynamically adapt to user feedback, but often suffer from content homogeneity and filter bubble effects due to overfitting short-term user preferences. While recent efforts aim to improve content diversity, they predominantly operate in static or one-shot settings, neglecting the long-term evolution of user interests. Reinforcement learning provides a principled framework for optimizing long-term user satisfaction by modeling sequential decision-making processes. However, its application in recommendation is hindered by sparse, long-tailed user-item interactions and limited semantic planning capabilities. In this work, we propose LLM-Enhanced Reinforcement Learning (LERL), a novel hierarchical recommendation framework that integrates the semantic planning power of LLM with the fine-grained adaptability of RL. LERL consists of a high-level LLM-based planner that selects semantically diverse content categories, and a low-level RL policy that recommends personalized items within the selected semantic space. This hierarchical design narrows the action space, enhances planning efficiency, and mitigates overexposure to redundant content. Extensive experiments on real-world datasets demonstrate that LERL significantly improves long-term user satisfaction when compared with state-of-the-art baselines. The implementation of LERL is available at https://anonymous.4open.science/r/code3-18D3/.

</details>


### [16] [Differentiable Semantic ID for Generative Recommendation](https://arxiv.org/abs/2601.19711)
*Junchen Fu,Xuri Ge,Alexandros Karatzoglou,Ioannis Arapakis,Suzan Verberne,Joemon M. Jose,Zhaochun Ren*

Main category: cs.IR

TL;DR: 提出DIGER方法，通过引入Gumbel噪声和不确定性衰减策略，实现可微分的语义ID学习，解决生成式推荐中索引与推荐目标不匹配的问题。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐方法将语义ID视为预定义，独立训练分词器进行内容重建而非推荐优化，导致索引损失和推荐损失的目标不匹配。推荐梯度无法更新分词器，且传统可微分方法容易导致码本崩溃。

Method: 提出DIGER方法：1) 引入Gumbel噪声促进早期码本探索，缓解码本崩溃；2) 设计两种不确定性衰减策略，逐步减少噪声，实现从探索到利用的平滑过渡。

Result: 在多个公开数据集上的实验表明，可微分语义ID带来了一致的性能提升，验证了通过可微分SID对齐索引和推荐目标的有效性。

Conclusion: 可微分语义索引是生成式推荐的有前景研究方向，DIGER通过解决码本崩溃问题，首次实现了有效的可微分语义ID学习。

Abstract: Generative recommendation provides a novel paradigm in which each item is represented by a discrete semantic ID (SID) learned from rich content. Most existing methods treat SIDs as predefined and train recommenders under static indexing. In practice, SIDs are typically optimized only for content reconstruction rather than recommendation accuracy. This leads to an objective mismatch: the system optimizes an indexing loss to learn the SID and a recommendation loss for interaction prediction, but because the tokenizer is trained independently, the recommendation loss cannot update it. A natural approach is to make semantic indexing differentiable so that recommendation gradients can directly influence SID learning, but this often causes codebook collapse, where only a few codes are used. We attribute this issue to early deterministic assignments that limit codebook exploration, resulting in imbalance and unstable optimization.
  In this paper, we propose DIGER (Differentiable Semantic ID for Generative Recommendation), a first step toward effective differentiable semantic IDs for generative recommendation. DIGER introduces Gumbel noise to explicitly encourage early-stage exploration over codes, mitigating codebook collapse and improving code utilization. To balance exploration and convergence, we further design two uncertainty decay strategies that gradually reduce the Gumbel noise, enabling a smooth transition from early exploration to exploitation of learned SIDs. Extensive experiments on multiple public datasets demonstrate consistent improvements from differentiable semantic IDs. These results confirm the effectiveness of aligning indexing and recommendation objectives through differentiable SIDs and highlight differentiable semantic indexing as a promising research direction.

</details>
