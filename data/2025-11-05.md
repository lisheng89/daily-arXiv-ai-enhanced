<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 4]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Solving cold start in news recommendations: a RippleNet-based system for large scale media outlet](https://arxiv.org/abs/2511.02052)
*Karol Radziszewski,Michał Szpunar,Piotr Ociepka,Mateusz Buczyński*

Main category: cs.IR

TL;DR: 基于RippleNet的可扩展推荐系统实现，针对媒体领域，在波兰大型在线媒体平台Onet.pl中部署。通过将基于内容的物品嵌入集成到RippleNet的知识传播机制中，解决新发布内容的冷启动问题。


<details>
  <summary>Details</summary>
Motivation: 解决媒体推荐系统中新发布内容的冷启动问题，为大型在线媒体平台提供有效的推荐解决方案。

Method: 集成基于内容的物品嵌入到RippleNet的知识传播机制中，利用Amazon SageMaker进行分布式训练和推理，使用Apache Airflow编排数据管道和模型重训练工作流。

Result: 构建了包含用户和物品特征以及交互表的综合黄金数据集，实现了对新物品的有效评分，系统已在生产环境中部署。

Conclusion: 提出的解决方案成功解决了媒体推荐中的冷启动问题，通过集成内容嵌入和知识传播机制，为大规模媒体平台提供了有效的推荐能力。

Abstract: We present a scalable recommender system implementation based on RippleNet,
tailored for the media domain with a production deployment in Onet.pl, one of
Poland's largest online media platforms. Our solution addresses the cold-start
problem for newly published content by integrating content-based item
embeddings into the knowledge propagation mechanism of RippleNet, enabling
effective scoring of previously unseen items. The system architecture leverages
Amazon SageMaker for distributed training and inference, and Apache Airflow for
orchestrating data pipelines and model retraining workflows. To ensure
high-quality training data, we constructed a comprehensive golden dataset
consisting of user and item features and a separate interaction table, all
enabling flexible extensions and integration of new signals.

</details>


### [2] [Enhancing Multimodal Recommendations with Vision-Language Models and Information-Aware Fusion](https://arxiv.org/abs/2511.02113)
*Hai-Dang Kieu,Min Xu,Thanh Trung Huynh,Dung D. Le*

Main category: cs.IR

TL;DR: VLIF是一个基于视觉语言和信息论的多模态推荐框架，通过视觉增强模块生成细粒度图像描述，并基于部分信息分解进行可控的多模态融合，显著提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态推荐方法依赖粗糙的视觉特征和不受控的融合，导致冗余或不对齐的表征，视觉编码器难以捕捉与物品相关的关键语义，限制了多模态融合的效果。

Method: 提出VLIF框架：1）基于VLM的视觉增强模块，生成细粒度的标题引导描述，将产品图像转换为语义对齐的表征；2）信息感知融合模块，基于部分信息分解理论，解耦模态间的冗余和协同信号进行可控集成。

Result: 在三个Amazon数据集上的实验表明，VLIF持续优于最新的多模态基线方法，并显著增强了视觉特征的贡献。

Conclusion: VLIF通过细粒度视觉表征和信息感知融合，有效提升了多模态推荐系统的性能，证明了信息论指导的多模态融合策略的有效性。

Abstract: Recent advances in multimodal recommendation (MMR) have shown that
incorporating rich content sources such as images and text can lead to
significant gains representation quality. However, existing methods often rely
on coarse visual features and uncontrolled fusion, leading to redundant or
misaligned representations. As a result, visual encoders often fail to capture
salient, item-relevant semantics, limiting their contribution in multimodal
fusion. From an information-theoretic perspective, effective fusion should
balance the unique, shared, and redundant information across modalities,
preserving complementary cues while avoiding correlation bias. This paper
presents VLIF, a vision-language and information-theoretic fusion framework
that enhances multimodal recommendation through two key components. (i) A
VLM-based visual enrichment module generates fine-grained, title-guided
descriptions to transform product images into semantically aligned
representations. (ii) An information-aware fusion module, inspired by Partial
Information Decomposition (PID), disentangles redundant and synergistic signals
across modalities for controlled integration. Experiments on three Amazon
datasets demonstrate that VLIF consistently outperforms recent multimodal
baselines and substantially strengthens the contribution of visual features.

</details>


### [3] [KGBridge: Knowledge-Guided Prompt Learning for Non-overlapping Cross-Domain Recommendation](https://arxiv.org/abs/2511.02181)
*Yuhan Wang,Qing Xie,Zhifeng Bao,Mengzi Tang,Lin Li,Yongjian Liu*

Main category: cs.IR

TL;DR: KGBridge是一个基于知识图谱的提示学习框架，用于解决非重叠用户场景下的跨域序列推荐问题，通过关系级语义建模和两阶段训练实现有效的知识迁移。


<details>
  <summary>Details</summary>
Motivation: 现有基于知识图谱的跨域推荐方法在非重叠用户场景下面临三大挑战：对知识图谱稀疏性和流行度偏差敏感、依赖重叠用户进行域对齐、缺乏可迁移知识和域特定知识的显式解耦。

Method: 提出KGBridge框架，包含两个核心组件：KG增强的提示编码器（将关系级语义建模为软提示）和两阶段训练范式（跨域预训练+隐私保护微调），通过关系感知语义控制和对应驱动解耦来分离域共享和域特定语义。

Result: 在基准数据集上的大量实验表明，KGBridge始终优于最先进的基线方法，并在不同知识图谱稀疏度下保持鲁棒性，有效缓解了结构不平衡和语义纠缠问题。

Conclusion: KGBridge通过结合结构化知识引导和提示学习，在非重叠用户场景下实现了稳定有效的跨域知识迁移，为知识图谱增强的跨域推荐提供了新思路。

Abstract: Knowledge Graphs (KGs), as structured knowledge bases that organize
relational information across diverse domains, provide a unified semantic
foundation for cross-domain recommendation (CDR). By integrating symbolic
knowledge with user-item interactions, KGs enrich semantic representations,
support reasoning, and enhance model interpretability. Despite this potential,
existing KG-based methods still face major challenges in CDR, particularly
under non-overlapping user scenarios. These challenges arise from: (C1)
sensitivity to KG sparsity and popularity bias, (C2) dependence on overlapping
users for domain alignment and (C3) lack of explicit disentanglement between
transferable and domain-specific knowledge, which limit effective and stable
knowledge transfer. To this end, we propose KGBridge, a knowledge-guided prompt
learning framework for cross-domain sequential recommendation under
non-overlapping user scenarios. KGBridge comprises two core components: a
KG-enhanced Prompt Encoder, which models relation-level semantics as soft
prompts to provide structured and dynamic priors for user sequence modeling
(addressing C1), and a Two-stage Training Paradigm, which combines cross-domain
pretraining and privacy-preserving fine-tuning to enable knowledge transfer
without user overlap (addressing C2). By combining relation-aware semantic
control with correspondence-driven disentanglement, KGBridge explicitly
separates and balances domain-shared and domain-specific semantics, thereby
maintaining complementarity and stabilizing adaptation during fine-tuning
(addressing C3). Extensive experiments on benchmark datasets demonstrate that
KGBridge consistently outperforms state-of-the-art baselines and remains robust
under varying KG sparsity, highlighting its effectiveness in mitigating
structural imbalance and semantic entanglement in KG-enhanced cross-domain
recommendation.

</details>


### [4] [Average Precision at Cutoff k under Random Rankings: Expectation and Variance](https://arxiv.org/abs/2511.02571)
*Tetiana Manzhos,Tetiana Ianevych,Olga Melnyk*

Main category: cs.IR

TL;DR: 本文推导了AP@k的期望和方差，为MAP@k建立了随机基准，有助于更可靠地评估推荐系统和信息检索平台的排名算法质量。


<details>
  <summary>Details</summary>
Motivation: 推荐系统和信息检索平台依赖排名算法向用户展示最相关的内容，需要可靠的评估指标。MAP@k被广泛使用，但需要建立随机基准来更好地解释观察到的评分。

Method: 推导了AP@k的期望和方差，覆盖了离线和在线两种广泛使用的评估模型。期望建立了随机基准，方差量化了随机波动程度。

Result: 得到了AP@k的期望和方差表达式，这些可以作为MAP@k的基准，帮助区分算法性能与随机波动。

Conclusion: AP@k的期望和方差为MAP@k提供了重要的统计基准，使评估结果更加可靠和可解释。

Abstract: Recommender systems and information retrieval platforms rely on ranking
algorithms to present the most relevant items to users, thereby improving
engagement and satisfaction. Assessing the quality of these rankings requires
reliable evaluation metrics. Among them, Mean Average Precision at cutoff k
(MAP@k) is widely used, as it accounts for both the relevance of items and
their positions in the list.
  In this paper, the expectation and variance of Average Precision at k (AP@k)
are derived since they can be used as biselines for MAP@k. Here, we covered two
widely used evaluation models: offline and online. The expectation establishes
the baseline, indicating the level of MAP@k that can be achieved by pure
chance. The variance complements this baseline by quantifying the extent of
random fluctuations, enabling a more reliable interpretation of observed
scores.

</details>
