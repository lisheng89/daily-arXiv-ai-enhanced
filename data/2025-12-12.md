<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 3]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [STARS: Semantic Tokens with Augmented Representations for Recommendation at Scale](https://arxiv.org/abs/2512.10149)
*Han Chen,Steven Zhu,Yingrui Li*

Main category: cs.IR

TL;DR: STARS是一个为大规模、低延迟电商推荐设计的Transformer框架，通过双记忆用户嵌入、语义物品标记、上下文感知评分和两阶段检索，在保持毫秒级响应时间的同时显著提升推荐效果。


<details>
  <summary>Details</summary>
Motivation: 现实电商推荐系统需要在严格的毫秒级延迟约束下提供相关推荐，同时应对冷启动产品、快速变化的用户意图以及季节性、节假日、促销等动态上下文挑战。

Method: STARS采用Transformer架构，包含：1) 分离长期偏好和短期会话意图的双记忆用户嵌入；2) 融合预训练文本嵌入、可学习增量、LLM生成属性标签的语义物品标记；3) 学习日历和事件偏移的上下文感知评分；4) 离线嵌入生成和在线最大内积搜索的两阶段检索流水线。

Result: 在离线评估中，STARS比现有LambdaMART系统提升Hit@5超过75%。在600万次访问的大规模A/B测试中，总订单数+0.8%，首页加购+2.0%，用户访问次数+0.5%，均具有统计显著性。

Conclusion: 结合语义增强、多意图建模和部署导向设计，可以在不牺牲服务效率的情况下，在现实环境中实现最先进的推荐质量。

Abstract: Real-world ecommerce recommender systems must deliver relevant items under strict tens-of-milliseconds latency constraints despite challenges such as cold-start products, rapidly shifting user intent, and dynamic context including seasonality, holidays, and promotions. We introduce STARS, a transformer-based sequential recommendation framework built for large-scale, low-latency ecommerce settings. STARS combines several innovations: dual-memory user embeddings that separate long-term preferences from short-term session intent; semantic item tokens that fuse pretrained text embeddings, learnable deltas, and LLM-derived attribute tags, strengthening content-based matching, long-tail coverage, and cold-start performance; context-aware scoring with learned calendar and event offsets; and a latency-conscious two-stage retrieval pipeline that performs offline embedding generation and online maximum inner-product search with filtering, enabling tens-of-milliseconds response times. In offline evaluations on production-scale data, STARS improves Hit@5 by more than 75 percent relative to our existing LambdaMART system. A large-scale A/B test on 6 million visits shows statistically significant lifts, including Total Orders +0.8%, Add-to-Cart on Home +2.0%, and Visits per User +0.5%. These results demonstrate that combining semantic enrichment, multi-intent modeling, and deployment-oriented design can yield state-of-the-art recommendation quality in real-world environments without sacrificing serving efficiency.

</details>


### [2] [The Best of the Two Worlds: Harmonizing Semantic and Hash IDs for Sequential Recommendation](https://arxiv.org/abs/2512.10388)
*Ziwei Liu,Yejing Wang,Qidong Liu,Zijian Zhang,Chong Chen,Wei Huang,Xiangyu Zhao*

Main category: cs.IR

TL;DR: H2Rec是一个新颖的序列推荐框架，通过协调语义ID和哈希ID来解决长尾问题，平衡头部和尾部物品的推荐质量。


<details>
  <summary>Details</summary>
Motivation: 传统序列推荐系统使用哈希ID嵌入容易受长尾问题影响，而现有结合辅助信息的方法存在噪声协作共享或语义同质化问题。语义ID虽然能进行代码共享和多粒度语义建模，但存在协作压倒现象，导致头部和尾部物品性能权衡困难。

Method: 提出H2Rec框架，采用双分支建模架构：一个分支捕捉语义ID的多粒度语义，另一个分支保留哈希ID的独特协作身份。同时引入双级对齐策略，桥接两种表示，促进知识转移和支持鲁棒的偏好建模。

Result: 在三个真实世界数据集上的广泛实验表明，H2Rec能有效平衡头部和尾部物品的推荐质量，并超越现有基线方法。

Conclusion: H2Rec通过协调语义ID和哈希ID，解决了传统推荐系统中的长尾问题，实现了头部和尾部物品推荐性能的平衡提升。

Abstract: Conventional Sequential Recommender Systems (SRS) typically assign unique Hash IDs (HID) to construct item embeddings. These HID embeddings effectively learn collaborative information from historical user-item interactions, making them vulnerable to situations where most items are rarely consumed (the long-tail problem). Recent methods that incorporate auxiliary information often suffer from noisy collaborative sharing caused by co-occurrence signals or semantic homogeneity caused by flat dense embeddings. Semantic IDs (SIDs), with their capability of code sharing and multi-granular semantic modeling, provide a promising alternative. However, the collaborative overwhelming phenomenon hinders the further development of SID-based methods. The quantization mechanisms commonly compromise the uniqueness of identifiers required for modeling head items, creating a performance seesaw between head and tail items. To address this dilemma, we propose \textbf{\name}, a novel framework that harmonizes the SID and HID. Specifically, we devise a dual-branch modeling architecture that enables the model to capture both the multi-granular semantics within SID while preserving the unique collaborative identity of HID. Furthermore, we introduce a dual-level alignment strategy that bridges the two representations, facilitating knowledge transfer and supporting robust preference modeling. Extensive experiments on three real-world datasets show that \name~ effectively balances recommendation quality for both head and tail items while surpassing the existing baselines. The implementation code can be found online\footnote{https://github.com/ziwliu8/H2Rec}.

</details>


### [3] [Rethinking Popularity Bias in Collaborative Filtering via Analytical Vector Decomposition](https://arxiv.org/abs/2512.10688)
*Lingfeng Liu,Yixin Song,Dazhong Shen,Bing Yin,Hao Li,Yanyong Zhang,Chao Wang*

Main category: cs.IR

TL;DR: 本文揭示了协同过滤中流行度偏差的本质是贝叶斯成对排序优化的几何伪影，并提出方向分解与校正框架来从几何源头上解耦偏好与流行度。


<details>
  <summary>Details</summary>
Motivation: 流行度偏差严重削弱了协同过滤模型的个性化能力，导致过度推荐流行项目而忽视用户对小众内容的真实偏好。现有方法将其视为外部混杂因素，但本文发现流行度偏差实际上是贝叶斯成对排序优化固有的几何伪影。

Method: 提出方向分解与校正框架，通过非对称方向更新来精确校正嵌入几何。该框架引导正向交互沿着个性化偏好方向，同时引导负向交互远离全局流行度方向，从几何源头上解耦偏好与流行度。

Result: 在多个基于BPR的架构上进行广泛实验，DDC显著优于最先进的去偏方法，将训练损失降低到高度调优基线的不到5%，同时实现了更优的推荐质量和公平性。

Conclusion: 流行度偏差是BPR优化的固有几何特性而非外部混杂因素，DDC框架通过几何校正有效解决了这一问题，为协同过滤中的去偏提供了新的理论视角和实践方法。

Abstract: Popularity bias fundamentally undermines the personalization capabilities of collaborative filtering (CF) models, causing them to disproportionately recommend popular items while neglecting users' genuine preferences for niche content. While existing approaches treat this as an external confounding factor, we reveal that popularity bias is an intrinsic geometric artifact of Bayesian Pairwise Ranking (BPR) optimization in CF models. Through rigorous mathematical analysis, we prove that BPR systematically organizes item embeddings along a dominant "popularity direction" where embedding magnitudes directly correlate with interaction frequency. This geometric distortion forces user embeddings to simultaneously handle two conflicting tasks-expressing genuine preference and calibrating against global popularity-trapping them in suboptimal configurations that favor popular items regardless of individual tastes. We propose Directional Decomposition and Correction (DDC), a universally applicable framework that surgically corrects this embedding geometry through asymmetric directional updates. DDC guides positive interactions along personalized preference directions while steering negative interactions away from the global popularity direction, disentangling preference from popularity at the geometric source. Extensive experiments across multiple BPR-based architectures demonstrate that DDC significantly outperforms state-of-the-art debiasing methods, reducing training loss to less than 5% of heavily-tuned baselines while achieving superior recommendation quality and fairness. Code is available in https://github.com/LingFeng-Liu-AI/DDC.

</details>
