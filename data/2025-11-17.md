<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 6]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [LEMUR: Large scale End-to-end MUltimodal Recommendation](https://arxiv.org/abs/2511.10962)
*Xintian Han,Honggang Chen,Quan Lin,Jingyue Gao,Xiangyuan Ren,Lifei Zhu,Zhisheng Ye,Shikang Wu,XiongHang Xie,Xiaochu Gan,Bingzheng Wei,Peng Xu,Zhe Wang,Yuchao Zheng,Jingjian Lin,Di Wu,Junfeng Ge*

Main category: cs.IR

TL;DR: LEMUR是首个从原始数据端到端训练的大规模多模态推荐系统，通过联合优化多模态和推荐组件，解决了传统两阶段训练中的目标不一致问题，并在抖音搜索和广告中取得了显著效果提升。


<details>
  <summary>Details</summary>
Motivation: 传统基于ID的推荐系统在冷启动和泛化方面存在困难，而现有的多模态推荐系统采用两阶段训练范式，导致多模态学习与推荐目标不一致，且无法动态适应新数据。

Method: 提出LEMUR系统，采用端到端训练方式联合优化多模态和推荐组件；引入新颖的记忆库机制，在训练过程中增量累积历史多模态表示，以降低计算成本。

Result: 在抖音搜索部署一个月后，LEMUR使查询变更率衰减减少0.843%，QAUC提升0.81%；在抖音广告的多个离线指标上也显示出显著增益。

Conclusion: 结果验证了端到端多模态推荐在真实工业场景中的优越性，为推荐系统的发展提供了新的方向。

Abstract: Traditional ID-based recommender systems often struggle with cold-start and generalization challenges. Multimodal recommendation systems, which leverage textual and visual data, offer a promising solution to mitigate these issues. However, existing industrial approaches typically adopt a two-stage training paradigm: first pretraining a multimodal model, then applying its frozen representations to train the recommendation model. This decoupled framework suffers from misalignment between multimodal learning and recommendation objectives, as well as an inability to adapt dynamically to new data. To address these limitations, we propose LEMUR, the first large-scale multimodal recommender system trained end-to-end from raw data. By jointly optimizing both the multimodal and recommendation components, LEMUR ensures tighter alignment with downstream objectives while enabling real-time parameter updates. Constructing multimodal sequential representations from user history often entails prohibitively high computational costs. To alleviate this bottleneck, we propose a novel memory bank mechanism that incrementally accumulates historical multimodal representations throughout the training process. After one month of deployment in Douyin Search, LEMUR has led to a 0.843% reduction in query change rate decay and a 0.81% improvement in QAUC. Additionally, LEMUR has shown significant gains across key offline metrics for Douyin Advertisement. Our results validate the superiority of end-to-end multimodal recommendation in real-world industrial scenarios.

</details>


### [2] [GovScape: A Public Multimodal Search System for 70 Million Pages of Government PDFs](https://arxiv.org/abs/2511.11010)
*Kyle Deeds,Ying-Hsiang Huang,Claire Gong,Shreya Shaji,Alison Yan,Leslie Harka,Samuel J Klein,Shannon Zejiang Shen,Mark Phillips,Trevor Owens,Benjamin Charles Germain Lee*

Main category: cs.IR

TL;DR: GovScape是一个支持多模态搜索的公共系统，可对1000万份政府PDF文件进行元数据过滤、精确文本搜索、语义文本搜索和视觉搜索。


<details>
  <summary>Details</summary>
Motivation: 现有的网页档案虽然保存了大量政府PDF文件，但在访问和发现方面存在显著挑战，目前的浏览方式仅限于下载单个PDF和基本关键词搜索。

Method: 构建了包含元数据过滤、精确文本搜索、语义文本搜索和视觉搜索的多模态搜索系统，支持对1000万份PDF文件进行跨页搜索。

Result: 成功开发了GovScape系统，处理1000万份PDF的总计算成本约为1500美元，相当于每美元处理47000页PDF，展示了良好的可扩展性。

Conclusion: GovScape证明了大规模多模态搜索的可行性，并已开始向1亿+PDF规模扩展，为政府文档的访问和发现提供了新的解决方案。

Abstract: Efforts over the past three decades have produced web archives containing billions of webpage snapshots and petabytes of data. The End of Term Web Archive alone contains, among other file types, millions of PDFs produced by the federal government. While preservation with web archives has been successful, significant challenges for access and discoverability remain. For example, current affordances for browsing the End of Term PDFs are limited to downloading and browsing individual PDFs, as well as performing basic keyword search across them. In this paper, we introduce GovScape, a public search system that supports multimodal searches across 10,015,993 federal government PDFs from the 2020 End of Term crawl (70,958,487 total PDF pages) - to our knowledge, all renderable PDFs in the 2020 crawl that are 50 pages or under. GovScape supports four primary forms of search over these 10 million PDFs: in addition to providing (1) filter conditions over metadata facets including domain and crawl date and (2) exact text search against the PDF text, we provide (3) semantic text search and (4) visual search against the PDFs across individual pages, enabling users to structure queries such as "redacted documents" or "pie charts." We detail the constituent components of GovScape, including the search affordances, embedding pipeline, system architecture, and open source codebase. Significantly, the total estimated compute cost for GovScape's pre-processing pipeline for 10 million PDFs was approximately $1,500, equivalent to 47,000 PDF pages per dollar spent on compute, demonstrating the potential for immediate scalability. Accordingly, we outline steps that we have already begun pursuing toward multimodal search at the 100+ million PDF scale. GovScape can be found at https://www.govscape.net.

</details>


### [3] [Enhancing Group Recommendation using Soft Impute Singular Value Decomposition](https://arxiv.org/abs/2511.11172)
*Mubaraka Sani Ibrahim,Isah Charles Saidu,Lehel Csato*

Main category: cs.IR

TL;DR: 提出了一种基于软插补奇异值分解的群组推荐系统Group Soft-Impute SVD，用于解决群组推荐中的数据稀疏性和高维性问题。


<details>
  <summary>Details</summary>
Motivation: 随着群组活动的普及，需要基于群组成员集体偏好为群组提供推荐。现有群组推荐系统在处理稀疏高维数据时面临挑战。

Method: 使用软插补奇异值分解(SVD)进行低秩矩阵补全，通过Group Soft-Impute SVD方法增强群组推荐性能。

Result: 在Goodbooks、Movielens和合成数据集上，该方法在小用户群组的召回率上优于基于群组矩阵分解的基线方法，在所有群组规模上都能达到可比结果，且能恢复更低的矩阵秩。

Conclusion: Group Soft-Impute SVD方法能有效处理高维稀疏数据，在群组推荐任务中表现优异。

Abstract: The growing popularity of group activities increased the need to develop methods for providing recommendations to a group of users based on the collective preferences of the group members. Several group recommender systems have been proposed, but these methods often struggle due to sparsity and high-dimensionality of the available data, common in many real-world applications. In this paper, we propose a group recommender system called Group Soft-Impute SVD, which leverages soft-impute singular value decomposition to enhance group recommendations. This approach addresses the challenge of sparse high-dimensional data using low-rank matrix completion. We compared the performance of Group Soft-Impute SVD with Group MF based approaches and found that our method outperforms the baselines in recall for small user groups while achieving comparable results across all group sizes when tasked on Goodbooks, Movielens, and Synthetic datasets. Furthermore, our method recovers lower matrix ranks than the baselines, demonstrating its effectiveness in handling high-dimensional data.

</details>


### [4] [Align$^3$GR: Unified Multi-Level Alignment for LLM-based Generative Recommendation](https://arxiv.org/abs/2511.11255)
*Wencai Ye,Mingjie Sun,Shuhang Chen,Wenjin Wu,Peng Jiang*

Main category: cs.IR

TL;DR: Align³GR是一个新颖的推荐系统框架，通过统一token级、行为建模级和偏好级对齐，解决LLMs在推荐系统中的语义和行为不对齐问题，在公开数据集上显著超越SOTA基线。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在利用结构化世界知识和多步推理方面具有优势，但将其转化为现实推荐系统时面临语义和行为不对齐的根本挑战。

Method: 提出Align³GR框架：双tokenization融合用户-项目语义和协同信号；增强的行为建模与双向语义对齐；结合自博弈和真实世界反馈的渐进式DPO策略进行动态偏好适应。

Result: 在公开数据集上Recall@10提升17.8%，NDCG@10提升20.2%；在线A/B测试和工业级大规模推荐平台部署中均取得显著收益。

Conclusion: Align³GR通过多层次对齐策略有效解决了LLMs在推荐系统中的对齐问题，在离线评估和在线部署中均表现出卓越性能。

Abstract: Large Language Models (LLMs) demonstrate significant advantages in leveraging structured world knowledge and multi-step reasoning capabilities. However, fundamental challenges arise when transforming LLMs into real-world recommender systems due to semantic and behavioral misalignment. To bridge this gap, we propose Align$^3$GR, a novel framework that unifies token-level, behavior modeling-level, and preference-level alignment. Our approach introduces: Dual tokenization fusing user-item semantic and collaborative signals. Enhanced behavior modeling with bidirectional semantic alignment. Progressive DPO strategy combining self-play (SP-DPO) and real-world feedback (RF-DPO) for dynamic preference adaptation. Experiments show Align$^3$GR outperforms the SOTA baseline by +17.8% in Recall@10 and +20.2% in NDCG@10 on the public dataset, with significant gains in online A/B tests and full-scale deployment on an industrial large-scale recommendation platform.

</details>


### [5] [MOON Embedding: Multimodal Representation Learning for E-commerce Search Advertising](https://arxiv.org/abs/2511.11305)
*Chenghan Fu,Daoze Zhang,Yukang Lin,Zhanheng Nie,Xiang Zhang,Jianyu Liu,Yueran Liu,Wanxian Guan,Pengjie Wang,Jian Xu,Bo Zheng*

Main category: cs.IR

TL;DR: MOON是一个用于电商多模态表示学习的可持续迭代实践框架，已在淘宝搜索广告系统中全面部署，在CTR预测任务上实现20%的在线提升。


<details>
  <summary>Details</summary>
Motivation: 解决多模态表示学习与下游任务目标之间的不对齐问题，通过定义交换率来量化中间指标改进对下游收益的转化效果。

Method: 采用三阶段训练范式：预训练、后训练和应用，重点关注数据处理、训练策略、模型架构和下游应用四个维度的优化。

Result: 在CTR预测任务上实现20%的在线提升，这是三年来该任务上最大的改进，并完成了五次全规模迭代。

Conclusion: MOON框架通过系统化的迭代优化，为电商领域的多模态表示学习提供了有效的实践经验和可扩展性研究。

Abstract: We introduce MOON, our comprehensive set of sustainable iterative practices for multimodal representation learning for e-commerce applications. MOON has already been fully deployed across all stages of Taobao search advertising system, including retrieval, relevance, ranking, and so on. The performance gains are particularly significant on click-through rate (CTR) prediction task, which achieves an overall +20.00% online CTR improvement. Over the past three years, this project has delivered the largest improvement on CTR prediction task and undergone five full-scale iterations. Throughout the exploration and iteration of our MOON, we have accumulated valuable insights and practical experience that we believe will benefit the research community. MOON contains a three-stage training paradigm of "Pretraining, Post-training, and Application", allowing effective integration of multimodal representations with downstream tasks. Notably, to bridge the misalignment between the objectives of multimodal representation learning and downstream training, we define the exchange rate to quantify how effectively improvements in an intermediate metric can translate into downstream gains. Through this analysis, we identify the image-based search recall as a critical intermediate metric guiding the optimization of multimodal models. Over three years and five iterations, MOON has evolved along four critical dimensions: data processing, training strategy, model architecture, and downstream application. The lessons and insights gained through the iterative improvements will also be shared. As part of our exploration into scaling effects in the e-commerce field, we further conduct a systematic study of the scaling laws governing multimodal representation learning, examining multiple factors such as the number of training tokens, negative samples, and the length of user behavior sequences.

</details>


### [6] [SRLF: An Agent-Driven Set-Wise Reflective Learning Framework for Sequential Recommendation](https://arxiv.org/abs/2511.11370)
*Jiahao Wang,Bokang Fu,Yu Zhu,Yuli Liu*

Main category: cs.IR

TL;DR: 提出基于集合的反思学习框架SRLF，通过"评估-验证-反思"闭环机制，利用LLM的上下文学习能力对整组物品进行整体判断，解决了传统点式方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理主要关注单个物品评分建模，导致用户偏好理解不准确和物品语义表示僵化，需要更全面的方法来解决这些问题。

Method: SRLF框架采用集合层面的评估方法，综合分析物品间的复杂相互关系及其与用户偏好的整体匹配度，通过闭环学习机制提升推荐效果。

Result: 大量实验验证了该方法的有效性，在序列推荐任务中达到了最先进的性能水平。

Conclusion: 集合视角对于实现序列推荐任务的最优性能至关重要，SRLF框架为解决传统点式方法的局限性提供了有效方案。

Abstract: LLM-based agents are emerging as a promising paradigm for simulating user behavior to enhance recommender systems. However, their effectiveness is often limited by existing studies that focus on modeling user ratings for individual items. This point-wise approach leads to prevalent issues such as inaccurate user preference comprehension and rigid item-semantic representations.
  To address these limitations, we propose the novel Set-wise Reflective Learning Framework (SRLF). Our framework operationalizes a closed-loop "assess-validate-reflect" cycle that harnesses the powerful in-context learning capabilities of LLMs. SRLF departs from conventional point-wise assessment by formulating a holistic judgment on an entire set of items. It accomplishes this by comprehensively analyzing both the intricate interrelationships among items within the set and their collective alignment with the user's preference profile. This method of set-level contextual understanding allows our model to capture complex relational patterns essential to user behavior, making it significantly more adept for sequential recommendation. Extensive experiments validate our approach, confirming that this set-wise perspective is crucial for achieving state-of-the-art performance in sequential recommendation tasks.

</details>
