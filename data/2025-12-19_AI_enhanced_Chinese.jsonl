{"id": "2512.16033", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.16033", "abs": "https://arxiv.org/abs/2512.16033", "authors": ["Qihao Wang", "Pritom Saha Akash", "Varvara Kollia", "Kevin Chen-Chuan Chang", "Biwei Jiang", "Vadim Von Brzeski"], "title": "On Recommending Category: A Cascading Approach", "comment": null, "summary": "Recommendation plays a key role in e-commerce, enhancing user experience and boosting commercial success. Existing works mainly focus on recommending a set of items, but online e-commerce platforms have recently begun to pay attention to exploring users' potential interests at the category level. Category-level recommendation allows e-commerce platforms to promote users' engagements by expanding their interests to different types of items. In addition, it complements item-level recommendations when the latter becomes extremely challenging for users with little-known information and past interactions. Furthermore, it facilitates item-level recommendations in existing works. The predicted category, which is called intention in those works, aids the exploration of item-level preference. However, such category-level preference prediction has mostly been accomplished through applying item-level models. Some key differences between item-level recommendations and category-level recommendations are ignored in such a simplistic adaptation. In this paper, we propose a cascading category recommender (CCRec) model with a variational autoencoder (VAE) to encode item-level information to perform category-level recommendations. Experiments show the advantages of this model over methods designed for item-level recommendations.", "AI": {"tldr": "\u63d0\u51faCCRec\u6a21\u578b\uff0c\u4f7f\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7f16\u7801\u5546\u54c1\u7ea7\u4fe1\u606f\u8fdb\u884c\u54c1\u7c7b\u7ea7\u63a8\u8350\uff0c\u76f8\u6bd4\u5546\u54c1\u7ea7\u63a8\u8350\u65b9\u6cd5\u6709\u4f18\u52bf", "motivation": "\u7535\u5546\u5e73\u53f0\u5f00\u59cb\u5173\u6ce8\u54c1\u7c7b\u7ea7\u63a8\u8350\u4ee5\u6269\u5c55\u7528\u6237\u5174\u8da3\uff0c\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5c06\u5546\u54c1\u7ea7\u6a21\u578b\u7b80\u5355\u9002\u914d\u5230\u54c1\u7c7b\u7ea7\u63a8\u8350\uff0c\u5ffd\u7565\u4e86\u4e8c\u8005\u5173\u952e\u5dee\u5f02", "method": "\u63d0\u51fa\u7ea7\u8054\u54c1\u7c7b\u63a8\u8350\u5668(CCRec)\u6a21\u578b\uff0c\u4f7f\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668(VAE)\u7f16\u7801\u5546\u54c1\u7ea7\u4fe1\u606f\u6765\u6267\u884c\u54c1\u7c7b\u7ea7\u63a8\u8350", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u6a21\u578b\u76f8\u6bd4\u4e3a\u5546\u54c1\u7ea7\u63a8\u8350\u8bbe\u8ba1\u7684\u65b9\u6cd5\u5177\u6709\u4f18\u52bf", "conclusion": "CCRec\u6a21\u578b\u80fd\u6709\u6548\u8fdb\u884c\u54c1\u7c7b\u7ea7\u63a8\u8350\uff0c\u89e3\u51b3\u4e86\u5546\u54c1\u7ea7\u6a21\u578b\u7b80\u5355\u9002\u914d\u5230\u54c1\u7c7b\u7ea7\u63a8\u8350\u65f6\u5ffd\u7565\u7684\u5173\u952e\u5dee\u5f02\u95ee\u9898"}}
{"id": "2512.16236", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16236", "abs": "https://arxiv.org/abs/2512.16236", "authors": ["Tejul Pandit", "Sakshi Mahendru", "Meet Raval", "Dhvani Upadhyay"], "title": "The Evolution of Reranking Models in Information Retrieval: From Heuristic Methods to Large Language Models", "comment": "15 pages, 1 figure, Accepted in CLNLP'25", "summary": "Reranking is a critical stage in contemporary information retrieval (IR) systems, improving the relevance of the user-presented final results by honing initial candidate sets. This paper is a thorough guide to examine the changing reranker landscape and offer a clear view of the advancements made in reranking methods. We present a comprehensive survey of reranking models employed in IR, particularly within modern Retrieval Augmented Generation (RAG) pipelines, where retrieved documents notably influence output quality.\n  We embark on a chronological journey through the historical trajectory of reranking techniques, starting with foundational approaches, before exploring the wide range of sophisticated neural network architectures such as cross-encoders, sequence-generation models like T5, and Graph Neural Networks (GNNs) utilized for structural information. Recognizing the computational cost of advancing neural rerankers, we analyze techniques for enhancing efficiency, notably knowledge distillation for creating competitive, lighter alternatives. Furthermore, we map the emerging territory of integrating Large Language Models (LLMs) in reranking, examining novel prompting strategies and fine-tuning tactics. This survey seeks to elucidate the fundamental ideas, relative effectiveness, computational features, and real-world trade-offs of various reranking strategies. The survey provides a structured synthesis of the diverse reranking paradigms, highlighting their underlying principles and comparative strengths and weaknesses.", "AI": {"tldr": "\u672c\u6587\u662f\u4e00\u7bc7\u5173\u4e8e\u4fe1\u606f\u68c0\u7d22\u4e2d\u91cd\u6392\u5e8f\u6280\u672f\u7684\u5168\u9762\u7efc\u8ff0\uff0c\u7cfb\u7edf\u68b3\u7406\u4e86\u4ece\u57fa\u7840\u65b9\u6cd5\u5230\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u7684\u53d1\u5c55\u5386\u7a0b\uff0c\u7279\u522b\u5173\u6ce8\u4e86\u5728RAG\u7ba1\u9053\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u5206\u6790\u4e86\u6548\u7387\u4f18\u5316\u548cLLM\u96c6\u6210\u7b49\u524d\u6cbf\u65b9\u5411\u3002", "motivation": "\u91cd\u6392\u5e8f\u662f\u73b0\u4ee3\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u7684\u5173\u952e\u73af\u8282\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u6700\u7ec8\u7ed3\u679c\u7684\u76f8\u5173\u6027\u3002\u968f\u7740\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7ba1\u9053\u7684\u5174\u8d77\uff0c\u91cd\u6392\u5e8f\u6280\u672f\u5bf9\u8f93\u51fa\u8d28\u91cf\u7684\u5f71\u54cd\u65e5\u76ca\u91cd\u8981\u3002\u7136\u800c\uff0c\u8be5\u9886\u57df\u7f3a\u4e4f\u7cfb\u7edf\u7684\u7efc\u8ff0\u6765\u68b3\u7406\u6280\u672f\u53d1\u5c55\u8109\u7edc\u3001\u6bd4\u8f83\u4e0d\u540c\u65b9\u6cd5\u7684\u4f18\u52a3\uff0c\u4ee5\u53ca\u5206\u6790\u8ba1\u7b97\u6548\u7387\u4e0e\u6027\u80fd\u7684\u6743\u8861\u3002", "method": "\u91c7\u7528\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u6309\u65f6\u95f4\u987a\u5e8f\u68b3\u7406\u91cd\u6392\u5e8f\u6280\u672f\u7684\u53d1\u5c55\u5386\u7a0b\uff1a\u4ece\u57fa\u7840\u65b9\u6cd5\u5f00\u59cb\uff0c\u5230\u4ea4\u53c9\u7f16\u7801\u5668\u3001T5\u7b49\u5e8f\u5217\u751f\u6210\u6a21\u578b\u3001\u56fe\u795e\u7ecf\u7f51\u7edc\u7b49\u590d\u6742\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u3002\u540c\u65f6\u5206\u6790\u6548\u7387\u4f18\u5316\u6280\u672f\uff08\u5982\u77e5\u8bc6\u84b8\u998f\uff09\uff0c\u5e76\u63a2\u8ba8\u5927\u8bed\u8a00\u6a21\u578b\u5728\u91cd\u6392\u5e8f\u4e2d\u7684\u96c6\u6210\u7b56\u7565\uff08\u63d0\u793a\u5de5\u7a0b\u548c\u5fae\u8c03\uff09\u3002", "result": "\u63d0\u4f9b\u4e86\u91cd\u6392\u5e8f\u6280\u672f\u7684\u7ed3\u6784\u5316\u7efc\u5408\uff0c\u9610\u660e\u4e86\u4e0d\u540c\u8303\u5f0f\u7684\u57fa\u672c\u539f\u7406\u3001\u76f8\u5bf9\u6709\u6548\u6027\u3001\u8ba1\u7b97\u7279\u6027\u548c\u5b9e\u9645\u6743\u8861\u3002\u7279\u522b\u5f3a\u8c03\u4e86\u5728RAG\u7ba1\u9053\u4e2d\u91cd\u6392\u5e8f\u5bf9\u68c0\u7d22\u6587\u6863\u8d28\u91cf\u7684\u5173\u952e\u5f71\u54cd\uff0c\u4ee5\u53ca\u8f7b\u91cf\u5316\u6a21\u578b\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u5b9e\u73b0\u7ade\u4e89\u6027\u6027\u80fd\u7684\u53ef\u80fd\u6027\u3002", "conclusion": "\u91cd\u6392\u5e8f\u6280\u672f\u7ecf\u5386\u4e86\u4ece\u4f20\u7edf\u65b9\u6cd5\u5230\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u663e\u8457\u6f14\u8fdb\uff0c\u5728\u63d0\u5347\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u6027\u80fd\u65b9\u9762\u53d1\u6325\u5173\u952e\u4f5c\u7528\u3002\u672a\u6765\u53d1\u5c55\u65b9\u5411\u5305\u62ec\uff1a\u8fdb\u4e00\u6b65\u4f18\u5316\u8ba1\u7b97\u6548\u7387\u3001\u66f4\u6df1\u5165\u5730\u96c6\u6210\u5927\u8bed\u8a00\u6a21\u578b\u3001\u4ee5\u53ca\u63a2\u7d22\u5728\u590d\u6742\u68c0\u7d22\u573a\u666f\uff08\u5982RAG\uff09\u4e2d\u7684\u521b\u65b0\u5e94\u7528\u3002\u8be5\u7efc\u8ff0\u4e3a\u7814\u7a76\u8005\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u7cfb\u7edf\u7684\u6280\u672f\u8def\u7ebf\u56fe\u3002"}}
{"id": "2512.16348", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.16348", "abs": "https://arxiv.org/abs/2512.16348", "authors": ["Shayan Azizi", "Norihiro Okui", "Masataka Nakahara", "Ayumu Kubota", "Hassan Habibi Gharakheili"], "title": "From Flows to Functions: Macroscopic Behavioral Fingerprinting of IoT Devices via Network Services", "comment": "10 pages, 3 figures, 1 table, and 1 algorithm", "summary": "Identifying devices such as cameras, printers, voice assistants, or health monitoring sensors, collectively known as the Internet of Things (IoT), within a network is a critical operational task, particularly to manage the cyber risks they introduce. While behavioral fingerprinting based on network traffic analysis has shown promise, most existing approaches rely on machine learning (ML) techniques applied to fine-grained features of short-lived traffic units (packets and/or flows). These methods tend to be computationally expensive, sensitive to traffic measurement errors, and often produce opaque inferences. In this paper, we propose a macroscopic, lightweight, and explainable alternative to behavioral fingerprinting focusing on the network services (e.g., TCP/80, UDP/53) that IoT devices use to perform their intended functions over extended periods. Our contributions are threefold. (1) We demonstrate that IoT devices exhibit stable and distinguishable patterns in their use of network services over a period of time. We formalize the notion of service-level fingerprints and derive a generalized method to represent network behaviors using a configurable granularity parameter. (2) We develop a procedure to extract service-level fingerprints, apply it to traffic from 13 consumer IoT device types in a lab testbed, and evaluate the resulting representations in terms of their convergence and recurrence properties. (3) We validate the efficacy of service-level fingerprints for device identification in closed-set and open-set scenarios. Our findings are based on a large dataset comprising about 10 million IPFIX flow records collected over a 1.5-year period.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7f51\u7edc\u670d\u52a1\u4f7f\u7528\u6a21\u5f0f\u7684\u5b8f\u89c2\u3001\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u7684IoT\u8bbe\u5907\u6307\u7eb9\u8bc6\u522b\u65b9\u6cd5\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684\u7ec6\u7c92\u5ea6\u6d41\u91cf\u5206\u6790\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u7ec6\u7c92\u5ea6\u6d41\u91cf\u7279\u5f81\u7684IoT\u8bbe\u5907\u8bc6\u522b\u65b9\u6cd5\u8ba1\u7b97\u5f00\u9500\u5927\u3001\u5bf9\u6d4b\u91cf\u8bef\u5dee\u654f\u611f\u3001\u63a8\u7406\u4e0d\u900f\u660e\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u9c81\u68d2\u3001\u53ef\u89e3\u91ca\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u670d\u52a1\u7ea7\u6307\u7eb9\u6982\u5ff5\uff0c\u57fa\u4e8e\u8bbe\u5907\u957f\u671f\u4f7f\u7528\u7684\u7f51\u7edc\u670d\u52a1\u6a21\u5f0f\uff08\u5982TCP/80\u3001UDP/53\uff09\u6784\u5efa\u53ef\u914d\u7f6e\u7c92\u5ea6\u7684\u884c\u4e3a\u8868\u793a\uff0c\u5e76\u5f00\u53d1\u6307\u7eb9\u63d0\u53d6\u6d41\u7a0b\u3002", "result": "\u572813\u79cd\u6d88\u8d39\u7ea7IoT\u8bbe\u5907\u7684\u5b9e\u9a8c\u5ba4\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u670d\u52a1\u7ea7\u6307\u7eb9\u7684\u6536\u655b\u6027\u548c\u91cd\u590d\u6027\uff0c\u57fa\u4e8e150\u4e07\u6761IPFIX\u6d41\u8bb0\u5f55\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u5728\u5c01\u95ed\u96c6\u548c\u5f00\u653e\u96c6\u573a\u666f\u4e0b\u5747\u6709\u6548\u8bc6\u522b\u8bbe\u5907\u3002", "conclusion": "\u670d\u52a1\u7ea7\u6307\u7eb9\u63d0\u4f9b\u4e86\u4e00\u79cd\u7a33\u5b9a\u3001\u53ef\u533a\u5206\u3001\u8f7b\u91cf\u7ea7\u4e14\u53ef\u89e3\u91ca\u7684IoT\u8bbe\u5907\u8bc6\u522b\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u7ba1\u7406\u7269\u8054\u7f51\u8bbe\u5907\u5e26\u6765\u7684\u7f51\u7edc\u5b89\u5168\u98ce\u9669\u3002"}}
{"id": "2512.16425", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16425", "abs": "https://arxiv.org/abs/2512.16425", "authors": ["Allard Oelen", "Mohamad Yaser Jaradeh", "S\u00f6ren Auer"], "title": "Introducing ORKG ASK: an AI-driven Scholarly Literature Search and Exploration System Taking a Neuro-Symbolic Approach", "comment": null, "summary": "As the volume of published scholarly literature continues to grow, finding relevant literature becomes increasingly difficult. With the rise of generative Artificial Intelligence (AI), and particularly Large Language Models (LLMs), new possibilities emerge to find and explore literature. We introduce ASK (Assistant for Scientific Knowledge), an AI-driven scholarly literature search and exploration system that follows a neuro-symbolic approach. ASK aims to provide active support to researchers in finding relevant scholarly literature by leveraging vector search, LLMs, and knowledge graphs. The system allows users to input research questions in natural language and retrieve relevant articles. ASK automatically extracts key information and generates answers to research questions using a Retrieval-Augmented Generation (RAG) approach. We present an evaluation of ASK, assessing the system's usability and usefulness. Findings indicate that the system is user-friendly and users are generally satisfied while using the system.", "AI": {"tldr": "ASK\u662f\u4e00\u4e2a\u57fa\u4e8e\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u7684AI\u9a71\u52a8\u5b66\u672f\u6587\u732e\u641c\u7d22\u7cfb\u7edf\uff0c\u7ed3\u5408\u5411\u91cf\u641c\u7d22\u3001\u5927\u8bed\u8a00\u6a21\u578b\u548c\u77e5\u8bc6\u56fe\u8c31\uff0c\u5e2e\u52a9\u7814\u7a76\u8005\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63d0\u95ee\u627e\u5230\u76f8\u5173\u6587\u732e\u5e76\u751f\u6210\u7b54\u6848\u3002", "motivation": "\u968f\u7740\u5b66\u672f\u6587\u732e\u6570\u91cf\u5feb\u901f\u589e\u957f\uff0c\u5bfb\u627e\u76f8\u5173\u6587\u732e\u53d8\u5f97\u8d8a\u6765\u8d8a\u56f0\u96be\u3002\u751f\u6210\u5f0fAI\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5174\u8d77\u4e3a\u6587\u732e\u53d1\u73b0\u548c\u63a2\u7d22\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002", "method": "\u91c7\u7528\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u7ed3\u5408\u5411\u91cf\u641c\u7d22\u3001\u5927\u8bed\u8a00\u6a21\u578b\u548c\u77e5\u8bc6\u56fe\u8c31\u3002\u7cfb\u7edf\u4f7f\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u65b9\u6cd5\uff0c\u5141\u8bb8\u7528\u6237\u8f93\u5165\u81ea\u7136\u8bed\u8a00\u7814\u7a76\u95ee\u9898\uff0c\u81ea\u52a8\u63d0\u53d6\u5173\u952e\u4fe1\u606f\u5e76\u751f\u6210\u7b54\u6848\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u7cfb\u7edf\u7528\u6237\u53cb\u597d\uff0c\u7528\u6237\u5728\u4f7f\u7528\u8fc7\u7a0b\u4e2d\u666e\u904d\u6ee1\u610f\u3002\u7cfb\u7edf\u5728\u53ef\u7528\u6027\u548c\u5b9e\u7528\u6027\u65b9\u9762\u8868\u73b0\u826f\u597d\u3002", "conclusion": "ASK\u7cfb\u7edf\u6210\u529f\u5c55\u793a\u4e86AI\u9a71\u52a8\u5b66\u672f\u6587\u732e\u641c\u7d22\u7684\u6f5c\u529b\uff0c\u901a\u8fc7\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u6709\u6548\u652f\u6301\u7814\u7a76\u8005\u53d1\u73b0\u548c\u63a2\u7d22\u76f8\u5173\u5b66\u672f\u6587\u732e\u3002"}}
{"id": "2512.16576", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.16576", "abs": "https://arxiv.org/abs/2512.16576", "authors": ["Xufeng Liang", "Zhida Qin", "Chong Zhang", "Tianyu Huang", "Gangyi Ding"], "title": "InfoDCL: Informative Noise Enhanced Diffusion Based Contrastive Learning", "comment": null, "summary": "Contrastive learning has demonstrated promising potential in recommender systems. Existing methods typically construct sparser views by randomly perturbing the original interaction graph, as they have no idea about the authentic user preferences. Owing to the sparse nature of recommendation data, this paradigm can only capture insufficient semantic information. To address the issue, we propose InfoDCL, a novel diffusion-based contrastive learning framework for recommendation. Rather than injecting randomly sampled Gaussian noise, we employ a single-step diffusion process that integrates noise with auxiliary semantic information to generate signals and feed them to the standard diffusion process to generate authentic user preferences as contrastive views. Besides, based on a comprehensive analysis of the mutual influence between generation and preference learning in InfoDCL, we build a collaborative training objective strategy to transform the interference between them into mutual collaboration. Additionally, we employ multiple GCN layers only during inference stage to incorporate higher-order co-occurrence information while maintaining training efficiency. Extensive experiments on five real-world datasets demonstrate that InfoDCL significantly outperforms state-of-the-art methods. Our InfoDCL offers an effective solution for enhancing recommendation performance and suggests a novel paradigm for applying diffusion method in contrastive learning frameworks.", "AI": {"tldr": "InfoDCL\uff1a\u57fa\u4e8e\u6269\u6563\u7684\u5bf9\u6bd4\u5b66\u4e60\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408\u8bed\u4e49\u4fe1\u606f\u751f\u6210\u66f4\u771f\u5b9e\u7684\u5bf9\u6bd4\u89c6\u56fe\uff0c\u63d0\u5347\u63a8\u8350\u6027\u80fd", "motivation": "\u73b0\u6709\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u901a\u8fc7\u968f\u673a\u6270\u52a8\u4ea4\u4e92\u56fe\u6784\u5efa\u7a00\u758f\u89c6\u56fe\uff0c\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u7528\u6237\u504f\u597d\uff0c\u4e14\u63a8\u8350\u6570\u636e\u7a00\u758f\u6027\u5bfc\u81f4\u8bed\u4e49\u4fe1\u606f\u4e0d\u8db3", "method": "\u63d0\u51faInfoDCL\u6846\u67b6\uff1a1\uff09\u4f7f\u7528\u5355\u6b65\u6269\u6563\u8fc7\u7a0b\u878d\u5408\u566a\u58f0\u548c\u8f85\u52a9\u8bed\u4e49\u4fe1\u606f\u751f\u6210\u4fe1\u53f7\uff0c\u518d\u901a\u8fc7\u6807\u51c6\u6269\u6563\u8fc7\u7a0b\u751f\u6210\u771f\u5b9e\u7528\u6237\u504f\u597d\u4f5c\u4e3a\u5bf9\u6bd4\u89c6\u56fe\uff1b2\uff09\u6784\u5efa\u534f\u540c\u8bad\u7ec3\u76ee\u6807\u7b56\u7565\uff0c\u5c06\u751f\u6210\u4e0e\u504f\u597d\u5b66\u4e60\u4e4b\u95f4\u7684\u5e72\u6270\u8f6c\u5316\u4e3a\u76f8\u4e92\u534f\u4f5c\uff1b3\uff09\u4ec5\u5728\u63a8\u7406\u9636\u6bb5\u4f7f\u7528\u591a\u5c42GCN\u878d\u5165\u9ad8\u9636\u5171\u73b0\u4fe1\u606f\uff0c\u4fdd\u6301\u8bad\u7ec3\u6548\u7387", "result": "\u5728\u4e94\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cInfoDCL\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5", "conclusion": "InfoDCL\u4e3a\u63d0\u5347\u63a8\u8350\u6027\u80fd\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4e3a\u5728\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u4e2d\u5e94\u7528\u6269\u6563\u65b9\u6cd5\u63d0\u51fa\u4e86\u65b0\u8303\u5f0f"}}
{"id": "2512.16661", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16661", "abs": "https://arxiv.org/abs/2512.16661", "authors": ["Jacob Reiss", "Shikshya Shiwakoti", "Samuel Goldsmith", "Ujjwal Pandit"], "title": "Microsoft Academic Graph Information Retrieval for Research Recommendation and Assistance", "comment": "5 pages, 3 figures", "summary": "In today's information-driven world, access to scientific publications has become increasingly easy. At the same time, filtering through the massive volume of available research has become more challenging than ever. Graph Neural Networks (GNNs) and graph attention mechanisms have shown strong effectiveness in searching large-scale information databases, particularly when combined with modern large language models. In this paper, we propose an Attention-Based Subgraph Retriever, a GNN-as-retriever model that applies attention-based pruning to extract a refined subgraph, which is then passed to a large language model for advanced knowledge reasoning.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u5b50\u56fe\u68c0\u7d22\u5668\uff0c\u7ed3\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u77e5\u8bc6\u63a8\u7406", "motivation": "\u79d1\u5b66\u6587\u732e\u83b7\u53d6\u65e5\u76ca\u4fbf\u6377\uff0c\u4f46\u6d77\u91cf\u7814\u7a76\u7b5b\u9009\u53d8\u5f97\u56f0\u96be\u3002\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u56fe\u6ce8\u610f\u529b\u673a\u5236\u5728\u5927\u89c4\u6a21\u4fe1\u606f\u6570\u636e\u5e93\u641c\u7d22\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u662f\u4e0e\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u65f6\u3002", "method": "\u63d0\u51fa\u6ce8\u610f\u529b\u57fa\u4e8e\u5b50\u56fe\u68c0\u7d22\u5668\uff0c\u8fd9\u662f\u4e00\u79cdGNN\u4f5c\u4e3a\u68c0\u7d22\u5668\u7684\u6a21\u578b\uff0c\u5e94\u7528\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u526a\u679d\u6280\u672f\u63d0\u53d6\u7cbe\u70bc\u5b50\u56fe\uff0c\u7136\u540e\u5c06\u5b50\u56fe\u4f20\u9012\u7ed9\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u9ad8\u7ea7\u77e5\u8bc6\u63a8\u7406\u3002", "result": "\u672a\u5728\u6458\u8981\u4e2d\u660e\u786e\u8bf4\u660e\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c\uff0c\u4f46\u6697\u793a\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u5927\u89c4\u6a21\u4fe1\u606f\u68c0\u7d22\u548c\u77e5\u8bc6\u63a8\u7406\u4efb\u52a1\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u68c0\u7d22\u80fd\u529b\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u5904\u7406\u6d77\u91cf\u79d1\u5b66\u6587\u732e\u7b5b\u9009\u548c\u77e5\u8bc6\u63a8\u7406\u7684\u65b0\u65b9\u6cd5\u3002"}}
