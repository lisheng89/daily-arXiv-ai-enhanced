<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 16]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Design and Evaluation of Whole-Page Experience Optimization for E-commerce Search](https://arxiv.org/abs/2602.02514)
*Pratik Lahiri,Bingqing Ge,Zhou Qin,Aditya Jumde,Shuning Huo,Lucas Scottini,Yi Liu,Mahmoud Mamlouk,Wenyang Liu*

Main category: cs.IR

TL;DR: 提出全页面体验优化框架，解决电商搜索结果页从线性列表到复杂非线性布局的转变问题，同时优化短期信号和长期用户满意度。


<details>
  <summary>Details</summary>
Motivation: 电商搜索结果页正从线性列表演变为复杂的非线性布局，传统基于位置的排序模型已不再适用。现有优化框架通常只最大化短期信号（如点击、当日收入），而长期满意度指标（如预期两周收入）涉及延迟反馈和困难的长期信用归因问题。

Method: 提出全页面体验优化框架，与传统列表式排序器不同，该方法明确建模商品相关性、二维位置布局和视觉元素之间的相互作用。使用因果框架基于准实验数据开发长期用户满意度度量指标。

Result: 通过行业规模的A/B测试验证，模型在品牌相关性（主要客户体验指标）上提升了1.86%，同时实现了+0.05%的统计显著收入增长。

Conclusion: 提出的全页面体验优化框架能够有效解决现代电商搜索结果页的复杂布局挑战，同时优化短期和长期用户满意度指标，在实际应用中取得了显著效果。

Abstract: E-commerce Search Results Pages (SRPs) are evolving from linear lists to complex, non-linear layouts, rendering traditional position-biased ranking models insufficient. Moreover, existing optimization frameworks typically maximize short-term signals (e.g., clicks, same-day revenue) because long-term satisfaction metrics (e.g., expected two-week revenue) involve delayed feedback and challenging long-horizon credit attribution. To bridge these gaps, we propose a novel Whole-Page Experience Optimization Framework. Unlike traditional list-wise rankers, our approach explicitly models the interplay between item relevance, 2D positional layout, and visual elements. We use a causal framework to develop metrics for measuring long-term user satisfaction based on quasi-experimental data. We validate our approach through industry-scale A/B testing, where the model demonstrated a 1.86% improvement in brand relevance (our primary customer experience metric) while simultaneously achieving a statistically significant revenue uplift of +0.05%

</details>


### [2] [Col-Bandit: Zero-Shot Query-Time Pruning for Late-Interaction Retrieval](https://arxiv.org/abs/2602.02827)
*Roi Pony,Adi Raz,Oshri Naparstek,Idan Friedman,Udi Barzelay*

Main category: cs.IR

TL;DR: Col-Bandit是一种查询时剪枝算法，通过将重排序建模为有限总体Top-K识别问题，自适应地揭示必要的MaxSim条目，在保持排序质量的同时将多向量检索器的计算成本降低5倍。


<details>
  <summary>Details</summary>
Motivation: 多向量延迟交互检索器（如ColBERT）虽然检索质量高，但查询时计算成本巨大，需要对每个候选文档进行详尽的token级MaxSim交互计算。现有的单向量近似方法虽然降低了成本，但往往导致显著的精度损失。

Method: Col-Bandit将重排序建模为有限总体Top-K识别问题，维护部分观察文档分数的不确定性感知边界，自适应地揭示确定top结果所需的（文档，查询token）MaxSim条目。该方法作为零样本、即插即用层运行在标准多向量系统之上，无需索引修改、离线预处理或模型重训练。

Result: 在文本（BEIR）和多模态（REAL-MM-RAG）基准测试中，Col-Bandit在保持排序保真度的同时，将MaxSim FLOPs减少高达5倍，表明密集延迟交互评分包含大量冗余，可以在查询时高效识别和剪枝。

Conclusion: Col-Bandit证明了多向量检索器在查询时存在显著的计算冗余，通过智能的自适应剪枝策略可以在保持检索质量的同时大幅降低计算成本，为高效的多向量检索系统提供了实用的解决方案。

Abstract: Multi-vector late-interaction retrievers such as ColBERT achieve state-of-the-art retrieval quality, but their query-time cost is dominated by exhaustively computing token-level MaxSim interactions for every candidate document. While approximating late interaction with single-vector representations reduces cost, it often incurs substantial accuracy loss. We introduce Col-Bandit, a query-time pruning algorithm that reduces this computational burden by casting reranking as a finite-population Top-$K$ identification problem. Col-Bandit maintains uncertainty-aware bounds over partially observed document scores and adaptively reveals only the (document, query token) MaxSim entries needed to determine the top results under statistical decision bounds with a tunable relaxation. Unlike coarse-grained approaches that prune entire documents or tokens offline, Col-Bandit sparsifies the interaction matrix on the fly. It operates as a zero-shot, drop-in layer over standard multi-vector systems, requiring no index modifications, offline preprocessing, or model retraining. Experiments on textual (BEIR) and multimodal (REAL-MM-RAG) benchmarks show that Col-Bandit preserves ranking fidelity while reducing MaxSim FLOPs by up to 5$\times$, indicating that dense late-interaction scoring contains substantial redundancy that can be identified and pruned efficiently at query time.

</details>


### [3] [Efficiency Optimizations for Superblock-based Sparse Retrieval](https://arxiv.org/abs/2602.02883)
*Parker Carlson,Wentai Xie,Rohil Shah,Tao Yang*

Main category: cs.IR

TL;DR: 提出一种简单有效的超块剪枝方案，结合紧凑索引结构和零配置，在保持竞争力的同时减少LSR检索开销


<details>
  <summary>Details</summary>
Motivation: 学习稀疏检索结合了语言模型的语义匹配和高效CPU友好算法，但现有超块聚合方法在查询处理时使用高级剪枝启发式方法，存在计算开销问题

Method: 提出简单有效的超块剪枝方案，结合紧凑索引结构和鲁棒的零配置方法，适用于多种LSR模型和数据集

Result: 在MS MARCO和BEIR数据集上评估，证明该方案能减少超块分数计算开销，同时保持竞争力，可作为高效稀疏检索的强有力替代方案

Conclusion: 提出的超块剪枝方案简单有效，通过分析论证和实验验证，为高效稀疏检索提供了有竞争力的替代方案

Abstract: Learned sparse retrieval (LSR) is a popular method for first-stage retrieval because it combines the semantic matching of language models with efficient CPU-friendly algorithms. Previous work aggregates blocks into "superblocks" to quickly skip the visitation of blocks during query processing by using an advanced pruning heuristic. This paper proposes a simple and effective superblock pruning scheme that reduces the overhead of superblock score computation while preserving competitive relevance. It combines this scheme with a compact index structure and a robust zero-shot configuration that is effective across LSR models and multiple datasets. This paper provides an analytical justification and evaluation on the MS MARCO and BEIR datasets, demonstrating that the proposed scheme can be a strong alternative for efficient sparse retrieval.

</details>


### [4] [ALPBench: A Benchmark for Attribution-level Long-term Personal Behavior Understanding](https://arxiv.org/abs/2602.03056)
*Lu Ren,Junda She,Xinchen Luo,Tao Wang,Xin Ye,Xu Zhang,Muxuan Wang,Xiao Yang,Chenguang Wang,Fei Xie,Yiwei Zhou,Danjun Wu,Guodong Zhang,Yifei Hu,Guoying Zheng,Shujie Yang,Xingmei Wang,Shiyao Wang,Yukun Zhou,Fan Yang,Size Li,Kuo Cai,Qiang Luo,Ruiming Tang,Han Li,Kun Gai*

Main category: cs.IR

TL;DR: ALPBench是一个用于评估LLM在属性级别长期个人行为理解能力的新基准，专注于预测用户感兴趣的属性组合而非具体物品，支持对新物品的评估


<details>
  <summary>Details</summary>
Motivation: 当前LLM在个性化推荐中准确捕捉用户偏好仍具挑战，需要系统评估LLM在长期用户行为建模方面的能力，现有基准主要关注物品预测而非用户偏好属性理解

Method: 引入ALPBench基准，将用户历史行为表示为自然语言序列，预测用户感兴趣的属性组合而非具体物品，支持对全新物品的评估，专注于属性组合预测任务

Result: ALPBench能够进行细粒度个性化评估，揭示当前LLM在捕捉多属性复杂交互和长期行为序列推理方面的挑战，为评估LLM的长期偏好理解能力提供系统框架

Conclusion: ALPBench填补了LLM在长期个人行为理解评估方面的空白，通过属性组合预测任务提供可解释、基于推理的个性化评估框架，有助于推动LLM在个性化推荐领域的发展

Abstract: Recent advances in large language models have highlighted their potential for personalized recommendation, where accurately capturing user preferences remains a key challenge. Leveraging their strong reasoning and generalization capabilities, LLMs offer new opportunities for modeling long-term user behavior. To systematically evaluate this, we introduce ALPBench, a Benchmark for Attribution-level Long-term Personal Behavior Understanding. Unlike item-focused benchmarks, ALPBench predicts user-interested attribute combinations, enabling ground-truth evaluation even for newly introduced items. It models preferences from long-term historical behaviors rather than users' explicitly expressed requests, better reflecting enduring interests. User histories are represented as natural language sequences, allowing interpretable, reasoning-based personalization. ALPBench enables fine-grained evaluation of personalization by focusing on the prediction of attribute combinations task that remains highly challenging for current LLMs due to the need to capture complex interactions among multiple attributes and reason over long-term user behavior sequences.

</details>


### [5] [PAMAS: Self-Adaptive Multi-Agent System with Perspective Aggregation for Misinformation Detection](https://arxiv.org/abs/2602.03158)
*Zongwei Wang,Min Gao,Junliang Yu,Tong Chen,Chenghua Lin*

Main category: cs.IR

TL;DR: PAMAS是一个用于社交媒体虚假信息检测的多智能体框架，通过视角聚合机制解决传统多智能体系统中的信息淹没问题，显著提升检测准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 社交媒体虚假信息具有多样性和上下文依赖性，传统检测方法面临挑战。传统多智能体系统存在"信息淹没"问题，即大量真实内容淹没了稀疏而微弱的欺骗线索，导致检测困难。

Method: 提出PAMAS框架，采用分层视角感知聚合机制：1）审计员从专门特征子集中捕获异常线索；2）协调员聚合审计员视角以增强覆盖同时保持多样性；3）决策者通过演化记忆和完整上下文访问综合所有下级洞察做出最终判断。此外，引入自适应机制进行动态拓扑优化和基于路由的推理。

Result: 在多个基准数据集上的广泛实验表明，PAMAS在准确性和效率方面均表现优异，为虚假信息检测提供了可扩展且可信赖的方法。

Conclusion: PAMAS通过视角聚合机制有效解决了多智能体系统中的信息淹没问题，显著提升了虚假信息检测性能，为社交媒体可信信息验证提供了创新解决方案。

Abstract: Misinformation on social media poses a critical threat to information credibility, as its diverse and context-dependent nature complicates detection. Large language model-empowered multi-agent systems (MAS) present a promising paradigm that enables cooperative reasoning and collective intelligence to combat this threat. However, conventional MAS suffer from an information-drowning problem, where abundant truthful content overwhelms sparse and weak deceptive cues. With full input access, agents tend to focus on dominant patterns, and inter-agent communication further amplifies this bias. To tackle this issue, we propose PAMAS, a multi-agent framework with perspective aggregation, which employs hierarchical, perspective-aware aggregation to highlight anomaly cues and alleviate information drowning. PAMAS organizes agents into three roles: Auditors, Coordinators, and a Decision-Maker. Auditors capture anomaly cues from specialized feature subsets; Coordinators aggregate their perspectives to enhance coverage while maintaining diversity; and the Decision-Maker, equipped with evolving memory and full contextual access, synthesizes all subordinate insights to produce the final judgment. Furthermore, to improve efficiency in multi-agent collaboration, PAMAS incorporates self-adaptive mechanisms for dynamic topology optimization and routing-based inference, enhancing both efficiency and scalability. Extensive experiments on multiple benchmark datasets demonstrate that PAMAS achieves superior accuracy and efficiency, offering a scalable and trustworthy way for misinformation detection.

</details>


### [6] [Distribution-Aware End-to-End Embedding for Streaming Numerical Features in Click-Through Rate Prediction](https://arxiv.org/abs/2602.03223)
*Jiahao Liu,Hongji Ruan,Weimin Zhang,Ziye Tong,Derick Tang,Zhanpeng Zeng,Qinsong Zeng,Peng Zhang,Tun Lu,Ning Gu*

Main category: cs.IR

TL;DR: DAES：面向流式训练场景的数值特征嵌入框架，通过自适应调制机制整合分布信息，解决传统方法中的语义漂移和分布信息丢失问题


<details>
  <summary>Details</summary>
Motivation: 传统静态分箱方法依赖离线统计，在流式环境中容易产生语义漂移；神经嵌入方法虽支持端到端学习，但丢弃了显式的分布信息。流式特征常违反i.i.d.假设，且数值分布的上下文依赖性常被忽视

Method: 提出DAES端到端框架：1）基于蓄水池采样的高效分布估计方法；2）两种场感知分布调制策略，以捕捉流式分布和场依赖语义

Result: DAES在离线和在线实验中显著优于现有方法，已在拥有数亿日活用户的领先短视频平台全面部署

Conclusion: DAES成功解决了流式训练中数值特征嵌入的挑战，通过整合分布信息和自适应调制机制，实现了更优的点击率预测性能

Abstract: This paper explores effective numerical feature embedding for Click-Through Rate prediction in streaming environments. Conventional static binning methods rely on offline statistics of numerical distributions; however, this inherently two-stage process often triggers semantic drift during bin boundary updates. While neural embedding methods enable end-to-end learning, they often discard explicit distributional information. Integrating such information end-to-end is challenging because streaming features often violate the i.i.d. assumption, precluding unbiased estimation of the population distribution via the expectation of order statistics. Furthermore, the critical context dependency of numerical distributions is often neglected. To this end, we propose DAES, an end-to-end framework designed to tackle numerical feature embedding in streaming training scenarios by integrating distributional information with an adaptive modulation mechanism. Specifically, we introduce an efficient reservoir-sampling-based distribution estimation method and two field-aware distribution modulation strategies to capture streaming distributions and field-dependent semantics. DAES significantly outperforms existing approaches as demonstrated by extensive offline and online experiments and has been fully deployed on a leading short-video platform with hundreds of millions of daily active users.

</details>


### [7] [To Search or Not to Search: Aligning the Decision Boundary of Deep Search Agents via Causal Intervention](https://arxiv.org/abs/2602.03304)
*Wenlin Zhang,Kuicai Dong,Junyi Li,Yingyi Zhang,Xiaopeng Li,Pengyue Jia,Yi Wen,Derong Xu,Maolin Wang,Yichao Wang,Yong Liu,Xiangyu Zhao*

Main category: cs.IR

TL;DR: 该论文提出DAS框架，通过因果干预诊断决策边界错误，并使用偏好优化对齐策略，解决深度搜索代理中过度搜索和搜索不足的问题，提高准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前深度搜索代理存在严重效率问题：由于无法准确判断何时停止搜索并开始回答，导致过度搜索。根本原因是决策边界错位，即判断何时积累足够信息来回答的阈值不准确，这源于结果导向的训练方式优先考虑最终结果而非搜索过程本身。

Method: 提出包含两个关键组件的综合框架：1) 基于因果干预的诊断方法，通过比较每个决策点的实际轨迹和反事实轨迹来识别边界错误；2) 决策边界对齐方法(DAS)，从因果反馈构建偏好数据集，并通过偏好优化对齐策略。

Result: 实验表明决策边界错误在现有先进代理中普遍存在。DAS方法有效校准了这些边界，显著减轻了过度搜索和搜索不足问题，在准确性和效率方面取得了实质性提升。

Conclusion: DAS框架通过因果干预诊断和偏好优化对齐，成功解决了深度搜索代理中的决策边界错位问题，实现了更准确、高效的自主搜索推理。

Abstract: Deep search agents, which autonomously iterate through multi-turn web-based reasoning, represent a promising paradigm for complex information-seeking tasks. However, current agents suffer from critical inefficiency: they conduct excessive searches as they cannot accurately judge when to stop searching and start answering. This stems from outcome-centric training that prioritize final results over the search process itself. We identify the root cause as misaligned decision boundaries, the threshold determining when accumulated information suffices to answer. This causes over-search (redundant searching despite sufficient knowledge) and under-search (premature termination yielding incorrect answers). To address these errors, we propose a comprehensive framework comprising two key components. First, we introduce causal intervention-based diagnosis that identifies boundary errors by comparing factual and counterfactual trajectories at each decision point. Second, we develop Decision Boundary Alignment for Deep Search agents (DAS), which constructs preference datasets from causal feedback and aligns policies via preference optimization. Experiments on public datasets demonstrate that decision boundary errors are pervasive across state-of-the-art agents. Our DAS method effectively calibrates these boundaries, mitigating both over-search and under-search to achieve substantial gains in accuracy and efficiency. Our code and data are publicly available at: https://github.com/Applied-Machine-Learning-Lab/WWW2026_DAS.

</details>


### [8] [Learning to Select: Query-Aware Adaptive Dimension Selection for Dense Retrieval](https://arxiv.org/abs/2602.03306)
*Zhanyu Wu,Richong Zhang,Zhijie Nie*

Main category: cs.IR

TL;DR: 提出Query-Aware Adaptive Dimension Selection框架，通过监督学习直接从查询嵌入预测维度重要性，无需伪相关反馈，提高密集检索效果


<details>
  <summary>Details</summary>
Motivation: 密集检索中查询和文档的高维嵌入表示存在冗余：对于特定信息需求，只有部分维度对排序有帮助。现有方法要么依赖噪声大的伪相关反馈，要么学习全局变换而不显式建模查询感知的维度重要性。

Method: 首先使用监督相关性标签构建维度重要性分布的oracle，然后训练一个预测器将查询嵌入映射到这些标签蒸馏的重要性分数。推理时，预测器仅基于查询嵌入选择查询感知的维度子集进行相似度计算。

Result: 在多个密集检索器和基准测试上的实验表明，学习的维度选择器在检索效果上优于全维度基线、基于PRF的掩码方法和监督适配器基线。

Conclusion: 提出的框架能够有效学习查询感知的维度重要性，无需伪相关反馈，显著提升密集检索性能，为查询特定的维度选择提供了监督学习方案。

Abstract: Dense retrieval represents queries and docu-002 ments as high-dimensional embeddings, but003 these representations can be redundant at the004 query level: for a given information need, only005 a subset of dimensions is consistently help-006 ful for ranking. Prior work addresses this via007 pseudo-relevance feedback (PRF) based dimen-008 sion importance estimation, which can produce009 query-aware masks without labeled data but010 often relies on noisy pseudo signals and heuris-011 tic test-time procedures. In contrast, super-012 vised adapter methods leverage relevance labels013 to improve embedding quality, yet they learn014 global transformations shared across queries015 and do not explicitly model query-aware di-016 mension importance. We propose a Query-017 Aware Adaptive Dimension Selection frame-018 work that learns to predict per-dimension im-019 portance directly from query embedding. We020 first construct oracle dimension importance dis-021 tributions over embedding dimensions using022 supervised relevance labels, and then train a023 predictor to map a query embedding to these024 label-distilled importance scores. At inference,025 the predictor selects a query-aware subset of026 dimensions for similarity computation based027 solely on the query embedding, without pseudo-028 relevance feedback. Experiments across multi-029 ple dense retrievers and benchmarks show that030 our learned dimension selector improves re-031 trieval effectiveness over the full-dimensional032 baseline as well as PRF-based masking and033 supervised adapter baselines.

</details>


### [9] [SCASRec: A Self-Correcting and Auto-Stopping Model for Generative Route List Recommendation](https://arxiv.org/abs/2602.03324)
*Chao Chen,Longfei Xu,Daohan Su,Tengfei Liu,Hanyu Guo,Yihai Duan,Kaikui Liu,Xiangxiang Chu*

Main category: cs.IR

TL;DR: SCASRec是一个统一的生成式推荐框架，将排序和冗余消除整合到端到端过程中，解决了多阶段推荐系统中训练目标与在线指标不对齐、冗余消除规则僵化、各阶段分离导致次优性能等问题。


<details>
  <summary>Details</summary>
Motivation: 当前多阶段推荐系统存在三个关键问题：1）离线训练目标与在线指标不对齐，离线增益不一定转化为在线改进；2）冗余消除依赖僵化的手工规则，无法适应用户意图的高方差和现实场景的复杂性；3）精细排序和重排序阶段严格分离导致次优性能，各模块孤立优化无法实现联合优化的全局最优。

Method: 提出SCASRec（自校正和自停止推荐）统一生成框架，引入逐步校正奖励（SCR）通过关注困难样本来指导列表级优化，并采用可学习的推荐结束（EOR）标记来自适应终止生成过程。

Result: 在两个大规模开源路线推荐数据集上的实验表明，SCASRec在离线和在线设置中都达到了最先进水平。该框架已在真实导航应用中完全部署，证明了其有效性。

Conclusion: SCASRec通过端到端的统一框架解决了多阶段推荐系统的核心问题，实现了排序和冗余消除的联合优化，在实际应用中表现出色。

Abstract: Route recommendation systems commonly adopt a multi-stage pipeline involving fine-ranking and re-ranking to produce high-quality ordered recommendations. However, this paradigm faces three critical limitations. First, there is a misalignment between offline training objectives and online metrics. Offline gains do not necessarily translate to online improvements. Actual performance must be validated through A/B testing, which may potentially compromise the user experience. Second, redundancy elimination relies on rigid, handcrafted rules that lack adaptability to the high variance in user intent and the unstructured complexity of real-world scenarios. Third, the strict separation between fine-ranking and re-ranking stages leads to sub-optimal performance. Since each module is optimized in isolation, the fine-ranking stage remains oblivious to the list-level objectives (e.g., diversity) targeted by the re-ranker, thereby preventing the system from achieving a jointly optimized global optimum. To overcome these intertwined challenges, we propose \textbf{SCASRec} (\textbf{S}elf-\textbf{C}orrecting and \textbf{A}uto-\textbf{S}topping \textbf{Rec}ommendation), a unified generative framework that integrates ranking and redundancy elimination into a single end-to-end process. SCASRec introduces a stepwise corrective reward (SCR) to guide list-wise refinement by focusing on hard samples, and employs a learnable End-of-Recommendation (EOR) token to terminate generation adaptively when no further improvement is expected. Experiments on two large-scale, open-sourced route recommendation datasets demonstrate that SCASRec establishes an SOTA in offline and online settings. SCASRec has been fully deployed in a real-world navigation app, demonstrating its effectiveness.

</details>


### [10] [Beyond Exposure: Optimizing Ranking Fairness with Non-linear Time-Income Functions](https://arxiv.org/abs/2602.03345)
*Xuancheng Li,Tao Yang,Yujia Zhou,Qingyao Ai,Yiqun Liu*

Main category: cs.IR

TL;DR: 提出收入公平性概念，考虑时间等上下文因素对提供商效用的影响，开发了DIDRF算法来同时优化排名效果和收入公平性


<details>
  <summary>Details</summary>
Motivation: 当前排名优化中，曝光公平性主要基于位置决定曝光，忽略了时间等其他影响收入的重要因素，无法准确反映提供商的真实效用

Method: 提出收入公平性正式定义和度量指标，开发DIDRF算法，基于当前时间步的边际收入增益，使用泰勒展开梯度同时优化效果和收入公平性

Result: 模拟实验显示现有基于曝光公平性的算法无法优化收入公平性，DIDRF在离线和在线设置中，在不同时间-收入函数下均优于现有方法

Conclusion: 收入公平性比传统曝光公平性更能准确反映提供商效用，DIDRF算法能有效同时优化排名效果和收入公平性

Abstract: Ranking is central to information distribution in web search and recommendation. Nowadays, in ranking optimization, the fairness to item providers is viewed as a crucial factor alongside ranking relevance for users. There are currently numerous concepts of fairness and one widely recognized fairness concept is Exposure Fairness. However, it relies primarily on exposure determined solely by position, overlooking other factors that significantly influence income, such as time. To address this limitation, we propose to study ranking fairness when the provider utility is influenced by other contextual factors and is neither equal to nor proportional to item exposure. We give a formal definition of Income Fairness and develop a corresponding measurement metric. Simulated experiments show that existing-exposure-fairness-based ranking algorithms fail to optimize the proposed income fairness. Therefore, we propose the Dynamic-Income-Derivative-aware Ranking Fairness algorithm, which, based on the marginal income gain at the present timestep, uses Taylor-expansion-based gradients to simultaneously optimize effectiveness and income fairness. In both offline and online settings with diverse time-income functions, DIDRF consistently outperforms state-of-the-art methods.

</details>


### [11] [AesRec: A Dataset for Aesthetics-Aligned Clothing Outfit Recommendation](https://arxiv.org/abs/2602.03416)
*Wenxin Ye,Lin Li,Ming Li,Yang Shen,Kanghong Wang,Jimmy Xiangji Huang*

Main category: cs.IR

TL;DR: 该论文提出了AesRec基准数据集，包含系统化的服装美学量化标注，用于开发美学对齐的推荐系统，实验证明整合美学信息能同时满足用户个性化需求和提供美学指导。


<details>
  <summary>Details</summary>
Motivation: 现有服装推荐方法主要依赖用户-物品-搭配交互行为，忽视了服装美学的显式表征，导致无法有效提供美学指导。

Method: 基于专业服装质量标准和时尚美学原则，定义多维美学指标：单品层面评估6个维度，搭配层面评估8个维度；利用视觉语言模型进行大规模美学评分，并通过人机一致性验证确保可靠性。

Result: 在时尚数据集上进行了严格的人机一致性验证，确认了生成评分的可靠性；基于AesRec的实验结果表明，将量化美学信息整合到服装推荐模型中，既能满足用户个性化需求，又能提供美学指导。

Conclusion: AesRec基准数据集填补了服装推荐中美学表征的空白，通过系统化的美学量化标注，使得推荐系统能够同时兼顾个性化和美学指导，为美学对齐的推荐系统开发提供了重要基础。

Abstract: Clothing recommendation extends beyond merely generating personalized outfits; it serves as a crucial medium for aesthetic guidance. However, existing methods predominantly rely on user-item-outfit interaction behaviors while overlooking explicit representations of clothing aesthetics. To bridge this gap, we present the AesRec benchmark dataset featuring systematic quantitative aesthetic annotations, thereby enabling the development of aesthetics-aligned recommendation systems. Grounded in professional apparel quality standards and fashion aesthetic principles, we define a multidimensional set of indicators. At the item level, six dimensions are independently assessed: silhouette, chromaticity, materiality, craftsmanship, wearability, and item-level impression. Transitioning to the outfit level, the evaluation retains the first five core attributes while introducing stylistic synergy, visual harmony, and outfit-level impression as distinct metrics to capture the collective aesthetic impact. Given the increasing human-like proficiency of Vision-Language Models in multimodal understanding and interaction, we leverage them for large-scale aesthetic scoring. We conduct rigorous human-machine consistency validation on a fashion dataset, confirming the reliability of the generated ratings. Experimental results based on AesRec further demonstrate that integrating quantified aesthetic information into clothing recommendation models can provide aesthetic guidance for users while fulfilling their personalized requirements.

</details>


### [12] [RankSteer: Activation Steering for Pointwise LLM Ranking](https://arxiv.org/abs/2602.03422)
*Yumeng Wang,Catherine Chen,Suzan Verberne*

Main category: cs.IR

TL;DR: RankSteer：一种后激活导向框架，通过控制表示空间中的三个解耦方向（决策、证据、角色）来校准零样本点式LLM排序行为，无需修改模型权重或进行显式跨文档比较。


<details>
  <summary>Details</summary>
Motivation: LLM作为零样本排序器性能对提示工程（特别是角色扮演指令）高度敏感。研究发现角色相关信号编码在与查询-文档表示分离的激活通道中，因此可以直接在激活层面引导排序行为，避免脆弱的提示工程。

Method: 提出RankSteer框架，识别表示空间中三个可引导的解耦方向：1）决策方向：将隐藏状态映射到相关性分数；2）证据方向：捕获决策头未直接利用的相关性信号；3）角色方向：在不注入相关性信息的情况下调节模型行为。通过推理时的投影干预联合控制这些方向。

Result: 在TREC DL 20和多个BEIR基准测试中，RankSteer仅使用少量锚点查询就持续提升了排序质量，表明点式LLM排序器中存在大量未充分利用的排序能力。几何分析显示导向通过稳定排序几何和减少离散度来改进排序。

Conclusion: 激活导向是校准LLM排序行为的有效方法，无需修改权重或跨文档比较。研究揭示了LLM内部如何表示和校准相关性判断，为理解LLM排序机制提供了新视角。

Abstract: Large language models (LLMs) have recently shown strong performance as zero-shot rankers, yet their effectiveness is highly sensitive to prompt formulation, particularly role-play instructions. Prior analyses suggest that role-related signals are encoded along activation channels that are largely separate from query-document representations, raising the possibility of steering ranking behavior directly at the activation level rather than through brittle prompt engineering. In this work, we propose RankSteer, a post-hoc activation steering framework for zero-shot pointwise LLM ranking. We characterize ranking behavior through three disentangled and steerable directions in representation space: a \textbf{decision direction} that maps hidden states to relevance scores, an \textbf{evidence direction} that captures relevance signals not directly exploited by the decision head, and a \textbf{role direction} that modulates model behavior without injecting relevance information. Using projection-based interventions at inference time, RankSteer jointly controls these directions to calibrate ranking behavior without modifying model weights or introducing explicit cross-document comparisons. Experiments on TREC DL 20 and multiple BEIR benchmarks show that RankSteer consistently improves ranking quality using only a small number of anchor queries, demonstrating that substantial ranking capacity remains under-utilized in pointwise LLM rankers. We further provide a geometric analysis revealing that steering improves ranking by stabilizing ranking geometry and reducing dispersion, offering new insight into how LLMs internally represent and calibrate relevance judgments.

</details>


### [13] [Failure is Feedback: History-Aware Backtracking for Agentic Traversal in Multimodal Graphs](https://arxiv.org/abs/2602.03432)
*Joohyung Yun,Doyup Lee,Wook-Shin Han*

Main category: cs.IR

TL;DR: FiF 提出了一种基于失败反馈的开放域多模态文档检索方法，通过历史感知回溯机制和经济理性代理工作流，在多个基准测试中实现了最先进的检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的检索方法存在两个主要问题：1）使用统一的相似性度量，忽略了跳转特定的语义；2）采用僵化的预定义路径规划，缺乏动态错误纠正能力。这要求检索器能够根据演化上下文自适应推理，并能智能地从死胡同中恢复。

Method: FiF 将子图检索建模为序列决策过程，包含两个关键创新：1）历史感知回溯机制，利用失败遍历的上下文信息，而不仅仅是简单回退状态；2）经济理性代理工作流，采用成本感知的遍历方法，动态权衡检索精度和推理成本，仅在先前失败证明合理时才升级到计算密集的LLM推理。

Result: 在 MultimodalQA、MMCoQA 和 WebQA 基准测试上的广泛实验表明，FiF 实现了最先进的检索性能。

Conclusion: FiF 通过将失败作为反馈，实现了更智能、更高效的开放域多模态文档检索，能够自适应地处理复杂查询并在错误中学习改进。

Abstract: Open-domain multimodal document retrieval aims to retrieve specific components (paragraphs, tables, or images) from large and interconnected document corpora. Existing graph-based retrieval approaches typically rely on a uniform similarity metric that overlooks hop-specific semantics, and their rigid pre-defined plans hinder dynamic error correction. These limitations suggest that a retriever should adapt its reasoning to the evolving context and recover intelligently from dead ends. To address these needs, we propose Failure is Feedback (FiF), which casts subgraph retrieval as a sequential decision process and introduces two key innovations. (i) We introduce a history-aware backtracking mechanism; unlike standard backtracking that simply reverts the state, our approach piggybacks on the context of failed traversals, leveraging insights from previous failures. (ii) We implement an economically-rational agentic workflow. Unlike conventional agents with static strategies, our orchestrator employs a cost-aware traversal method to dynamically manage the trade-off between retrieval accuracy and inference costs, escalating to intensive LLM-based reasoning only when the prior failure justifies the additional computational investment. Extensive experiments show that FiF achieves state-of-the-art retrieval on the benchmarks of MultimodalQA, MMCoQA and WebQA.

</details>


### [14] [Tutorial on Reasoning for IR & IR for Reasoning](https://arxiv.org/abs/2602.03640)
*Mohanna Hoveyda,Panagiotis Efstratiadis,Arjen de Vries,Maarten de Rijke*

Main category: cs.IR

TL;DR: 该教程提出了一个统一的推理分析框架，帮助信息检索研究者理解跨学科推理方法，并指导构建具备推理能力的检索系统。


<details>
  <summary>Details</summary>
Motivation: 传统信息检索主要关注语义相关性排序，但现实信息需求需要逻辑约束、多步推理和证据综合等推理能力。当前AI社区中推理方法分散在不同学科，使得IR研究者难以识别相关思路和机会。

Method: 首先在IR背景下定义推理的工作定义，并从中推导出统一的分析框架。该框架将现有方法映射到反映定义核心组件的轴上，提供全面概述并展示权衡与互补性。

Result: 创建了一个帮助导航碎片化推理研究景观的框架，揭示了不同方法的权衡与互补性，展示了IR如何从跨学科进展中受益，以及检索过程如何在更广泛推理系统中发挥核心作用。

Conclusion: 该教程为参与者提供了概念框架和实践指导，以增强具备推理能力的IR系统，同时将IR定位为既受益于又能贡献于更广泛推理方法发展的领域。

Abstract: Information retrieval has long focused on ranking documents by semantic relatedness. Yet many real-world information needs demand more: enforcement of logical constraints, multi-step inference, and synthesis of multiple pieces of evidence. Addressing these requirements is, at its core, a problem of reasoning. Across AI communities, researchers are developing diverse solutions for the problem of reasoning, from inference-time strategies and post-training of LLMs, to neuro-symbolic systems, Bayesian and probabilistic frameworks, geometric representations, and energy-based models. These efforts target the same problem: to move beyond pattern-matching systems toward structured, verifiable inference. However, they remain scattered across disciplines, making it difficult for IR researchers to identify the most relevant ideas and opportunities. To help navigate the fragmented landscape of research in reasoning, this tutorial first articulates a working definition of reasoning within the context of information retrieval and derives from it a unified analytical framework. The framework maps existing approaches along axes that reflect the core components of the definition. By providing a comprehensive overview of recent approaches and mapping current methods onto the defined axes, we expose their trade-offs and complementarities, highlight where IR can benefit from cross-disciplinary advances, and illustrate how retrieval process itself can play a central role in broader reasoning systems. The tutorial will equip participants with both a conceptual framework and practical guidance for enhancing reasoning-capable IR systems, while situating IR as a domain that both benefits and contributes to the broader development of reasoning methodologies.

</details>


### [15] [Bringing Reasoning to Generative Recommendation Through the Lens of Cascaded Ranking](https://arxiv.org/abs/2602.03692)
*Xinyu Lin,Pengyuan Liu,Wenjie Wang,Yicheng Hu,Chen Xu,Fuli Feng,Qifan Wang,Tat-Seng Chua*

Main category: cs.IR

TL;DR: CARE提出级联推理框架解决生成式推荐中的偏差放大问题，通过渐进历史编码和查询锚定推理机制提升推荐多样性和准确性


<details>
  <summary>Details</summary>
Motivation: 当前生成式推荐模型存在偏差放大问题，随着token生成过程推进，token级偏差不断放大，限制了推荐多样性并损害用户体验。与传统多阶段流水线相比，生成式推荐存在两个局限性：对编码历史的同质依赖，以及固定的计算预算阻碍了更深层的用户偏好理解。

Method: 提出CARE级联推理框架：1) 渐进历史编码机制 - 随着生成过程推进逐步纳入更细粒度的历史信息；2) 查询锚定推理机制 - 通过并行推理步骤对历史信息进行更深层理解，分配更多计算资源。在三个生成式推荐骨干网络上实例化CARE。

Result: 在四个数据集上的实验结果表明，CARE在推荐准确性、多样性、效率方面具有优越性，并展现出良好的可扩展性。

Conclusion: CARE通过解决生成式推荐中的偏差放大问题，有效提升了推荐系统的性能，为资源高效的端到端推荐提供了新的解决方案。

Abstract: Generative Recommendation (GR) has become a promising end-to-end approach with high FLOPS utilization for resource-efficient recommendation. Despite the effectiveness, we show that current GR models suffer from a critical \textbf{bias amplification} issue, where token-level bias escalates as token generation progresses, ultimately limiting the recommendation diversity and hurting the user experience. By comparing against the key factor behind the success of traditional multi-stage pipelines, we reveal two limitations in GR that can amplify the bias: homogeneous reliance on the encoded history, and fixed computational budgets that prevent deeper user preference understanding.
  To combat the bias amplification issue, it is crucial for GR to 1) incorporate more heterogeneous information, and 2) allocate greater computational resources at each token generation step. To this end, we propose CARE, a simple yet effective cascaded reasoning framework for debiased GR. To incorporate heterogeneous information, we introduce a progressive history encoding mechanism, which progressively incorporates increasingly fine-grained history information as the generation process advances. To allocate more computations, we propose a query-anchored reasoning mechanism, which seeks to perform a deeper understanding of historical information through parallel reasoning steps. We instantiate CARE on three GR backbones. Empirical results on four datasets show the superiority of CARE in recommendation accuracy, diversity, efficiency, and promising scalability. The codes and datasets are available at https://github.com/Linxyhaha/CARE.

</details>


### [16] [Multimodal Generative Recommendation for Fusing Semantic and Collaborative Signals](https://arxiv.org/abs/2602.03713)
*Moritz Vandenhirtz,Kaveh Hassani,Shervin Ghasemlou,Shuai Shao,Hamid Eghbalzadeh,Fuchun Peng,Jun Liu,Michael Louis Iuzzolino*

Main category: cs.IR

TL;DR: MSCGRec是一种多模态语义与协同生成式推荐系统，通过结合多种语义模态、自监督量化学习和协同特征融合，在大型数据集上超越了传统序列推荐和生成式推荐方法。


<details>
  <summary>Details</summary>
Motivation: 传统生成式推荐方法虽然通过离散语义编码减少内存开销，但在大型项目集上表现仍不及传统序列推荐器，限制了其在实际大规模场景中的应用。

Method: 1) 结合多种语义模态；2) 基于DINO框架的图像自监督量化学习；3) 从序列推荐器中提取协同特征作为独立模态进行融合；4) 提出受限序列学习，在训练时限制输出空间到允许的标记集合。

Result: 在三个大型真实世界数据集上的实验表明，MSCGRec超越了序列推荐和生成式推荐基线方法，并通过消融研究验证了各组件的影响。

Conclusion: MSCGRec通过多模态语义与协同特征的融合，成功解决了生成式推荐在大型项目集上的性能瓶颈，为实际大规模推荐场景提供了有效的解决方案。

Abstract: Sequential recommender systems rank relevant items by modeling a user's interaction history and computing the inner product between the resulting user representation and stored item embeddings. To avoid the significant memory overhead of storing large item sets, the generative recommendation paradigm instead models each item as a series of discrete semantic codes. Here, the next item is predicted by an autoregressive model that generates the code sequence corresponding to the predicted item. However, despite promising ranking capabilities on small datasets, these methods have yet to surpass traditional sequential recommenders on large item sets, limiting their adoption in the very scenarios they were designed to address. To resolve this, we propose MSCGRec, a Multimodal Semantic and Collaborative Generative Recommender. MSCGRec incorporates multiple semantic modalities and introduces a novel self-supervised quantization learning approach for images based on the DINO framework. Additionally, MSCGRec fuses collaborative and semantic signals by extracting collaborative features from sequential recommenders and treating them as a separate modality. Finally, we propose constrained sequence learning that restricts the large output space during training to the set of permissible tokens. We empirically demonstrate on three large real-world datasets that MSCGRec outperforms both sequential and generative recommendation baselines and provide an extensive ablation study to validate the impact of each component.

</details>
