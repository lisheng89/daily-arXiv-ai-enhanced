<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 17]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [AgenticShop: Benchmarking Agentic Product Curation for Personalized Web Shopping](https://arxiv.org/abs/2602.12315)
*Sunghwan Kim,Ryang Heo,Yongsik Seo,Jinyoung Yeo,Dongha Lee*

Main category: cs.IR

TL;DR: 提出了AgenticShop基准，用于评估开放网络环境中个性化产品推荐的智能代理系统，发现现有系统在真实购物场景中表现不足。


<details>
  <summary>Details</summary>
Motivation: 电子商务的快速发展导致信息环境嘈杂和碎片化，增加了用户的认知负担。虽然智能代理系统在自动化用户端任务方面显示出潜力，但现有基准无法全面评估这些系统在开放网络环境中进行产品推荐的能力，特别是在购物场景覆盖和个性化评估方面存在不足。

Method: 提出了AgenticShop基准，该基准具有三个关键特征：1）真实的购物场景；2）多样化的用户配置文件；3）可验证的、基于检查表的个性化评估框架。通过这个基准来全面评估智能代理系统在开放网络环境中的个性化产品推荐能力。

Result: 通过大量实验证明，当前的智能代理系统在个性化产品推荐方面仍然存在明显不足，强调了需要开发能够有效在现代网络中为用户推荐定制化产品的用户端系统。

Conclusion: AgenticShop是第一个用于评估开放网络环境中个性化产品推荐智能代理系统的基准，揭示了现有系统的局限性，为未来开发更有效的用户端购物代理系统提供了评估框架和方向。

Abstract: The proliferation of e-commerce has made web shopping platforms key gateways for customers navigating the vast digital marketplace. Yet this rapid expansion has led to a noisy and fragmented information environment, increasing cognitive burden as shoppers explore and purchase products online. With promising potential to alleviate this challenge, agentic systems have garnered growing attention for automating user-side tasks in web shopping. Despite significant advancements, existing benchmarks fail to comprehensively evaluate how well agentic systems can curate products in open-web settings. Specifically, they have limited coverage of shopping scenarios, focusing only on simplified single-platform lookups rather than exploratory search. Moreover, they overlook personalization in evaluation, leaving unclear whether agents can adapt to diverse user preferences in realistic shopping contexts. To address this gap, we present AgenticShop, the first benchmark for evaluating agentic systems on personalized product curation in open-web environment. Crucially, our approach features realistic shopping scenarios, diverse user profiles, and a verifiable, checklist-driven personalization evaluation framework. Through extensive experiments, we demonstrate that current agentic systems remain largely insufficient, emphasizing the need for user-side systems that effectively curate tailored products across the modern web.

</details>


### [2] [An Industrial-Scale Sequential Recommender for LinkedIn Feed Ranking](https://arxiv.org/abs/2602.12354)
*Lars Hertel,Gaurav Srivastava,Syed Ali Naqvi,Satyam Kumar,Yue Zhang,Borja Ocejo,Benjamin Zelditch,Adrian Englhardt,Hailing Cheng,Andy Hu,Antonio Alonso,Daming Li,Siddharth Dangi,Chen Zhu,Mingzhou Zhou,Wanning Li,Tao Huang,Fedor Borisyuk,Ganesh Parameswaran,Birjodh Singh Tiwana,Sriram Sankar,Qing Lan,Julie Choi,Souvik Ghosh*

Main category: cs.IR

TL;DR: LinkedIn开发了基于Transformer的Feed-SR序列推荐模型，替代原有DCNv2排序器，在严格生产约束下显著提升用户参与度


<details>
  <summary>Details</summary>
Motivation: LinkedIn Feed需要为全球专业人士提供相关内容发现、建立联系和知识分享，现有DCNv2模型在序列推荐方面存在局限性，需要更先进的模型来提升推荐效果

Method: 采用Transformer架构的序列推荐模型Feed-SR，详细设计了建模选择、训练技术和服务优化，以满足LinkedIn规模的生产部署要求

Result: Feed-SR成为LinkedIn Feed的主要成员体验，在线A/B测试显示相比现有生产模型，用户参与度显著提升（+2.10%时间花费）

Conclusion: Feed-SR在在线指标和生产效率方面提供了最佳组合，成功部署为LinkedIn Feed的主要推荐系统，相比其他序列和LLM架构具有更好的实用性

Abstract: LinkedIn Feed enables professionals worldwide to discover relevant content, build connections, and share knowledge at scale. We present Feed Sequential Recommender (Feed-SR), a transformer-based sequential ranking model for LinkedIn Feed that replaces a DCNv2-based ranker and meets strict production constraints. We detail the modeling choices, training techniques, and serving optimizations that enable deployment at LinkedIn scale. Feed-SR is currently the primary member experience on LinkedIn's Feed and shows significant improvements in member engagement (+2.10% time spent) in online A/B tests compared to the existing production model. We also describe our deployment experience with alternative sequential and LLM-based ranking architectures and why Feed-SR provided the best combination of online metrics and production efficiency.

</details>


### [3] [Latent Customer Segmentation and Value-Based Recommendation Leveraging a Two-Stage Model with Missing Labels](https://arxiv.org/abs/2602.12485)
*Keerthi Gopalakrishnan,Tianning Dong,Chia-Yen Ho,Yokila Arora,Topojoy Biswas,Jason Cho,Sushant Kumar,Kannan Achan*

Main category: cs.IR

TL;DR: 提出两阶段多模型架构，使用自步损失改进客户分类，区分活动影响、有机参与和低参与客户，提高营销活动精准度和转化效率


<details>
  <summary>Details</summary>
Motivation: 传统营销活动会侵蚀品牌价值且投资回报率低，现有经济算法常将高参与度客户误判为理想目标，导致参与和转化效率低下。需要更精准的客户分类方法

Method: 两阶段多模型架构：第一阶段使用多类神经网络区分活动影响客户、有机参与客户和低参与客户；第二阶段应用二元标签校正模型，在缺失标签框架下识别真正的活动驱动意图，在训练中细化客户细分

Result: 通过分离主动参与和有机行为，系统实现更精准的活动定向，降低曝光成本，提高转化效率。A/B测试显示关键成功指标提升超过100个基点

Conclusion: 意图感知细分对价值驱动营销策略有效，提出的架构能显著改善客户分类精度和营销效率

Abstract: The success of businesses depends on their ability to convert consumers into loyal customers. A customer's value proposition is a primary determinant in this process, requiring a balance between affordability and long-term brand equity. Broad marketing campaigns can erode perceived brand value and reduce return on investment, while existing economic algorithms often misidentify highly engaged customers as ideal targets, leading to inefficient engagement and conversion outcomes.
  This work introduces a two-stage multi-model architecture employing Self-Paced Loss to improve customer categorization. The first stage uses a multi-class neural network to distinguish customers influenced by campaigns, organically engaged customers, and low-engagement customers. The second stage applies a binary label correction model to identify true campaign-driven intent using a missing-label framework, refining customer segmentation during training.
  By separating prompted engagement from organic behavior, the system enables more precise campaign targeting, reduces exposure costs, and improves conversion efficiency. A/B testing demonstrates over 100 basis points improvement in key success metrics, highlighting the effectiveness of intent-aware segmentation for value-driven marketing strategies.

</details>


### [4] [Visual RAG Toolkit: Scaling Multi-Vector Visual Retrieval with Training-Free Pooling and Multi-Stage Search](https://arxiv.org/abs/2602.12510)
*Ara Yeroyan*

Main category: cs.IR

TL;DR: Visual RAG Toolkit通过训练无关的模型感知池化和多阶段检索，显著提升视觉多向量检索的效率，将每页向量从数千个减少到数十个，实现二次方级比较减少，在保持精度的同时提升4倍吞吐量。


<details>
  <summary>Details</summary>
Motivation: 多向量视觉检索器（如ColPali风格的延迟交互模型）虽然精度高，但扩展性差，因为每页产生数千个向量，导致索引和搜索成本高昂。需要一种实用的系统来扩展视觉多向量检索，同时降低硬件门槛。

Method: 1. 基于Matryoshka Embeddings思想，采用静态空间池化（包括轻量级滑动窗口平均变体）处理补丁嵌入，生成紧凑的瓦片级和全局表示用于快速候选生成；2. 使用完整多向量嵌入进行精确的MaxSim重排序；3. 提供强大的预处理流程（高分辨率PDF转图像、边缘裁剪、视觉标记索引）和可复现的评估管道。

Result: 在ViDoRe v2基准测试中，两阶段检索通常能保持NDCG和Recall @ 5/10的精度，仅有轻微下降，同时显著提升吞吐量（约4倍QPS）。在常见截断值（k≤10）下表现稳健，主要敏感度出现在非常大的k值时。

Conclusion: Visual RAG Toolkit通过强调常见截断值的效率，降低了硬件门槛，使最先进的视觉检索在实际应用中更加可访问。该方法无需后训练、适配器或蒸馏，实现了二次方级向量比较减少。

Abstract: Multi-vector visual retrievers (e.g., ColPali-style late interaction models) deliver strong accuracy, but scale poorly because each page yields thousands of vectors, making indexing and search increasingly expensive. We present Visual RAG Toolkit, a practical system for scaling visual multi-vector retrieval with training-free, model-aware pooling and multi-stage retrieval. Motivated by Matryoshka Embeddings, our method performs static spatial pooling - including a lightweight sliding-window averaging variant - over patch embeddings to produce compact tile-level and global representations for fast candidate generation, followed by exact MaxSim reranking using full multi-vector embeddings.
  Our design yields a quadratic reduction in vector-to-vector comparisons by reducing stored vectors per page from thousands to dozens, notably without requiring post-training, adapters, or distillation. Across experiments with interaction-style models such as ColPali and ColSmol-500M, we observe that over the limited ViDoRe v2 benchmark corpus 2-stage retrieval typically preserves NDCG and Recall @ 5/10 with minimal degradation, while substantially improving throughput (approximately 4x QPS); with sensitivity mainly at very large k. The toolkit additionally provides robust preprocessing - high resolution PDF to image conversion, optional margin/empty-region cropping and token hygiene (indexing only visual tokens) - and a reproducible evaluation pipeline, enabling rapid exploration of two-, three-, and cascaded retrieval variants. By emphasizing efficiency at common cutoffs (e.g., k <= 10), the toolkit lowers hardware barriers and makes state-of-the-art visual retrieval more accessible in practice.

</details>


### [5] [DiffuRank: Effective Document Reranking with Diffusion Language Models](https://arxiv.org/abs/2602.12528)
*Qi Liu,Kun Ai,Jiaxin Mao,Yanzhao Zhang,Mingxin Li,Dingkun Long,Pengjun Xie,Fengbin Zhu,Ji-Rong Wen*

Main category: cs.IR

TL;DR: DiffuRank：基于扩散语言模型的文档重排框架，通过并行解码和灵活生成顺序解决自回归模型效率低、错误传播的问题


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的文档重排方法主要依赖自回归生成，存在效率低（逐token解码延迟高）和灵活性差（固定从左到右顺序导致早期错误传播且难以修正）的问题

Method: 提出DiffuRank框架，基于扩散语言模型(dLLMs)实现三种重排策略：1)点式方法评估单个查询-文档对相关性；2)基于logit的列表方法联合评估多个文档相关性；3)基于排列的列表方法将dLLMs标准解码过程适配到重排任务

Result: 在多个基准测试中，dLLMs在零样本和微调设置下都取得了与相似规模自回归LLM相当甚至更好的性能，证明了扩散模型作为文档重排替代架构的潜力

Conclusion: 扩散语言模型为文档重排提供了有前景的替代方案，支持更灵活的生成顺序和并行解码，在保持性能的同时可能提升效率和可控性

Abstract: Recent advances in large language models (LLMs) have inspired new paradigms for document reranking. While this paradigm better exploits the reasoning and contextual understanding capabilities of LLMs, most existing LLM-based rerankers rely on autoregressive generation, which limits their efficiency and flexibility. In particular, token-by-token decoding incurs high latency, while the fixed left-to-right generation order causes early prediction errors to propagate and is difficult to revise. To address these limitations, we explore the use of diffusion language models (dLLMs) for document reranking and propose DiffuRank, a reranking framework built upon dLLMs. Unlike autoregressive models, dLLMs support more flexible decoding and generation processes that are not constrained to a left-to-right order, and enable parallel decoding, which may lead to improved efficiency and controllability. Specifically, we investigate three reranking strategies based on dLLMs: (1) a pointwise approach that uses dLLMs to estimate the relevance of each query-document pair; (2) a logit-based listwise approach that prompts dLLMs to jointly assess the relevance of multiple documents and derives ranking lists directly from model logits; and (3) a permutation-based listwise approach that adapts the canonical decoding process of dLLMs to the reranking tasks. For each approach, we design corresponding training methods to fully exploit the advantages of dLLMs. We evaluate both zero-shot and fine-tuned reranking performance on multiple benchmarks. Experimental results show that dLLMs achieve performance comparable to, and in some cases exceeding, that of autoregressive LLMs with similar model sizes. These findings demonstrate the promise of diffusion-based language models as a compelling alternative to autoregressive architectures for document reranking.

</details>


### [6] [Reasoning to Rank: An End-to-End Solution for Exploiting Large Language Models for Recommendation](https://arxiv.org/abs/2602.12530)
*Kehan Zheng,Deyao Hong,Qian Li,Jun Zhang,Huan Yu,Jie Jiang,Hongning Wang*

Main category: cs.IR

TL;DR: 提出Reasoning to Rank框架，通过强化学习端到端训练LLM进行推荐推理，优化推荐效用


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统需要超越基于模式的评分，进行深度推理来理解用户偏好。虽然已有工作利用LLM进行推荐，但如何有效优化模型以提升推荐效用仍待探索

Method: 提出Reasoning to Rank端到端训练框架，将推荐效用优化内化到LLM的逐步推理学习中。在用户-物品级别进行推理以避免位置偏差，并使用强化学习进行端到端训练

Result: 在三个Amazon数据集和一个大规模工业数据集上的实验显示，相比传统和基于LLM的解决方案都取得了持续提升。深入分析验证了框架关键组件的必要性

Conclusion: 该框架为基于LLM的推荐系统提供了有效的端到端训练方法，为这一研究方向的发展提供了启示

Abstract: Recommender systems are tasked to infer users' evolving preferences and rank items aligned with their intents, which calls for in-depth reasoning beyond pattern-based scoring. Recent efforts start to leverage large language models (LLMs) for recommendation, but how to effectively optimize the model for improved recommendation utility is still under explored. In this work, we propose Reasoning to Rank, an end-to-end training framework that internalizes recommendation utility optimization into the learning of step-by-step reasoning in LLMs. To avoid position bias in LLM reasoning and enable direct optimization of the reasoning process, our framework performs reasoning at the user-item level and employs reinforcement learning for end-to-end training of the LLM. Experiments on three Amazon datasets and a large-scale industrial dataset showed consistent gains over strong conventional and LLM-based solutions. Extensive in-depth analyses validate the necessity of the key components in the proposed framework and shed lights on the future developments of this line of work.

</details>


### [7] [CAPTS: Channel-Aware, Preference-Aligned Trigger Selection for Multi-Channel Item-to-Item Retrieval](https://arxiv.org/abs/2602.12564)
*Xiaoyou Zhou,Yuqi Liu,Zhao Liu,Xiao Lv,Bo Chen,Ruiming Tang,Guorui Zhou*

Main category: cs.IR

TL;DR: CAPTS框架通过价值归因模块和通道自适应触发路由，解决了多通道检索中触发选择的偏见和协调问题，提升了推荐系统性能。


<details>
  <summary>Details</summary>
Motivation: 现有工业推荐系统在多通道检索中面临两个主要挑战：1）偏见价值归因 - 仅基于触发反馈而非下游检索效用评估触发价值；2）无协调多通道路由 - 各通道独立选择触发导致跨通道重叠。这些问题限制了多通道检索的整体效果。

Method: 提出CAPTS框架，包含两个核心模块：1）价值归因模块（VAM）- 通过前瞻监督为每个触发分配下游I2I通道检索产生的后续参与价值；2）通道自适应触发路由（CATR）- 协调触发到通道的分配，最大化多通道检索的整体价值。

Result: 在快手国际短视频平台Kwai上进行的离线实验和大规模在线A/B测试显示，CAPTS持续提升多通道召回率，在线测试中平均设备使用时间提升+0.351%。

Conclusion: CAPTS框架有效解决了多通道触发选择中的价值归因偏见和通道协调问题，通过统一的学习路由方法显著提升了工业推荐系统的性能。

Abstract: Large-scale industrial recommender systems commonly adopt multi-channel retrieval for candidate generation, combining direct user-to-item (U2I) retrieval with two-hop user-to-item-to-item (U2I2I) pipelines. In U2I2I, the system selects a small set of historical interactions as triggers to seed downstream item-to-item (I2I) retrieval across multiple channels. In production, triggers are often selected using rule-based policies or learned scorers and tuned in a channel-by-channel manner. However, these practices face two persistent challenges: biased value attribution that values triggers by on-trigger feedback rather than their downstream utility as retrieval seeds, and uncoordinated multi-channel routing where channels select triggers independently under a shared quota, increasing cross-channel overlap. To address these challenges, we propose Channel-Aware, Preference-Aligned Trigger Selection (CAPTS), a unified and flexible framework that treats multi-channel trigger selection as a learnable routing problem. CAPTS introduces a Value Attribution Module (VAM) that provides look-ahead supervision by crediting each trigger with the subsequent engagement generated by items retrieved from it on each I2I channel, and a Channel-Adaptive Trigger Routing (CATR) module that coordinates trigger-to-channel assignment to maximize the overall value of multi-channel retrieval. Extensive offline experiments and large-scale online A/B tests on Kwai, Kuaishou's international short-video platform, show that CAPTS consistently improves multi-channel recall offline and delivers a +0.351% lift in average time spent per device online.

</details>


### [8] [RQ-GMM: Residual Quantized Gaussian Mixture Model for Multimodal Semantic Discretization in CTR Prediction](https://arxiv.org/abs/2602.12593)
*Ziye Tong,Jiahao Liu,Weimin Zhang,Hongji Ruan,Derick Tang,Zhanpeng Zeng,Qinsong Zeng,Peng Zhang,Tun Lu,Ning Gu*

Main category: cs.IR

TL;DR: RQ-GMM使用残差量化高斯混合模型将多模态嵌入离散化为语义ID，解决CTR预测中预训练嵌入与CTR模型目标不一致的问题，在公开数据集和在线A/B测试中显著提升广告主价值。


<details>
  <summary>Details</summary>
Motivation: 多模态内容对CTR预测至关重要，但直接将预训练模型的连续嵌入输入CTR模型效果不佳，因为优化目标和收敛速度不一致。现有离散化方法存在码本利用率低、重建精度差和语义区分度不足的问题。

Method: 提出RQ-GMM（残差量化高斯混合模型），通过高斯混合模型结合残差量化来更好地捕捉多模态嵌入空间的统计结构，实现更优的码本利用率和重建精度。

Result: 在公开数据集和大型短视频平台的在线A/B测试中，RQ-GMM相比强基线获得1.502%的广告主价值提升，已完全部署并为数亿用户提供日常推荐服务。

Conclusion: RQ-GMM通过概率建模有效解决了多模态嵌入离散化问题，显著提升了CTR预测性能，在实际工业场景中验证了其有效性。

Abstract: Multimodal content is crucial for click-through rate (CTR) prediction. However, directly incorporating continuous embeddings from pre-trained models into CTR models yields suboptimal results due to misaligned optimization objectives and convergence speed inconsistency during joint training. Discretizing embeddings into semantic IDs before feeding them into CTR models offers a more effective solution, yet existing methods suffer from limited codebook utilization, reconstruction accuracy, and semantic discriminability. We propose RQ-GMM (Residual Quantized Gaussian Mixture Model), which introduces probabilistic modeling to better capture the statistical structure of multimodal embedding spaces. Through Gaussian Mixture Models combined with residual quantization, RQ-GMM achieves superior codebook utilization and reconstruction accuracy. Experiments on public datasets and online A/B tests on a large-scale short-video platform serving hundreds of millions of users demonstrate substantial improvements: RQ-GMM yields a 1.502% gain in Advertiser Value over strong baselines. The method has been fully deployed, serving daily recommendations for hundreds of millions of users.

</details>


### [9] [Self-EvolveRec: Self-Evolving Recommender Systems with LLM-based Directional Feedback](https://arxiv.org/abs/2602.12612)
*Sein Kim,Sangwu Park,Hongseok Kang,Wonjoong Kim,Jimin Seo,Yeonjun In,Kanghoon Yoon,Chanyoung Park*

Main category: cs.IR

TL;DR: Self-EvolveRec是一个新颖的推荐系统自动设计框架，通过集成用户模拟器进行定性批判和模型诊断工具进行定量验证，建立定向反馈循环，显著超越了传统NAS和LLM驱动的代码进化方法。


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统自动化设计方法（如NAS）受限于人类先验定义的固定搜索空间，而最近的LLM驱动代码进化框架虽然转向开放程序空间，但主要依赖NDCG、命中率等标量指标，缺乏对模型失败的定性洞察和改进方向指导。

Method: 提出Self-EvolveRec框架，建立定向反馈循环：1）集成用户模拟器提供定性批判；2）模型诊断工具进行定量内部验证；3）引入诊断工具-模型协同进化策略，确保评估标准随推荐架构演化而动态适应。

Result: 大量实验表明，Self-EvolveRec在推荐性能和用户满意度方面显著优于最先进的NAS和LLM驱动的代码进化基线方法。

Conclusion: Self-EvolveRec通过建立定向反馈循环和动态评估适应机制，解决了传统自动化推荐系统设计方法的局限性，为开放式的推荐架构进化提供了有效解决方案。

Abstract: Traditional methods for automating recommender system design, such as Neural Architecture Search (NAS), are often constrained by a fixed search space defined by human priors, limiting innovation to pre-defined operators. While recent LLM-driven code evolution frameworks shift fixed search space target to open-ended program spaces, they primarily rely on scalar metrics (e.g., NDCG, Hit Ratio) that fail to provide qualitative insights into model failures or directional guidance for improvement. To address this, we propose Self-EvolveRec, a novel framework that establishes a directional feedback loop by integrating a User Simulator for qualitative critiques and a Model Diagnosis Tool for quantitative internal verification. Furthermore, we introduce a Diagnosis Tool - Model Co-Evolution strategy to ensure that evaluation criteria dynamically adapt as the recommendation architecture evolves. Extensive experiments demonstrate that Self-EvolveRec significantly outperforms state-of-the-art NAS and LLM-driven code evolution baselines in both recommendation performance and user satisfaction. Our code is available at https://github.com/Sein-Kim/self_evolverec.

</details>


### [10] [Training Dense Retrievers with Multiple Positive Passages](https://arxiv.org/abs/2602.12727)
*Benben Wang,Minghao Tang,Hengran Zhang,Jiafeng Guo,Keping Bi*

Main category: cs.IR

TL;DR: 本文系统研究了检索器训练中的多正例优化目标，发现LSEPair损失在不同设置下表现最稳健，而JointLH和SumMargLH对正例质量敏感。


<details>
  <summary>Details</summary>
Motivation: 知识密集型系统（如RAG）依赖检索器性能，但传统训练受限于稀疏的单正例标注，导致假阴性噪声和次优监督。虽然LLM可以大规模收集密集的多正例相关性标签，但如何有效利用这些密集信号进行训练仍不明确。

Method: 将JointLH、SumMargLH和LSEPair等代表性目标统一到对比学习框架下，进行理论分析揭示其梯度行为差异，并在Natural Questions、MS MARCO和BEIR基准上进行实证评估，涵盖同质LLM标注数据和异质混合标注两种现实场景。

Result: LSEPair在不同设置下均表现出优越的稳健性和性能，而JointLH和SumMargLH对正例质量高度敏感。简单的随机采样策略（Rand1LH）可作为可靠基线。理论分析与实证结果一致，为利用密集LLM增强监督提升检索器效果提供了实用设计原则。

Conclusion: 通过系统研究多正例优化目标，发现LSEPair是最稳健的选择，为利用LLM生成的密集标注改进检索器训练提供了理论指导和实践建议。

Abstract: Modern knowledge-intensive systems, such as retrieval-augmented generation (RAG), rely on effective retrievers to establish the performance ceiling for downstream modules. However, retriever training has been bottlenecked by sparse, single-positive annotations, which lead to false-negative noise and suboptimal supervision. While the advent of large language models (LLMs) makes it feasible to collect comprehensive multi-positive relevance labels at scale, the optimal strategy for incorporating these dense signals into training remains poorly understood. In this paper, we present a systematic study of multi-positive optimization objectives for retriever training. We unify representative objectives, including Joint Likelihood (JointLH), Summed Marginal Likelihood (SumMargLH), and Log-Sum-Exp Pairwise (LSEPair) loss, under a shared contrastive learning framework. Our theoretical analysis characterizes their distinct gradient behaviors, revealing how each allocates probability mass across positive document sets. Empirically, we conduct extensive evaluations on Natural Questions, MS MARCO, and the BEIR benchmark across two realistic regimes: homogeneous LLM-annotated data and heterogeneous mixtures of human and LLM labels. Our results show that LSEPair consistently achieves superior robustness and performance across settings, while JointLH and SumMargLH exhibit high sensitivity to the quality of positives. Furthermore, we find that the simple strategy of random sampling (Rand1LH) serves as a reliable baseline. By aligning theoretical insights with empirical findings, we provide practical design principles for leveraging dense, LLM-augmented supervision to enhance retriever effectiveness.

</details>


### [11] [SQuTR: A Robustness Benchmark for Spoken Query to Text Retrieval under Acoustic Noise](https://arxiv.org/abs/2602.12783)
*Yuejie Li,Ke Yang,Yueying Hua,Berlin Chen,Jianhao Nie,Yueping He,Caixin Kang*

Main category: cs.IR

TL;DR: SQuTR是一个用于口语查询检索的鲁棒性基准测试，包含大规模数据集和统一评估协议，用于评估系统在复杂声学扰动下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有口语查询检索评估数据集通常局限于简单查询和受限噪声条件，无法充分评估系统在复杂声学扰动下的鲁棒性。

Method: 构建SQuTR基准测试，聚合6个常用英中文本检索数据集的37,317个独特查询，使用200个真实说话者语音配置文件合成语音，并混合17类真实环境噪声在可控信噪比下。

Result: 检索性能随噪声增加而下降，不同系统下降幅度差异显著，即使大规模检索模型在极端噪声下也表现不佳，表明鲁棒性仍是关键瓶颈。

Conclusion: SQuTR为口语查询到文本检索的鲁棒性研究提供了可复现的测试平台和诊断分析工具，有助于推动该领域的未来发展。

Abstract: Spoken query retrieval is an important interaction mode in modern information retrieval. However, existing evaluation datasets are often limited to simple queries under constrained noise conditions, making them inadequate for assessing the robustness of spoken query retrieval systems under complex acoustic perturbations. To address this limitation, we present SQuTR, a robustness benchmark for spoken query retrieval that includes a large-scale dataset and a unified evaluation protocol. SQuTR aggregates 37,317 unique queries from six commonly used English and Chinese text retrieval datasets, spanning multiple domains and diverse query types. We synthesize speech using voice profiles from 200 real speakers and mix 17 categories of real-world environmental noise under controlled SNR levels, enabling reproducible robustness evaluation from quiet to highly noisy conditions. Under the unified protocol, we conduct large-scale evaluations on representative cascaded and end-to-end retrieval systems. Experimental results show that retrieval performance decreases as noise increases, with substantially different drops across systems. Even large-scale retrieval models struggle under extreme noise, indicating that robustness remains a critical bottleneck. Overall, SQuTR provides a reproducible testbed for benchmarking and diagnostic analysis, and facilitates future research on robustness in spoken query to text retrieval.

</details>


### [12] [WISE: A Multimodal Search Engine for Visual Scenes, Audio, Objects, Faces, Speech, and Metadata](https://arxiv.org/abs/2602.12819)
*Prasanna Sridhar,Horace Lee,David M. S. Pinto,Andrew Zisserman,Abhishek Dutta*

Main category: cs.IR

TL;DR: WISE是一个开源的多模态音视频搜索引擎，支持自然语言、图像、人脸、音频等多种查询方式，可扩展到百万级图像和千小时视频检索。


<details>
  <summary>Details</summary>
Motivation: 为没有机器学习专业知识的用户提供实用的多模态检索工具，将多种检索能力集成到单一工具中，支持本地部署保护隐私敏感数据。

Method: 采用向量搜索技术实现高效检索，支持场景级和对象级的图像/视频查询、人脸搜索、音频事件检索、语音转录搜索和元数据过滤，具有模块化架构便于集成新模型。

Result: 开发出可扩展的多模态搜索引擎，支持跨模态组合查询（如"火车"对象+德国元数据），已在多个实际应用案例中验证，代码开源可用。

Conclusion: WISE为多模态检索提供了实用的开源解决方案，使非专业用户也能进行复杂的跨模态搜索，特别适合处理敏感或私有数据集合。

Abstract: In this paper, we present WISE, an open-source audiovisual search engine which integrates a range of multimodal retrieval capabilities into a single, practical tool accessible to users without machine learning expertise. WISE supports natural-language and reverse-image queries at both the scene level (e.g. empty street) and object level (e.g. horse) across images and videos; face-based search for specific individuals; audio retrieval of acoustic events using text (e.g. wood creak) or an audio file; search over automatically transcribed speech; and filtering by user-provided metadata. Rich insights can be obtained by combining queries across modalities -- for example, retrieving German trains from a historical archive by applying the object query "train" and the metadata query "Germany", or searching for a face in a place. By employing vector search techniques, WISE can scale to support efficient retrieval over millions of images or thousands of hours of video. Its modular architecture facilitates the integration of new models. WISE can be deployed locally for private or sensitive collections, and has been applied to various real-world use cases. Our code is open-source and available at https://gitlab.com/vgg/wise/wise.

</details>


### [13] [JARVIS: An Evidence-Grounded Retrieval System for Interpretable Deceptive Reviews Adjudication](https://arxiv.org/abs/2602.12941)
*Nan Lu,Leyang Li,Yurong Hu,Rui Lin,Shaoyi Xu*

Main category: cs.IR

TL;DR: JARVIS框架通过增强检索和证据图结构检测虚假评论，提升检测性能和可解释性


<details>
  <summary>Details</summary>
Motivation: 现有虚假评论检测方法存在两个关键限制：泛化能力不足和缺乏可解释性，需要更有效的解决方案

Method: 提出JARVIS框架：从待评估评论出发，通过混合稠密-稀疏多模态检索获取语义相似证据，通过共享实体扩展关系信号，构建异质证据图，然后使用大语言模型进行基于证据的裁决

Result: 离线实验中，在构建的评论数据集上，精确度从0.953提升到0.988，召回率从0.830提升到0.901；生产环境中，召回量增加27%，人工检查时间减少75%，模型生成分析的采纳率达到96.4%

Conclusion: JARVIS框架有效解决了虚假评论检测中的泛化能力和可解释性问题，在离线实验和生产环境中都表现出显著性能提升

Abstract: Deceptive reviews, refer to fabricated feedback designed to artificially manipulate the perceived quality of products. Within modern e-commerce ecosystems, these reviews remain a critical governance challenge. Despite advances in review-level and graph-based detection methods, two pivotal limitations remain: inadequate generalization and lack of interpretability. To address these challenges, we propose JARVIS, a framework providing Judgment via Augmented Retrieval and eVIdence graph Structures. Starting from the review to be evaluated, it retrieves semantically similar evidence via hybrid dense-sparse multimodal retrieval, expands relational signals through shared entities, and constructs a heterogeneous evidence graph. Large language model then performs evidence-grounded adjudication to produce interpretable risk assessments. Offline experiments demonstrate that JARVIS enhances performance on our constructed review dataset, achieving a precision increase from 0.953 to 0.988 and a recall boost from 0.830 to 0.901. In the production environment, our framework achieves a 27% increase in the recall volume and reduces manual inspection time by 75%. Furthermore, the adoption rate of the model-generated analysis reaches 96.4%.

</details>


### [14] [RGAlign-Rec: Ranking-Guided Alignment for Latent Query Reasoning in Recommendation Systems](https://arxiv.org/abs/2602.12968)
*Junhua Liu,Yang Jihao,Cheng Chang,Kunrong LI,Bin Fu,Kwan Hui Lim*

Main category: cs.IR

TL;DR: RGAlign-Rec：一个闭环对齐框架，通过LLM语义推理器与查询增强排序模型结合，解决电商聊天机器人中主动意图预测的语义鸿沟和目标错配问题。


<details>
  <summary>Details</summary>
Motivation: 现代电商聊天机器人需要主动意图预测能力以实现"零查询"推荐，但现有工业系统面临两个核心挑战：1）离散用户特征与知识库语义意图之间的语义鸿沟；2）通用LLM输出与任务特定排序效用之间的目标错配。

Method: 提出RGAlign-Rec框架，整合基于LLM的语义推理器和查询增强排序模型。引入排序引导对齐（RGA）多阶段训练范式，利用下游排序信号作为反馈来优化LLM的潜在推理。

Result: 在Shopee大规模工业数据集上，RGAlign-Rec实现GAUC提升0.12%，错误率相对降低3.52%，Recall@3提升0.56%。在线A/B测试显示查询增强模型（QE-Rec）带来CTR提升0.98%，后续排序引导对齐阶段额外贡献0.13%增益。

Conclusion: 排序感知对齐能有效同步语义推理与排序目标，显著提升现实世界主动推荐系统的预测准确性和服务质量，为解决工业推荐系统中的语义鸿沟和目标对齐问题提供了有效方案。

Abstract: Proactive intent prediction is a critical capability in modern e-commerce chatbots, enabling "zero-query" recommendations by anticipating user needs from behavioral and contextual signals. However, existing industrial systems face two fundamental challenges: (1) the semantic gap between discrete user features and the semantic intents within the chatbot's Knowledge Base, and (2) the objective misalignment between general-purpose LLM outputs and task-specific ranking utilities. To address these issues, we propose RGAlign-Rec, a closed-loop alignment framework that integrates an LLM-based semantic reasoner with a Query-Enhanced (QE) ranking model. We also introduce Ranking-Guided Alignment (RGA), a multi-stage training paradigm that utilizes downstream ranking signals as feedback to refine the LLM's latent reasoning. Extensive experiments on a large-scale industrial dataset from Shopee demonstrate that RGAlign-Rec achieves a 0.12% gain in GAUC, leading to a significant 3.52% relative reduction in error rate, and a 0.56% improvement in Recall@3. Online A/B testing further validates the cumulative effectiveness of our framework: the Query-Enhanced model (QE-Rec) initially yields a 0.98% improvement in CTR, while the subsequent Ranking-Guided Alignment stage contributes an additional 0.13% gain. These results indicate that ranking-aware alignment effectively synchronizes semantic reasoning with ranking objectives, significantly enhancing both prediction accuracy and service quality in real-world proactive recommendation systems.

</details>


### [15] [Awakening Dormant Users: Generative Recommendation with Counterfactual Functional Role Reasoning](https://arxiv.org/abs/2602.13134)
*Huishi Luo,Shuokai Li,Hanchen Yang,Zhongbo Sun,Haojie Ding,Boheng Zhang,Zijia Cai,Renliang Qian,Fan Yang,Tingting Gao,Chenyi Lei,Wenwu Ou,Fuzhen Zhuang*

Main category: cs.IR

TL;DR: RoleGen是一个唤醒电商平台休眠用户的框架，通过建模商品在转化轨迹中的功能性角色，结合LLM推理器和生成式行为骨干网络，显著提升召回率和订单量。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常基于单步估计商品内在价值（如即时点击概率），忽略了商品的工具性效应——特定交互可以触发潜在意图并驱动后续转化决策，导致对休眠用户的唤醒效果不佳。

Method: 提出RoleGen框架：1) LLM推理器显式建模商品在上下文中的功能性角色，重构意图演化过程；2) 使用反事实推理模拟多样化转化路径，缓解兴趣塌陷；3) 将推理候选商品集成到生成式骨干网络中，通过"推理-执行-反馈-反思"闭环策略进行优化。

Result: 在快手电商平台的离线实验和在线A/B测试中，RoleGen实现了Recall@1提升6.2%，在线订单量增加7.3%，有效激活了休眠用户群体。

Conclusion: RoleGen通过建模商品在转化轨迹中的功能性角色，结合LLM推理和生成式方法，显著提升了电商平台休眠用户的唤醒效果，为GMV增长提供了有效解决方案。

Abstract: Awakening dormant users, who remain engaged but exhibit low conversion, is a pivotal driver for incremental GMV growth in large-scale e-commerce platforms. However, existing approaches often yield suboptimal results since they typically rely on single-step estimation of an item's intrinsic value (e.g., immediate click probability). This mechanism overlooks the instrumental effect of items, where specific interactions act as triggers to shape latent intent and drive subsequent decisions along a conversion trajectory. To bridge this gap, we propose RoleGen, a novel framework that synergizes a Conversion Trajectory Reasoner with a Generative Behavioral Backbone. Specifically, the LLM-based Reasoner explicitly models the context-dependent Functional Role of items to reconstruct intent evolution. It further employs counterfactual inference to simulate diverse conversion paths, effectively mitigating interest collapse. These reasoned candidate items are integrated into the generative backbone, which is optimized via a collaborative "Reasoning-Execution-Feedback-Reflection" closed-loop strategy to ensure grounded execution. Extensive offline experiments and online A/B testing on the Kuaishou e-commerce platform demonstrate that RoleGen achieves a 6.2% gain in Recall@1 and a 7.3% increase in online order volume, confirming its effectiveness in activating the dormant user base.

</details>


### [16] [Asynchronous Verified Semantic Caching for Tiered LLM Architectures](https://arxiv.org/abs/2602.13165)
*Asmit Kumar Singh,Haozhe Wang,Laxmi Naga Santosh Attaluri,Tak Chiam,Weihua Zhu*

Main category: cs.IR

TL;DR: Krites是一种异步LLM判断的语义缓存策略，通过LLM验证来扩展静态缓存的覆盖范围，而不影响关键路径延迟。


<details>
  <summary>Details</summary>
Motivation: LLM在搜索、助手和代理工作流中处于关键路径，需要语义缓存来降低推理成本和延迟。传统静态-动态分层缓存使用单一嵌入相似度阈值，存在保守阈值错过安全重用机会与激进阈值导致语义错误响应的硬性权衡。

Method: Krites采用异步LLM判断策略：在关键路径上保持标准静态阈值策略行为；当提示的最邻近静态邻居略低于静态阈值时，异步调用LLM法官验证静态响应是否适用于新提示；批准的匹配被提升到动态缓存中，允许未来重复和改写重用策划的静态答案。

Result: 在对话和搜索工作负载的跟踪驱动模拟中，Krites将使用策划静态答案服务的请求比例（直接静态命中加验证提升）提高了最多3.9倍，同时关键路径延迟保持不变。

Conclusion: Krites通过异步LLM验证机制有效扩展了静态缓存的覆盖范围，解决了传统阈值策略的硬性权衡问题，在不增加关键路径延迟的情况下显著提高了缓存命中率。

Abstract: Large language models (LLMs) now sit in the critical path of search, assistance, and agentic workflows, making semantic caching essential for reducing inference cost and latency. Production deployments typically use a tiered static-dynamic design: a static cache of curated, offline vetted responses mined from logs, backed by a dynamic cache populated online. In practice, both tiers are commonly governed by a single embedding similarity threshold, which induces a hard tradeoff: conservative thresholds miss safe reuse opportunities, while aggressive thresholds risk serving semantically incorrect responses. We introduce \textbf{Krites}, an asynchronous, LLM-judged caching policy that expands static coverage without changing serving decisions. On the critical path, Krites behaves exactly like a standard static threshold policy. When the nearest static neighbor of the prompt falls just below the static threshold, Krites asynchronously invokes an LLM judge to verify whether the static response is acceptable for the new prompt. Approved matches are promoted into the dynamic cache, allowing future repeats and paraphrases to reuse curated static answers and expanding static reach over time. In trace-driven simulations on conversational and search workloads, Krites increases the fraction of requests served with curated static answers (direct static hits plus verified promotions) by up to $\textbf{3.9}$ times for conversational traffic and search-style queries relative to tuned baselines, with unchanged critical path latency.

</details>


### [17] [Fix Before Search: Benchmarking Agentic Query Visual Pre-processing in Multimodal Retrieval-augmented Generation](https://arxiv.org/abs/2602.13179)
*Jiankun Zhang,Shenglai Zeng,Kai Guo,Xinnan Dai,Hui Liu,Jiliang Tang,Yi Chang*

Main category: cs.IR

TL;DR: V-QPP-Bench是首个专注于视觉查询预处理（V-QPP）的综合性基准测试，用于解决多模态检索增强生成（MRAG）中视觉查询不完美的问题，通过评估发现视觉缺陷会严重降低检索性能，而适当的预处理可以显著恢复性能。


<details>
  <summary>Details</summary>
Motivation: 现有MRAG系统通常将视觉输入视为静态且无噪声的，但现实中的视觉查询往往存在几何变形、质量退化或语义模糊等"不完美"问题，这会导致灾难性的检索失败。目前缺乏专门针对视觉查询预处理的系统性研究。

Method: 将V-QPP定义为智能体决策任务，要求MLLMs自主诊断视觉缺陷并部署感知工具来优化查询。构建了包含46,700个不完美查询的综合性基准测试，涵盖多种MRAG范式，评估了不同预处理策略的效果。

Result: 1) 视觉缺陷会严重降低检索召回率和端到端MRAG性能；2) 理想的预处理可以恢复接近完美的性能，但现成的MLLMs在工具选择和参数预测方面表现不佳；3) 监督微调能使紧凑模型达到与大型专有模型相当或更优的性能。

Conclusion: V-QPP-Bench为开发鲁棒的MRAG系统提供了重要基准，证明了视觉查询预处理对多模态检索增强生成的关键作用，并展示了通过专门训练可以显著提升预处理能力。

Abstract: Multimodal Retrieval-Augmented Generation (MRAG) has emerged as a key paradigm for grounding MLLMs with external knowledge. While query pre-processing (e.g., rewriting) is standard in text-based RAG, existing MRAG pipelines predominantly treat visual inputs as static and immutable, implicitly assuming they are noise-free. However, real-world visual queries are often ``imperfect'' -- suffering from geometric distortions, quality degradation, or semantic ambiguity -- leading to catastrophic retrieval failures. To address this gap, we propose V-QPP-Bench, the first comprehensive benchmark dedicated to Visual Query Pre-processing (V-QPP). We formulate V-QPP as an agentic decision-making task where MLLMs must autonomously diagnose imperfections and deploy perceptual tools to refine queries. Our extensive evaluation across 46,700 imperfect queries and diverse MRAG paradigms reveals three critical insights: (1) Vulnerability -- visual imperfections severely degrade both retrieval recall and end-to-end MRAG performance; (2) Restoration Potential \& Bottleneck -- while oracle preprocessing recovers near-perfect performance, off-the-shelf MLLMs struggle with tool selection and parameter prediction without specialized training; and (3) Training Enhancement -- supervised fine-tuning enables compact models to achieve comparable or superior performance to larger proprietary models, demonstrating the benchmark's value for developing robust MRAG systems The code is available at https://github.com/phycholosogy/VQQP_Bench

</details>
