<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 9]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Is Grokipedia Right-Leaning? Comparing Political Framing in Wikipedia and Grokipedia on Controversial Topics](https://arxiv.org/abs/2601.15484)
*Philipp Eibl,Erica Coppolillo,Simone Mungari,Luca Luceri*

Main category: cs.IR

TL;DR: 比较分析维基百科和Grokipedia在政治争议话题上的差异，发现两者语义相似度随文章章节递减，在争议话题上分歧更大，且两者都主要呈现左倾框架，但Grokipedia呈现更明显的双峰分布并包含更多右倾内容。


<details>
  <summary>Details</summary>
Motivation: 在线百科全书是现代信息基础设施的核心，常涉及意识形态偏见争议。维基百科长期被指责有左倾偏见，而xAI推出的AI生成百科全书Grokipedia则被视为右倾替代品。本研究旨在比较分析这两个平台在政治争议话题上的差异。

Method: 对维基百科和Grokipedia在已确立的政治争议话题上进行对比分析，具体考察语义框架、政治倾向和内容优先级的差异。使用语义相似度分析、政治倾向检测等方法。

Result: 1. 两个平台的语义相似度随文章章节递减；2. 在争议话题上的分歧比随机抽样话题更大；3. 两个百科全书都主要呈现左倾框架；4. Grokipedia呈现更明显的双峰分布，右倾内容更突出。

Conclusion: 维基百科和Grokipedia在政治争议话题上存在系统性差异，虽然两者都主要呈现左倾框架，但Grokipedia包含更多右倾内容，呈现更明显的意识形态双峰分布。实验代码已公开。

Abstract: Online encyclopedias are central to contemporary information infrastructures and have become focal points of debates over ideological bias. Wikipedia, in particular, has long been accused of left-leaning bias, while Grokipedia, an AI-generated encyclopedia launched by xAI, has been framed as a right-leaning alternative. This paper presents a comparative analysis of Wikipedia and Grokipedia on well-established politically contested topics. Specifically, we examine differences in semantic framing, political orientation, and content prioritization. We find that semantic similarity between the two platforms decays across article sections and diverges more strongly on controversial topics than on randomly sampled ones. Additionally, we show that both encyclopedias predominantly exhibit left-leaning framings, although Grokipedia exhibits a more bimodal distribution with increased prominence of right-leaning content. The experimental code is publicly available.

</details>


### [2] [DS@GT at TREC TOT 2025: Bridging Vague Recollection with Fusion Retrieval and Learned Reranking](https://arxiv.org/abs/2601.15518)
*Wenxin Zhou,Ritesh Mehta,Anthony Miyaguchi*

Main category: cs.IR

TL;DR: 提出两阶段检索系统，结合多种检索方法与学习型重排序器及LLM重排序，用于TREC Tip-of-the-Tongue任务，通过混合检索和Gemini-2.5-flash重排序达到最佳效果


<details>
  <summary>Details</summary>
Motivation: 解决TREC Tip-of-the-Tongue（话到嘴边）任务的检索挑战，该任务需要从模糊记忆中检索具体信息，传统单一检索方法效果有限

Method: 两阶段检索系统：第一阶段采用混合检索，结合LLM检索、稀疏检索（BM25）和稠密检索（BGE-M3），并引入主题感知多索引稠密检索；第二阶段使用训练好的LambdaMART重排序器和LLM重排序；为训练生成5000个合成ToT查询

Result: 最佳系统（混合检索+Gemini-2.5-flash重排序）在测试集上达到召回率0.66和NDCG@1000为0.41，证明了融合检索的有效性

Conclusion: 融合多种互补检索方法与LLM重排序能有效解决Tip-of-the-Tongue任务，混合检索策略显著提升检索性能

Abstract: We develop a two-stage retrieval system that combines multiple complementary retrieval methods with a learned reranker and LLM-based reranking, to address the TREC Tip-of-the-Tongue (ToT) task. In the first stage, we employ hybrid retrieval that merges LLM-based retrieval, sparse (BM25), and dense (BGE-M3) retrieval methods. We also introduce topic-aware multi-index dense retrieval that partitions the Wikipedia corpus into 24 topical domains. In the second stage, we evaluate both a trained LambdaMART reranker and LLM-based reranking. To support model training, we generate 5000 synthetic ToT queries using LLMs. Our best system achieves recall of 0.66 and NDCG@1000 of 0.41 on the test set by combining hybrid retrieval with Gemini-2.5-flash reranking, demonstrating the effectiveness of fusion retrieval.

</details>


### [3] [Blockchain-Based Spectrum Resource Securitization via Semi-Fungible Token-Lock](https://arxiv.org/abs/2601.15594)
*Zhixian Zhou,Bin Chen,Zhe Peng,Zhiming Liang,Ruijun Wu,Chen Sun,Shuo Wang*

Main category: cs.IR

TL;DR: 本文提出SFT Lock方法，通过锁/解锁机制替代铸造/销毁操作，在保持NFT身份和历史可追溯性的同时实现频谱资产的分割所有权和可转移性，显著降低链上开销。


<details>
  <summary>Details</summary>
Motivation: 随着6G网络发展，频谱资产需要灵活、动态和高效的利用，这推动了基于区块链的频谱证券化。现有基于ERC404混合代币模型的方法在资产转移时频繁进行铸造和销毁操作，这会破坏代币身份连续性并增加链上开销。

Method: 提出半同质化代币锁定(SFT Lock)方法，采用锁/解锁机制替代铸造/销毁操作，通过确定性状态转换保持NFT身份和历史可追溯性。设计了模块化智能合约架构支持频谱授权、证券化和共享，并引入质押机制增强资产流动性。

Result: 在私有以太坊网络上的实验结果表明，与ERC404混合代币模型相比，所提方法在保持功能正确性和可追溯性的同时，实现了显著的gas节省。

Conclusion: SFT Lock方法为6G网络中的频谱证券化提供了一种更高效、更可持续的解决方案，通过减少链上操作同时保持资产身份连续性，解决了现有方法的局限性。

Abstract: As 6G networks evolve, spectrum assets require flexible, dynamic, and efficient utilization, motivating blockchain based spectrum securitization. Existing approaches based on ERC404 style hybrid token models rely on frequent minting and burning during asset transfers, which disrupt token identity continuity and increase on chain overhead. This paper proposes the Semi Fungible Token Lock (SFT Lock) method, a lock/unlock based mechanism that preserves NFT identity and historical traceability while enabling fractional ownership and transferability. By replacing mint/burn operations with deterministic state transitions, SFT Lock ensures consistent lifecycle representation of spectrum assets and significantly reduces on chain operations. Based on this mechanism, a modular smart contract architecture is designed to support spectrum authorization, securitization, and sharing, and a staking mechanism is introduced to enhance asset liquidity. Experimental results on a private Ethereum network demonstrate that, compared with ERC404 style hybrid token models, the proposed method achieves substantial gas savings while maintaining functional correctness and traceability.

</details>


### [4] [Enhancing guidance for missing data in diffusion-based sequential recommendation](https://arxiv.org/abs/2601.15673)
*Qilong Yan,Yifei Xing,Dugang Liu,Jingpu Duan,Jian Yin*

Main category: cs.IR

TL;DR: 提出CARD模型，通过反事实注意力机制增强用户兴趣转折点信号，抑制序列噪声，提升扩散模型在序列推荐中的生成质量


<details>
  <summary>Details</summary>
Motivation: 现有序列推荐方法从分类转向扩散生成范式，但用户序列中的缺失数据导致引导信号质量下降。现有方法仅去除局部相似项，忽略了用户兴趣的"关键转折点"，这些转折点对准确预测后续用户意图至关重要

Method: 提出CARD模型：1) 双面汤普森采样方法识别发生显著兴趣转移的序列；2) 对这些序列使用反事实注意力机制量化每个项目的重要性，为扩散模型提供动态重新加权的交互向量作为高质量引导信号

Result: 实验表明该方法在真实世界数据上表现良好，且计算开销不大

Conclusion: CARD模型通过关注用户兴趣转折点并抑制序列噪声，有效提升了扩散模型在序列推荐中的生成质量，为解决序列数据缺失导致的引导信号质量问题提供了新思路

Abstract: Contemporary sequential recommendation methods are becoming more complex, shifting from classification to a diffusion-guided generative paradigm. However, the quality of guidance in the form of user information is often compromised by missing data in the observed sequences, leading to suboptimal generation quality. Existing methods address this by removing locally similar items, but overlook ``critical turning points'' in user interest, which are crucial for accurately predicting subsequent user intent. To address this, we propose a novel Counterfactual Attention Regulation Diffusion model (CARD), which focuses on amplifying the signal from key interest-turning-point items while concurrently identifying and suppressing noise within the user sequence. CARD consists of (1) a Dual-side Thompson Sampling method to identify sequences undergoing significant interest shift, and (2) a counterfactual attention mechanism for these sequences to quantify the importance of each item. In this manner, CARD provides the diffusion model with a high-quality guidance signal composed of dynamically re-weighted interaction vectors to enable effective generation. Experiments show our method works well on real-world data without being computationally expensive. Our code is available at https://github.com/yanqilong3321/CARD.

</details>


### [5] [CoNRec: Context-Discerning Negative Recommendation with LLMs](https://arxiv.org/abs/2601.15721)
*Xinda Chen,Jiawei Wu,Yishuang Liu,Jialin Zhu,Shuwen Xiao,Junjun Zheng,Xiangheng Kong,Yuning Jiang*

Main category: cs.IR

TL;DR: 提出首个基于大语言模型的负反馈建模框架，通过语义ID表示和渐进式GRPO训练解决负反馈稀疏性问题，并设计新的奖励函数和评估指标来纠正传统负项预测目标与用户真实负偏好的偏差。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统主要将负反馈作为辅助信号来增强正推荐，很少直接建模负兴趣，且由于负反馈数据稀疏，模型易受正反馈主导的上下文理解偏差影响。传统负项预测目标与用户真实负偏好存在根本性错位。

Method: 1) 使用语义ID表示替代基于文本的项目描述；2) 引入项目级对齐任务增强LLM对负反馈语义上下文的理解；3) 设计渐进式GRPO训练范式，动态平衡正负行为上下文的利用；4) 提出基于多日未来负反馈及其协同信号的新奖励函数和评估指标。

Result: 论文提出了首个LLM负反馈建模框架，通过语义ID表示和渐进式训练解决了负反馈稀疏性问题，新设计的奖励函数和评估指标能更准确地反映用户真实负偏好，减少推荐顺序带来的偏差。

Conclusion: 该研究填补了负反馈建模的空白，提出的LLM框架能更好地理解和利用用户负偏好，为推荐系统提供了更全面的用户兴趣理解，有助于提升系统性能和用户体验。

Abstract: Understanding what users like is relatively straightforward; understanding what users dislike, however, remains a challenging and underexplored problem. Research into users' negative preferences has gained increasing importance in modern recommendation systems. Numerous platforms have introduced explicit negative feedback mechanisms and leverage such signals to refine their recommendation models. Beyond traditional business metrics, user experience-driven metrics, such as negative feedback rates, have become critical indicators for evaluating system performance. However, most existing approaches primarily use negative feedback as an auxiliary signal to enhance positive recommendations, paying little attention to directly modeling negative interests, which can be highly valuable in offline applications. Moreover, due to the inherent sparsity of negative feedback data, models often suffer from context understanding biases induced by positive feedback dominance. To address these challenges, we propose the first large language model framework for negative feedback modeling with special designed context-discerning modules. We use semantic ID Representation to replace text-based item descriptions and introduce an item-level alignment task that enhances the LLM's understanding of the semantic context behind negative feedback. Furthermore, we design a Progressive GRPO training paradigm that enables the model to dynamically balance the positive and negative behavioral context utilization. Besides, our investigation further reveals a fundamental misalignment between the conventional next-negative-item prediction objective and users' true negative preferences, which is heavily influenced by the system's recommendation order. To mitigate this, we propose a novel reward function and evaluation metric grounded in multi-day future negative feedback and their collaborative signals.

</details>


### [6] [CGPT: Cluster-Guided Partial Tables with LLM-Generated Supervision for Table Retrieval](https://arxiv.org/abs/2601.15849)
*Tsung-Hsiang Chou,Chen-Jui Yu,Shui-Hsiang Hsu,Yao-Chung Fan*

Main category: cs.IR

TL;DR: CGPT通过LLM生成监督信号增强表格检索，使用聚类构建语义多样的部分表格，生成合成查询进行对比学习，在多个基准测试中显著提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 通用嵌入模型在文本检索中表现良好，但在表格检索中存在语义压缩和查询-表格不匹配问题。现有LLM检索增强方法依赖启发式部分表格选择，且很少利用合成查询作为监督信号来改进嵌入模型。

Method: CGPT训练框架：1) 使用K-means聚类表格实例，跨聚类采样构建语义多样的部分表格；2) 用LLM为这些部分表格生成合成查询；3) 通过硬负例对比微调来优化嵌入模型。

Result: 在四个公开基准测试（MimoTable、OTTQA、FetaQA、E2E-WTQ）中，CGPT平均R@1提升16.54%，优于包括QGpT在内的检索基线。在统一多领域语料设置中，CGPT展现出强大的跨领域泛化能力，即使使用较小LLM生成查询也有效。

Conclusion: 语义引导的部分表格构建结合LLM生成监督的对比训练，为大规模表格检索提供了有效且可扩展的范式。该方法能显著提升表格检索性能并具有良好的泛化能力。

Abstract: General-purpose embedding models have demonstrated strong performance in text retrieval but remain suboptimal for table retrieval, where highly structured content leads to semantic compression and query-table mismatch. Recent LLM-based retrieval augmentation methods mitigate this issue by generating synthetic queries, yet they often rely on heuristic partial-table selection and seldom leverage these synthetic queries as supervision to improve the embedding model. We introduce CGPT, a training framework that enhances table retrieval through LLM-generated supervision. CGPT constructs semantically diverse partial tables by clustering table instances using K-means and sampling across clusters to broaden semantic coverage. An LLM then generates synthetic queries for these partial tables, which are used in hard-negative contrastive fine-tuning to refine the embedding model. Experiments across four public benchmarks (MimoTable, OTTQA, FetaQA, and E2E-WTQ) show that CGPT consistently outperforms retrieval baselines, including QGpT, with an average R@1 improvement of 16.54 percent. In a unified multi-domain corpus setting, CGPT further demonstrates strong cross-domain generalization and remains effective even when using smaller LLMs for synthetic query generation. These results indicate that semantically guided partial-table construction, combined with contrastive training from LLM-generated supervision, provides an effective and scalable paradigm for large-scale table retrieval. Our code is available at https://github.com/yumeow0122/CGPT.

</details>


### [7] [STAR: Semantic Table Representation with Header-Aware Clustering and Adaptive Weighted Fusion](https://arxiv.org/abs/2601.15860)
*Shui-Hsiang Hsu,Tsung-Hsiang Chou,Chen-Jui Yu,Yao-Chung Fan*

Main category: cs.IR

TL;DR: STAR框架通过语义聚类和加权融合改进表格语义表示，在五个基准测试中均优于QGpT方法


<details>
  <summary>Details</summary>
Motivation: 表格检索面临非结构化文本与结构化表格之间的结构和语义差异挑战。现有方法如QGpT通过生成合成查询来丰富表格语义，但依赖粗糙的部分表格采样和简单融合策略，限制了语义多样性并阻碍有效的查询-表格对齐。

Method: STAR框架包含三个步骤：1) 使用基于表头的K-means聚类对语义相似行分组，选择代表性中心实例构建多样化部分表格；2) 生成聚类特定的合成查询以全面覆盖表格语义空间；3) 采用加权融合策略整合表格和查询嵌入，实现细粒度语义对齐。

Result: 在五个基准测试中，STAR在所有数据集上的Recall指标均一致高于QGpT，证明了语义聚类和自适应加权融合对鲁棒表格表示的有效性。

Conclusion: STAR通过语义聚类和加权融合能够从结构化和文本源中捕获互补信息，提高表格表示的表达能力，为表格检索任务提供了有效的解决方案。

Abstract: Table retrieval is the task of retrieving the most relevant tables from large-scale corpora given natural language queries. However, structural and semantic discrepancies between unstructured text and structured tables make embedding alignment particularly challenging. Recent methods such as QGpT attempt to enrich table semantics by generating synthetic queries, yet they still rely on coarse partial-table sampling and simple fusion strategies, which limit semantic diversity and hinder effective query-table alignment. We propose STAR (Semantic Table Representation), a lightweight framework that improves semantic table representation through semantic clustering and weighted fusion. STAR first applies header-aware K-means clustering to group semantically similar rows and selects representative centroid instances to construct a diverse partial table. It then generates cluster-specific synthetic queries to comprehensively cover the table's semantic space. Finally, STAR employs weighted fusion strategies to integrate table and query embeddings, enabling fine-grained semantic alignment. This design enables STAR to capture complementary information from structured and textual sources, improving the expressiveness of table representations. Experiments on five benchmarks show that STAR achieves consistently higher Recall than QGpT on all datasets, demonstrating the effectiveness of semantic clustering and adaptive weighted fusion for robust table representation. Our code is available at https://github.com/adsl135789/STAR.

</details>


### [8] [MMGRid: Navigating Temporal-aware and Cross-domain Generative Recommendation via Model Merging](https://arxiv.org/abs/2601.15930)
*Tianjun Wei,Enneng Yang,Yingpeng Du,Huizhong Guo,Jie Zhang,Zhu Sun*

Main category: cs.IR

TL;DR: 本文首次系统研究了生成式推荐系统中的模型合并问题，提出了MMGRid框架来组织不同上下文训练的模型，揭示了参数冲突和时效性偏差等关键挑战，并提供了解决方案。


<details>
  <summary>Details</summary>
Motivation: 模型合并为集成多个专业模型提供了高效机制，但在推荐系统领域尚未充分探索。生成式推荐模型规模快速增长且计算成本高昂，使得模型合并在成本敏感部署场景中特别有吸引力。需要研究如何合并针对不同现实世界上下文（如时间演化和领域异构）训练的生成式推荐器。

Method: 提出了统一的MMGRid框架，构建结构化的上下文网格来组织由时间演化和领域多样性诱导的不同上下文训练的GR检查点。所有检查点都来自共享的基础LLM，但在特定上下文数据上进行微调，形成用于系统分析模型合并的现实可控模型空间。

Result: 研究发现：1）从LLM训练GR模型会因token分布偏移和目标差异引入参数冲突，可通过基础模型替换来分离任务感知和上下文特定参数变化以缓解冲突；2）跨上下文增量训练会引入时效性偏差，可通过加权上下文合并有效平衡；3）最优合并权重与上下文相关的交互特征相关，为实际部署中的权重选择提供了实用指导。

Conclusion: 本研究首次系统探索了生成式推荐中的模型合并，揭示了关键挑战并提出了解决方案。MMGRid框架为分析跨上下文模型合并提供了结构化方法，研究结果为实际部署中的模型合并策略提供了实用指导，特别是在处理时间演化和领域异构的现实世界场景时。

Abstract: Model merging (MM) offers an efficient mechanism for integrating multiple specialized models without access to original training data or costly retraining. While MM has demonstrated success in domains like computer vision, its role in recommender systems (RSs) remains largely unexplored. Recently, Generative Recommendation (GR) has emerged as a new paradigm in RSs, characterized by rapidly growing model scales and substantial computational costs, making MM particularly appealing for cost-sensitive deployment scenarios. In this work, we present the first systematic study of MM in GR through a contextual lens. We focus on a fundamental yet underexplored challenge in real-world: how to merge generative recommenders specialized to different real-world contexts, arising from temporal evolving user behaviors and heterogeneous application domains. To this end, we propose a unified framework MMGRid, a structured contextual grid of GR checkpoints that organizes models trained under diverse contexts induced by temporal evolution and domain diversity. All checkpoints are derived from a shared base LLM but fine-tuned on context-specific data, forming a realistic and controlled model space for systematically analyzing MM across GR paradigms and merging algorithms. Our investigation reveals several key insights. First, training GR models from LLMs can introduce parameter conflicts during merging due to token distribution shifts and objective disparities; such conflicts can be alleviated by disentangling task-aware and context-specific parameter changes via base model replacement. Second, incremental training across contexts induces recency bias, which can be effectively balanced through weighted contextual merging. Notably, we observe that optimal merging weights correlate with context-dependent interaction characteristics, offering practical guidance for weight selection in real-world deployments.

</details>


### [9] [Unveiling and Simulating Short-Video Addiction Behaviors via Economic Addiction Theory](https://arxiv.org/abs/2601.15975)
*Chen Xu,Zhipeng Yi,Ruizi Wang,Wenjie Wang,Jun Xu,Maarten de Rijke*

Main category: cs.IR

TL;DR: 该研究结合经济学成瘾理论与推荐系统行为数据，分析短视频成瘾模式，并提出AddictSim模拟框架，通过群体相对策略优化训练，发现多样性算法可缓解成瘾行为。


<details>
  <summary>Details</summary>
Motivation: 短视频平台用户流量大但存在成瘾问题，传统问卷研究样本小且有偏差，平台行为数据为分析成瘾行为提供了新机会。

Method: 结合经济学成瘾理论与推荐系统隐式行为数据，提出AddictSim训练框架，采用均值适应策略和群体相对策略优化训练，在两大数据集上进行实验。

Result: 短视频成瘾遵循与传统成瘾行为相似的功能模式，强度与社会科学研究一致；AddictSim优于现有训练策略；多样性算法能有效缓解成瘾行为。

Conclusion: 短视频成瘾可通过行为数据分析，AddictSim能有效建模成瘾模式，多样性推荐算法是缓解成瘾的有效策略。

Abstract: Short-video applications have attracted substantial user traffic. However, these platforms also foster problematic usage patterns, commonly referred to as short-video addiction, which pose risks to both user health and the sustainable development of platforms. Prior studies on this issue have primarily relied on questionnaires or volunteer-based data collection, which are often limited by small sample sizes and population biases. In contrast, short-video platforms have large-scale behavioral data, offering a valuable foundation for analyzing addictive behaviors. To examine addiction-aware behavior patterns, we combine economic addiction theory with users' implicit behavior captured by recommendation systems. Our analysis shows that short-video addiction follows functional patterns similar to traditional forms of addictive behavior (e.g., substance abuse) and that its intensity is consistent with findings from previous social science studies. To develop a simulator that can learn and model these patterns, we introduce a novel training framework, AddictSim. To consider the personalized addiction patterns, AddictSim uses a mean-to-adapted strategy with group relative policy optimization training. Experiments on two large-scale datasets show that AddictSim consistently outperforms existing training strategies. Our simulation results show that integrating diversity-aware algorithms can mitigate addictive behaviors well.

</details>
