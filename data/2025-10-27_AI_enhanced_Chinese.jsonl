{"id": "2510.21021", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.21021", "abs": "https://arxiv.org/abs/2510.21021", "authors": ["Xiaoxin Ye", "Chengkai Huang", "Hongtao Huang", "Lina Yao"], "title": "Gaussian Mixture Flow Matching with Domain Alignment for Multi-Domain Sequential Recommendation", "comment": null, "summary": "Users increasingly interact with content across multiple domains, resulting\nin sequential behaviors marked by frequent and complex transitions. While\nCross-Domain Sequential Recommendation (CDSR) models two-domain interactions,\nMulti-Domain Sequential Recommendation (MDSR) introduces significantly more\ndomain transitions, compounded by challenges such as domain heterogeneity and\nimbalance. Existing approaches often overlook the intricacies of domain\ntransitions, tend to overfit to dense domains while underfitting sparse ones,\nand struggle to scale effectively as the number of domains increases. We\npropose \\textit{GMFlowRec}, an efficient generative framework for MDSR that\nmodels domain-aware transition trajectories via Gaussian Mixture Flow Matching.\nGMFlowRec integrates: (1) a unified dual-masked Transformer to disentangle\ndomain-invariant and domain-specific intents, (2) a Gaussian Mixture flow field\nto capture diverse behavioral patterns, and (3) a domain-aligned prior to\nsupport frequent and sparse transitions. Extensive experiments on JD and Amazon\ndatasets demonstrate that GMFlowRec achieves state-of-the-art performance with\nup to 44\\% improvement in NDCG@5, while maintaining high efficiency via a\nsingle unified backbone, making it scalable for real-world multi-domain\nsequential recommendation.", "AI": {"tldr": "GMFlowRec\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u57df\u5e8f\u5217\u63a8\u8350\u7684\u9ad8\u6548\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u9ad8\u65af\u6df7\u5408\u6d41\u5339\u914d\u5efa\u6a21\u57df\u611f\u77e5\u8f6c\u6362\u8f68\u8ff9\uff0c\u5728JD\u548cAmazon\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0cNDCG@5\u63d0\u5347\u9ad8\u8fbe44%\u3002", "motivation": "\u7528\u6237\u5728\u591a\u57df\u4e2d\u7684\u4ea4\u4e92\u884c\u4e3a\u5177\u6709\u9891\u7e41\u590d\u6742\u7684\u8f6c\u6362\uff0c\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u4e86\u57df\u8f6c\u6362\u7684\u590d\u6742\u6027\uff0c\u5bb9\u6613\u5728\u5bc6\u96c6\u57df\u4e0a\u8fc7\u62df\u5408\u800c\u5728\u7a00\u758f\u57df\u4e0a\u6b20\u62df\u5408\uff0c\u4e14\u96be\u4ee5\u6269\u5c55\u5230\u66f4\u591a\u57df\u3002", "method": "\u4f7f\u7528\u7edf\u4e00\u7684\u53cc\u63a9\u7801Transformer\u89e3\u8026\u57df\u4e0d\u53d8\u548c\u57df\u7279\u5b9a\u610f\u56fe\uff0c\u9ad8\u65af\u6df7\u5408\u6d41\u573a\u6355\u6349\u591a\u6837\u5316\u884c\u4e3a\u6a21\u5f0f\uff0c\u57df\u5bf9\u9f50\u5148\u9a8c\u652f\u6301\u9891\u7e41\u548c\u7a00\u758f\u8f6c\u6362\u3002", "result": "\u5728JD\u548cAmazon\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGMFlowRec\u5728NDCG@5\u6307\u6807\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe44%\u7684\u63d0\u5347\uff0c\u540c\u65f6\u901a\u8fc7\u5355\u4e00\u7edf\u4e00\u9aa8\u5e72\u7f51\u7edc\u4fdd\u6301\u9ad8\u6548\u7387\u3002", "conclusion": "GMFlowRec\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u5b9e\u65f6\u591a\u57df\u5e8f\u5217\u63a8\u8350\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u57df\u5f02\u8d28\u6027\u548c\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u65b9\u9762\u90fd\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2510.21028", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.21028", "abs": "https://arxiv.org/abs/2510.21028", "authors": ["Amna Al-Araimi", "Yue Zheng", "Haiming Liu"], "title": "Communication Platform for Non-verbal Autistic children in Oman using Android mobile", "comment": null, "summary": "This paper discusses the issue regarding Non-verbal Autism Spectrum Disorder.\nIt has been observed that this mental disorder is listed in major parts of the\nworld including the US, UK, and India. To mitigate this type of disorder, a\nwide range of smartphones, computers, and artificial intelligence technologies\nhave been used. This technology has helped the population cope with\nsocialization and communication needs. Many applications have been developed to\nenhance the communication capabilities of non-verbal autistic children. This\nthesis project proposes the development of a platform that includes a web panel\nand an Android mobile application to assist non-verbal autistic children in\ncommunication, especially in Oman. Different interventions have been merged to\nimprove the quality of life for people on the autism spectrum. The main problem\nidentified in this case is that fragmented approaches are not suitable for\nautistic children. The augmented reality framework provides the capability to\nengage autistic children in creative play and self-reflection through\ninteractive screen-based activities.", "AI": {"tldr": "\u5f00\u53d1\u4e00\u4e2a\u5305\u542b\u7f51\u9875\u9762\u677f\u548cAndroid\u79fb\u52a8\u5e94\u7528\u7684\u5e73\u53f0\uff0c\u5e2e\u52a9\u963f\u66fc\u7684\u975e\u8bed\u8a00\u81ea\u95ed\u75c7\u513f\u7ae5\u6539\u5584\u6c9f\u901a\u80fd\u529b\uff0c\u901a\u8fc7\u589e\u5f3a\u73b0\u5b9e\u6846\u67b6\u63d0\u4f9b\u4e92\u52a8\u6d3b\u52a8\u3002", "motivation": "\u89e3\u51b3\u975e\u8bed\u8a00\u81ea\u95ed\u75c7\u8c31\u7cfb\u969c\u788d\u60a3\u8005\u5728\u5168\u7403\u8303\u56f4\u5185\u7684\u6c9f\u901a\u56f0\u96be\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u963f\u66fc\u5730\u533a\uff0c\u73b0\u6709\u788e\u7247\u5316\u65b9\u6cd5\u4e0d\u9002\u5408\u81ea\u95ed\u75c7\u513f\u7ae5\u7684\u9700\u6c42\u3002", "method": "\u6574\u5408\u591a\u79cd\u5e72\u9884\u63aa\u65bd\uff0c\u5f00\u53d1\u5305\u542b\u7f51\u9875\u9762\u677f\u548cAndroid\u79fb\u52a8\u5e94\u7528\u7684\u5e73\u53f0\uff0c\u91c7\u7528\u589e\u5f3a\u73b0\u5b9e\u6846\u67b6\u8fdb\u884c\u4e92\u52a8\u5c4f\u5e55\u6d3b\u52a8\uff0c\u4fc3\u8fdb\u521b\u9020\u6027\u6e38\u620f\u548c\u81ea\u6211\u53cd\u601d\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7efc\u5408\u5e73\u53f0\u65b9\u6848\uff0c\u80fd\u591f\u5e2e\u52a9\u975e\u8bed\u8a00\u81ea\u95ed\u75c7\u513f\u7ae5\u6539\u5584\u793e\u4ea4\u5316\u548c\u6c9f\u901a\u80fd\u529b\uff0c\u63d0\u9ad8\u751f\u6d3b\u8d28\u91cf\u3002", "conclusion": "\u7efc\u5408\u6027\u7684\u6280\u672f\u5e73\u53f0\u6bd4\u788e\u7247\u5316\u65b9\u6cd5\u66f4\u9002\u5408\u81ea\u95ed\u75c7\u513f\u7ae5\uff0c\u589e\u5f3a\u73b0\u5b9e\u6846\u67b6\u80fd\u6709\u6548\u4fc3\u8fdb\u4ed6\u4eec\u7684\u6c9f\u901a\u548c\u793e\u4ea4\u53d1\u5c55\u3002"}}
{"id": "2510.21151", "categories": ["cs.IR", "H.5.2; H.3.3; I.2.7"], "pdf": "https://arxiv.org/pdf/2510.21151", "abs": "https://arxiv.org/abs/2510.21151", "authors": ["David Guo", "Minqi Sun", "Yilun Jiang", "Jiazhou Liang", "Scott Sanner"], "title": "VOGUE: A Multimodal Dataset for Conversational Recommendation in Fashion", "comment": null, "summary": "Multimodal conversational recommendation has emerged as a promising paradigm\nfor delivering personalized experiences through natural dialogue enriched by\nvisual and contextual grounding. Yet, current multimodal conversational\nrecommendation datasets remain limited: existing resources either simulate\nconversations, omit user history, or fail to collect sufficiently detailed\nfeedback, all of which constrain the types of research and evaluation they\nsupport.\n  To address these gaps, we introduce VOGUE, a novel dataset of 60 humanhuman\ndialogues in realistic fashion shopping scenarios. Each dialogue is paired with\na shared visual catalogue, item metadata, user fashion profiles and histories,\nand post-conversation ratings from both Seekers and Assistants. This design\nenables rigorous evaluation of conversational inference, including not only\nalignment between predicted and ground-truth preferences, but also calibration\nagainst full rating distributions and comparison with explicit and implicit\nuser satisfaction signals.\n  Our initial analyses of VOGUE reveal distinctive dynamics of visually\ngrounded dialogue. For example, recommenders frequently suggest items\nsimultaneously in feature-based groups, which creates distinct conversational\nphases bridged by Seeker critiques and refinements. Benchmarking multimodal\nlarge language models against human recommenders shows that while MLLMs\napproach human-level alignment in aggregate, they exhibit systematic\ndistribution errors in reproducing human ratings and struggle to generalize\npreference inference beyond explicitly discussed items. These findings\nestablish VOGUE as both a unique resource for studying multimodal\nconversational systems and as a challenge dataset beyond the current\nrecommendation capabilities of existing top-tier multimodal foundation models\nsuch as GPT-4o-mini, GPT-5-mini, and Gemini-2.5-Flash.", "AI": {"tldr": "VOGUE\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u591a\u6a21\u6001\u5bf9\u8bdd\u63a8\u8350\u6570\u636e\u96c6\uff0c\u5305\u542b60\u4e2a\u771f\u5b9e\u65f6\u5c1a\u8d2d\u7269\u573a\u666f\u7684\u4eba\u7c7b\u5bf9\u8bdd\uff0c\u914d\u6709\u89c6\u89c9\u76ee\u5f55\u3001\u7528\u6237\u6863\u6848\u548c\u5386\u53f2\u8bb0\u5f55\uff0c\u4ee5\u53ca\u5bf9\u8bdd\u540e\u8bc4\u5206\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5bf9\u8bdd\u63a8\u8350\u6570\u636e\u96c6\u5b58\u5728\u5c40\u9650\u6027\uff1a\u8981\u4e48\u6a21\u62df\u5bf9\u8bdd\uff0c\u8981\u4e48\u5ffd\u7565\u7528\u6237\u5386\u53f2\uff0c\u6216\u8005\u7f3a\u4e4f\u8be6\u7ec6\u53cd\u9988\uff0c\u9650\u5236\u4e86\u7814\u7a76\u548c\u8bc4\u4f30\u7684\u8303\u56f4\u3002", "method": "\u6536\u96c660\u4e2a\u4eba\u7c7b\u5bf9\u8bdd\uff0c\u5305\u542b\u5171\u4eab\u89c6\u89c9\u76ee\u5f55\u3001\u7269\u54c1\u5143\u6570\u636e\u3001\u7528\u6237\u65f6\u5c1a\u6863\u6848\u548c\u5386\u53f2\uff0c\u4ee5\u53ca\u5bf9\u8bdd\u540e\u8bc4\u5206\uff0c\u652f\u6301\u5bf9\u8bdd\u63a8\u7406\u7684\u4e25\u683c\u8bc4\u4f30\u3002", "result": "\u5206\u6790\u663e\u793a\u89c6\u89c9\u5bf9\u8bdd\u7684\u72ec\u7279\u52a8\u6001\uff0c\u63a8\u8350\u8005\u7ecf\u5e38\u6309\u7279\u5f81\u5206\u7ec4\u5efa\u8bae\u7269\u54c1\u3002\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6574\u4f53\u5bf9\u9f50\u4e0a\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\uff0c\u4f46\u5728\u91cd\u73b0\u4eba\u7c7b\u8bc4\u5206\u5206\u5e03\u548c\u6cdb\u5316\u504f\u597d\u63a8\u7406\u65b9\u9762\u5b58\u5728\u7cfb\u7edf\u6027\u9519\u8bef\u3002", "conclusion": "VOGUE\u65e2\u662f\u7814\u7a76\u591a\u6a21\u6001\u5bf9\u8bdd\u7cfb\u7edf\u7684\u72ec\u7279\u8d44\u6e90\uff0c\u4e5f\u662f\u8d85\u8d8a\u5f53\u524d\u9876\u7ea7\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u63a8\u8350\u80fd\u529b\u7684\u6311\u6218\u6570\u636e\u96c6\u3002"}}
{"id": "2510.21242", "categories": ["cs.IR", "H.3.3; H.3.5"], "pdf": "https://arxiv.org/pdf/2510.21242", "abs": "https://arxiv.org/abs/2510.21242", "authors": ["Yimeng Bai", "Chang Liu", "Yang Zhang", "Dingxian Wang", "Frank Yang", "Andrew Rabinovich", "Wenge Rong", "Fuli Feng"], "title": "Bi-Level Optimization for Generative Recommendation: Bridging Tokenization and Generation", "comment": null, "summary": "Generative recommendation is emerging as a transformative paradigm by\ndirectly generating recommended items, rather than relying on matching.\nBuilding such a system typically involves two key components: (1) optimizing\nthe tokenizer to derive suitable item identifiers, and (2) training the\nrecommender based on those identifiers. Existing approaches often treat these\ncomponents separately--either sequentially or in alternation--overlooking their\ninterdependence. This separation can lead to misalignment: the tokenizer is\ntrained without direct guidance from the recommendation objective, potentially\nyielding suboptimal identifiers that degrade recommendation performance.\n  To address this, we propose BLOGER, a Bi-Level Optimization for GEnerative\nRecommendation framework, which explicitly models the interdependence between\nthe tokenizer and the recommender in a unified optimization process. The lower\nlevel trains the recommender using tokenized sequences, while the upper level\noptimizes the tokenizer based on both the tokenization loss and recommendation\nloss. We adopt a meta-learning approach to solve this bi-level optimization\nefficiently, and introduce gradient surgery to mitigate gradient conflicts in\nthe upper-level updates, thereby ensuring that item identifiers are both\ninformative and recommendation-aligned. Extensive experiments on real-world\ndatasets demonstrate that BLOGER consistently outperforms state-of-the-art\ngenerative recommendation methods while maintaining practical efficiency with\nno significant additional computational overhead, effectively bridging the gap\nbetween item tokenization and autoregressive generation.", "AI": {"tldr": "BLOGER\u662f\u4e00\u4e2a\u7528\u4e8e\u751f\u6210\u5f0f\u63a8\u8350\u7684\u53cc\u5c42\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u4e00\u4f18\u5316\u5206\u8bcd\u5668\u548c\u63a8\u8350\u5668\u6765\u89e3\u51b3\u4e24\u8005\u5206\u79bb\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u751f\u6210\u5f0f\u63a8\u8350\u65b9\u6cd5\u901a\u5e38\u5c06\u5206\u8bcd\u5668\u548c\u63a8\u8350\u5668\u5206\u5f00\u8bad\u7ec3\uff0c\u5ffd\u89c6\u4e86\u5b83\u4eec\u4e4b\u95f4\u7684\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb\uff0c\u5bfc\u81f4\u5206\u8bcd\u5668\u8bad\u7ec3\u7f3a\u4e4f\u63a8\u8350\u76ee\u6807\u7684\u76f4\u63a5\u6307\u5bfc\uff0c\u4ea7\u751f\u6b21\u4f18\u7684\u6807\u8bc6\u7b26\uff0c\u4ece\u800c\u964d\u4f4e\u63a8\u8350\u6027\u80fd\u3002", "method": "\u63d0\u51faBLOGER\u6846\u67b6\uff0c\u91c7\u7528\u53cc\u5c42\u4f18\u5316\u65b9\u6cd5\uff1a\u4e0b\u5c42\u8bad\u7ec3\u63a8\u8350\u5668\u4f7f\u7528\u5206\u8bcd\u540e\u7684\u5e8f\u5217\uff0c\u4e0a\u5c42\u57fa\u4e8e\u5206\u8bcd\u635f\u5931\u548c\u63a8\u8350\u635f\u5931\u4f18\u5316\u5206\u8bcd\u5668\u3002\u4f7f\u7528\u5143\u5b66\u4e60\u65b9\u6cd5\u9ad8\u6548\u6c42\u89e3\u53cc\u5c42\u4f18\u5316\uff0c\u5e76\u5f15\u5165\u68af\u5ea6\u624b\u672f\u6765\u7f13\u89e3\u4e0a\u5c42\u66f4\u65b0\u4e2d\u7684\u68af\u5ea6\u51b2\u7a81\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cBLOGER\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u751f\u6210\u5f0f\u63a8\u8350\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u5b9e\u9645\u6548\u7387\uff0c\u6ca1\u6709\u663e\u8457\u589e\u52a0\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "BLOGER\u6709\u6548\u5f25\u5408\u4e86\u9879\u76ee\u5206\u8bcd\u548c\u81ea\u56de\u5f52\u751f\u6210\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u901a\u8fc7\u7edf\u4e00\u4f18\u5316\u5206\u8bcd\u5668\u548c\u63a8\u8350\u5668\uff0c\u786e\u4fdd\u9879\u76ee\u6807\u8bc6\u7b26\u65e2\u4fe1\u606f\u4e30\u5bcc\u53c8\u4e0e\u63a8\u8350\u76ee\u6807\u5bf9\u9f50\u3002"}}
{"id": "2510.21276", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.21276", "abs": "https://arxiv.org/abs/2510.21276", "authors": ["Qiyong Zhong", "Jiajie Su", "Yunshan Ma", "Julian McAuley", "Yupeng Hou"], "title": "Pctx: Tokenizing Personalized Context for Generative Recommendation", "comment": null, "summary": "Generative recommendation (GR) models tokenize each action into a few\ndiscrete tokens (called semantic IDs) and autoregressively generate the next\ntokens as predictions, showing advantages such as memory efficiency,\nscalability, and the potential to unify retrieval and ranking. Despite these\nbenefits, existing tokenization methods are static and non-personalized. They\ntypically derive semantic IDs solely from item features, assuming a universal\nitem similarity that overlooks user-specific perspectives. However, under the\nautoregressive paradigm, semantic IDs with the same prefixes always receive\nsimilar probabilities, so a single fixed mapping implicitly enforces a\nuniversal item similarity standard across all users. In practice, the same item\nmay be interpreted differently depending on user intentions and preferences. To\naddress this issue, we propose a personalized context-aware tokenizer that\nincorporates a user's historical interactions when generating semantic IDs.\nThis design allows the same item to be tokenized into different semantic IDs\nunder different user contexts, enabling GR models to capture multiple\ninterpretive standards and produce more personalized predictions. Experiments\non three public datasets demonstrate up to 11.44% improvement in NDCG@10 over\nnon-personalized action tokenization baselines. Our code is available at\nhttps://github.com/YoungZ365/Pctx.", "AI": {"tldr": "\u63d0\u51fa\u4e2a\u6027\u5316\u4e0a\u4e0b\u6587\u611f\u77e5\u5206\u8bcd\u5668\uff0c\u5c06\u7528\u6237\u5386\u53f2\u4ea4\u4e92\u878d\u5165\u8bed\u4e49ID\u751f\u6210\uff0c\u4f7f\u540c\u4e00\u7269\u54c1\u5728\u4e0d\u540c\u7528\u6237\u4e0a\u4e0b\u6587\u4e2d\u88ab\u5206\u8bcd\u4e3a\u4e0d\u540c\u8bed\u4e49ID\uff0c\u63d0\u5347\u751f\u6210\u5f0f\u63a8\u8350\u7684\u4e2a\u6027\u5316\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u5206\u8bcd\u65b9\u6cd5\u9759\u6001\u4e14\u975e\u4e2a\u6027\u5316\uff0c\u4ec5\u4ece\u7269\u54c1\u7279\u5f81\u6d3e\u751f\u8bed\u4e49ID\uff0c\u5047\u8bbe\u7edf\u4e00\u7684\u7269\u54c1\u76f8\u4f3c\u6027\u6807\u51c6\uff0c\u5ffd\u7565\u4e86\u7528\u6237\u7279\u5b9a\u7684\u89c6\u89d2\u548c\u504f\u597d\u3002", "method": "\u8bbe\u8ba1\u4e2a\u6027\u5316\u4e0a\u4e0b\u6587\u611f\u77e5\u5206\u8bcd\u5668\uff0c\u5728\u751f\u6210\u8bed\u4e49ID\u65f6\u878d\u5165\u7528\u6237\u5386\u53f2\u4ea4\u4e92\u4fe1\u606f\uff0c\u4f7f\u540c\u4e00\u7269\u54c1\u5728\u4e0d\u540c\u7528\u6237\u4e0a\u4e0b\u6587\u4e2d\u4ea7\u751f\u4e0d\u540c\u5206\u8bcd\u7ed3\u679c\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u76f8\u6bd4\u975e\u4e2a\u6027\u5316\u52a8\u4f5c\u5206\u8bcd\u57fa\u7ebf\uff0cNDCG@10\u6307\u6807\u63d0\u5347\u6700\u9ad8\u8fbe11.44%\u3002", "conclusion": "\u4e2a\u6027\u5316\u4e0a\u4e0b\u6587\u611f\u77e5\u5206\u8bcd\u5668\u80fd\u591f\u6355\u6349\u591a\u79cd\u89e3\u91ca\u6807\u51c6\uff0c\u4f7f\u751f\u6210\u5f0f\u63a8\u8350\u6a21\u578b\u4ea7\u751f\u66f4\u4e2a\u6027\u5316\u7684\u9884\u6d4b\uff0c\u663e\u8457\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2510.21333", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21333", "abs": "https://arxiv.org/abs/2510.21333", "authors": ["Yunbo Hou", "Tianle Yang", "Ruijie Li", "Li He", "Liang Wang", "Weiping Li", "Bo Zheng", "Guojie Song"], "title": "CausalRec: A CausalBoost Attention Model for Sequential Recommendation", "comment": "11 pages, 3 figures", "summary": "Recent advances in correlation-based sequential recommendation systems have\ndemonstrated substantial success. Specifically, the attention-based model\noutperforms other RNN-based and Markov chains-based models by capturing both\nshort- and long-term dependencies more effectively. However, solely focusing on\nitem co-occurrences overlooks the underlying motivations behind user behaviors,\nleading to spurious correlations and potentially inaccurate recommendations. To\naddress this limitation, we present a novel framework that integrates causal\nattention for sequential recommendation, CausalRec. It incorporates a causal\ndiscovery block and a CausalBooster. The causal discovery block learns the\ncausal graph in user behavior sequences, and we provide a theory to guarantee\nthe identifiability of the learned causal graph. The CausalBooster utilizes the\ndiscovered causal graph to refine the attention mechanism, prioritizing\nbehaviors with causal significance. Experimental evaluations on real-world\ndatasets indicate that CausalRec outperforms several state-of-the-art methods,\nwith average improvements of 7.21% in Hit Rate (HR) and 8.65% in Normalized\nDiscounted Cumulative Gain (NDCG). To the best of our knowledge, this is the\nfirst model to incorporate causality through the attention mechanism in\nsequential recommendation, demonstrating the value of causality in generating\nmore accurate and reliable recommendations.", "AI": {"tldr": "\u63d0\u51faCausalRec\u6846\u67b6\uff0c\u901a\u8fc7\u56e0\u679c\u6ce8\u610f\u529b\u673a\u5236\u6539\u8fdb\u5e8f\u5217\u63a8\u8350\u7cfb\u7edf\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u4ec5\u5173\u6ce8\u9879\u76ee\u5171\u73b0\u800c\u5ffd\u7565\u7528\u6237\u884c\u4e3a\u52a8\u673a\u7684\u95ee\u9898\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u76f8\u5173\u6027\u7684\u5e8f\u5217\u63a8\u8350\u7cfb\u7edf\u4ec5\u5173\u6ce8\u9879\u76ee\u5171\u73b0\uff0c\u5ffd\u7565\u4e86\u7528\u6237\u884c\u4e3a\u80cc\u540e\u7684\u56e0\u679c\u52a8\u673a\uff0c\u5bfc\u81f4\u865a\u5047\u76f8\u5173\u6027\u548c\u4e0d\u51c6\u786e\u7684\u63a8\u8350\u3002\u9700\u8981\u5f15\u5165\u56e0\u679c\u63a8\u7406\u6765\u8bc6\u522b\u771f\u6b63\u5f71\u54cd\u7528\u6237\u884c\u4e3a\u7684\u56e0\u7d20\u3002", "method": "\u63d0\u51faCausalRec\u6846\u67b6\uff0c\u5305\u542b\u56e0\u679c\u53d1\u73b0\u6a21\u5757\u548cCausalBooster\u3002\u56e0\u679c\u53d1\u73b0\u6a21\u5757\u5b66\u4e60\u7528\u6237\u884c\u4e3a\u5e8f\u5217\u4e2d\u7684\u56e0\u679c\u56fe\uff0cCausalBooster\u5229\u7528\u53d1\u73b0\u7684\u56e0\u679c\u56fe\u6539\u8fdb\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4f18\u5148\u8003\u8651\u5177\u6709\u56e0\u679c\u91cd\u8981\u6027\u7684\u884c\u4e3a\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCausalRec\u4f18\u4e8e\u591a\u79cd\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5728\u547d\u4e2d\u7387(HR)\u4e0a\u5e73\u5747\u63d0\u53477.21%\uff0c\u5728\u5f52\u4e00\u5316\u6298\u635f\u7d2f\u8ba1\u589e\u76ca(NDCG)\u4e0a\u5e73\u5747\u63d0\u53478.65%\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u5728\u5e8f\u5217\u63a8\u8350\u4e2d\u878d\u5165\u56e0\u679c\u6027\u7684\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u56e0\u679c\u6027\u5728\u751f\u6210\u66f4\u51c6\u786e\u53ef\u9760\u63a8\u8350\u4e2d\u7684\u4ef7\u503c\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2510.21352", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.21352", "abs": "https://arxiv.org/abs/2510.21352", "authors": ["Mariam Arustashvili", "Krisztian Balog"], "title": "SciNUP: Natural Language User Interest Profiles for Scientific Literature Recommendation", "comment": null, "summary": "The use of natural language (NL) user profiles in recommender systems offers\ngreater transparency and user control compared to traditional representations.\nHowever, there is scarcity of large-scale, publicly available test collections\nfor evaluating NL profile-based recommendation. To address this gap, we\nintroduce SciNUP, a novel synthetic dataset for scholarly recommendation that\nleverages authors' publication histories to generate NL profiles and\ncorresponding ground truth items. We use this dataset to conduct a comparison\nof baseline methods, ranging from sparse and dense retrieval approaches to\nstate-of-the-art LLM-based rerankers. Our results show that while baseline\nmethods achieve comparable performance, they often retrieve different items,\nindicating complementary behaviors. At the same time, considerable headroom for\nimprovement remains, highlighting the need for effective NL-based\nrecommendation approaches. The SciNUP dataset thus serves as a valuable\nresource for fostering future research and development in this area.", "AI": {"tldr": "\u63d0\u51fa\u4e86SciNUP\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7528\u6237\u753b\u50cf\u7684\u63a8\u8350\u7cfb\u7edf\uff0c\u901a\u8fc7\u4f5c\u8005\u53d1\u8868\u5386\u53f2\u751f\u6210\u81ea\u7136\u8bed\u8a00\u753b\u50cf\u548c\u5bf9\u5e94\u771f\u5b9e\u63a8\u8350\u9879\uff0c\u6bd4\u8f83\u4e86\u591a\u79cd\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7528\u6237\u753b\u50cf\u7684\u63a8\u8350\u7cfb\u7edf\u7f3a\u4e4f\u5927\u89c4\u6a21\u516c\u5f00\u6d4b\u8bd5\u6570\u636e\u96c6\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5b66\u672f\u63a8\u8350\u9886\u57df\u3002", "method": "\u521b\u5efaSciNUP\u5408\u6210\u6570\u636e\u96c6\uff0c\u5229\u7528\u4f5c\u8005\u53d1\u8868\u5386\u53f2\u751f\u6210\u81ea\u7136\u8bed\u8a00\u753b\u50cf\uff1b\u6bd4\u8f83\u7a00\u758f\u68c0\u7d22\u3001\u7a20\u5bc6\u68c0\u7d22\u548c\u57fa\u4e8eLLM\u7684\u91cd\u6392\u5e8f\u7b49\u57fa\u7ebf\u65b9\u6cd5\u3002", "result": "\u57fa\u7ebf\u65b9\u6cd5\u6027\u80fd\u76f8\u5f53\u4f46\u63a8\u8350\u4e0d\u540c\u9879\u76ee\uff0c\u663e\u793a\u4e92\u8865\u884c\u4e3a\uff1b\u540c\u65f6\u5b58\u5728\u8f83\u5927\u6539\u8fdb\u7a7a\u95f4\uff0c\u8868\u660e\u9700\u8981\u66f4\u6709\u6548\u7684\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7684\u63a8\u8350\u65b9\u6cd5\u3002", "conclusion": "SciNUP\u6570\u636e\u96c6\u4e3a\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7528\u6237\u753b\u50cf\u7684\u63a8\u8350\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u8d44\u6e90\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u672a\u6765\u53d1\u5c55\u3002"}}
{"id": "2510.21603", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.21603", "abs": "https://arxiv.org/abs/2510.21603", "authors": ["Kuicai Dong", "Shurui Huang", "Fangda Ye", "Wei Han", "Zhi Zhang", "Dexun Li", "Wenjun Li", "Qu Yang", "Gang Wang", "Yichao Wang", "Chen Zhang", "Yong Liu"], "title": "Doc-Researcher: A Unified System for Multimodal Document Parsing and Deep Research", "comment": "preprint", "summary": "Deep Research systems have revolutionized how LLMs solve complex questions\nthrough iterative reasoning and evidence gathering. However, current systems\nremain fundamentally constrained to textual web data, overlooking the vast\nknowledge embedded in multimodal documents Processing such documents demands\nsophisticated parsing to preserve visual semantics (figures, tables, charts,\nand equations), intelligent chunking to maintain structural coherence, and\nadaptive retrieval across modalities, which are capabilities absent in existing\nsystems. In response, we present Doc-Researcher, a unified system that bridges\nthis gap through three integrated components: (i) deep multimodal parsing that\npreserves layout structure and visual semantics while creating multi-granular\nrepresentations from chunk to document level, (ii) systematic retrieval\narchitecture supporting text-only, vision-only, and hybrid paradigms with\ndynamic granularity selection, and (iii) iterative multi-agent workflows that\ndecompose complex queries, progressively accumulate evidence, and synthesize\ncomprehensive answers across documents and modalities. To enable rigorous\nevaluation, we introduce M4DocBench, the first benchmark for Multi-modal,\nMulti-hop, Multi-document, and Multi-turn deep research. Featuring 158\nexpert-annotated questions with complete evidence chains across 304 documents,\nM4DocBench tests capabilities that existing benchmarks cannot assess.\nExperiments demonstrate that Doc-Researcher achieves 50.6% accuracy, 3.4xbetter\nthan state-of-the-art baselines, validating that effective document research\nrequires not just better retrieval, but fundamentally deep parsing that\npreserve multimodal integrity and support iterative research. Our work\nestablishes a new paradigm for conducting deep research on multimodal document\ncollections.", "AI": {"tldr": "Doc-Researcher\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u591a\u6a21\u6001\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u89e3\u6790\u3001\u7cfb\u7edf\u5316\u68c0\u7d22\u67b6\u6784\u548c\u591a\u4ee3\u7406\u5de5\u4f5c\u6d41\u7a0b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7cfb\u7edf\u4ec5\u9650\u4e8e\u6587\u672c\u6570\u636e\u7684\u5c40\u9650\u6027\uff0c\u5728M4DocBench\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e8650.6%\u7684\u51c6\u786e\u7387\uff0c\u6bd4\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u63d0\u53473.4\u500d\u3002", "motivation": "\u5f53\u524d\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u4ec5\u9650\u4e8e\u6587\u672c\u7f51\u7edc\u6570\u636e\uff0c\u5ffd\u7565\u4e86\u591a\u6a21\u6001\u6587\u6863\u4e2d\u5d4c\u5165\u7684\u4e30\u5bcc\u77e5\u8bc6\uff08\u56fe\u8868\u3001\u516c\u5f0f\u7b49\uff09\uff0c\u9700\u8981\u80fd\u591f\u4fdd\u6301\u89c6\u89c9\u8bed\u4e49\u3001\u7ed3\u6784\u8fde\u8d2f\u6027\u548c\u8de8\u6a21\u6001\u68c0\u7d22\u80fd\u529b\u7684\u7cfb\u7edf\u3002", "method": "\u7cfb\u7edf\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a1) \u6df1\u5ea6\u591a\u6a21\u6001\u89e3\u6790\uff0c\u4fdd\u6301\u5e03\u5c40\u7ed3\u6784\u548c\u89c6\u89c9\u8bed\u4e49\uff1b2) \u652f\u6301\u6587\u672c\u3001\u89c6\u89c9\u548c\u6df7\u5408\u68c0\u7d22\u7684\u7cfb\u7edf\u5316\u67b6\u6784\uff1b3) \u8fed\u4ee3\u591a\u4ee3\u7406\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5206\u89e3\u590d\u6742\u67e5\u8be2\u5e76\u7efc\u5408\u591a\u6587\u6863\u591a\u6a21\u6001\u7b54\u6848\u3002", "result": "\u5728M4DocBench\u57fa\u51c6\u4e0a\u8fbe\u523050.6%\u7684\u51c6\u786e\u7387\uff0c\u6bd4\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u63d0\u53473.4\u500d\uff0c\u9a8c\u8bc1\u4e86\u4fdd\u6301\u591a\u6a21\u6001\u5b8c\u6574\u6027\u548c\u652f\u6301\u8fed\u4ee3\u7814\u7a76\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u672c\u6587\u5efa\u7acb\u4e86\u4e00\u4e2a\u5728\u591a\u6a21\u6001\u6587\u6863\u96c6\u5408\u4e0a\u8fdb\u884c\u6df1\u5ea6\u7814\u7a76\u7684\u65b0\u8303\u5f0f\uff0c\u8868\u660e\u6709\u6548\u7684\u6587\u6863\u7814\u7a76\u4e0d\u4ec5\u9700\u8981\u66f4\u597d\u7684\u68c0\u7d22\u80fd\u529b\uff0c\u66f4\u9700\u8981\u80fd\u591f\u4fdd\u6301\u591a\u6a21\u6001\u5b8c\u6574\u6027\u7684\u6df1\u5ea6\u89e3\u6790\u3002"}}
{"id": "2510.21671", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.21671", "abs": "https://arxiv.org/abs/2510.21671", "authors": ["Yabo Yin", "Yang Xi", "Jialong Wang", "Shanqi Wang", "Jiateng Hu"], "title": "A Data-Centric Approach to Multilingual E-Commerce Product Search: Case Study on Query-Category and Query-Item Relevance", "comment": null, "summary": "Multilingual e-commerce search suffers from severe data imbalance across\nlanguages, label noise, and limited supervision for low-resource\nlanguages--challenges that impede the cross-lingual generalization of relevance\nmodels despite the strong capabilities of large language models (LLMs). In this\nwork, we present a practical, architecture-agnostic, data-centric framework to\nenhance performance on two core tasks: Query-Category (QC) relevance (matching\nqueries to product categories) and Query-Item (QI) relevance (matching queries\nto product titles). Rather than altering the model, we redesign the training\ndata through three complementary strategies: (1) translation-based augmentation\nto synthesize examples for languages absent in training, (2) semantic negative\nsampling to generate hard negatives and mitigate class imbalance, and (3)\nself-validation filtering to detect and remove likely mislabeled instances.\nEvaluated on the CIKM AnalytiCup 2025 dataset, our approach consistently yields\nsubstantial F1 score improvements over strong LLM baselines, achieving\ncompetitive results in the official competition. Our findings demonstrate that\nsystematic data engineering can be as impactful as--and often more deployable\nthan--complex model modifications, offering actionable guidance for building\nrobust multilingual search systems in the real-world e-commerce settings.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6570\u636e\u4e2d\u5fc3\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7ffb\u8bd1\u589e\u5f3a\u3001\u8bed\u4e49\u8d1f\u91c7\u6837\u548c\u81ea\u9a8c\u8bc1\u8fc7\u6ee4\u4e09\u79cd\u7b56\u7565\u6539\u8fdb\u591a\u8bed\u8a00\u7535\u5546\u641c\u7d22\u4e2d\u7684\u67e5\u8be2-\u7c7b\u522b\u548c\u67e5\u8be2-\u5546\u54c1\u76f8\u5173\u6027\u4efb\u52a1\uff0c\u5728CIKM AnalytiCup 2025\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u4e86F1\u5206\u6570\u3002", "motivation": "\u89e3\u51b3\u591a\u8bed\u8a00\u7535\u5546\u641c\u7d22\u4e2d\u6570\u636e\u4e0d\u5e73\u8861\u3001\u6807\u7b7e\u566a\u58f0\u548c\u4f4e\u8d44\u6e90\u8bed\u8a00\u76d1\u7763\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u8fd9\u4e9b\u6311\u6218\u963b\u788d\u4e86\u76f8\u5173\u6027\u6a21\u578b\u7684\u8de8\u8bed\u8a00\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u91c7\u7528\u67b6\u6784\u65e0\u5173\u7684\u6570\u636e\u4e2d\u5fc3\u65b9\u6cd5\uff1a1) \u7ffb\u8bd1\u589e\u5f3a\u4e3a\u8bad\u7ec3\u4e2d\u7f3a\u5931\u7684\u8bed\u8a00\u5408\u6210\u793a\u4f8b\uff1b2) \u8bed\u4e49\u8d1f\u91c7\u6837\u751f\u6210\u56f0\u96be\u8d1f\u4f8b\u7f13\u89e3\u7c7b\u522b\u4e0d\u5e73\u8861\uff1b3) \u81ea\u9a8c\u8bc1\u8fc7\u6ee4\u68c0\u6d4b\u5e76\u79fb\u9664\u53ef\u80fd\u9519\u8bef\u6807\u8bb0\u7684\u5b9e\u4f8b\u3002", "result": "\u5728CIKM AnalytiCup 2025\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4\u5f3a\u5927\u7684LLM\u57fa\u7ebf\uff0c\u8be5\u65b9\u6cd5\u6301\u7eed\u5e26\u6765\u663e\u8457\u7684F1\u5206\u6570\u63d0\u5347\uff0c\u5728\u5b98\u65b9\u7ade\u8d5b\u4e2d\u53d6\u5f97\u4e86\u6709\u7ade\u4e89\u529b\u7684\u7ed3\u679c\u3002", "conclusion": "\u7cfb\u7edf\u7684\u6570\u636e\u5de5\u7a0b\u53ef\u4ee5\u4e0e\u590d\u6742\u6a21\u578b\u4fee\u6539\u4e00\u6837\u6709\u6548\uff0c\u4e14\u901a\u5e38\u66f4\u6613\u4e8e\u90e8\u7f72\uff0c\u4e3a\u6784\u5efa\u73b0\u5b9e\u4e16\u754c\u7535\u5546\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u591a\u8bed\u8a00\u641c\u7d22\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\u3002"}}
