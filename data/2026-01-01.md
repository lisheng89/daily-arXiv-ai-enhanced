<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 10]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [An Comparative Analysis about KYC on a Recommendation System Toward Agentic Recommendation System](https://arxiv.org/abs/2512.23961)
*Junjie H. Xu*

Main category: cs.IR

TL;DR: 该研究提出了一种基于智能体AI的KYC推荐系统，并在广告、新闻、八卦、用户生成内容和技术五个垂直领域进行评估，通过nDCG指标对比不同KYC使用强度的实验组表现。


<details>
  <summary>Details</summary>
Motivation: 金融领域的KYC（了解你的客户）需要更智能的推荐系统来提升用户体验和合规性，现有系统在不同内容垂直领域的表现需要系统评估，以指导大规模智能体推荐系统的工程实践。

Method: 使用智能体AI构建KYC推荐系统，在五个内容垂直领域（广告、新闻、八卦、用户生成内容、技术）进行实验，将用户按KYC使用强度分为四个实验组，使用nDCG@1、nDCG@3、nDCG@5指标评估性能，并参考百度、小红书等行业基准。

Result: 研究提供了不同KYC使用强度实验组在五个垂直领域的nDCG性能数据，展示了智能体AI推荐系统在不同场景下的表现差异，为工程实践提供了实证依据。

Conclusion: 智能体AI在KYC推荐系统中具有应用潜力，不同内容垂直领域需要差异化的推荐策略，KYC使用强度对推荐效果有显著影响，该研究为大规模智能体推荐系统的工程实现提供了参考框架。

Abstract: This research presents a cutting-edge recommendation system utilizing agentic AI for KYC (Know Your Customer in the financial domain), and its evaluation across five distinct content verticals: Advertising (Ad), News, Gossip, Sharing (User-Generated Content), and Technology (Tech). The study compares the performance of four experimental groups, grouping by the intense usage of KYC, benchmarking them against the Normalized Discounted Cumulative Gain (nDCG) metric at truncation levels of $k=1$, $k=3$, and $k=5$. By synthesizing experimental data with theoretical frameworks and industry benchmarks from platforms such as Baidu and Xiaohongshu, this research provides insight by showing experimental results for engineering a large-scale agentic recommendation system.

</details>


### [2] [Time-Aware Adaptive Side Information Fusion for Sequential Recommendation](https://arxiv.org/abs/2512.24246)
*Jie Luo,Wenyu Zhang,Xinming Zhang,Yuan Fang*

Main category: cs.IR

TL;DR: TASIF框架通过时间感知、自适应噪声过滤和高效侧信息融合，解决了时序推荐中忽略时间动态、噪声敏感和计算昂贵的问题。


<details>
  <summary>Details</summary>
Motivation: 当前时序推荐模型存在三个关键挑战：忽略时间戳的细粒度时间动态、对用户交互序列中的噪声敏感、依赖计算昂贵的融合架构。

Method: 提出TASIF框架，包含三个协同组件：1) 简单即插即用的时间跨度划分机制捕捉全局时间模式；2) 自适应频率过滤器使用可学习门控自适应去噪特征序列；3) 高效自适应侧信息融合层采用"引导而非混合"架构，属性引导注意力机制但不混入内容表示的项目嵌入。

Result: 在四个公共数据集上的广泛实验表明，TASIF显著优于最先进的基线方法，同时在训练中保持出色的效率。

Conclusion: TASIF框架系统解决了时序推荐中的关键挑战，通过时间感知、自适应去噪和高效融合实现了更好的性能和效率。

Abstract: Incorporating item-side information, such as category and brand, into sequential recommendation is a well-established and effective approach for improving performance. However, despite significant advancements, current models are generally limited by three key challenges: they often overlook the fine-grained temporal dynamics inherent in timestamps, exhibit vulnerability to noise in user interaction sequences, and rely on computationally expensive fusion architectures. To systematically address these challenges, we propose the Time-Aware Adaptive Side Information Fusion (TASIF) framework. TASIF integrates three synergistic components: (1) a simple, plug-and-play time span partitioning mechanism to capture global temporal patterns; (2) an adaptive frequency filter that leverages a learnable gate to denoise feature sequences adaptively, thereby providing higher-quality inputs for subsequent fusion modules; and (3) an efficient adaptive side information fusion layer, this layer employs a "guide-not-mix" architecture, where attributes guide the attention mechanism without being mixed into the content-representing item embeddings, ensuring deep interaction while ensuring computational efficiency. Extensive experiments on four public datasets demonstrate that TASIF significantly outperforms state-of-the-art baselines while maintaining excellent efficiency in training. Our source code is available at https://github.com/jluo00/TASIF.

</details>


### [3] [RAGPart & RAGMask: Retrieval-Stage Defenses Against Corpus Poisoning in Retrieval-Augmented Generation](https://arxiv.org/abs/2512.24268)
*Pankayaraj Pathmanathan,Michael-Andrei Panaitescu-Liess,Cho-Yu Jason Chiang,Furong Huang*

Main category: cs.IR

TL;DR: 提出两种针对RAG系统检索阶段的防御方法RAGPart和RAGMask，通过文档分区和令牌掩码技术抵御恶意文档注入攻击，在保持正常性能的同时显著降低攻击成功率。


<details>
  <summary>Details</summary>
Motivation: RAG系统虽然能增强LLM的外部知识并减少幻觉，但面临检索语料库中毒攻击的严重漏洞，攻击者通过注入恶意文档来操纵模型输出，需要轻量级且无需修改生成模型的防御方案。

Method: 提出两种互补的检索阶段防御方法：1) RAGPart利用密集检索器的训练动态，通过文档分区技术减轻中毒点的影响；2) RAGMask基于目标令牌掩码下的显著相似度变化识别可疑令牌。两种方法直接在检索器上操作，计算轻量且无需修改生成模型。

Result: 在两个基准测试、四种中毒策略和四种最先进检索器上，防御方法能持续降低攻击成功率，同时在良性条件下保持实用性。还引入了可解释的攻击来压力测试防御效果。

Conclusion: 研究展示了检索阶段防御的潜力和局限性，为鲁棒的RAG部署提供了实用见解，表明轻量级检索器层面的防御能有效对抗语料库中毒攻击。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a promising paradigm to enhance large language models (LLMs) with external knowledge, reducing hallucinations and compensating for outdated information. However, recent studies have exposed a critical vulnerability in RAG pipelines corpus poisoning where adversaries inject malicious documents into the retrieval corpus to manipulate model outputs. In this work, we propose two complementary retrieval-stage defenses: RAGPart and RAGMask. Our defenses operate directly on the retriever, making them computationally lightweight and requiring no modification to the generation model. RAGPart leverages the inherent training dynamics of dense retrievers, exploiting document partitioning to mitigate the effect of poisoned points. In contrast, RAGMask identifies suspicious tokens based on significant similarity shifts under targeted token masking. Across two benchmarks, four poisoning strategies, and four state-of-the-art retrievers, our defenses consistently reduce attack success rates while preserving utility under benign conditions. We further introduce an interpretable attack to stress-test our defenses. Our findings highlight the potential and limitations of retrieval-stage defenses, providing practical insights for robust RAG deployments.

</details>


### [4] [MaRCA: Multi-Agent Reinforcement Learning for Dynamic Computation Allocation in Large-Scale Recommender Systems](https://arxiv.org/abs/2512.24325)
*Wan Jiang,Xinyi Zang,Yudong Zhao,Yusi Zou,Yunfei Lu,Junbo Tong,Yang Liu,Ming Li,Jiani Shi,Xin Yang*

Main category: cs.IR

TL;DR: MaRCA是一个用于大规模推荐系统的多智能体强化学习框架，通过端到端计算资源分配实现业务收入最大化，在实际部署中实现了16.67%的收入提升。


<details>
  <summary>Details</summary>
Motivation: 现代推荐系统面临模型复杂性和流量规模增长带来的计算挑战，现有方法通常简化多阶段计算资源分配，忽略了阶段间依赖关系，限制了全局最优性。

Method: 提出MaRCA框架：1）将推荐系统各阶段建模为合作智能体，采用集中训练分散执行（CTDE）优化资源约束下的收入；2）引入AutoBucket TestBench进行准确计算成本估计；3）使用基于模型预测控制（MPC）的收入-成本平衡器预测流量负载并调整权衡。

Result: 自2024年11月在领先全球电商平台的广告管道中端到端部署以来，MaRCA每天持续处理数千亿广告请求，使用现有计算资源实现了16.67%的收入提升。

Conclusion: MaRCA通过多智能体强化学习框架有效解决了大规模推荐系统的计算资源分配问题，实现了显著的商业价值提升，证明了端到端优化方法的有效性。

Abstract: Modern recommender systems face significant computational challenges due to growing model complexity and traffic scale, making efficient computation allocation critical for maximizing business revenue. Existing approaches typically simplify multi-stage computation resource allocation, neglecting inter-stage dependencies, thus limiting global optimality. In this paper, we propose MaRCA, a multi-agent reinforcement learning framework for end-to-end computation resource allocation in large-scale recommender systems. MaRCA models the stages of a recommender system as cooperative agents, using Centralized Training with Decentralized Execution (CTDE) to optimize revenue under computation resource constraints. We introduce an AutoBucket TestBench for accurate computation cost estimation, and a Model Predictive Control (MPC)-based Revenue-Cost Balancer to proactively forecast traffic loads and adjust the revenue-cost trade-off accordingly. Since its end-to-end deployment in the advertising pipeline of a leading global e-commerce platform in November 2024, MaRCA has consistently handled hundreds of billions of ad requests per day and has delivered a 16.67% revenue uplift using existing computation resources.

</details>


### [5] [On the Factual Consistency of Text-based Explainable Recommendation Models](https://arxiv.org/abs/2512.24366)
*Ben Kabongo,Vincent Guigue*

Main category: cs.IR

TL;DR: 该研究提出了一个评估基于文本的可解释推荐系统事实一致性的框架，发现现有模型虽然语义相似度高，但事实一致性极低，揭示了当前可解释推荐系统的事实性缺陷。


<details>
  <summary>Details</summary>
Motivation: 当前基于文本的可解释推荐系统虽然能生成流畅的解释，但其事实一致性（是否与可用证据相符）尚未得到充分探索。现有评估主要关注语义相似度，而忽略了事实准确性这一关键维度。

Method: 1. 设计基于提示的流水线，使用LLM从评论中提取原子解释性陈述，构建专注于事实内容的地面真值；2. 在亚马逊评论数据集的五个类别上创建增强基准；3. 提出结合LLM和NLI的陈述级对齐指标，评估生成解释的事实一致性和相关性。

Result: 对六个最先进的可解释推荐模型进行广泛实验发现：虽然模型在语义相似度得分很高（BERTScore F1: 0.81-0.90），但所有事实性指标都显示性能极低（LLM基于陈述级精确率：4.38%-32.88%），揭示了事实一致性与语义相似度之间的巨大差距。

Conclusion: 研究强调了在可解释推荐中需要进行事实性感知评估的重要性，为开发更可信的解释系统奠定了基础。当前模型在事实一致性方面存在严重缺陷，需要新的方法来确保解释与可用证据相符。

Abstract: Text-based explainable recommendation aims to generate natural-language explanations that justify item recommendations, to improve user trust and system transparency. Although recent advances leverage LLMs to produce fluent outputs, a critical question remains underexplored: are these explanations factually consistent with the available evidence? We introduce a comprehensive framework for evaluating the factual consistency of text-based explainable recommenders. We design a prompting-based pipeline that uses LLMs to extract atomic explanatory statements from reviews, thereby constructing a ground truth that isolates and focuses on their factual content. Applying this pipeline to five categories from the Amazon Reviews dataset, we create augmented benchmarks for fine-grained evaluation of explanation quality. We further propose statement-level alignment metrics that combine LLM- and NLI-based approaches to assess both factual consistency and relevance of generated explanations. Across extensive experiments on six state-of-the-art explainable recommendation models, we uncover a critical gap: while models achieve high semantic similarity scores (BERTScore F1: 0.81-0.90), all our factuality metrics reveal alarmingly low performance (LLM-based statement-level precision: 4.38%-32.88%). These findings underscore the need for factuality-aware evaluation in explainable recommendation and provide a foundation for developing more trustworthy explanation systems.

</details>


### [6] [MEIC-DT: Memory-Efficient Incremental Clustering for Long-Text Coreference Resolution with Dual-Threshold Constraints](https://arxiv.org/abs/2512.24711)
*Kangyang Luo,Shuzheng Si,Yuzhuo Bai,Cheng Gao,Zhitong Wang,Cheng Huang,Yingli Shen,Yufeng Han,Wenhao Li,Cunliang Kong,Maosong Sun*

Main category: cs.IR

TL;DR: MEIC-DT是一种基于轻量级Transformer的双阈值内存高效增量聚类方法，用于指代消解，在严格内存约束下保持高性能。


<details>
  <summary>Details</summary>
Motivation: 当前监督神经方法在指代消解中仍是SOTA，但其在增量聚类方面的潜力未被充分探索，特别是面临长文本处理时效率与性能平衡的挑战。

Method: 提出MEIC-DT方法，包含：1）双阈值约束机制，精确控制Transformer输入规模在预定义内存预算内；2）统计感知驱逐策略（SAES），利用训练和推理阶段的统计特征进行智能缓存管理；3）内部正则化策略（IRP），通过选择最具代表性的提及来战略性地压缩聚类，保持语义完整性。

Result: 在常见基准测试上的广泛实验表明，MEIC-DT在严格内存约束下实现了高度竞争力的指代消解性能。

Conclusion: MEIC-DT成功解决了增量聚类中效率与性能的平衡问题，为长文本指代消解提供了一种内存高效的解决方案。

Abstract: In the era of large language models (LLMs), supervised neural methods remain the state-of-the-art (SOTA) for Coreference Resolution. Yet, their full potential is underexplored, particularly in incremental clustering, which faces the critical challenge of balancing efficiency with performance for long texts. To address the limitation, we propose \textbf{MEIC-DT}, a novel dual-threshold, memory-efficient incremental clustering approach based on a lightweight Transformer. MEIC-DT features a dual-threshold constraint mechanism designed to precisely control the Transformer's input scale within a predefined memory budget. This mechanism incorporates a Statistics-Aware Eviction Strategy (\textbf{SAES}), which utilizes distinct statistical profiles from the training and inference phases for intelligent cache management. Furthermore, we introduce an Internal Regularization Policy (\textbf{IRP}) that strategically condenses clusters by selecting the most representative mentions, thereby preserving semantic integrity. Extensive experiments on common benchmarks demonstrate that MEIC-DT achieves highly competitive coreference performance under stringent memory constraints.

</details>


### [7] [MDiffFR: Modality-Guided Diffusion Generation for Cold-start Items in Federated Recommendation](https://arxiv.org/abs/2512.24715)
*Kang Fu,Honglei Zhang,Xuechao Zou,Yidong Li*

Main category: cs.IR

TL;DR: 提出MDiffFR方法，使用模态引导的扩散模型为联邦推荐中的冷启动物品生成嵌入，解决了传统一对一映射方法的局限性


<details>
  <summary>Details</summary>
Motivation: 联邦推荐中严格的隐私约束限制了跨客户端的数据访问，使得冷启动物品难以学习有效的全局表示。传统基于属性到嵌入映射的方法存在数据分布变化和嵌入对齐问题

Method: 提出MDiffFR框架：在服务器端使用定制的扩散模型为冷启动物品生成嵌入，利用预训练的模态编码器提取模态特征作为条件信号指导反向去噪过程

Result: 在四个真实数据集上的实验表明，该方法在联邦推荐中始终优于所有基线方法。理论分析验证了该方法相比现有映射方法具有更强的隐私保证

Conclusion: MDiffFR通过生成式扩散模型有效解决了联邦推荐中的物品冷启动问题，提供了更好的嵌入对齐和更强的隐私保护

Abstract: Federated recommendations (FRs) provide personalized services while preserving user privacy by keeping user data on local clients, which has attracted significant attention in recent years. However, due to the strict privacy constraints inherent in FRs, access to user-item interaction data and user profiles across clients is highly restricted, making it difficult to learn globally effective representations for new (cold-start) items. Consequently, the item cold-start problem becomes even more challenging in FRs. Existing solutions typically predict embeddings for new items through the attribute-to-embedding mapping paradigm, which establishes a fixed one-to-one correspondence between item attributes and their embeddings. However, this one-to-one mapping paradigm often fails to model varying data distributions and tends to cause embedding misalignment, as verified by our empirical studies. To this end, we propose MDiffFR, a novel generation-based modality-guided diffusion method for cold-start items in FRs. In this framework, we employ a tailored diffusion model on the server to generate embeddings for new items, which are then distributed to clients for cold-start inference. To align item semantics, we deploy a pre-trained modality encoder to extract modality features as conditional signals to guide the reverse denoising process. Furthermore, our theoretical analysis verifies that the proposed method achieves stronger privacy guarantees compared to existing mapping-based approaches. Extensive experiments on four real datasets demonstrate that our method consistently outperforms all baselines in FRs.

</details>


### [8] [OpenOneRec Technical Report](https://arxiv.org/abs/2512.24762)
*Guorui Zhou,Honghui Bao,Jiaming Huang,Jiaxin Deng,Jinghao Zhang,Junda She,Kuo Cai,Lejian Ren,Lu Ren,Qiang Luo,Qianqian Wang,Qigen Hu,Rongzhou Zhang,Ruiming Tang,Shiyao Wang,Wuchao Li,Xiangyu Wu,Xinchen Luo,Xingmei Wang,Yifei Hu,Yunfan Wu,Zhanyu Liu,Zhiyang Zhang,Zixing Zhang,Bo Chen,Bin Wen,Chaoyi Ma,Chengru Song,Chenglong Chu,Defu Lian,Fan Yang,Feng Jiang,Hongtao Cheng,Huanjie Wang,Kun Gai,Pengfei Zheng,Qiang Wang,Rui Huang,Siyang Mao,Tingting Gao,Wei Yuan,Yan Wang,Yang Zhou,Yi Su,Zexuan Cheng,Zhixin Ling,Ziming Li*

Main category: cs.IR

TL;DR: 提出了RecIF-Bench基准测试、大规模训练数据集和OneRec-Foundation模型，旨在缩小推荐系统与通用智能之间的差距，在多个任务上取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统（如OneRec系列）虽然将推荐流程统一为端到端生成框架，但仍与通用智能存在显著差距。它们受限于孤立数据，成为领域专家——擅长模式匹配但缺乏世界知识、推理能力和指令跟随能力，且缺乏评估这些综合能力的整体基准。

Method: 1) 提出RecIF-Bench基准测试，涵盖8个多样化任务，全面评估从基础预测到复杂推理的能力；2) 发布包含160,000用户、9600万交互的大规模训练数据集；3) 开源完整训练流程（数据处理、共同预训练、后训练）；4) 发布OneRec-Foundation模型系列（1.7B和8B参数）。

Result: OneRec-Foundation模型在RecIF-Bench所有任务上取得新的SOTA结果。在Amazon基准测试中，模型在10个多样化数据集上的Recall@10平均提升26.8%。展示了推荐能力可预测扩展，同时减轻通用知识的灾难性遗忘。

Conclusion: 这项工作朝着构建真正智能的推荐系统迈出了一步，但实现这一愿景仍面临显著的技术和理论挑战，需要更广泛的研究参与。模型在多个基准测试中表现优异，证明了方法的有效性。

Abstract: While the OneRec series has successfully unified the fragmented recommendation pipeline into an end-to-end generative framework, a significant gap remains between recommendation systems and general intelligence. Constrained by isolated data, they operate as domain specialists-proficient in pattern matching but lacking world knowledge, reasoning capabilities, and instruction following. This limitation is further compounded by the lack of a holistic benchmark to evaluate such integrated capabilities. To address this, our contributions are: 1) RecIF Bench & Open Data: We propose RecIF-Bench, a holistic benchmark covering 8 diverse tasks that thoroughly evaluate capabilities from fundamental prediction to complex reasoning. Concurrently, we release a massive training dataset comprising 96 million interactions from 160,000 users to facilitate reproducible research. 2) Framework & Scaling: To ensure full reproducibility, we open-source our comprehensive training pipeline, encompassing data processing, co-pretraining, and post-training. Leveraging this framework, we demonstrate that recommendation capabilities can scale predictably while mitigating catastrophic forgetting of general knowledge. 3) OneRec-Foundation: We release OneRec Foundation (1.7B and 8B), a family of models establishing new state-of-the-art (SOTA) results across all tasks in RecIF-Bench. Furthermore, when transferred to the Amazon benchmark, our models surpass the strongest baselines with an average 26.8% improvement in Recall@10 across 10 diverse datasets (Figure 1). This work marks a step towards building truly intelligent recommender systems. Nonetheless, realizing this vision presents significant technical and theoretical challenges, highlighting the need for broader research engagement in this promising direction.

</details>


### [9] [HiGR: Efficient Generative Slate Recommendation via Hierarchical Planning and Multi-Objective Preference Alignment](https://arxiv.org/abs/2512.24787)
*Yunsheng Pang,Zijian Liu,Yudong Li,Shaojie Zhu,Zijian Luo,Chenyun Yu,Sikai Wu,Shichen Shen,Cong Xu,Bin Wang,Kai Jiang,Hongyong Yu,Chengxiang Zhuo,Zang Li*

Main category: cs.IR

TL;DR: HiGR是一个高效的生成式slate推荐框架，通过分层规划和列表级偏好对齐，解决了现有自回归方法在语义纠缠和低效解码方面的问题，在商业媒体平台上实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归slate推荐方法存在两个主要问题：1）项目tokenization的语义纠缠，导致生成控制困难；2）顺序解码效率低下，缺乏对slate的整体规划。这限制了生成式推荐系统的实际应用效果。

Method: HiGR采用三层设计：1）使用残差量化和对比约束的自动编码器，将项目token化为语义结构化的ID；2）将生成过程解耦为列表级规划阶段（全局slate意图）和项目级解码阶段（具体项目选择）；3）引入列表级偏好对齐目标，直接使用隐式用户反馈优化slate质量。

Result: 在大规模商业媒体平台上的实验表明，HiGR在离线评估中比最先进方法提升超过10%的推荐质量，推理速度提升5倍；在线A/B测试中，平均观看时间和平均视频观看量分别提升1.22%和1.73%。

Conclusion: HiGR通过分层规划和列表级偏好对齐，有效解决了生成式slate推荐中的语义纠缠和低效解码问题，在推荐质量和推理效率上都取得了显著提升，证明了其在工业级推荐系统中的实用价值。

Abstract: Slate recommendation, where users are presented with a ranked list of items simultaneously, is widely adopted in online platforms. Recent advances in generative models have shown promise in slate recommendation by modeling sequences of discrete semantic IDs autoregressively. However, existing autoregressive approaches suffer from semantically entangled item tokenization and inefficient sequential decoding that lacks holistic slate planning. To address these limitations, we propose HiGR, an efficient generative slate recommendation framework that integrates hierarchical planning with listwise preference alignment. First, we propose an auto-encoder utilizing residual quantization and contrastive constraints to tokenize items into semantically structured IDs for controllable generation. Second, HiGR decouples generation into a list-level planning stage for global slate intent, followed by an item-level decoding stage for specific item selection. Third, we introduce a listwise preference alignment objective to directly optimize slate quality using implicit user feedback. Experiments on our large-scale commercial media platform demonstrate that HiGR delivers consistent improvements in both offline evaluations and online deployment. Specifically, it outperforms state-of-the-art methods by over 10% in offline recommendation quality with a 5x inference speedup, while further achieving a 1.22% and 1.73% increase in Average Watch Time and Average Video Views in online A/B tests.

</details>


### [10] [RAIR: A Rule-Aware Benchmark Uniting Challenging Long-Tail and Visual Salience Subset for E-commerce Relevance Assessment](https://arxiv.org/abs/2512.24943)
*Chenji Lu,Zhuo Chen,Hui Zhao,Zhenyi Wang,Pengjie Wang,Jian Xu,Bo Zheng*

Main category: cs.IR

TL;DR: RAIR是一个中文电商搜索相关性评估基准，包含通用、长尾困难和视觉显著性三个子集，为LLM和VLM提供标准化评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有相关性评估基准缺乏足够复杂性，导致行业缺乏标准化评估指标，需要建立更全面的评估框架。

Method: 提出RAIR基准，包含三个子集：通用子集（行业平衡采样）、长尾困难子集（挑战性案例）、视觉显著性子集（多模态理解）。基于真实场景构建，提供通用规则集。

Result: 在14个开源和闭源模型上测试，RAIR对GPT-5等先进模型仍构成足够挑战，GPT-5表现最佳。基准数据已公开可用。

Conclusion: RAIR为电商搜索相关性评估提供了标准化基准，为LLM和VLM评估提供新见解，促进行业标准化评估发展。

Abstract: Search relevance plays a central role in web e-commerce. While large language models (LLMs) have shown significant results on relevance task, existing benchmarks lack sufficient complexity for comprehensive model assessment, resulting in an absence of standardized relevance evaluation metrics across the industry. To address this limitation, we propose Rule-Aware benchmark with Image for Relevance assessment(RAIR), a Chinese dataset derived from real-world scenarios. RAIR established a standardized framework for relevance assessment and provides a set of universal rules, which forms the foundation for standardized evaluation. Additionally, RAIR analyzes essential capabilities required for current relevance models and introduces a comprehensive dataset consists of three subset: (1) a general subset with industry-balanced sampling to evaluate fundamental model competencies; (2) a long-tail hard subset focus on challenging cases to assess performance limits; (3) a visual salience subset for evaluating multimodal understanding capabilities. We conducted experiments on RAIR using 14 open and closed-source models. The results demonstrate that RAIR presents sufficient challenges even for GPT-5, which achieved the best performance. RAIR data are now available, serving as an industry benchmark for relevance assessment while providing new insights into general LLM and Visual Language Model(VLM) evaluation.

</details>
