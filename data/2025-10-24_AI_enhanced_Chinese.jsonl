{"id": "2510.19986", "categories": ["cs.IR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.19986", "abs": "https://arxiv.org/abs/2510.19986", "authors": ["Drew B. Thomas"], "title": "Automating Iconclass: LLMs and RAG for Large-Scale Classification of Religious Woodcuts", "comment": "29 pages, 7 figures. First presented at the \"Digital Humanities and\n  Artificial Intelligence\" conference at the University of Reading on 17 June\n  2024", "summary": "This paper presents a novel methodology for classifying early modern\nreligious images by using Large Language Models (LLMs) and vector databases in\ncombination with Retrieval-Augmented Generation (RAG). The approach leverages\nthe full-page context of book illustrations from the Holy Roman Empire,\nallowing the LLM to generate detailed descriptions that incorporate both visual\nand textual elements. These descriptions are then matched to relevant Iconclass\ncodes through a hybrid vector search. This method achieves 87% and 92%\nprecision at five and four levels of classification, significantly\noutperforming traditional image and keyword-based searches. By employing\nfull-page descriptions and RAG, the system enhances classification accuracy,\noffering a powerful tool for large-scale analysis of early modern visual\narchives. This interdisciplinary approach demonstrates the growing potential of\nLLMs and RAG in advancing research within art history and digital humanities.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u5411\u91cf\u6570\u636e\u5e93\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\uff0c\u7528\u4e8e\u65e9\u671f\u73b0\u4ee3\u5b97\u6559\u56fe\u50cf\u5206\u7c7b\uff0c\u5728\u5206\u7c7b\u7cbe\u5ea6\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u56fe\u50cf\u548c\u57fa\u4e8e\u5173\u952e\u5b57\u7684\u641c\u7d22\u65b9\u6cd5\u5728\u65e9\u671f\u73b0\u4ee3\u5b97\u6559\u56fe\u50cf\u5206\u7c7b\u4e2d\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7ed3\u5408\u89c6\u89c9\u548c\u6587\u672c\u5143\u7d20\u7684\u66f4\u51c6\u786e\u5206\u7c7b\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5305\u542b\u89c6\u89c9\u548c\u6587\u672c\u5143\u7d20\u7684\u5b8c\u6574\u9875\u9762\u63cf\u8ff0\uff0c\u901a\u8fc7\u6df7\u5408\u5411\u91cf\u641c\u7d22\u5339\u914d\u76f8\u5173\u7684Iconclass\u4ee3\u7801\uff0c\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\u3002", "result": "\u5728\u4e94\u4e2a\u548c\u56db\u4e2a\u5206\u7c7b\u7ea7\u522b\u4e0a\u5206\u522b\u8fbe\u523087%\u548c92%\u7684\u7cbe\u786e\u5ea6\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u56fe\u50cf\u548c\u57fa\u4e8e\u5173\u952e\u5b57\u7684\u641c\u7d22\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86LLMs\u548cRAG\u5728\u827a\u672f\u53f2\u548c\u6570\u5b57\u4eba\u6587\u5b66\u79d1\u7814\u7a76\u4e2d\u7684\u5de8\u5927\u6f5c\u529b\uff0c\u4e3a\u5927\u89c4\u6a21\u65e9\u671f\u73b0\u4ee3\u89c6\u89c9\u6863\u6848\u5206\u6790\u63d0\u4f9b\u4e86\u5f3a\u5927\u5de5\u5177\u3002"}}
{"id": "2510.20150", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.20150", "abs": "https://arxiv.org/abs/2510.20150", "authors": ["Yaochen Zhu", "Harald Steck", "Dawen Liang", "Yinhan He", "Jundong Li", "Nathan Kallus"], "title": "Rank-GRPO: Training LLM-based Conversational Recommender Systems with Reinforcement Learning", "comment": null, "summary": "Large language models (LLMs) are reshaping the recommender system paradigm by\nenabling users to express preferences and receive recommendations through\nconversations. Yet, aligning LLMs to the recommendation task remains\nchallenging: pretrained LLMs often generate out-of-catalog items, violate\nrequired output formats, and their ranking quality degrades sharply toward the\nend of the generated list. To this end, we propose ConvRec-R1, a two-stage\nframework for end-to-end training of LLM-based conversational recommender\nsystems. In Stage 1, we construct a behavioral-cloning dataset with a\nRemap-Reflect-Adjust pipeline, which produces high-quality, catalog-grounded\ndemonstrations from powerful blackbox LLMs to warm-start the RL training. In\nStage 2, we propose Rank-GRPO, a principled extension of group relative policy\noptimization (GRPO) tailored to tasks with rank-style outputs. Rank-GRPO treats\neach rank in the recommendation list as the unit instead of token (too\nfine-grained) or sequence (too coarse), redefining rewards to remove non-causal\ncredit assignment and introducing a rank-level importance ratio based on the\ngeometric mean of rank-wise token probabilities to stabilize policy updates.\nExperiments on the public Reddit-v2 dataset show that ConvRec-R1 converges\nfaster and achieves higher Recall and NDCG than GRPO-style baselines. Code and\ndatasets are released at https://github.com/yaochenzhu/Rank-GRPO.", "AI": {"tldr": "ConvRec-R1\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u7528\u4e8e\u8bad\u7ec3\u57fa\u4e8eLLM\u7684\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\uff0c\u901a\u8fc7\u884c\u4e3a\u514b\u9686\u6570\u636e\u96c6\u548cRank-GRPO\u4f18\u5316\u7b97\u6cd5\u89e3\u51b3LLM\u5728\u63a8\u8350\u4efb\u52a1\u4e2d\u7684\u5bf9\u9f50\u95ee\u9898\u3002", "motivation": "\u9884\u8bad\u7ec3LLM\u5728\u63a8\u8350\u4efb\u52a1\u4e2d\u5b58\u5728\u751f\u6210\u76ee\u5f55\u5916\u9879\u76ee\u3001\u8fdd\u53cd\u8f93\u51fa\u683c\u5f0f\u8981\u6c42\u4ee5\u53ca\u6392\u540d\u8d28\u91cf\u5728\u5217\u8868\u672b\u5c3e\u6025\u5267\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e13\u95e8\u7684\u5bf9\u9f50\u65b9\u6cd5\u3002", "method": "\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528Remap-Reflect-Adjust\u7ba1\u9053\u6784\u5efa\u884c\u4e3a\u514b\u9686\u6570\u636e\u96c6\uff1b\u7b2c\u4e8c\u9636\u6bb5\u63d0\u51faRank-GRPO\u7b97\u6cd5\uff0c\u5c06\u63a8\u8350\u5217\u8868\u4e2d\u7684\u6bcf\u4e2a\u6392\u540d\u4f5c\u4e3a\u4f18\u5316\u5355\u4f4d\uff0c\u91cd\u65b0\u5b9a\u4e49\u5956\u52b1\u5e76\u5f15\u5165\u57fa\u4e8e\u51e0\u4f55\u5e73\u5747\u7684\u6392\u540d\u7ea7\u91cd\u8981\u6027\u6bd4\u7387\u3002", "result": "\u5728Reddit-v2\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cConvRec-R1\u6bd4GRPO\u57fa\u7ebf\u6536\u655b\u66f4\u5feb\uff0c\u5e76\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684Recall\u548cNDCG\u6307\u6807\u3002", "conclusion": "ConvRec-R1\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\u548c\u4e13\u95e8\u7684Rank-GRPO\u7b97\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u5bf9\u9f50\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u63a8\u8350\u8d28\u91cf\u3002"}}
{"id": "2510.20193", "categories": ["cs.IR", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20193", "abs": "https://arxiv.org/abs/2510.20193", "authors": ["Rahul Raja", "Arpita Vats"], "title": "Multimedia-Aware Question Answering: A Review of Retrieval and Cross-Modal Reasoning Architectures", "comment": "In Proceedings of the 2nd ACM Workshop in AI-powered Question and\n  Answering Systems (AIQAM '25), October 27-28, 2025, Dublin, Ireland. ACM, New\n  York, NY, USA, 8 pages. https://doi.org/10.1145/3746274.3760393", "summary": "Question Answering (QA) systems have traditionally relied on structured text\ndata, but the rapid growth of multimedia content (images, audio, video, and\nstructured metadata) has introduced new challenges and opportunities for\nretrieval-augmented QA. In this survey, we review recent advancements in QA\nsystems that integrate multimedia retrieval pipelines, focusing on\narchitectures that align vision, language, and audio modalities with user\nqueries. We categorize approaches based on retrieval methods, fusion\ntechniques, and answer generation strategies, and analyze benchmark datasets,\nevaluation protocols, and performance tradeoffs. Furthermore, we highlight key\nchallenges such as cross-modal alignment, latency-accuracy tradeoffs, and\nsemantic grounding, and outline open problems and future research directions\nfor building more robust and context-aware QA systems leveraging multimedia\ndata.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u591a\u5a92\u4f53\u68c0\u7d22\u589e\u5f3a\u95ee\u7b54\u7cfb\u7edf\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u91cd\u70b9\u5173\u6ce8\u591a\u6a21\u6001\u5bf9\u9f50\u67b6\u6784\uff0c\u5206\u6790\u4e86\u68c0\u7d22\u65b9\u6cd5\u3001\u878d\u5408\u6280\u672f\u548c\u7b54\u6848\u751f\u6210\u7b56\u7565\uff0c\u5e76\u8ba8\u8bba\u4e86\u8de8\u6a21\u6001\u5bf9\u9f50\u3001\u5ef6\u8fdf-\u51c6\u786e\u6027\u6743\u8861\u7b49\u5173\u952e\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u95ee\u7b54\u7cfb\u7edf\u4e3b\u8981\u4f9d\u8d56\u7ed3\u6784\u5316\u6587\u672c\u6570\u636e\uff0c\u4f46\u591a\u5a92\u4f53\u5185\u5bb9\u7684\u5feb\u901f\u589e\u957f\u4e3a\u68c0\u7d22\u589e\u5f3a\u95ee\u7b54\u5e26\u6765\u4e86\u65b0\u7684\u6311\u6218\u548c\u673a\u9047\uff0c\u9700\u8981\u6574\u5408\u89c6\u89c9\u3001\u8bed\u8a00\u548c\u97f3\u9891\u7b49\u591a\u6a21\u6001\u4fe1\u606f\u3002", "method": "\u901a\u8fc7\u5206\u7c7b\u68c0\u7d22\u65b9\u6cd5\u3001\u878d\u5408\u6280\u672f\u548c\u7b54\u6848\u751f\u6210\u7b56\u7565\u6765\u7cfb\u7edf\u5206\u6790\u591a\u5a92\u4f53\u95ee\u7b54\u7cfb\u7edf\u67b6\u6784\uff0c\u5e76\u8bc4\u4f30\u57fa\u51c6\u6570\u636e\u96c6\u3001\u8bc4\u4f30\u534f\u8bae\u548c\u6027\u80fd\u6743\u8861\u3002", "result": "\u8bba\u6587\u7cfb\u7edf\u68b3\u7406\u4e86\u591a\u5a92\u4f53\u95ee\u7b54\u7cfb\u7edf\u7684\u6280\u672f\u8def\u7ebf\u548c\u53d1\u5c55\u73b0\u72b6\uff0c\u8bc6\u522b\u4e86\u5f53\u524d\u7cfb\u7edf\u5728\u8de8\u6a21\u6001\u5bf9\u9f50\u3001\u8bed\u4e49\u57fa\u7840\u7b49\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u591a\u5a92\u4f53\u68c0\u7d22\u589e\u5f3a\u95ee\u7b54\u7cfb\u7edf\u9762\u4e34\u8de8\u6a21\u6001\u5bf9\u9f50\u3001\u5ef6\u8fdf-\u51c6\u786e\u6027\u6743\u8861\u7b49\u5173\u952e\u6311\u6218\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u6784\u5efa\u66f4\u9c81\u68d2\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u7cfb\u7edf\u3002"}}
{"id": "2510.20260", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.20260", "abs": "https://arxiv.org/abs/2510.20260", "authors": ["Changping Meng", "Hongyi Ling", "Jianling Wang", "Yifan Liu", "Shuzhou Zhang", "Dapeng Hong", "Mingyan Gao", "Onkar Dalal", "Ed Chi", "Lichan Hong", "Haokai Lu", "Ningren Han"], "title": "Balancing Fine-tuning and RAG: A Hybrid Strategy for Dynamic LLM Recommendation Updates", "comment": "RecSys 2025 Industry Track", "summary": "Large Language Models (LLMs) empower recommendation systems through their\nadvanced reasoning and planning capabilities. However, the dynamic nature of\nuser interests and content poses a significant challenge: While initial\nfine-tuning aligns LLMs with domain knowledge and user preferences, it fails to\ncapture such real-time changes, necessitating robust update mechanisms. This\npaper investigates strategies for updating LLM-powered recommenders, focusing\non the trade-offs between ongoing fine-tuning and Retrieval-Augmented\nGeneration (RAG). Using an LLM-powered user interest exploration system as a\ncase study, we perform a comparative analysis of these methods across\ndimensions like cost, agility, and knowledge incorporation. We propose a hybrid\nupdate strategy that leverages the long-term knowledge adaptation of periodic\nfine-tuning with the agility of low-cost RAG. We demonstrate through live A/B\nexperiments on a billion-user platform that this hybrid approach yields\nstatistically significant improvements in user satisfaction, offering a\npractical and cost-effective framework for maintaining high-quality LLM-powered\nrecommender systems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76LLM\u63a8\u8350\u7cfb\u7edf\u7684\u66f4\u65b0\u7b56\u7565\uff0c\u6bd4\u8f83\u6301\u7eed\u5fae\u8c03\u4e0eRAG\u65b9\u6cd5\u7684\u4f18\u52a3\uff0c\u63d0\u51fa\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u7684\u6df7\u5408\u66f4\u65b0\u7b56\u7565\uff0c\u5e76\u5728\u5341\u4ebf\u7ea7\u7528\u6237\u5e73\u53f0\u4e0a\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u7528\u6237\u5174\u8da3\u548c\u5185\u5bb9\u7684\u52a8\u6001\u53d8\u5316\u4f7f\u5f97LLM\u63a8\u8350\u7cfb\u7edf\u9700\u8981\u6709\u6548\u7684\u66f4\u65b0\u673a\u5236\uff0c\u521d\u59cb\u5fae\u8c03\u65e0\u6cd5\u6355\u6349\u5b9e\u65f6\u53d8\u5316\uff0c\u9700\u8981\u7814\u7a76\u7a33\u5065\u7684\u66f4\u65b0\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528LLM\u9a71\u52a8\u7684\u7528\u6237\u5174\u8da3\u63a2\u7d22\u7cfb\u7edf\u4f5c\u4e3a\u6848\u4f8b\uff0c\u6bd4\u8f83\u6301\u7eed\u5fae\u8c03\u548cRAG\u65b9\u6cd5\u5728\u6210\u672c\u3001\u654f\u6377\u6027\u548c\u77e5\u8bc6\u6574\u5408\u7b49\u7ef4\u5ea6\u7684\u8868\u73b0\uff0c\u63d0\u51fa\u6df7\u5408\u66f4\u65b0\u7b56\u7565\u3002", "result": "\u5728\u5341\u4ebf\u7ea7\u7528\u6237\u5e73\u53f0\u7684\u5b9e\u65f6A/B\u5b9e\u9a8c\u4e2d\uff0c\u6df7\u5408\u65b9\u6cd5\u5728\u7528\u6237\u6ee1\u610f\u5ea6\u65b9\u9762\u53d6\u5f97\u4e86\u7edf\u8ba1\u663e\u8457\u7684\u6539\u8fdb\u3002", "conclusion": "\u6df7\u5408\u66f4\u65b0\u7b56\u7565\u7ed3\u5408\u4e86\u5468\u671f\u6027\u5fae\u8c03\u7684\u957f\u671f\u77e5\u8bc6\u9002\u5e94\u6027\u548c\u4f4e\u6210\u672cRAG\u7684\u654f\u6377\u6027\uff0c\u4e3a\u7ef4\u62a4\u9ad8\u8d28\u91cfLLM\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u7ecf\u6d4e\u9ad8\u6548\u7684\u6846\u67b6\u3002"}}
{"id": "2510.20276", "categories": ["cs.IR", "cs.HC", "cs.MA", "cs.SD"], "pdf": "https://arxiv.org/pdf/2510.20276", "abs": "https://arxiv.org/abs/2510.20276", "authors": ["Wonil Kim", "Hyeongseok Wi", "Seungsoon Park", "Taejun Kim", "Sangeun Keum", "Keunhyoung Kim", "Taewan Kim", "Jongmin Jung", "Taehyoung Kim", "Gaetan Guerrero", "Mael Le Goff", "Julie Po", "Dongjoo Moon", "Juhan Nam", "Jongpil Lee"], "title": "From Generation to Attribution: Music AI Agent Architectures for the Post-Streaming Era", "comment": "Accepted to the NeurIPS 2025 AI4Music Workshop", "summary": "Generative AI is reshaping music creation, but its rapid growth exposes\nstructural gaps in attribution, rights management, and economic models. Unlike\npast media shifts, from live performance to recordings, downloads, and\nstreaming, AI transforms the entire lifecycle of music, collapsing boundaries\nbetween creation, distribution, and monetization. However, existing streaming\nsystems, with opaque and concentrated royalty flows, are ill-equipped to handle\nthe scale and complexity of AI-driven production. We propose a content-based\nMusic AI Agent architecture that embeds attribution directly into the creative\nworkflow through block-level retrieval and agentic orchestration. Designed for\niterative, session-based interaction, the system organizes music into granular\ncomponents (Blocks) stored in BlockDB; each use triggers an Attribution Layer\nevent for transparent provenance and real-time settlement. This framework\nreframes AI from a generative tool into infrastructure for a Fair AI Media\nPlatform. By enabling fine-grained attribution, equitable compensation, and\nparticipatory engagement, it points toward a post-streaming paradigm where\nmusic functions not as a static catalog but as a collaborative and adaptive\necosystem.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5185\u5bb9\u5757\u7684\u97f3\u4e50AI\u4ee3\u7406\u67b6\u6784\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u68c0\u7d22\u548c\u4ee3\u7406\u7f16\u6392\u5c06\u5f52\u5c5e\u6743\u76f4\u63a5\u5d4c\u5165\u521b\u4f5c\u6d41\u7a0b\uff0c\u65e8\u5728\u89e3\u51b3AI\u97f3\u4e50\u751f\u6210\u4e2d\u7684\u5f52\u5c5e\u3001\u6743\u5229\u7ba1\u7406\u548c\u7ecf\u6d4e\u6a21\u578b\u95ee\u9898\u3002", "motivation": "\u751f\u6210\u5f0fAI\u6b63\u5728\u91cd\u5851\u97f3\u4e50\u521b\u4f5c\uff0c\u4f46\u5176\u5feb\u901f\u53d1\u5c55\u66b4\u9732\u4e86\u5f52\u5c5e\u6743\u3001\u6743\u5229\u7ba1\u7406\u548c\u7ecf\u6d4e\u6a21\u578b\u7684\u7ed3\u6784\u6027\u7f3a\u9677\u3002\u73b0\u6709\u6d41\u5a92\u4f53\u7cfb\u7edf\u65e0\u6cd5\u5904\u7406AI\u9a71\u52a8\u751f\u4ea7\u7684\u89c4\u6a21\u548c\u590d\u6742\u6027\u3002", "method": "\u8bbe\u8ba1\u57fa\u4e8e\u5185\u5bb9\u5757\u7684\u97f3\u4e50AI\u4ee3\u7406\u67b6\u6784\uff0c\u5c06\u97f3\u4e50\u7ec4\u7ec7\u4e3a\u7ec6\u7c92\u5ea6\u7ec4\u4ef6\uff08\u5757\uff09\u5b58\u50a8\u5728BlockDB\u4e2d\uff0c\u901a\u8fc7\u5f52\u5c5e\u5c42\u5b9e\u73b0\u900f\u660e\u6eaf\u6e90\u548c\u5b9e\u65f6\u7ed3\u7b97\uff0c\u652f\u6301\u8fed\u4ee3\u5f0f\u3001\u57fa\u4e8e\u4f1a\u8bdd\u7684\u4ea4\u4e92\u3002", "result": "\u8be5\u6846\u67b6\u5c06AI\u4ece\u751f\u6210\u5de5\u5177\u8f6c\u53d8\u4e3a\u516c\u5e73AI\u5a92\u4f53\u5e73\u53f0\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u652f\u6301\u7ec6\u7c92\u5ea6\u5f52\u5c5e\u3001\u516c\u5e73\u8865\u507f\u548c\u53c2\u4e0e\u5f0f\u4e92\u52a8\u3002", "conclusion": "\u8be5\u65b9\u6848\u6307\u5411\u540e\u6d41\u5a92\u4f53\u8303\u5f0f\uff0c\u97f3\u4e50\u4e0d\u518d\u4f5c\u4e3a\u9759\u6001\u76ee\u5f55\uff0c\u800c\u662f\u4f5c\u4e3a\u534f\u4f5c\u548c\u81ea\u9002\u5e94\u751f\u6001\u7cfb\u7edf\u8fd0\u4f5c\u3002"}}
{"id": "2510.20455", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.20455", "abs": "https://arxiv.org/abs/2510.20455", "authors": ["Xiaokai Wei", "Jiajun Wu", "Daiyao Yi", "Reza Shirkavand", "Michelle Gong"], "title": "Rotate Both Ways: Time-and-Order RoPE for Generative Recommendation", "comment": null, "summary": "Generative recommenders, typically transformer-based autoregressive models,\npredict the next item or action from a user's interaction history. Their\neffectiveness depends on how the model represents where an interaction event\noccurs in the sequence (discrete index) and when it occurred in wall-clock\ntime. Prevailing approaches inject time via learned embeddings or relative\nattention biases. In this paper, we argue that RoPE-based approaches, if\ndesigned properly, can be a stronger alternative for jointly modeling temporal\nand sequential information in user behavior sequences. While vanilla RoPE in\nLLMs considers only token order, generative recommendation requires\nincorporating both event time and token index. To address this, we propose\nTime-and-Order RoPE (TO-RoPE), a family of rotary position embedding designs\nthat treat index and time as angle sources shaping the query-key geometry\ndirectly. We present three instantiations: early fusion, split-by-dim, and\nsplit-by-head. Extensive experiments on both publicly available datasets and a\nproprietary industrial dataset show that TO-RoPE variants consistently improve\naccuracy over existing methods for encoding time and index. These results\nposition rotary embeddings as a simple, principled, and deployment-friendly\nfoundation for generative recommendation.", "AI": {"tldr": "\u63d0\u51fa\u4e86TO-RoPE\uff0c\u4e00\u79cd\u6539\u8fdb\u7684\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u4e2d\u540c\u65f6\u5efa\u6a21\u65f6\u95f4\u987a\u5e8f\u548c\u4e8b\u4ef6\u7d22\u5f15\u4fe1\u606f\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u901a\u8fc7\u5b66\u4e60\u7684\u5d4c\u5165\u6216\u76f8\u5bf9\u6ce8\u610f\u529b\u504f\u7f6e\u6765\u6ce8\u5165\u65f6\u95f4\u4fe1\u606f\uff0c\u4f46RoPE\u65b9\u6cd5\u5982\u679c\u8bbe\u8ba1\u5f97\u5f53\uff0c\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u8054\u5408\u5efa\u6a21\u7528\u6237\u884c\u4e3a\u5e8f\u5217\u4e2d\u7684\u65f6\u95f4\u548c\u987a\u5e8f\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u4e86TO-RoPE\u7cfb\u5217\u8bbe\u8ba1\uff0c\u5c06\u7d22\u5f15\u548c\u65f6\u95f4\u4f5c\u4e3a\u89d2\u5ea6\u6e90\u6765\u76f4\u63a5\u5851\u9020\u67e5\u8be2-\u952e\u51e0\u4f55\u7ed3\u6784\uff0c\u5305\u62ec\u65e9\u671f\u878d\u5408\u3001\u6309\u7ef4\u5ea6\u5206\u5272\u548c\u6309\u5934\u5206\u5272\u4e09\u79cd\u5b9e\u73b0\u65b9\u5f0f\u3002", "result": "\u5728\u516c\u5f00\u6570\u636e\u96c6\u548c\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cTO-RoPE\u53d8\u4f53\u5728\u7f16\u7801\u65f6\u95f4\u548c\u7d22\u5f15\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u65cb\u8f6c\u5d4c\u5165\u4e3a\u751f\u6210\u5f0f\u63a8\u8350\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u3001\u6709\u539f\u5219\u4e14\u6613\u4e8e\u90e8\u7f72\u7684\u57fa\u7840\u6846\u67b6\u3002"}}
{"id": "2510.20674", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.20674", "abs": "https://arxiv.org/abs/2510.20674", "authors": ["Rakshith R", "Shubham Sharma", "Mohammed Sameer Khan", "Ankush Chopra"], "title": "Analyticup E-commerce Product Search Competition Technical Report from Team Tredence_AICOE", "comment": null, "summary": "This study presents the multilingual e-commerce search system developed by\nthe Tredence_AICOE team. The competition features two multilingual relevance\ntasks: Query-Category (QC) Relevance, which evaluates how well a user's search\nquery aligns with a product category, and Query-Item (QI) Relevance, which\nmeasures the match between a multilingual search query and an individual\nproduct listing. To ensure full language coverage, we performed data\naugmentation by translating existing datasets into languages missing from the\ndevelopment set, enabling training across all target languages. We fine-tuned\nGemma-3 12B and Qwen-2.5 14B model for both tasks using multiple strategies.\nThe Gemma-3 12B (4-bit) model achieved the best QC performance using original\nand translated data, and the best QI performance using original, translated,\nand minority class data creation. These approaches secured 4th place on the\nfinal leaderboard, with an average F1-score of 0.8857 on the private test set.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u591a\u8bed\u8a00\u7535\u5546\u641c\u7d22\u7cfb\u7edf\uff0c\u5728Query-Category\u548cQuery-Item\u4e24\u4e2a\u591a\u8bed\u8a00\u76f8\u5173\u6027\u4efb\u52a1\u4e2d\uff0c\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u548c\u6a21\u578b\u5fae\u8c03\uff0c\u4f7f\u7528Gemma-3 12B\u6a21\u578b\u53d6\u5f97\u4e86\u6700\u4f73\u6027\u80fd\uff0c\u6700\u7ec8\u5728\u6392\u884c\u699c\u4e0a\u83b7\u5f97\u7b2c4\u540d\u3002", "motivation": "\u89e3\u51b3\u591a\u8bed\u8a00\u7535\u5546\u641c\u7d22\u4e2d\u7684Query-Category\u548cQuery-Item\u76f8\u5173\u6027\u8bc4\u4f30\u95ee\u9898\uff0c\u786e\u4fdd\u5bf9\u6240\u6709\u76ee\u6807\u8bed\u8a00\u7684\u5b8c\u6574\u8986\u76d6\u3002", "method": "\u901a\u8fc7\u5c06\u73b0\u6709\u6570\u636e\u96c6\u7ffb\u8bd1\u6210\u5f00\u53d1\u96c6\u4e2d\u7f3a\u5931\u7684\u8bed\u8a00\u6765\u8fdb\u884c\u6570\u636e\u589e\u5f3a\uff0c\u7136\u540e\u4f7f\u7528\u591a\u79cd\u7b56\u7565\u5bf9Gemma-3 12B\u548cQwen-2.5 14B\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002", "result": "Gemma-3 12B\u6a21\u578b\u5728\u4f7f\u7528\u539f\u59cb\u548c\u7ffb\u8bd1\u6570\u636e\u65f6\u83b7\u5f97\u6700\u4f73QC\u6027\u80fd\uff0c\u5728\u4f7f\u7528\u539f\u59cb\u3001\u7ffb\u8bd1\u548c\u5c11\u6570\u7c7b\u6570\u636e\u521b\u5efa\u65f6\u83b7\u5f97\u6700\u4f73QI\u6027\u80fd\uff0c\u5728\u79c1\u6709\u6d4b\u8bd5\u96c6\u4e0a\u5e73\u5747F1\u5f97\u5206\u4e3a0.8857\u3002", "conclusion": "\u6570\u636e\u589e\u5f3a\u548c\u6a21\u578b\u5fae\u8c03\u7b56\u7565\u5728\u591a\u8bed\u8a00\u7535\u5546\u641c\u7d22\u4efb\u52a1\u4e2d\u8868\u73b0\u6709\u6548\uff0cGemma-3 12B\u6a21\u578b\u5728\u4e24\u4e2a\u76f8\u5173\u6027\u4efb\u52a1\u4e2d\u90fd\u53d6\u5f97\u4e86\u6700\u4f73\u6027\u80fd\uff0c\u6700\u7ec8\u83b7\u5f97\u6392\u884c\u699c\u7b2c4\u540d\u3002"}}
{"id": "2510.20815", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.20815", "abs": "https://arxiv.org/abs/2510.20815", "authors": ["Minjie Hong", "Zetong Zhou", "Zirun Guo", "Ziang Zhang", "Ruofan Hu", "Weinan Gan", "Jieming Zhu", "Zhou Zhao"], "title": "Generative Reasoning Recommendation via LLMs", "comment": null, "summary": "Despite their remarkable reasoning capabilities across diverse domains, large\nlanguage models (LLMs) face fundamental challenges in natively functioning as\ngenerative reasoning recommendation models (GRRMs), where the intrinsic\nmodeling gap between textual semantics and collaborative filtering signals,\ncombined with the sparsity and stochasticity of user feedback, presents\nsignificant obstacles. This work explores how to build GRRMs by adapting\npre-trained LLMs, which achieves a unified understanding-reasoning-prediction\nmanner for recommendation tasks. We propose GREAM, an end-to-end framework that\nintegrates three components: (i) Collaborative-Semantic Alignment, which fuses\nheterogeneous textual evidence to construct semantically consistent, discrete\nitem indices and auxiliary alignment tasks that ground linguistic\nrepresentations in interaction semantics; (ii) Reasoning Curriculum Activation,\nwhich builds a synthetic dataset with explicit Chain-of-Thought supervision and\na curriculum that progresses through behavioral evidence extraction, latent\npreference modeling, intent inference, recommendation formulation, and denoised\nsequence rewriting; and (iii) Sparse-Regularized Group Policy Optimization\n(SRPO), which stabilizes post-training via Residual-Sensitive Verifiable Reward\nand Bonus-Calibrated Group Advantage Estimation, enabling end-to-end\noptimization under verifiable signals despite sparse successes. GREAM natively\nsupports two complementary inference modes: Direct Sequence Recommendation for\nhigh-throughput, low-latency deployment, and Sequential Reasoning\nRecommendation that first emits an interpretable reasoning chain for causal\ntransparency. Experiments on three datasets demonstrate consistent gains over\nstrong baselines, providing a practical path toward verifiable-RL-driven LLM\nrecommenders.", "AI": {"tldr": "GREAM\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u9884\u8bad\u7ec3LLM\u9002\u914d\u4e3a\u751f\u6210\u5f0f\u63a8\u7406\u63a8\u8350\u6a21\u578b\uff0c\u7edf\u4e00\u4e86\u7406\u89e3-\u63a8\u7406-\u9884\u6d4b\u8fc7\u7a0b\uff0c\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u3002", "motivation": "\u5c3d\u7ba1LLM\u5728\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u539f\u751f\u4f5c\u4e3a\u751f\u6210\u5f0f\u63a8\u7406\u63a8\u8350\u6a21\u578b\u5b58\u5728\u5efa\u6a21\u5dee\u8ddd\uff0c\u56e0\u4e3a\u6587\u672c\u8bed\u4e49\u4e0e\u534f\u540c\u8fc7\u6ee4\u4fe1\u53f7\u4e4b\u95f4\u5b58\u5728\u5185\u5728\u5dee\u5f02\uff0c\u4e14\u7528\u6237\u53cd\u9988\u7a00\u758f\u968f\u673a\u3002", "method": "\u63d0\u51faGREAM\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a\u534f\u540c\u8bed\u4e49\u5bf9\u9f50\u3001\u63a8\u7406\u8bfe\u7a0b\u6fc0\u6d3b\u3001\u7a00\u758f\u6b63\u5219\u5316\u7ec4\u7b56\u7565\u4f18\u5316\uff0c\u652f\u6301\u4e24\u79cd\u63a8\u7406\u6a21\u5f0f\uff1a\u76f4\u63a5\u5e8f\u5217\u63a8\u8350\u548c\u987a\u5e8f\u63a8\u7406\u63a8\u8350\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGREAM\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u53d6\u5f97\u4e86\u6301\u7eed\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "GREAM\u4e3a\u53ef\u9a8c\u8bc1RL\u9a71\u52a8\u7684LLM\u63a8\u8350\u5668\u63d0\u4f9b\u4e86\u4e00\u6761\u5b9e\u7528\u8def\u5f84\uff0c\u5b9e\u73b0\u4e86\u7aef\u5230\u7aef\u4f18\u5316\u548c\u56e0\u679c\u900f\u660e\u5ea6\u3002"}}
