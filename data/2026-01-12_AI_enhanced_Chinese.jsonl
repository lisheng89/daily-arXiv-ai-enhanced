{"id": "2601.05253", "categories": ["cs.IR", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.05253", "abs": "https://arxiv.org/abs/2601.05253", "authors": ["Hadi Hosseini", "Debmalya Mandal", "Amrit Puhan"], "title": "SP-Rank: A Dataset for Ranked Preferences with Secondary Information", "comment": null, "summary": "We introduce $\\mathbf{SP-Rank}$, the first large-scale, publicly available dataset for benchmarking algorithms that leverage both first-order preferences and second-order predictions in ranking tasks. Each datapoint includes a personal vote (first-order signal) and a meta-prediction of how others will vote (second-order signal), allowing richer modeling than traditional datasets that capture only individual preferences. SP-Rank contains over 12,000 human-generated datapoints across three domains -- geography, movies, and paintings, and spans nine elicitation formats with varying subset sizes. This structure enables empirical analysis of preference aggregation when expert identities are unknown but presumed to exist, and individual votes represent noisy estimates of a shared ground-truth ranking. We benchmark SP-Rank by comparing traditional aggregation methods that use only first-order votes against SP-Voting, a second-order method that jointly reasons over both signals to infer ground-truth rankings. While SP-Rank also supports models that rely solely on second-order predictions, our benchmarks emphasize the gains from combining both signals. We evaluate performance across three core tasks: (1) full ground-truth rank recovery, (2) subset-level rank recovery, and (3) probabilistic modeling of voter behavior. Results show that incorporating second-order signals substantially improves accuracy over vote-only methods. Beyond social choice, SP-Rank supports downstream applications in learning-to-rank, extracting expert knowledge from noisy crowds, and training reward models in preference-based fine-tuning pipelines. We release the dataset, code, and baseline evaluations (available at https://github.com/amrit19/SP-Rank-Dataset ) to foster research in human preference modeling, aggregation theory, and human-AI alignment.", "AI": {"tldr": "SP-Rank\u662f\u9996\u4e2a\u5927\u89c4\u6a21\u516c\u5f00\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u7ed3\u5408\u4e00\u9636\u504f\u597d\u548c\u4e8c\u9636\u9884\u6d4b\u7684\u6392\u5e8f\u7b97\u6cd5\uff0c\u5305\u542b12,000+\u6570\u636e\u70b9\uff0c\u6db5\u76d6\u5730\u7406\u3001\u7535\u5f71\u3001\u7ed8\u753b\u4e09\u4e2a\u9886\u57df\uff0c\u652f\u6301\u4e5d\u79cd\u4e0d\u540c\u7684\u6536\u96c6\u683c\u5f0f\u3002", "motivation": "\u4f20\u7edf\u6570\u636e\u96c6\u901a\u5e38\u53ea\u6355\u83b7\u4e2a\u4f53\u504f\u597d\uff08\u4e00\u9636\u4fe1\u53f7\uff09\uff0c\u7f3a\u4e4f\u5bf9\u4ed6\u4eba\u504f\u597d\u9884\u6d4b\uff08\u4e8c\u9636\u4fe1\u53f7\uff09\u7684\u5efa\u6a21\u3002\u9700\u8981\u6570\u636e\u96c6\u6765\u652f\u6301\u7814\u7a76\u5982\u4f55\u5728\u4e13\u5bb6\u8eab\u4efd\u672a\u77e5\u4f46\u5047\u8bbe\u5b58\u5728\u7684\u60c5\u51b5\u4e0b\uff0c\u4ece\u566a\u58f0\u6295\u7968\u4e2d\u63a8\u65ad\u5171\u4eab\u7684\u771f\u5b9e\u6392\u5e8f\u3002", "method": "\u521b\u5efaSP-Rank\u6570\u636e\u96c6\uff0c\u6bcf\u4e2a\u6570\u636e\u70b9\u5305\u542b\u4e2a\u4eba\u6295\u7968\uff08\u4e00\u9636\u4fe1\u53f7\uff09\u548c\u5bf9\u4ed6\u4eba\u7684\u6295\u7968\u9884\u6d4b\uff08\u4e8c\u9636\u4fe1\u53f7\uff09\u3002\u6570\u636e\u96c6\u5305\u542b12,000+\u4eba\u7c7b\u751f\u6210\u6570\u636e\u70b9\uff0c\u6db5\u76d6\u4e09\u4e2a\u9886\u57df\u548c\u4e5d\u79cd\u6536\u96c6\u683c\u5f0f\u3002\u63d0\u51faSP-Voting\u65b9\u6cd5\uff0c\u8054\u5408\u63a8\u7406\u4e24\u4e2a\u4fe1\u53f7\u6765\u63a8\u65ad\u771f\u5b9e\u6392\u5e8f\u3002", "result": "\u7ed3\u5408\u4e8c\u9636\u4fe1\u53f7\u663e\u8457\u63d0\u9ad8\u4e86\u6392\u5e8f\u51c6\u786e\u6027\uff0c\u4f18\u4e8e\u4ec5\u4f7f\u7528\u6295\u7968\u7684\u65b9\u6cd5\u3002\u5728\u4e09\u4e2a\u6838\u5fc3\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff1a\u5b8c\u6574\u771f\u5b9e\u6392\u5e8f\u6062\u590d\u3001\u5b50\u96c6\u7ea7\u6392\u5e8f\u6062\u590d\u3001\u6295\u7968\u8005\u884c\u4e3a\u7684\u6982\u7387\u5efa\u6a21\u3002", "conclusion": "SP-Rank\u6570\u636e\u96c6\u586b\u8865\u4e86\u7ed3\u5408\u4e00\u9636\u548c\u4e8c\u9636\u4fe1\u53f7\u8fdb\u884c\u6392\u5e8f\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u652f\u6301\u793e\u4ea4\u9009\u62e9\u3001\u5b66\u4e60\u6392\u5e8f\u3001\u4ece\u566a\u58f0\u4f17\u5305\u4e2d\u63d0\u53d6\u4e13\u5bb6\u77e5\u8bc6\u3001\u504f\u597d\u5fae\u8c03\u4e2d\u7684\u5956\u52b1\u6a21\u578b\u8bad\u7ec3\u7b49\u5e94\u7528\u3002\u516c\u5f00\u6570\u636e\u96c6\u548c\u4ee3\u7801\u4ee5\u4fc3\u8fdb\u4eba\u7c7b\u504f\u597d\u5efa\u6a21\u3001\u805a\u5408\u7406\u8bba\u548c\u4eba\u673a\u5bf9\u9f50\u7814\u7a76\u3002"}}
{"id": "2601.05254", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05254", "abs": "https://arxiv.org/abs/2601.05254", "authors": ["Wenbiao Tao", "Yunshi Lan", "Weining Qian"], "title": "TagRAG: Tag-guided Hierarchical Knowledge Graph Retrieval-Augmented Generation", "comment": null, "summary": "Retrieval-Augmented Generation enhances language models by retrieving external knowledge to support informed and grounded responses. However, traditional RAG methods rely on fragment-level retrieval, limiting their ability to address query-focused summarization queries. GraphRAG introduces a graph-based paradigm for global knowledge reasoning, yet suffers from inefficiencies in information extraction, costly resource consumption, and poor adaptability to incremental updates. To overcome these limitations, we propose TagRAG, a tag-guided hierarchical knowledge graph RAG framework designed for efficient global reasoning and scalable graph maintenance. TagRAG introduces two key components: (1) Tag Knowledge Graph Construction, which extracts object tags and their relationships from documents and organizes them into hierarchical domain tag chains for structured knowledge representation, and (2) Tag-Guided Retrieval-Augmented Generation, which retrieves domain-centric tag chains to localize and synthesize relevant knowledge during inference. This design significantly adapts to smaller language models, improves retrieval granularity, and supports efficient knowledge increment. Extensive experiments on UltraDomain datasets spanning Agriculture, Computer Science, Law, and cross-domain settings demonstrate that TagRAG achieves an average win rate of 95.41\\% against baselines while maintaining about 14.6x construction and 1.9x retrieval efficiency compared with GraphRAG.", "AI": {"tldr": "TagRAG\u662f\u4e00\u4e2a\u57fa\u4e8e\u6807\u7b7e\u5f15\u5bfc\u7684\u5206\u5c42\u77e5\u8bc6\u56fe\u8c31RAG\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u53d6\u5bf9\u8c61\u6807\u7b7e\u53ca\u5176\u5173\u7cfb\u6784\u5efa\u5c42\u6b21\u5316\u9886\u57df\u6807\u7b7e\u94fe\uff0c\u5b9e\u73b0\u9ad8\u6548\u5168\u5c40\u63a8\u7406\u548c\u53ef\u6269\u5c55\u7684\u56fe\u8c31\u7ef4\u62a4\uff0c\u663e\u8457\u63d0\u5347\u5c0f\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfRAG\u65b9\u6cd5\u4f9d\u8d56\u7247\u6bb5\u7ea7\u68c0\u7d22\uff0c\u96be\u4ee5\u5904\u7406\u67e5\u8be2\u805a\u7126\u7684\u6458\u8981\u67e5\u8be2\uff1bGraphRAG\u867d\u7136\u5f15\u5165\u57fa\u4e8e\u56fe\u7684\u5168\u5c40\u77e5\u8bc6\u63a8\u7406\uff0c\u4f46\u5b58\u5728\u4fe1\u606f\u63d0\u53d6\u6548\u7387\u4f4e\u3001\u8d44\u6e90\u6d88\u8017\u5927\u3001\u589e\u91cf\u66f4\u65b0\u9002\u5e94\u6027\u5dee\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faTagRAG\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u6807\u7b7e\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa - \u4ece\u6587\u6863\u4e2d\u63d0\u53d6\u5bf9\u8c61\u6807\u7b7e\u53ca\u5176\u5173\u7cfb\uff0c\u7ec4\u7ec7\u6210\u5c42\u6b21\u5316\u9886\u57df\u6807\u7b7e\u94fe\uff1b2) \u6807\u7b7e\u5f15\u5bfc\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210 - \u68c0\u7d22\u9886\u57df\u4e2d\u5fc3\u7684\u6807\u7b7e\u94fe\u6765\u5b9a\u4f4d\u548c\u5408\u6210\u76f8\u5173\u77e5\u8bc6\u3002", "result": "\u5728\u6db5\u76d6\u519c\u4e1a\u3001\u8ba1\u7b97\u673a\u79d1\u5b66\u3001\u6cd5\u5f8b\u548c\u8de8\u9886\u57df\u8bbe\u7f6e\u7684UltraDomain\u6570\u636e\u96c6\u4e0a\uff0cTagRAG\u76f8\u5bf9\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u5e73\u5747\u80dc\u7387\u8fbe\u523095.41%\uff0c\u540c\u65f6\u76f8\u6bd4GraphRAG\u4fdd\u6301\u7ea614.6\u500d\u7684\u6784\u5efa\u6548\u7387\u548c1.9\u500d\u7684\u68c0\u7d22\u6548\u7387\u3002", "conclusion": "TagRAG\u901a\u8fc7\u6807\u7b7e\u5f15\u5bfc\u7684\u5206\u5c42\u77e5\u8bc6\u56fe\u8c31\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfRAG\u548cGraphRAG\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u5168\u5c40\u63a8\u7406\u3001\u66f4\u597d\u7684\u68c0\u7d22\u7c92\u5ea6\u3001\u5bf9\u5c0f\u8bed\u8a00\u6a21\u578b\u7684\u9002\u5e94\u6027\u4ee5\u53ca\u9ad8\u6548\u7684\u77e5\u8bc6\u589e\u91cf\u66f4\u65b0\u3002"}}
{"id": "2601.05255", "categories": ["cs.IR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.05255", "abs": "https://arxiv.org/abs/2601.05255", "authors": ["Sai Khadloya", "Kush Juvekar", "Arghya Bhattacharya", "Utkarsh Saxena"], "title": "CourtNav: Voice-Guided, Anchor-Accurate Navigation of Long Legal Documents in Courtrooms", "comment": null, "summary": "Judicial work depends on close reading of long records, charge sheets, pleadings, annexures, orders, often spanning hundreds of pages. With limited staff support, exhaustive reading during hearings is impractical. We present CourtNav, a voice-guided, anchor-first navigator for legal PDFs that maps a judge's spoken command (e.g., \"go to paragraph 23\", \"highlight the contradiction in the cross-examination\") directly to a highlighted paragraph in seconds. CourtNav transcribes the command, classifies intent with a grammar-first(Exact regex matching), LLM-backed router classifying the queries using few shot examples, retrieves over a layout-aware hybrid index, and auto-scrolls the viewer to the cited span while highlighting it and close alternates. By design, the interface shows only grounded passages, never free text, keeping evidence verifiable and auditable. This need is acute in India, where judgments and cross-examinations are notoriously long.In a pilot on representative charge sheets, pleadings, and orders, median time-to-relevance drops from 3-5 minutes (manual navigation) to 10-15 seconds; with quick visual verification included, 30-45 seconds. Under fixed time budgets, this navigation-first design increases the breadth of the record actually consulted while preserving control and transparency.", "AI": {"tldr": "CourtNav\u662f\u4e00\u4e2a\u8bed\u97f3\u5f15\u5bfc\u7684\u6cd5\u5f8bPDF\u5bfc\u822a\u7cfb\u7edf\uff0c\u901a\u8fc7\u8bed\u97f3\u547d\u4ee4\u5feb\u901f\u5b9a\u4f4d\u6587\u6863\u4e2d\u7684\u7279\u5b9a\u6bb5\u843d\uff0c\u5c06\u6cd5\u5b98\u67e5\u627e\u76f8\u5173\u4fe1\u606f\u7684\u65f6\u95f4\u4ece3-5\u5206\u949f\u7f29\u77ed\u523010-15\u79d2\u3002", "motivation": "\u53f8\u6cd5\u5de5\u4f5c\u9700\u8981\u9605\u8bfb\u5197\u957f\u7684\u6cd5\u5f8b\u6587\u4ef6\uff08\u6570\u767e\u9875\uff09\uff0c\u4f46\u6cd5\u5b98\u5728\u5ead\u5ba1\u4e2d\u65f6\u95f4\u6709\u9650\uff0c\u65e0\u6cd5\u8be6\u5c3d\u9605\u8bfb\u6240\u6709\u6750\u6599\u3002\u7279\u522b\u662f\u5728\u5370\u5ea6\uff0c\u5224\u51b3\u4e66\u548c\u4ea4\u53c9\u8be2\u95ee\u8bb0\u5f55\u5c24\u5176\u5197\u957f\uff0c\u9700\u8981\u9ad8\u6548\u7684\u5de5\u5177\u6765\u5feb\u901f\u5b9a\u4f4d\u5173\u952e\u4fe1\u606f\u3002", "method": "\u5f00\u53d1\u4e86CourtNav\u7cfb\u7edf\uff1a1\uff09\u8bed\u97f3\u8f6c\u5f55\u6cd5\u5b98\u547d\u4ee4\uff1b2\uff09\u4f7f\u7528\u8bed\u6cd5\u4f18\u5148\uff08\u7cbe\u786e\u6b63\u5219\u5339\u914d\uff09\u548cLLM\u8f85\u52a9\u7684\u8def\u7531\u5668\u5206\u7c7b\u67e5\u8be2\u610f\u56fe\uff1b3\uff09\u5728\u5e03\u5c40\u611f\u77e5\u7684\u6df7\u5408\u7d22\u5f15\u4e0a\u8fdb\u884c\u68c0\u7d22\uff1b4\uff09\u81ea\u52a8\u6eda\u52a8\u5230\u76ee\u6807\u6bb5\u843d\u5e76\u9ad8\u4eae\u663e\u793a\uff0c\u540c\u65f6\u663e\u793a\u76f8\u8fd1\u66ff\u4ee3\u9009\u9879\u3002\u7cfb\u7edf\u8bbe\u8ba1\u53ea\u663e\u793a\u6709\u4f9d\u636e\u7684\u6bb5\u843d\uff0c\u4e0d\u751f\u6210\u81ea\u7531\u6587\u672c\u3002", "result": "\u5728\u4ee3\u8868\u6027\u8d77\u8bc9\u4e66\u3001\u8bc9\u72b6\u548c\u547d\u4ee4\u7684\u8bd5\u70b9\u4e2d\uff1a\u4e2d\u4f4d\u67e5\u627e\u65f6\u95f4\u4ece\u624b\u52a8\u5bfc\u822a\u76843-5\u5206\u949f\u964d\u81f310-15\u79d2\uff1b\u5305\u542b\u5feb\u901f\u89c6\u89c9\u9a8c\u8bc1\u540e\u4e3a30-45\u79d2\u3002\u5728\u56fa\u5b9a\u65f6\u95f4\u9884\u7b97\u4e0b\uff0c\u8fd9\u79cd\u5bfc\u822a\u4f18\u5148\u8bbe\u8ba1\u589e\u52a0\u4e86\u5b9e\u9645\u67e5\u9605\u7684\u8bb0\u5f55\u5e7f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u63a7\u5236\u548c\u900f\u660e\u5ea6\u3002", "conclusion": "CourtNav\u901a\u8fc7\u8bed\u97f3\u5bfc\u822a\u7cfb\u7edf\u663e\u8457\u63d0\u9ad8\u4e86\u6cd5\u5b98\u67e5\u9605\u6cd5\u5f8b\u6587\u6863\u7684\u6548\u7387\uff0c\u5c06\u67e5\u627e\u65f6\u95f4\u5927\u5e45\u7f29\u77ed\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8bc1\u636e\u7684\u53ef\u9a8c\u8bc1\u6027\u548c\u53ef\u5ba1\u8ba1\u6027\uff0c\u6709\u52a9\u4e8e\u5728\u6709\u9650\u65f6\u95f4\u5185\u66f4\u5168\u9762\u5730\u67e5\u9605\u6848\u4ef6\u8bb0\u5f55\u3002"}}
{"id": "2601.05257", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05257", "abs": "https://arxiv.org/abs/2601.05257", "authors": ["Hou-Wan Long", "Yicheng Song", "Zidong Wang", "Tianshu Sun"], "title": "KP-Agent: Keyword Pruning in Sponsored Search Advertising via LLM-Powered Contextual Bandits", "comment": null, "summary": "Sponsored search advertising (SSA) requires advertisers to constantly adjust keyword strategies. While bid adjustment and keyword generation are well-studied, keyword pruning-refining keyword sets to enhance campaign performance-remains under-explored. This paper addresses critical inefficiencies in current practices as evidenced by a dataset containing 0.5 million SSA records from a pharmaceutical advertiser on search engine Meituan, China's largest delivery platform. We propose KP-Agent, an LLM agentic system with domain tool set and a memory module. By modeling keyword pruning within a contextual bandit framework, KP-Agent generates code snippets to refine keyword sets through reinforcement learning. Experiments show KP-Agent improves cumulative profit by up to 49.28% over baselines.", "AI": {"tldr": "\u63d0\u51faKP-Agent LLM\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u591a\u81c2\u8001\u864e\u673a\u6846\u67b6\u548c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u5173\u952e\u8bcd\u4fee\u526a\uff0c\u5728\u7f8e\u56e2\u533b\u836f\u5e7f\u544a\u6570\u636e\u4e0a\u5b9e\u73b0\u7d2f\u8ba1\u5229\u6da6\u63d0\u534749.28%", "motivation": "\u8d5e\u52a9\u641c\u7d22\u5e7f\u544a\u4e2d\uff0c\u5173\u952e\u8bcd\u4fee\u526a\uff08\u4f18\u5316\u5173\u952e\u8bcd\u96c6\u4ee5\u63d0\u5347\u5e7f\u544a\u6548\u679c\uff09\u7814\u7a76\u4e0d\u8db3\uff0c\u73b0\u6709\u5b9e\u8df5\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u95ee\u9898\u3002\u57fa\u4e8e\u7f8e\u56e2\u5e73\u53f0\u533b\u836f\u5e7f\u544a\u554650\u4e07\u6761\u6570\u636e\u53d1\u73b0\u5f53\u524d\u65b9\u6cd5\u9700\u8981\u6539\u8fdb\u3002", "method": "\u63d0\u51faKP-Agent LLM\u4ee3\u7406\u7cfb\u7edf\uff0c\u5305\u542b\u9886\u57df\u5de5\u5177\u96c6\u548c\u8bb0\u5fc6\u6a21\u5757\u3002\u5c06\u5173\u952e\u8bcd\u4fee\u526a\u5efa\u6a21\u4e3a\u4e0a\u4e0b\u6587\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u751f\u6210\u4ee3\u7801\u7247\u6bb5\u6765\u4f18\u5316\u5173\u952e\u8bcd\u96c6\u3002", "result": "\u5b9e\u9a8c\u663e\u793aKP-Agent\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7d2f\u8ba1\u5229\u6da6\u63d0\u5347\u6700\u9ad8\u8fbe49.28%\uff0c\u663e\u8457\u6539\u5584\u4e86\u5e7f\u544a\u6d3b\u52a8\u6548\u679c\u3002", "conclusion": "KP-Agent\u7cfb\u7edf\u6709\u6548\u89e3\u51b3\u4e86\u8d5e\u52a9\u641c\u7d22\u5e7f\u544a\u4e2d\u5173\u952e\u8bcd\u4fee\u526a\u7684\u6311\u6218\uff0c\u901a\u8fc7LLM\u4ee3\u7406\u548c\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u5e7f\u544a\u6d3b\u52a8\u6027\u80fd\u3002"}}
{"id": "2601.05258", "categories": ["cs.IR", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.05258", "abs": "https://arxiv.org/abs/2601.05258", "authors": ["Kaichun Wang", "Yanguang Chen", "Ting Zhang", "Mengyao Bao", "Keyu Chen", "Xu Hu", "Yongliang Wang", "Jingsheng Yang", "Jinsong Zhang", "Fei Lu"], "title": "From Events to Trending: A Multi-Stage Hotspots Detection Method Based on Generative Query Indexing", "comment": null, "summary": "LLM-based conversational systems have become a popular gateway for information access, yet most existing chatbots struggle to handle news-related trending queries effectively. To improve user experience, an effective trending query detection method is urgently needed to enable differentiated processing of such target traffic. However, current research on trending detection tailored to the dialogue system scenario remains largely unexplored, and methods designed for traditional search engines often underperform in conversational contexts due to radically distinct query distributions and expression patterns. To fill this gap, we propose a multi-stage framework for trending detection, which achieves systematic optimization from both offline generation and online identification perspectives. Specifically, our framework first exploits selected hot events to generate index queries, establishing a key bridge between static events and dynamic user queries. It then employs a retrieval matching mechanism for real-time online detection of trending queries, where we introduce a cascaded recall and ranking architecture to balance detection efficiency and accuracy. Furthermore, to better adapt to the practical application scenario, our framework adopts a single-recall module as a cold-start strategy to collect online data for fine-tuning the reranker. Extensive experiments demonstrate that our framework significantly outperforms baseline methods in both offline evaluations and online A/B tests, and user satisfaction is relatively improved by 27\\% in terms of positive-negative feedback ratio.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u9762\u5411\u5bf9\u8bdd\u7cfb\u7edf\u7684\u591a\u9636\u6bb5\u8d8b\u52bf\u67e5\u8be2\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u79bb\u7ebf\u751f\u6210\u548c\u5728\u7ebf\u8bc6\u522b\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u65b0\u95fb\u76f8\u5173\u8d8b\u52bf\u67e5\u8be2\u7684\u5904\u7406\u6548\u679c", "motivation": "\u73b0\u6709\u804a\u5929\u673a\u5668\u4eba\u96be\u4ee5\u6709\u6548\u5904\u7406\u65b0\u95fb\u76f8\u5173\u8d8b\u52bf\u67e5\u8be2\uff0c\u800c\u4f20\u7edf\u641c\u7d22\u5f15\u64ce\u7684\u8d8b\u52bf\u68c0\u6d4b\u65b9\u6cd5\u5728\u5bf9\u8bdd\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u4e13\u95e8\u9488\u5bf9\u5bf9\u8bdd\u7cfb\u7edf\u573a\u666f\u7684\u8d8b\u52bf\u68c0\u6d4b\u65b9\u6cd5", "method": "\u591a\u9636\u6bb5\u6846\u67b6\uff1a1) \u5229\u7528\u70ed\u70b9\u4e8b\u4ef6\u751f\u6210\u7d22\u5f15\u67e5\u8be2\uff1b2) \u91c7\u7528\u68c0\u7d22\u5339\u914d\u673a\u5236\u8fdb\u884c\u5b9e\u65f6\u5728\u7ebf\u68c0\u6d4b\uff1b3) \u5f15\u5165\u7ea7\u8054\u53ec\u56de\u548c\u6392\u5e8f\u67b6\u6784\u5e73\u8861\u6548\u7387\u4e0e\u51c6\u786e\u6027\uff1b4) \u4f7f\u7528\u5355\u53ec\u56de\u6a21\u5757\u4f5c\u4e3a\u51b7\u542f\u52a8\u7b56\u7565\u6536\u96c6\u6570\u636e\u5fae\u8c03\u91cd\u6392\u5e8f\u5668", "result": "\u6846\u67b6\u5728\u79bb\u7ebf\u8bc4\u4f30\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7528\u6237\u6ee1\u610f\u5ea6\u5728\u6b63\u8d1f\u53cd\u9988\u6bd4\u65b9\u9762\u76f8\u5bf9\u63d0\u534727%", "conclusion": "\u8be5\u591a\u9636\u6bb5\u8d8b\u52bf\u68c0\u6d4b\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5bf9\u8bdd\u7cfb\u7edf\u4e2d\u8d8b\u52bf\u67e5\u8be2\u68c0\u6d4b\u7684\u6311\u6218\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u4f18\u5316\u663e\u8457\u63d0\u5347\u4e86\u7528\u6237\u4f53\u9a8c"}}
{"id": "2601.05259", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05259", "abs": "https://arxiv.org/abs/2601.05259", "authors": ["Haotao Xie", "Ruilin Chen", "Yicheng Wu", "Zhan Zhao", "Yuanyuan Liu"], "title": "A Technical Report on the Second Place Solution for the CIKM 2025 AnalytiCup Competition", "comment": null, "summary": "In this work, we address the challenge of multilingual category relevance judgment in e-commerce search, where traditional ensemble-based systems improve accuracy but at the cost of heavy training, inference, and maintenance complexity. To overcome this limitation, we propose a simplified yet effective framework that leverages prompt engineering with Chain-of-Thought task decomposition to guide reasoning within a single large language model. Specifically, our approach decomposes the relevance judgment process into four interpretable subtasks: translation, intent understanding, category matching, and relevance judgment -- and fine-tunes a base model (Qwen2.5-14B) using Low-Rank Adaptation (LoRA) for efficient adaptation. This design not only reduces computational and storage overhead but also enhances interpretability by explicitly structuring the model's reasoning path. Experimental results show that our single-model framework achieves competitive accuracy and high inference efficiency, processing 20 samples per second on a single A100 GPU. In the CIKM 2025 AnalytiCup Competition Proposals, our method achieved 0.8902 on the public leaderboard and 0.8889 on the private leaderboard, validating the effectiveness and robustness of the proposed approach. These results highlight that structured prompting combined with lightweight fine-tuning can outperform complex ensemble systems, offering a new paradigm for scalable industrial AI applications.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u63d0\u793a\u5de5\u7a0b\u548c\u601d\u7ef4\u94fe\u4efb\u52a1\u5206\u89e3\u7684\u5355\u6a21\u578b\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u8bed\u8a00\u7535\u5546\u641c\u7d22\u5206\u7c7b\u76f8\u5173\u6027\u5224\u65ad\uff0c\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u548c\u7ef4\u62a4\u590d\u6742\u5ea6\u3002", "motivation": "\u4f20\u7edf\u96c6\u6210\u7cfb\u7edf\u867d\u7136\u80fd\u63d0\u9ad8\u591a\u8bed\u8a00\u7535\u5546\u641c\u7d22\u5206\u7c7b\u76f8\u5173\u6027\u5224\u65ad\u7684\u51c6\u786e\u6027\uff0c\u4f46\u5b58\u5728\u8bad\u7ec3\u3001\u63a8\u7406\u548c\u7ef4\u62a4\u590d\u6742\u5ea6\u9ad8\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u8f7b\u91cf\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u601d\u7ef4\u94fe\u4efb\u52a1\u5206\u89e3\u5c06\u76f8\u5173\u6027\u5224\u65ad\u8fc7\u7a0b\u5206\u4e3a\u56db\u4e2a\u53ef\u89e3\u91ca\u5b50\u4efb\u52a1\uff1a\u7ffb\u8bd1\u3001\u610f\u56fe\u7406\u89e3\u3001\u7c7b\u522b\u5339\u914d\u548c\u76f8\u5173\u6027\u5224\u65ad\uff0c\u7136\u540e\u57fa\u4e8eQwen2.5-14B\u6a21\u578b\u901a\u8fc7LoRA\u8fdb\u884c\u8f7b\u91cf\u5316\u5fae\u8c03\u3002", "result": "\u5728CIKM 2025 AnalytiCup\u7ade\u8d5b\u4e2d\uff0c\u516c\u5f00\u699c\u5f97\u52060.8902\uff0c\u79c1\u6709\u699c\u5f97\u52060.8889\uff1b\u5355A100 GPU\u4e0a\u5904\u7406\u901f\u5ea6\u8fbe20\u6837\u672c/\u79d2\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u548c\u9ad8\u63a8\u7406\u6548\u7387\u3002", "conclusion": "\u7ed3\u6784\u5316\u63d0\u793a\u4e0e\u8f7b\u91cf\u5316\u5fae\u8c03\u7ed3\u5408\u7684\u5355\u6a21\u578b\u6846\u67b6\u80fd\u591f\u8d85\u8d8a\u590d\u6742\u96c6\u6210\u7cfb\u7edf\uff0c\u4e3a\u53ef\u6269\u5c55\u7684\u5de5\u4e1aAI\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u548c\u5b58\u50a8\u5f00\u9500\u3002"}}
{"id": "2601.05260", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05260", "abs": "https://arxiv.org/abs/2601.05260", "authors": ["Armin Gerami", "Kazem Faghih", "Ramani Duraiswami"], "title": "Quantifying Document Impact in RAG-LLMs", "comment": null, "summary": "Retrieval Augmented Generation (RAG) enhances Large Language Models (LLMs) by connecting them to external knowledge, improving accuracy and reducing outdated information. However, this introduces challenges such as factual inconsistencies, source conflicts, bias propagation, and security vulnerabilities, which undermine the trustworthiness of RAG systems. A key gap in current RAG evaluation is the lack of a metric to quantify the contribution of individual retrieved documents to the final output. To address this, we introduce the Influence Score (IS), a novel metric based on Partial Information Decomposition that measures the impact of each retrieved document on the generated response. We validate IS through two experiments. First, a poison attack simulation across three datasets demonstrates that IS correctly identifies the malicious document as the most influential in $86\\%$ of cases. Second, an ablation study shows that a response generated using only the top-ranked documents by IS is consistently judged more similar to the original response than one generated from the remaining documents. These results confirm the efficacy of IS in isolating and quantifying document influence, offering a valuable tool for improving the transparency and reliability of RAG systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5ea6\u91cf\u6807\u51c6\u2014\u2014\u5f71\u54cd\u529b\u5206\u6570\uff08IS\uff09\uff0c\u7528\u4e8e\u91cf\u5316\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u4e2d\u5355\u4e2a\u68c0\u7d22\u6587\u6863\u5bf9\u6700\u7ec8\u8f93\u51fa\u7684\u8d21\u732e\uff0c\u89e3\u51b3\u4e86\u5f53\u524dRAG\u8bc4\u4f30\u4e2d\u7f3a\u4e4f\u6587\u6863\u7ea7\u5f71\u54cd\u529b\u91cf\u5316\u7684\u95ee\u9898\u3002", "motivation": "\u867d\u7136\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u901a\u8fc7\u8fde\u63a5\u5916\u90e8\u77e5\u8bc6\u63d0\u9ad8\u4e86LLM\u7684\u51c6\u786e\u6027\u548c\u65f6\u6548\u6027\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u4e8b\u5b9e\u4e0d\u4e00\u81f4\u3001\u6765\u6e90\u51b2\u7a81\u3001\u504f\u89c1\u4f20\u64ad\u548c\u5b89\u5168\u6f0f\u6d1e\u7b49\u95ee\u9898\uff0c\u524a\u5f31\u4e86RAG\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\u3002\u5f53\u524dRAG\u8bc4\u4f30\u7684\u4e00\u4e2a\u5173\u952e\u7f3a\u9677\u662f\u7f3a\u4e4f\u91cf\u5316\u5355\u4e2a\u68c0\u7d22\u6587\u6863\u5bf9\u6700\u7ec8\u8f93\u51fa\u8d21\u732e\u7684\u5ea6\u91cf\u6807\u51c6\u3002", "method": "\u57fa\u4e8e\u90e8\u5206\u4fe1\u606f\u5206\u89e3\uff08Partial Information Decomposition\uff09\u63d0\u51fa\u4e86\u5f71\u54cd\u529b\u5206\u6570\uff08IS\uff09\u8fd9\u4e00\u65b0\u5ea6\u91cf\u6807\u51c6\uff0c\u7528\u4e8e\u6d4b\u91cf\u6bcf\u4e2a\u68c0\u7d22\u6587\u6863\u5bf9\u751f\u6210\u54cd\u5e94\u7684\u5177\u4f53\u5f71\u54cd\u3002\u901a\u8fc7\u4e24\u4e2a\u5b9e\u9a8c\u9a8c\u8bc1IS\u7684\u6709\u6548\u6027\uff1a1\uff09\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6bd2\u5316\u653b\u51fb\u6a21\u62df\uff1b2\uff09\u8fdb\u884c\u6d88\u878d\u7814\u7a76\uff0c\u6bd4\u8f83\u4ec5\u4f7f\u7528IS\u6392\u540d\u9760\u524d\u6587\u6863\u751f\u6210\u7684\u54cd\u5e94\u4e0e\u4f7f\u7528\u5269\u4f59\u6587\u6863\u751f\u6210\u7684\u54cd\u5e94\u3002", "result": "1\uff09\u6bd2\u5316\u653b\u51fb\u5b9e\u9a8c\u4e2d\uff0cIS\u572886%\u7684\u60c5\u51b5\u4e0b\u6b63\u786e\u8bc6\u522b\u51fa\u6076\u610f\u6587\u6863\u4e3a\u6700\u5177\u5f71\u54cd\u529b\u7684\u6587\u6863\uff1b2\uff09\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0c\u4ec5\u4f7f\u7528IS\u6392\u540d\u9760\u524d\u6587\u6863\u751f\u6210\u7684\u54cd\u5e94\u6bd4\u4f7f\u7528\u5269\u4f59\u6587\u6863\u751f\u6210\u7684\u54cd\u5e94\u66f4\u63a5\u8fd1\u539f\u59cb\u54cd\u5e94\uff0c\u8bc1\u660e\u4e86IS\u5728\u9694\u79bb\u548c\u91cf\u5316\u6587\u6863\u5f71\u54cd\u529b\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5f71\u54cd\u529b\u5206\u6570\uff08IS\uff09\u80fd\u591f\u6709\u6548\u9694\u79bb\u548c\u91cf\u5316RAG\u7cfb\u7edf\u4e2d\u5355\u4e2a\u68c0\u7d22\u6587\u6863\u7684\u5f71\u54cd\u529b\uff0c\u4e3a\u63d0\u9ad8RAG\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u548c\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u89e3\u51b3\u5f53\u524dRAG\u8bc4\u4f30\u4e2d\u7684\u5173\u952e\u7f3a\u9677\u3002"}}
{"id": "2601.05261", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05261", "abs": "https://arxiv.org/abs/2601.05261", "authors": ["Muhammad Mufti", "Omar Hammad", "Mahfuzur Rahman"], "title": "Improving User Experience with Personalized Review Ranking and Summarization", "comment": null, "summary": "Online consumer reviews play a crucial role in guiding purchase decisions by offering insights into product quality, usability, and performance. However, the increasing volume of user-generated reviews has led to information overload, making it difficult for consumers to identify content that aligns with their specific preferences. Existing review ranking systems typically rely on metrics such as helpfulness votes, star ratings, and recency, but these fail to capture individual user interests and often treat textual sentiment and rating signals separately. This research addresses these limitations by proposing a personalized framework that integrates review ranking and abstractive summarization to enhance decision-making efficiency. The proposed system begins by modeling each user's sentiment through a hybrid analysis of star ratings and review content. Simultaneously, user preferences were derived from historical reviews using sentence embeddings and clustering, forming semantic profiles aligned with thematic and sentiment dimensions. A relevance scoring algorithm matched these profiles with unseen reviews based on sentiment and aspect similarity. Top-matched reviews were then summarized to reflect individual interests. A user study with 70 participants demonstrated that the personalized approach improved satisfaction, perceived relevance, and decision-making confidence, while reducing time spent reading. The results highlight the method's effectiveness in alleviating information overload and delivering content tailored to user-specific preferences, emphasizing its value in enhancing user experience in review-rich decision-making environments.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e00\u4e2a\u4e2a\u6027\u5316\u6846\u67b6\uff0c\u6574\u5408\u8bc4\u8bba\u6392\u5e8f\u548c\u6458\u8981\u751f\u6210\uff0c\u901a\u8fc7\u5206\u6790\u7528\u6237\u5386\u53f2\u8bc4\u8bba\u5efa\u7acb\u8bed\u4e49\u504f\u597d\u6863\u6848\uff0c\u5339\u914d\u65b0\u8bc4\u8bba\u5e76\u751f\u6210\u4e2a\u6027\u5316\u6458\u8981\uff0c\u4ee5\u89e3\u51b3\u4fe1\u606f\u8fc7\u8f7d\u95ee\u9898\u3002", "motivation": "\u5728\u7ebf\u6d88\u8d39\u8005\u8bc4\u8bba\u6570\u91cf\u6fc0\u589e\u5bfc\u81f4\u4fe1\u606f\u8fc7\u8f7d\uff0c\u73b0\u6709\u6392\u5e8f\u7cfb\u7edf\u4f9d\u8d56\u6709\u7528\u6027\u6295\u7968\u3001\u661f\u7ea7\u8bc4\u5206\u548c\u65f6\u6548\u6027\u7b49\u6307\u6807\uff0c\u65e0\u6cd5\u6355\u6349\u4e2a\u4f53\u7528\u6237\u5174\u8da3\uff0c\u4e14\u5c06\u6587\u672c\u60c5\u611f\u548c\u8bc4\u5206\u4fe1\u53f7\u5206\u5f00\u5904\u7406\u3002", "method": "\u63d0\u51fa\u4e2a\u6027\u5316\u6846\u67b6\uff1a1) \u901a\u8fc7\u661f\u7ea7\u8bc4\u5206\u548c\u8bc4\u8bba\u5185\u5bb9\u7684\u6df7\u5408\u5206\u6790\u5efa\u6a21\u7528\u6237\u60c5\u611f\uff1b2) \u4f7f\u7528\u53e5\u5b50\u5d4c\u5165\u548c\u805a\u7c7b\u4ece\u5386\u53f2\u8bc4\u8bba\u4e2d\u63d0\u53d6\u7528\u6237\u504f\u597d\uff0c\u5f62\u6210\u8bed\u4e49\u6863\u6848\uff1b3) \u57fa\u4e8e\u60c5\u611f\u548c\u65b9\u9762\u76f8\u4f3c\u6027\u7684\u76f8\u5173\u6027\u8bc4\u5206\u7b97\u6cd5\u5339\u914d\u65b0\u8bc4\u8bba\uff1b4) \u5bf9\u5339\u914d\u5ea6\u9ad8\u7684\u8bc4\u8bba\u751f\u6210\u53cd\u6620\u4e2a\u4f53\u5174\u8da3\u7684\u6458\u8981\u3002", "result": "70\u540d\u53c2\u4e0e\u8005\u7684\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u4e2a\u6027\u5316\u65b9\u6cd5\u63d0\u9ad8\u4e86\u6ee1\u610f\u5ea6\u3001\u611f\u77e5\u76f8\u5173\u6027\u548c\u51b3\u7b56\u4fe1\u5fc3\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u9605\u8bfb\u65f6\u95f4\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u4fe1\u606f\u8fc7\u8f7d\u95ee\u9898\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u4f9b\u7b26\u5408\u7528\u6237\u7279\u5b9a\u504f\u597d\u7684\u5185\u5bb9\uff0c\u5728\u8bc4\u8bba\u4e30\u5bcc\u7684\u51b3\u7b56\u73af\u5883\u4e2d\u589e\u5f3a\u7528\u6237\u4f53\u9a8c\uff0c\u5f3a\u8c03\u4e86\u4e2a\u6027\u5316\u5728\u63d0\u9ad8\u51b3\u7b56\u6548\u7387\u65b9\u9762\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.05262", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05262", "abs": "https://arxiv.org/abs/2601.05262", "authors": ["Xiaocong Yang"], "title": "LLM2IR: simple unsupervised contrastive learning makes long-context LLM great retriever", "comment": "MS Thesis", "summary": "Modern dense information retrieval (IR) models usually rely on costly large-scale pretraining. In this paper, we introduce LLM2IR, an efficient unsupervised contrastive learning framework to convert any decoder-only large language model (LLM) to an information retrieval model. Despite its simplicity, the effectiveness is proven among different LLMs on multiple IR benchmarks including LoCo, LongEmbed and BEIR. We also find that models with a longer context length tend to have a stronger IR capacity by comparing task performances of models in the same model family. Our work not only provides an effective way to build IR models on the state-of-the-art LLMs, but also shed light on the relationship between information retrieval ability and model context length, which helps the design of better information retrievers.", "AI": {"tldr": "LLM2IR\uff1a\u4e00\u79cd\u5c06\u89e3\u7801\u5668\u4e13\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8f6c\u6362\u4e3a\u4fe1\u606f\u68c0\u7d22\u6a21\u578b\u7684\u9ad8\u6548\u65e0\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u65e0\u9700\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\uff0c\u4e14\u53d1\u73b0\u6a21\u578b\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0eIR\u80fd\u529b\u6b63\u76f8\u5173", "motivation": "\u73b0\u4ee3\u5bc6\u96c6\u4fe1\u606f\u68c0\u7d22\u6a21\u578b\u901a\u5e38\u4f9d\u8d56\u6602\u8d35\u7684\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u6784\u5efaIR\u6a21\u578b\uff0c\u540c\u65f6\u63a2\u7d22\u6a21\u578b\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0eIR\u80fd\u529b\u7684\u5173\u7cfb", "method": "\u63d0\u51faLLM2IR\u6846\u67b6\uff0c\u901a\u8fc7\u65e0\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u5c06\u4efb\u4f55\u89e3\u7801\u5668\u4e13\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8f6c\u6362\u4e3a\u4fe1\u606f\u68c0\u7d22\u6a21\u578b\uff0c\u65e0\u9700\u5927\u89c4\u6a21\u9884\u8bad\u7ec3", "result": "\u5728\u4e0d\u540cLLM\u548c\u591a\u4e2aIR\u57fa\u51c6\u6d4b\u8bd5\uff08LoCo\u3001LongEmbed\u3001BEIR\uff09\u4e0a\u8bc1\u660e\u6709\u6548\u6027\uff0c\u53d1\u73b0\u540c\u4e00\u6a21\u578b\u5bb6\u65cf\u4e2d\u4e0a\u4e0b\u6587\u957f\u5ea6\u8d8a\u957f\u7684\u6a21\u578bIR\u80fd\u529b\u8d8a\u5f3a", "conclusion": "LLM2IR\u4e3a\u5728\u6700\u65b0LLM\u4e0a\u6784\u5efaIR\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u4fe1\u606f\u68c0\u7d22\u80fd\u529b\u4e0e\u6a21\u578b\u4e0a\u4e0b\u6587\u957f\u5ea6\u7684\u5173\u7cfb\uff0c\u6709\u52a9\u4e8e\u8bbe\u8ba1\u66f4\u597d\u7684\u4fe1\u606f\u68c0\u7d22\u5668"}}
{"id": "2601.05263", "categories": ["cs.IR", "cs.DS"], "pdf": "https://arxiv.org/pdf/2601.05263", "abs": "https://arxiv.org/abs/2601.05263", "authors": ["Zhen Yi Lau"], "title": "A General Metric-Space Formulation of the Time Warp Edit Distance (TWED)", "comment": "20 pages, 1 algorithm, small technical note on the generalization of the Time Warp Edit Distance (TWED) to arbitrary metric spaces", "summary": "This short technical note presents a formal generalization of the Time Warp Edit Distance (TWED) proposed by Marteau (2009) to arbitrary metric spaces. By viewing both the observation and temporal domains as metric spaces $(X, d)$ and $(T, \u0394)$, we define a Generalized TWED (GTWED) that remains a true metric under mild assumptions. We provide self-contained proofs of its metric properties and show that the classical TWED is recovered as a special case when $X = \\mathbb{R}^d$, $T \\subset \\mathbb{R}$, and $g(x) = x$. This note focuses on the theoretical structure of GTWED and its implications for extending elastic distances beyond time series, which enables the use of TWED-like metrics on sequences over arbitrary domains such as symbolic data, manifolds, or embeddings.", "AI": {"tldr": "\u63d0\u51fa\u5e7f\u4e49\u65f6\u95f4\u626d\u66f2\u7f16\u8f91\u8ddd\u79bb(GTWED)\uff0c\u5c06TWED\u4ece\u5b9e\u6570\u65f6\u95f4\u5e8f\u5217\u63a8\u5e7f\u5230\u4efb\u610f\u5ea6\u91cf\u7a7a\u95f4\uff0c\u4fdd\u6301\u5ea6\u91cf\u6027\u8d28", "motivation": "\u5c06\u65f6\u95f4\u626d\u66f2\u7f16\u8f91\u8ddd\u79bb(TWED)\u4ece\u5b9e\u6570\u65f6\u95f4\u5e8f\u5217\u6269\u5c55\u5230\u66f4\u4e00\u822c\u7684\u5ea6\u91cf\u7a7a\u95f4\uff0c\u4f7f\u5176\u80fd\u5e94\u7528\u4e8e\u7b26\u53f7\u6570\u636e\u3001\u6d41\u5f62\u3001\u5d4c\u5165\u7b49\u4efb\u610f\u57df\u4e0a\u7684\u5e8f\u5217", "method": "\u5c06\u89c2\u6d4b\u57df\u548c\u65f6\u95f4\u57df\u90fd\u89c6\u4e3a\u5ea6\u91cf\u7a7a\u95f4(X,d)\u548c(T,\u0394)\uff0c\u5b9a\u4e49\u5e7f\u4e49TWED(GTWED)\uff0c\u5728\u6e29\u548c\u5047\u8bbe\u4e0b\u8bc1\u660e\u5176\u5ea6\u91cf\u6027\u8d28\uff0c\u5e76\u5c55\u793a\u7ecf\u5178TWED\u662f\u5176\u7279\u4f8b", "result": "GTWED\u5728\u6e29\u548c\u5047\u8bbe\u4e0b\u4fdd\u6301\u5ea6\u91cf\u6027\u8d28\uff0c\u7ecf\u5178TWED\u662f\u5f53X=\u211d^d\u3001T\u2282\u211d\u3001g(x)=x\u65f6\u7684\u7279\u4f8b\uff0c\u4e3a\u5f39\u6027\u8ddd\u79bb\u5728\u975e\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e0a\u7684\u5e94\u7528\u63d0\u4f9b\u7406\u8bba\u6846\u67b6", "conclusion": "GTWED\u4e3aTWED\u7c7b\u5ea6\u91cf\u5728\u4efb\u610f\u57df\u5e8f\u5217\u4e0a\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u6269\u5c55\uff0c\u4f7f\u5f39\u6027\u8ddd\u79bb\u80fd\u7528\u4e8e\u7b26\u53f7\u6570\u636e\u3001\u6d41\u5f62\u3001\u5d4c\u5165\u7b49\u66f4\u5e7f\u6cdb\u7684\u6570\u636e\u7c7b\u578b"}}
{"id": "2601.05264", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05264", "abs": "https://arxiv.org/abs/2601.05264", "authors": ["Dean Wampler", "Dave Nielson", "Alireza Seddighi"], "title": "Engineering the RAG Stack: A Comprehensive Review of the Architecture and Trust Frameworks for Retrieval-Augmented Generation Systems", "comment": "86 pages, 2 figures, 37 tables. A comprehensive review of Retrieval-Augmented Generation (RAG) architectures and trust frameworks (2018-2025), encompassing a unified taxonomy, evaluation benchmarks, and trust-safety modeling", "summary": "This article provides a comprehensive systematic literature review of academic studies, industrial applications, and real-world deployments from 2018 to 2025, providing a practical guide and detailed overview of modern Retrieval-Augmented Generation (RAG) architectures. RAG offers a modular approach for integrating external knowledge without increasing the capacity of the model as LLM systems expand. Research and engineering practices have been fragmented as a result of the increasing diversity of RAG methodologies, which encompasses a variety of fusion mechanisms, retrieval strategies, and orchestration approaches. We provide quantitative assessment frameworks, analyze the implications for trust and alignment, and systematically consolidate existing RAG techniques into a unified taxonomy. This document is a practical framework for the deployment of resilient, secure, and domain-adaptable RAG systems, synthesizing insights from academic literature, industry reports, and technical implementation guides. It also functions as a technical reference.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf92018-2025\u5e74\u95f4\u7684RAG\u6280\u672f\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff0c\u63d0\u4f9b\u4e86\u73b0\u4ee3\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u67b6\u6784\u7684\u5b9e\u8df5\u6307\u5357\u548c\u8be6\u7ec6\u6982\u8ff0\uff0c\u5305\u62ec\u7edf\u4e00\u5206\u7c7b\u6cd5\u3001\u8bc4\u4f30\u6846\u67b6\u548c\u90e8\u7f72\u6307\u5bfc\u3002", "motivation": "\u968f\u7740LLM\u7cfb\u7edf\u6269\u5c55\uff0cRAG\u63d0\u4f9b\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u65b9\u6cd5\u6765\u96c6\u6210\u5916\u90e8\u77e5\u8bc6\u800c\u65e0\u9700\u589e\u52a0\u6a21\u578b\u5bb9\u91cf\u3002\u7136\u800c\uff0c\u7531\u4e8eRAG\u65b9\u6cd5\u65e5\u76ca\u591a\u6837\u5316\uff08\u5305\u62ec\u5404\u79cd\u878d\u5408\u673a\u5236\u3001\u68c0\u7d22\u7b56\u7565\u548c\u7f16\u6392\u65b9\u6cd5\uff09\uff0c\u7814\u7a76\u548c\u5de5\u7a0b\u5b9e\u8df5\u53d8\u5f97\u788e\u7247\u5316\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u6574\u5408\u548c\u6307\u5bfc\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u6574\u54082018-2025\u5e74\u95f4\u7684\u5b66\u672f\u7814\u7a76\u3001\u5de5\u4e1a\u5e94\u7528\u548c\u5b9e\u9645\u90e8\u7f72\u6848\u4f8b\u3002\u901a\u8fc7\u6784\u5efa\u7edf\u4e00\u5206\u7c7b\u6cd5\u6765\u7cfb\u7edf\u6574\u5408\u73b0\u6709RAG\u6280\u672f\uff0c\u63d0\u4f9b\u5b9a\u91cf\u8bc4\u4f30\u6846\u67b6\uff0c\u5e76\u5206\u6790\u4fe1\u4efb\u548c\u5bf9\u9f50\u7684\u5f71\u54cd\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u5168\u9762\u7684RAG\u6280\u672f\u5206\u7c7b\u4f53\u7cfb\uff0c\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5206\u6790\u4e86RAG\u7cfb\u7edf\u5728\u4fe1\u4efb\u548c\u5bf9\u9f50\u65b9\u9762\u7684\u5f71\u54cd\uff0c\u5e76\u5f62\u6210\u4e86\u90e8\u7f72\u5f39\u6027\u3001\u5b89\u5168\u548c\u9886\u57df\u9002\u5e94\u6027RAG\u7cfb\u7edf\u7684\u5b9e\u8df5\u6846\u67b6\u3002", "conclusion": "\u8be5\u8bba\u6587\u4e3aRAG\u6280\u672f\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u6574\u5408\u6846\u67b6\u548c\u5b9e\u8df5\u6307\u5357\uff0c\u65e2\u53ef\u4f5c\u4e3a\u6280\u672f\u53c2\u8003\uff0c\u4e5f\u53ef\u4f5c\u4e3a\u90e8\u7f72\u53ef\u9760RAG\u7cfb\u7edf\u7684\u5b9e\u7528\u6846\u67b6\uff0c\u5f25\u5408\u4e86\u5b66\u672f\u7814\u7a76\u4e0e\u5de5\u4e1a\u5e94\u7528\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002"}}
{"id": "2601.05265", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05265", "abs": "https://arxiv.org/abs/2601.05265", "authors": ["Mile Stankovic"], "title": "Cross-Document Topic-Aligned Chunking for Retrieval-Augmented Generation", "comment": null, "summary": "Chunking quality determines RAG system performance. Current methods partition documents individually, but complex queries need information scattered across multiple sources: the knowledge fragmentation problem. We introduce Cross-Document Topic-Aligned (CDTA) chunking, which reconstructs knowledge at the corpus level. It first identifies topics across documents, maps segments to each topic, and synthesizes them into unified chunks.\n  On HotpotQA multi-hop reasoning, our method reached 0.93 faithfulness versus 0.83 for contextual retrieval and 0.78 for semantic chunking, a 12% improvement over current industry best practice (p < 0.05). On UAE Legal texts, it reached 0.94 faithfulness with 0.93 citation accuracy. At k = 3, it maintains 0.91 faithfulness while semantic methods drop to 0.68, with a single CDTA chunk containing information requiring multiple traditional fragments.\n  Indexing costs are higher, but synthesis produces information-dense chunks that reduce query-time retrieval needs. For high-query-volume applications with distributed knowledge, cross-document synthesis improves measurably over within-document optimization.", "AI": {"tldr": "CDTA chunking\u901a\u8fc7\u8de8\u6587\u6863\u4e3b\u9898\u5bf9\u9f50\u89e3\u51b3\u77e5\u8bc6\u788e\u7247\u5316\u95ee\u9898\uff0c\u5728HotpotQA\u4e0a\u8fbe\u52300.93\u5fe0\u5b9e\u5ea6\uff0c\u6bd4\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u63d0\u534712%", "motivation": "\u5f53\u524dRAG\u7cfb\u7edf\u7684\u5206\u5757\u65b9\u6cd5\u5728\u5355\u4e2a\u6587\u6863\u5185\u8fdb\u884c\uff0c\u4f46\u590d\u6742\u67e5\u8be2\u9700\u8981\u8de8\u591a\u4e2a\u6765\u6e90\u7684\u4fe1\u606f\uff0c\u5b58\u5728\u77e5\u8bc6\u788e\u7247\u5316\u95ee\u9898", "method": "\u63d0\u51fa\u8de8\u6587\u6863\u4e3b\u9898\u5bf9\u9f50\u5206\u5757\u65b9\u6cd5\uff1a1) \u8bc6\u522b\u8de8\u6587\u6863\u4e3b\u9898\uff1b2) \u5c06\u6587\u6863\u7247\u6bb5\u6620\u5c04\u5230\u76f8\u5e94\u4e3b\u9898\uff1b3) \u5408\u6210\u7edf\u4e00\u7684\u77e5\u8bc6\u5757", "result": "\u5728HotpotQA\u591a\u8df3\u63a8\u7406\u4e0a\u8fbe\u52300.93\u5fe0\u5b9e\u5ea6\uff0c\u6bd4\u4e0a\u4e0b\u6587\u68c0\u7d22(0.83)\u548c\u8bed\u4e49\u5206\u5757(0.78)\u663e\u8457\u63d0\u5347\uff1b\u5728k=3\u65f6\u4ecd\u4fdd\u63010.91\u5fe0\u5b9e\u5ea6\uff0c\u800c\u4f20\u7edf\u65b9\u6cd5\u964d\u81f30.68", "conclusion": "\u867d\u7136\u7d22\u5f15\u6210\u672c\u8f83\u9ad8\uff0c\u4f46\u5408\u6210\u4fe1\u606f\u5bc6\u96c6\u7684\u77e5\u8bc6\u5757\u51cf\u5c11\u4e86\u67e5\u8be2\u65f6\u68c0\u7d22\u9700\u6c42\uff0c\u5bf9\u4e8e\u9ad8\u67e5\u8be2\u91cf\u4e14\u77e5\u8bc6\u5206\u6563\u7684\u5e94\u7528\uff0c\u8de8\u6587\u6863\u5408\u6210\u4f18\u4e8e\u6587\u6863\u5185\u4f18\u5316"}}
{"id": "2601.05266", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05266", "abs": "https://arxiv.org/abs/2601.05266", "authors": ["Muzakkiruddin Ahmed Mohammed", "John R. Talburt", "Leon Claasssens", "Adriaan Marais"], "title": "Retrieval-Augmented Multi-LLM Ensemble for Industrial Part Specification Extraction", "comment": "The 17th International Conference on Knowledge and Systems Engineering", "summary": "Industrial part specification extraction from unstructured text remains a persistent challenge in manufacturing, procurement, and maintenance, where manual processing is both time-consuming and error-prone. This paper introduces a retrieval-augmented multi-LLM ensemble framework that orchestrates nine state-of-the-art Large Language Models (LLMs) within a structured three-phase pipeline. RAGsemble addresses key limitations of single-model systems by combining the complementary strengths of model families including Gemini (2.0, 2.5, 1.5), OpenAI (GPT-4o, o4-mini), Mistral Large, and Gemma (1B, 4B, 3n-e4b), while grounding outputs in factual data using FAISS-based semantic retrieval. The system architecture consists of three stages: (1) parallel extraction by diverse LLMs, (2) targeted research augmentation leveraging high-performing models, and (3) intelligent synthesis with conflict resolution and confidence-aware scoring. RAG integration provides real-time access to structured part databases, enabling the system to validate, refine, and enrich outputs through similarity-based reference retrieval. Experimental results using real industrial datasets demonstrate significant gains in extraction accuracy, technical completeness, and structured output quality compared to leading single-LLM baselines. Key contributions include a scalable ensemble architecture for industrial domains, seamless RAG integration throughout the pipeline, comprehensive quality assessment mechanisms, and a production-ready solution suitable for deployment in knowledge-intensive manufacturing environments.", "AI": {"tldr": "\u63d0\u51faRAGsemble\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u7684\u591aLLM\u96c6\u6210\u65b9\u6cd5\uff0c\u4ece\u975e\u7ed3\u6784\u5316\u6587\u672c\u4e2d\u63d0\u53d6\u5de5\u4e1a\u96f6\u4ef6\u89c4\u683c\uff0c\u663e\u8457\u63d0\u5347\u51c6\u786e\u6027\u548c\u5b8c\u6574\u6027\u3002", "motivation": "\u5de5\u4e1a\u96f6\u4ef6\u89c4\u683c\u4ece\u975e\u7ed3\u6784\u5316\u6587\u672c\u4e2d\u63d0\u53d6\u662f\u5236\u9020\u4e1a\u3001\u91c7\u8d2d\u548c\u7ef4\u62a4\u4e2d\u7684\u6301\u7eed\u6311\u6218\uff0c\u624b\u52a8\u5904\u7406\u8017\u65f6\u4e14\u6613\u51fa\u9519\uff0c\u73b0\u6709\u5355\u6a21\u578b\u7cfb\u7edf\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u7684\u591aLLM\u96c6\u6210\u6846\u67b6\uff0c\u6574\u54089\u4e2a\u5148\u8fdbLLM\uff08Gemini\u3001OpenAI\u3001Mistral\u3001Gemma\u7cfb\u5217\uff09\uff0c\u6784\u5efa\u4e09\u9636\u6bb5\u6d41\u6c34\u7ebf\uff1a\u5e76\u884c\u63d0\u53d6\u3001\u9488\u5bf9\u6027\u7814\u7a76\u589e\u5f3a\u3001\u667a\u80fd\u5408\u6210\u4e0e\u51b2\u7a81\u89e3\u51b3\uff0c\u7ed3\u5408FAISS\u8bed\u4e49\u68c0\u7d22\u63d0\u4f9b\u4e8b\u5b9e\u6570\u636e\u652f\u6301\u3002", "result": "\u5728\u771f\u5b9e\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4\u9886\u5148\u7684\u5355LLM\u57fa\u7ebf\uff0c\u5728\u63d0\u53d6\u51c6\u786e\u6027\u3001\u6280\u672f\u5b8c\u6574\u6027\u548c\u7ed3\u6784\u5316\u8f93\u51fa\u8d28\u91cf\u65b9\u9762\u53d6\u5f97\u663e\u8457\u63d0\u5347\u3002", "conclusion": "RAGsemble\u4e3a\u5de5\u4e1a\u9886\u57df\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u96c6\u6210\u67b6\u6784\u3001\u5168\u6d41\u7a0bRAG\u96c6\u6210\u3001\u5168\u9762\u7684\u8d28\u91cf\u8bc4\u4f30\u673a\u5236\uff0c\u4ee5\u53ca\u9002\u7528\u4e8e\u77e5\u8bc6\u5bc6\u96c6\u578b\u5236\u9020\u73af\u5883\u7684\u5373\u7528\u578b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.05267", "categories": ["cs.IR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05267", "abs": "https://arxiv.org/abs/2601.05267", "authors": ["Geonwoo Bang", "Dongho Kim", "Moohong Min"], "title": "Transforming User Defined Criteria into Explainable Indicators with an Integrated LLM AHP System", "comment": null, "summary": "Evaluating complex texts across domains requires converting user defined criteria into quantitative, explainable indicators, which is a persistent challenge in search and recommendation systems. Single prompt LLM evaluations suffer from complexity and latency issues, while criterion specific decomposition approaches rely on naive averaging or opaque black-box aggregation methods. We present an interpretable aggregation framework combining LLM scoring with the Analytic Hierarchy Process. Our method generates criterion specific scores via LLM as judge, measures discriminative power using Jensen Shannon distance, and derives statistically grounded weights through AHP pairwise comparison matrices. Experiments on Amazon review quality assessment and depression related text scoring demonstrate that our approach achieves high explainability and operational efficiency while maintaining comparable predictive power, making it suitable for real time latency sensitive web services.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u805a\u5408\u6846\u67b6\uff0c\u7ed3\u5408LLM\u8bc4\u5206\u4e0e\u5c42\u6b21\u5206\u6790\u6cd5\uff0c\u7528\u4e8e\u8de8\u9886\u57df\u590d\u6742\u6587\u672c\u8bc4\u4f30", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u5355\u63d0\u793aLLM\u8bc4\u4f30\u9762\u4e34\u590d\u6742\u6027\u548c\u5ef6\u8fdf\u95ee\u9898\uff0c\u800c\u57fa\u4e8e\u51c6\u5219\u5206\u89e3\u7684\u65b9\u6cd5\u4f9d\u8d56\u6734\u7d20\u5e73\u5747\u6216\u4e0d\u900f\u660e\u7684\u9ed1\u76d2\u805a\u5408\u65b9\u6cd5\uff0c\u96be\u4ee5\u5c06\u7528\u6237\u5b9a\u4e49\u51c6\u5219\u8f6c\u5316\u4e3a\u53ef\u91cf\u5316\u7684\u53ef\u89e3\u91ca\u6307\u6807", "method": "\u63d0\u51fa\u53ef\u89e3\u91ca\u805a\u5408\u6846\u67b6\uff1a1) \u901a\u8fc7LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u751f\u6210\u51c6\u5219\u7279\u5b9a\u5206\u6570\uff1b2) \u4f7f\u7528Jensen-Shannon\u8ddd\u79bb\u6d4b\u91cf\u5224\u522b\u80fd\u529b\uff1b3) \u901a\u8fc7AHP\u6210\u5bf9\u6bd4\u8f83\u77e9\u9635\u63a8\u5bfc\u7edf\u8ba1\u57fa\u7840\u6743\u91cd", "result": "\u5728\u4e9a\u9a6c\u900a\u8bc4\u8bba\u8d28\u91cf\u8bc4\u4f30\u548c\u6291\u90c1\u76f8\u5173\u6587\u672c\u8bc4\u5206\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u53ef\u89e3\u91ca\u6027\u548c\u64cd\u4f5c\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u6bd4\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u9002\u5408\u5b9e\u65f6\u5ef6\u8fdf\u654f\u611f\u7684Web\u670d\u52a1", "conclusion": "\u8be5\u65b9\u6cd5\u89e3\u51b3\u4e86\u590d\u6742\u6587\u672c\u8bc4\u4f30\u4e2d\u7684\u53ef\u89e3\u91ca\u6027\u548c\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u641c\u7d22\u548c\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.05268", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05268", "abs": "https://arxiv.org/abs/2601.05268", "authors": ["Rob Koopman"], "title": "Separating Semantic Expansion from Linear Geometry for PubMed-Scale Vector Search", "comment": "4 pages", "summary": "We describe a PubMed scale retrieval framework that separates semantic interpretation from metric geometry. A large language model expands a natural language query into concise biomedical phrases; retrieval then operates in a fixed, mean free, approximately isotropic embedding space. Each document and query vector is formed as a weighted mean of token embeddings, projected onto the complement of nuisance axes and compressed by a Johnson Lindenstrauss transform. No parameters are trained. The system retrieves coherent biomedical clusters across the full MEDLINE corpus (about 40 million records) using exact cosine search on 256 dimensional int8 vectors. Evaluation is purely geometric: head cosine, compactness, centroid closure, and isotropy are compared with random vector baselines. Recall is not defined, since the language-model expansion specifies the effective target set.", "AI": {"tldr": "\u63d0\u51faPubMed\u89c4\u6a21\u68c0\u7d22\u6846\u67b6\uff0c\u5c06\u8bed\u4e49\u89e3\u91ca\u4e0e\u5ea6\u91cf\u51e0\u4f55\u5206\u79bb\uff0c\u4f7f\u7528LLM\u6269\u5c55\u67e5\u8be2\u4e3a\u751f\u7269\u533b\u5b66\u77ed\u8bed\uff0c\u5728\u56fa\u5b9a\u3001\u5747\u503c\u81ea\u7531\u3001\u8fd1\u4f3c\u5404\u5411\u540c\u6027\u7684\u5d4c\u5165\u7a7a\u95f4\u4e2d\u8fdb\u884c\u68c0\u7d22\uff0c\u65e0\u9700\u8bad\u7ec3\u53c2\u6570\u3002", "motivation": "\u4f20\u7edf\u68c0\u7d22\u7cfb\u7edf\u901a\u5e38\u5c06\u8bed\u4e49\u7406\u89e3\u548c\u51e0\u4f55\u68c0\u7d22\u8026\u5408\u5728\u4e00\u8d77\uff0c\u672c\u6587\u65e8\u5728\u5206\u79bb\u8fd9\u4e24\u4e2a\u65b9\u9762\uff0c\u901a\u8fc7\u8bed\u8a00\u6a21\u578b\u5904\u7406\u8bed\u4e49\u89e3\u91ca\uff0c\u5728\u56fa\u5b9a\u7684\u51e0\u4f55\u7a7a\u95f4\u4e2d\u8fdb\u884c\u9ad8\u6548\u68c0\u7d22\uff0c\u4ee5\u5b9e\u73b0\u5728\u5927\u89c4\u6a21\u751f\u7269\u533b\u5b66\u6587\u732e\uff08\u5982MEDLINE\u76844000\u4e07\u6761\u8bb0\u5f55\uff09\u4e0a\u7684\u7cbe\u786e\u68c0\u7d22\u3002", "method": "1. \u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u6269\u5c55\u4e3a\u7b80\u6d01\u7684\u751f\u7269\u533b\u5b66\u77ed\u8bed\uff1b2. \u5728\u56fa\u5b9a\u7684\u3001\u5747\u503c\u81ea\u7531\u3001\u8fd1\u4f3c\u5404\u5411\u540c\u6027\u7684\u5d4c\u5165\u7a7a\u95f4\u4e2d\u8fdb\u884c\u68c0\u7d22\uff1b3. \u6587\u6863\u548c\u67e5\u8be2\u5411\u91cf\u901a\u8fc7\u52a0\u6743\u5e73\u5747\u8bcd\u5d4c\u5165\u5f62\u6210\uff0c\u6295\u5f71\u5230\u5e72\u6270\u8f74\u8865\u7a7a\u95f4\uff0c\u5e76\u901a\u8fc7Johnson-Lindenstrauss\u53d8\u6362\u538b\u7f29\uff1b4. \u5728256\u7ef4int8\u5411\u91cf\u4e0a\u4f7f\u7528\u7cbe\u786e\u4f59\u5f26\u641c\u7d22\uff1b5. \u65e0\u9700\u8bad\u7ec3\u4efb\u4f55\u53c2\u6570\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u5728\u5b8c\u6574\u7684MEDLINE\u8bed\u6599\u5e93\uff08\u7ea64000\u4e07\u6761\u8bb0\u5f55\uff09\u4e0a\u68c0\u7d22\u51fa\u8fde\u8d2f\u7684\u751f\u7269\u533b\u5b66\u805a\u7c7b\uff0c\u4f7f\u7528\u7eaf\u51e0\u4f55\u8bc4\u4f30\u6307\u6807\uff08\u5934\u90e8\u4f59\u5f26\u3001\u7d27\u5bc6\u5ea6\u3001\u8d28\u5fc3\u95ed\u5408\u5ea6\u3001\u5404\u5411\u540c\u6027\uff09\u4e0e\u968f\u673a\u5411\u91cf\u57fa\u7ebf\u8fdb\u884c\u6bd4\u8f83\uff0c\u7531\u4e8e\u8bed\u8a00\u6a21\u578b\u6269\u5c55\u5b9a\u4e49\u4e86\u6709\u6548\u76ee\u6807\u96c6\uff0c\u56e0\u6b64\u672a\u5b9a\u4e49\u53ec\u56de\u7387\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u8bed\u4e49\u89e3\u91ca\u4e0e\u5ea6\u91cf\u51e0\u4f55\u7684\u5206\u79bb\uff0c\u901a\u8fc7\u8bed\u8a00\u6a21\u578b\u5904\u7406\u8bed\u4e49\uff0c\u5728\u56fa\u5b9a\u7684\u51e0\u4f55\u7a7a\u95f4\u4e2d\u8fdb\u884c\u9ad8\u6548\u68c0\u7d22\uff0c\u4e3a\u5927\u89c4\u6a21\u751f\u7269\u533b\u5b66\u6587\u732e\u68c0\u7d22\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u53c2\u6570\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2601.05269", "categories": ["cs.IR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05269", "abs": "https://arxiv.org/abs/2601.05269", "authors": ["Yoav Evron", "Michal Bar-Asher Siegal", "Michael Fire"], "title": "Studying Illustrations in Manuscripts: An Efficient Deep-Learning Approach", "comment": "14 pages, 5 figures", "summary": "The recent Artificial Intelligence (AI) revolution has opened transformative possibilities for the humanities, particularly in unlocking the visual content embedded in historical manuscripts. While digital archives now offer unprecedented access to these materials, the ability to systematically study illustrations at a large scale remains challenging. Our study presents a fast and scalable AI approach for detecting, extracting, and describing illustrations in digitized manuscripts. Focusing on collections like the Vatican Library, our system enables efficient visual analysis across millions of pages. Our pipeline consists of three stages: (1) a fine-tuned image classification model filters out text-only pages; (2) an efficient object detection model identifies and crops illustrations; and (3) a multimodal image captioning model generates concise, human-readable descriptions. These are stored in a searchable database, allowing scholars to retrieve relevant visual materials through keyword queries. By harnessing the power of recent AI advancements, we enable large-scale visual research that was previously impractical, empowering scholars in historical studies, art history, and cultural heritage to explore visual motifs, artistic styles, and cross-cultural influences with new precision and speed. Applying our pipeline to over three million digitized manuscript pages, we automatically identified and extracted more than 200,000 unique illustrations. This scale of processing in under 0.06 seconds per page, dramatically outperforms traditional segmentation techniques in both efficiency and accessibility for visual scholarship. Our work demonstrates how cutting-edge AI tools can profoundly reshape scholarly workflows and open new avenues for multidisciplinary research in the age of digital manuscripts.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5feb\u901f\u3001\u53ef\u6269\u5c55\u7684AI\u6d41\u6c34\u7ebf\uff0c\u7528\u4e8e\u68c0\u6d4b\u3001\u63d0\u53d6\u548c\u63cf\u8ff0\u6570\u5b57\u5316\u624b\u7a3f\u4e2d\u7684\u63d2\u56fe\uff0c\u5e94\u7528\u4e8e\u68b5\u8482\u5188\u56fe\u4e66\u9986\u7b49\u6536\u85cf\uff0c\u5904\u7406\u8d85\u8fc7300\u4e07\u9875\uff0c\u63d0\u53d620\u591a\u4e07\u5f20\u63d2\u56fe\uff0c\u6bcf\u9875\u5904\u7406\u65f6\u95f4\u4e0d\u52300.06\u79d2\u3002", "motivation": "\u867d\u7136\u6570\u5b57\u6863\u6848\u63d0\u4f9b\u4e86\u524d\u6240\u672a\u6709\u7684\u5386\u53f2\u624b\u7a3f\u8bbf\u95ee\u9014\u5f84\uff0c\u4f46\u5927\u89c4\u6a21\u7cfb\u7edf\u7814\u7a76\u63d2\u56fe\u4ecd\u7136\u56f0\u96be\u3002AI\u9769\u547d\u4e3a\u4eba\u6587\u5b66\u79d1\u63d0\u4f9b\u4e86\u53d8\u9769\u53ef\u80fd\u6027\uff0c\u7279\u522b\u662f\u89e3\u9501\u5386\u53f2\u624b\u7a3f\u4e2d\u7684\u89c6\u89c9\u5185\u5bb9\u3002", "method": "\u4e09\u9636\u6bb5\u6d41\u6c34\u7ebf\uff1a1) \u5fae\u8c03\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\u8fc7\u6ee4\u7eaf\u6587\u672c\u9875\u9762\uff1b2) \u9ad8\u6548\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u8bc6\u522b\u548c\u88c1\u526a\u63d2\u56fe\uff1b3) \u591a\u6a21\u6001\u56fe\u50cf\u63cf\u8ff0\u6a21\u578b\u751f\u6210\u7b80\u6d01\u3001\u4eba\u7c7b\u53ef\u8bfb\u7684\u63cf\u8ff0\u3002\u7ed3\u679c\u5b58\u50a8\u5728\u53ef\u641c\u7d22\u6570\u636e\u5e93\u4e2d\u3002", "result": "\u5e94\u7528\u4e8e\u8d85\u8fc7300\u4e07\u6570\u5b57\u5316\u624b\u7a3f\u9875\u9762\uff0c\u81ea\u52a8\u8bc6\u522b\u548c\u63d0\u53d6\u8d85\u8fc720\u4e07\u5f20\u72ec\u7279\u63d2\u56fe\uff0c\u6bcf\u9875\u5904\u7406\u65f6\u95f4\u4e0d\u52300.06\u79d2\uff0c\u5728\u6548\u7387\u548c\u53ef\u8bbf\u95ee\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u5206\u5272\u6280\u672f\u3002", "conclusion": "\u524d\u6cbfAI\u5de5\u5177\u80fd\u591f\u6df1\u523b\u91cd\u5851\u5b66\u672f\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4e3a\u6570\u5b57\u624b\u7a3f\u65f6\u4ee3\u7684\u591a\u5b66\u79d1\u7814\u7a76\u5f00\u8f9f\u65b0\u9014\u5f84\uff0c\u4f7f\u5b66\u8005\u80fd\u591f\u4ee5\u65b0\u7684\u7cbe\u5ea6\u548c\u901f\u5ea6\u63a2\u7d22\u89c6\u89c9\u4e3b\u9898\u3001\u827a\u672f\u98ce\u683c\u548c\u8de8\u6587\u5316\u5f71\u54cd\u3002"}}
{"id": "2601.05270", "categories": ["cs.IR", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2601.05270", "abs": "https://arxiv.org/abs/2601.05270", "authors": ["Tarun Prajapati"], "title": "LiveVectorLake: A Real-Time Versioned Knowledge Base Architecture for Streaming Vector Updates and Temporal Retrieval", "comment": "7 pages, 1 figure. Preprint; work in progress", "summary": "Modern Retrieval-Augmented Generation (RAG) systems struggle with a fundamental architectural tension: vector indices are optimized for query latency but poorly handle continuous knowledge updates, while data lakes excel at versioning but introduce query latency penalties. We introduce LiveVectorLake, a dual-tier temporal knowledge base architecture that enables real-time semantic search on current knowledge while maintaining complete version history for compliance, auditability, and point-in-time retrieval. The system introduces three core architectural contributions: (1) Content-addressable chunk-level synchronization using SHA-256 hashing for deterministic change detection without external state tracking; (2) Dual-tier storage separating hot-tier vector indices (Milvus with HNSW) from cold-tier columnar versioning (Delta Lake with Parquet), optimizing query latency and storage cost independently; (3) Temporal query routing enabling point-in-time knowledge retrieval via delta-versioning with ACID consistency across tiers. Evaluation on a 100-document corpus versioned across five time points demonstrates: (i) 10-15% re-processing of content during updates compared to 100% for full re-indexing; (ii) sub-100ms retrieval latency on current knowledge; (iii) sub-2s latency for temporal queries across version history; and (iv) storage cost optimization through hot/cold tier separation (only current chunks in expensive vector indices). The approach enables production RAG deployments requiring simultaneous optimization for query performance, update efficiency, and regulatory compliance. Code and resources: [https://github.com/praj-tarun/LiveVectorLake]", "AI": {"tldr": "LiveVectorLake\u63d0\u51fa\u53cc\u5c42\u7ea7\u65f6\u95f4\u77e5\u8bc6\u5e93\u67b6\u6784\uff0c\u89e3\u51b3RAG\u7cfb\u7edf\u4e2d\u5411\u91cf\u7d22\u5f15\u66f4\u65b0\u6548\u7387\u4e0e\u6570\u636e\u6e56\u67e5\u8be2\u5ef6\u8fdf\u7684\u77db\u76fe\uff0c\u5b9e\u73b0\u5b9e\u65f6\u8bed\u4e49\u641c\u7d22\u548c\u5b8c\u6574\u7248\u672c\u5386\u53f2\u7ba1\u7406\u3002", "motivation": "\u73b0\u4ee3RAG\u7cfb\u7edf\u9762\u4e34\u67b6\u6784\u77db\u76fe\uff1a\u5411\u91cf\u7d22\u5f15\u4f18\u5316\u67e5\u8be2\u5ef6\u8fdf\u4f46\u96be\u4ee5\u5904\u7406\u8fde\u7eed\u77e5\u8bc6\u66f4\u65b0\uff0c\u6570\u636e\u6e56\u64c5\u957f\u7248\u672c\u7ba1\u7406\u4f46\u5f15\u5165\u67e5\u8be2\u5ef6\u8fdf\u3002\u9700\u8981\u540c\u65f6\u4f18\u5316\u67e5\u8be2\u6027\u80fd\u3001\u66f4\u65b0\u6548\u7387\u548c\u5408\u89c4\u6027\u3002", "method": "\u91c7\u7528\u53cc\u5c42\u7ea7\u65f6\u95f4\u77e5\u8bc6\u5e93\u67b6\u6784\uff1a1) \u57fa\u4e8eSHA-256\u54c8\u5e0c\u7684\u5185\u5bb9\u5bfb\u5740\u5206\u5757\u540c\u6b65\uff1b2) \u70ed\u5c42\u5411\u91cf\u7d22\u5f15(Milvus+HNSW)\u4e0e\u51b7\u5c42\u5217\u5f0f\u7248\u672c\u5b58\u50a8(Delta Lake+Parquet)\u5206\u79bb\uff1b3) \u65f6\u95f4\u67e5\u8be2\u8def\u7531\u652f\u6301\u65f6\u95f4\u70b9\u77e5\u8bc6\u68c0\u7d22\u3002", "result": "\u5728100\u6587\u68635\u4e2a\u65f6\u95f4\u70b9\u7684\u8bc4\u4f30\u4e2d\uff1a\u66f4\u65b0\u65f6\u4ec5\u970010-15%\u5185\u5bb9\u91cd\u5904\u7406\uff1b\u5f53\u524d\u77e5\u8bc6\u68c0\u7d22\u5ef6\u8fdf<100ms\uff1b\u65f6\u95f4\u67e5\u8be2\u5ef6\u8fdf<2s\uff1b\u901a\u8fc7\u70ed\u51b7\u5c42\u5206\u79bb\u4f18\u5316\u5b58\u50a8\u6210\u672c\u3002", "conclusion": "LiveVectorLake\u89e3\u51b3\u4e86RAG\u7cfb\u7edf\u5728\u67e5\u8be2\u6027\u80fd\u3001\u66f4\u65b0\u6548\u7387\u548c\u5408\u89c4\u6027\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u4e3a\u9700\u8981\u540c\u65f6\u4f18\u5316\u8fd9\u4e9b\u6307\u6807\u7684\u751f\u4ea7\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2601.05461", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05461", "abs": "https://arxiv.org/abs/2601.05461", "authors": ["Mohammed Ali", "Abdelrahman Abdallah", "Amit Agarwal", "Hitesh Laxmichand Patel", "Adam Jatowt"], "title": "RECOR: Reasoning-focused Multi-turn Conversational Retrieval Benchmark", "comment": null, "summary": "Existing benchmarks treat multi-turn conversation and reasoning-intensive retrieval separately, yet real-world information seeking requires both. To bridge this gap, we present a benchmark for reasoning-based conversational information retrieval comprising 707 conversations (2,971 turns) across eleven domains. To ensure quality, our Decomposition-and-Verification framework transforms complex queries into fact-grounded multi-turn dialogues through multi-level validation, where atomic facts are verified against sources and explicit retrieval reasoning is generated for each turn. Comprehensive evaluation reveals that combining conversation history with reasoning doubles retrieval performance (Baseline .236 $\\rightarrow$ History+Reasoning .479 nDCG@10), while reasoning-specialized models substantially outperform dense encoders. Despite these gains, further analysis highlights that implicit reasoning remains challenging, particularly when logical connections are not explicitly stated in the text.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u63a8\u7406\u5f0f\u5bf9\u8bdd\u4fe1\u606f\u68c0\u7d22\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b707\u4e2a\u5bf9\u8bdd\u548c11\u4e2a\u9886\u57df\uff0c\u901a\u8fc7\u5206\u89e3\u4e0e\u9a8c\u8bc1\u6846\u67b6\u786e\u4fdd\u8d28\u91cf\uff0c\u7ed3\u679c\u663e\u793a\u7ed3\u5408\u5bf9\u8bdd\u5386\u53f2\u548c\u63a8\u7406\u80fd\u663e\u8457\u63d0\u5347\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5c06\u591a\u8f6e\u5bf9\u8bdd\u548c\u63a8\u7406\u5bc6\u96c6\u578b\u68c0\u7d22\u5206\u5f00\u5904\u7406\uff0c\u4f46\u73b0\u5b9e\u4e16\u754c\u7684\u4fe1\u606f\u641c\u7d22\u9700\u8981\u4e24\u8005\u7ed3\u5408\u3002\u4e3a\u4e86\u5f25\u8865\u8fd9\u4e00\u5dee\u8ddd\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u80fd\u591f\u8bc4\u4f30\u63a8\u7406\u5f0f\u5bf9\u8bdd\u4fe1\u606f\u68c0\u7d22\u7684\u57fa\u51c6\u3002", "method": "\u63d0\u51fa\u4e86\u5206\u89e3\u4e0e\u9a8c\u8bc1\u6846\u67b6\uff0c\u5c06\u590d\u6742\u67e5\u8be2\u8f6c\u5316\u4e3a\u57fa\u4e8e\u4e8b\u5b9e\u7684\u591a\u8f6e\u5bf9\u8bdd\uff0c\u901a\u8fc7\u591a\u5c42\u6b21\u9a8c\u8bc1\u786e\u4fdd\u8d28\u91cf\uff1a\u539f\u5b50\u4e8b\u5b9e\u4e0e\u6765\u6e90\u9a8c\u8bc1\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u5bf9\u8bdd\u8f6e\u6b21\u751f\u6210\u663e\u5f0f\u68c0\u7d22\u63a8\u7406\u3002", "result": "\u7ed3\u5408\u5bf9\u8bdd\u5386\u53f2\u548c\u63a8\u7406\u80fd\u5c06\u68c0\u7d22\u6027\u80fd\u63d0\u5347\u4e00\u500d\uff08\u57fa\u7ebf0.236 \u2192 \u5386\u53f2+\u63a8\u74060.479 nDCG@10\uff09\uff0c\u63a8\u7406\u4e13\u7528\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u5bc6\u96c6\u7f16\u7801\u5668\u3002\u4f46\u9690\u5f0f\u63a8\u7406\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u7279\u522b\u662f\u5f53\u903b\u8f91\u8fde\u63a5\u672a\u5728\u6587\u672c\u4e2d\u660e\u786e\u9648\u8ff0\u65f6\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u63a8\u7406\u5f0f\u5bf9\u8bdd\u4fe1\u606f\u68c0\u7d22\u7684\u57fa\u51c6\u7a7a\u767d\uff0c\u5c55\u793a\u4e86\u7ed3\u5408\u5bf9\u8bdd\u5386\u53f2\u548c\u63a8\u7406\u7684\u91cd\u8981\u6027\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u9690\u5f0f\u63a8\u7406\u4ecd\u7136\u662f\u672a\u6765\u7814\u7a76\u9700\u8981\u89e3\u51b3\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2601.05513", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05513", "abs": "https://arxiv.org/abs/2601.05513", "authors": ["Lei Wang", "Jinhang Wu", "Zhibin Wang", "Biye Li", "Haiping Hou"], "title": "LEAPS: An LLM-Empowered Adaptive Plugin for Taobao AI Search", "comment": null, "summary": "The rapid advancement of large language models has reshaped user search cognition, driving a paradigm shift from discrete keyword-based search to high-dimensional conversational interaction. However, existing e-commerce search architectures face a critical capability deficit in adapting to this change. Users are often caught in a dilemma: precise natural language descriptions frequently trigger zero-result scenarios, while the forced simplification of queries leads to decision overload from noisy, generic results. To tackle this challenge, we propose LEAPS (LLM-Empowered Adaptive Plugin for Taobao AI Search), which seamlessly upgrades traditional search systems via a \"Broaden-and-Refine\" paradigm. Specifically, it attaches plugins to both ends of the search pipeline: (1) Upstream, a Query Expander acts as an intent translator. It employs a novel three-stage training strategy--inverse data augmentation, posterior-knowledge supervised fine-tuning, and diversity-aware reinforcement learning--to generate adaptive and complementary query combinations that maximize the candidate product set. (2) Downstream, a Relevance Verifier serves as a semantic gatekeeper. By synthesizing multi-source data (e.g., OCR text, reviews) and leveraging chain-of-thought reasoning, it precisely filters noise to resolve selection overload. Extensive offline experiments and online A/B testing demonstrate that LEAPS significantly enhances conversational search experiences. Crucially, its non-invasive architecture preserves established retrieval performance optimized for short-text queries, while simultaneously allowing for low-cost integration into diverse back-ends. Fully deployed on Taobao AI Search since August 2025, LEAPS currently serves hundreds of millions of users monthly.", "AI": {"tldr": "LEAPS\u662f\u4e00\u4e2aLLM\u8d4b\u80fd\u7684\u6dd8\u5b9dAI\u641c\u7d22\u81ea\u9002\u5e94\u63d2\u4ef6\uff0c\u91c7\u7528\"\u6269\u5c55-\u7cbe\u70bc\"\u8303\u5f0f\uff0c\u901a\u8fc7\u4e0a\u6e38\u67e5\u8be2\u6269\u5c55\u5668\u548c\u4e0b\u6e38\u76f8\u5173\u6027\u9a8c\u8bc1\u5668\u63d0\u5347\u5bf9\u8bdd\u5f0f\u641c\u7d22\u4f53\u9a8c\uff0c\u540c\u65f6\u4fdd\u6301\u4f20\u7edf\u77ed\u6587\u672c\u67e5\u8be2\u7684\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u6539\u53d8\u4e86\u7528\u6237\u641c\u7d22\u8ba4\u77e5\uff0c\u4ece\u79bb\u6563\u5173\u952e\u8bcd\u641c\u7d22\u8f6c\u5411\u9ad8\u7ef4\u5bf9\u8bdd\u4ea4\u4e92\uff0c\u4f46\u73b0\u6709\u7535\u5546\u641c\u7d22\u67b6\u6784\u96be\u4ee5\u9002\u5e94\u8fd9\u79cd\u53d8\u5316\u3002\u7528\u6237\u9762\u4e34\u4e24\u96be\uff1a\u7cbe\u786e\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u5e38\u5bfc\u81f4\u96f6\u7ed3\u679c\uff0c\u7b80\u5316\u67e5\u8be2\u53c8\u4f1a\u4ea7\u751f\u566a\u58f0\u8fc7\u591a\u7684\u901a\u7528\u7ed3\u679c\u3002", "method": "\u63d0\u51faLEAPS\u7cfb\u7edf\uff0c\u5728\u641c\u7d22\u7ba1\u9053\u4e24\u7aef\u9644\u52a0\u63d2\u4ef6\uff1a1) \u4e0a\u6e38\u67e5\u8be2\u6269\u5c55\u5668\u4f5c\u4e3a\u610f\u56fe\u7ffb\u8bd1\u5668\uff0c\u91c7\u7528\u4e09\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff08\u9006\u6570\u636e\u589e\u5f3a\u3001\u540e\u9a8c\u77e5\u8bc6\u76d1\u7763\u5fae\u8c03\u3001\u591a\u6837\u6027\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\uff09\u751f\u6210\u81ea\u9002\u5e94\u4e92\u8865\u67e5\u8be2\u7ec4\u5408\uff1b2) \u4e0b\u6e38\u76f8\u5173\u6027\u9a8c\u8bc1\u5668\u4f5c\u4e3a\u8bed\u4e49\u628a\u5173\u8005\uff0c\u7efc\u5408\u591a\u6e90\u6570\u636e\uff08OCR\u6587\u672c\u3001\u8bc4\u8bba\u7b49\uff09\u5e76\u5229\u7528\u601d\u7ef4\u94fe\u63a8\u7406\u7cbe\u786e\u8fc7\u6ee4\u566a\u58f0\u3002", "result": "\u79bb\u7ebf\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u8868\u660eLEAPS\u663e\u8457\u63d0\u5347\u5bf9\u8bdd\u5f0f\u641c\u7d22\u4f53\u9a8c\u3002\u5176\u975e\u4fb5\u5165\u5f0f\u67b6\u6784\u65e2\u4fdd\u6301\u4e86\u9488\u5bf9\u77ed\u6587\u672c\u67e5\u8be2\u4f18\u5316\u7684\u68c0\u7d22\u6027\u80fd\uff0c\u53c8\u652f\u6301\u4f4e\u6210\u672c\u96c6\u6210\u5230\u4e0d\u540c\u540e\u7aef\u3002\u81ea2025\u5e748\u6708\u5168\u9762\u90e8\u7f72\u4e8e\u6dd8\u5b9dAI\u641c\u7d22\uff0c\u6bcf\u6708\u670d\u52a1\u6570\u4ebf\u7528\u6237\u3002", "conclusion": "LEAPS\u6210\u529f\u89e3\u51b3\u4e86\u7535\u5546\u641c\u7d22\u4e2d\u7cbe\u786e\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e0e\u566a\u58f0\u7ed3\u679c\u4e4b\u95f4\u7684\u4e24\u96be\u95ee\u9898\uff0c\u901a\u8fc7\"\u6269\u5c55-\u7cbe\u70bc\"\u8303\u5f0f\u65e0\u7f1d\u5347\u7ea7\u4f20\u7edf\u641c\u7d22\u7cfb\u7edf\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u65f6\u4ee3\u7684\u7535\u5546\u641c\u7d22\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.05549", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05549", "abs": "https://arxiv.org/abs/2601.05549", "authors": ["Tuan-Luc Huynh", "Weiqing Wang", "Trung Le", "Thuy-Trang Vu", "Dragan Ga\u0161evi\u0107", "Yuan-Fang Li", "Thanh-Toan Do"], "title": "Efficient Temporal-aware Matryoshka Adaptation for Temporal Information Retrieval", "comment": "18 pages", "summary": "Retrievers are a key bottleneck in Temporal Retrieval-Augmented Generation (RAG) systems: failing to retrieve temporally relevant context can degrade downstream generation, regardless of LLM reasoning. We propose Temporal-aware Matryoshka Representation Learning (TMRL), an efficient method that equips retrievers with temporal-aware Matryoshka embeddings. TMRL leverages the nested structure of Matryoshka embeddings to introduce a temporal subspace, enhancing temporal encoding while preserving general semantic representations. Experiments show that TMRL efficiently adapts diverse text embedding models, achieving competitive temporal retrieval and temporal RAG performance compared to prior Matryoshka-based non-temporal methods and prior temporal methods, while enabling flexible accuracy-efficiency trade-offs.", "AI": {"tldr": "TMRL\u662f\u4e00\u79cd\u9ad8\u6548\u65b9\u6cd5\uff0c\u901a\u8fc7\u65f6\u95f4\u611f\u77e5\u7684\u5957\u5a03\u5d4c\u5165\u63d0\u5347\u68c0\u7d22\u5668\u7684\u65f6\u95f4\u76f8\u5173\u6027\uff0c\u5728\u4fdd\u6301\u8bed\u4e49\u8868\u793a\u7684\u540c\u65f6\u589e\u5f3a\u65f6\u95f4\u7f16\u7801\uff0c\u5b9e\u73b0\u7075\u6d3b\u7684\u6548\u7387-\u7cbe\u5ea6\u6743\u8861\u3002", "motivation": "\u65f6\u95f4\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u4e2d\uff0c\u68c0\u7d22\u5668\u662f\u5173\u952e\u74f6\u9888\uff1a\u5982\u679c\u68c0\u7d22\u4e0d\u5230\u65f6\u95f4\u76f8\u5173\u7684\u4e0a\u4e0b\u6587\uff0c\u65e0\u8bbaLLM\u63a8\u7406\u80fd\u529b\u5982\u4f55\uff0c\u90fd\u4f1a\u964d\u4f4e\u4e0b\u6e38\u751f\u6210\u8d28\u91cf\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u65f6\u95f4\u611f\u77e5\u68c0\u7d22\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u65f6\u95f4\u611f\u77e5\u5957\u5a03\u8868\u793a\u5b66\u4e60\uff08TMRL\uff09\uff0c\u5229\u7528\u5957\u5a03\u5d4c\u5165\u7684\u5d4c\u5957\u7ed3\u6784\u5f15\u5165\u65f6\u95f4\u5b50\u7a7a\u95f4\uff0c\u589e\u5f3a\u65f6\u95f4\u7f16\u7801\u540c\u65f6\u4fdd\u6301\u901a\u7528\u8bed\u4e49\u8868\u793a\u3002\u8be5\u65b9\u6cd5\u80fd\u9ad8\u6548\u9002\u914d\u591a\u79cd\u6587\u672c\u5d4c\u5165\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660eTMRL\u5728\u65f6\u95f4\u68c0\u7d22\u548c\u65f6\u95f4RAG\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u76f8\u6bd4\u5148\u524d\u57fa\u4e8e\u5957\u5a03\u7684\u975e\u65f6\u95f4\u65b9\u6cd5\u548c\u65f6\u95f4\u65b9\u6cd5\u90fd\u6709\u7ade\u4e89\u529b\uff0c\u540c\u65f6\u652f\u6301\u7075\u6d3b\u7684\u7cbe\u5ea6-\u6548\u7387\u6743\u8861\u3002", "conclusion": "TMRL\u901a\u8fc7\u65f6\u95f4\u611f\u77e5\u7684\u5957\u5a03\u5d4c\u5165\u6709\u6548\u89e3\u51b3\u4e86\u65f6\u95f4RAG\u7cfb\u7edf\u4e2d\u68c0\u7d22\u5668\u7684\u65f6\u95f4\u76f8\u5173\u6027\u74f6\u9888\u95ee\u9898\uff0c\u4e3a\u65f6\u95f4\u654f\u611f\u7684\u4fe1\u606f\u68c0\u7d22\u63d0\u4f9b\u4e86\u9ad8\u6548\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.05588", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05588", "abs": "https://arxiv.org/abs/2601.05588", "authors": ["Benjamin Rozonoyer", "Chong You", "Michael Boratko", "Himanshu Jain", "Nilesh Gupta", "Srinadh Bhojanapalli", "Andrew McCallum", "Felix Yu"], "title": "Autoregressive Ranking: Bridging the Gap Between Dual and Cross Encoders", "comment": "22 pages, 5 figures", "summary": "Dual and cross encoders have long been mainstays of information retrieval (IR), but are being challenged by the emergent capabilities of LLMs. An LLM-based approach we term pointwise generative ranking - generating tokens the length of a single docID as opposed to a list in order to enable ranking via beam search - combines efficiency and expressivity benefits while leveraging the in-context capabilities of Causal Transformers. Although there is ample evidence to suggest that pretrained LLMs are well-suited for ranking, we find that the vast majority of LLM-based approaches rely on next-token prediction, a loss function which is fundamentally rank-agnostic (and especially so with pointwise supervision). In this paper, we first prove that the expressivity of pointwise generative ranking with multi-token docIDs is superior to that of dual encoders. We then propose SToICaL - a Simple Token-Item Calibrated Loss - which can incorporate rank-aware supervision at both the item and token levels within the pointwise setup. We run a suite of experiments on ranking tasks derived from WordNet (Fellbaum, 1998) and ESCI (Reddy et al., arXiv:2206.06588). Two variants of SToICaL successfully suppress the probability of invalid docID generations and improve on common ranking metrics beyond top-1 retrieval.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSToICaL\u635f\u5931\u51fd\u6570\uff0c\u7528\u4e8e\u6539\u8fdb\u57fa\u4e8eLLM\u7684\u70b9\u5f0f\u751f\u6210\u6392\u5e8f\u65b9\u6cd5\uff0c\u901a\u8fc7token\u548citem\u7ea7\u522b\u7684\u6821\u51c6\u63d0\u5347\u6392\u5e8f\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u6392\u5e8f\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e0b\u4e00\u4e2atoken\u9884\u6d4b\u635f\u5931\uff0c\u8fd9\u79cd\u635f\u5931\u51fd\u6570\u672c\u8d28\u4e0a\u662f\u4e0e\u6392\u5e8f\u65e0\u5173\u7684\uff08\u7279\u522b\u662f\u5728\u70b9\u5f0f\u76d1\u7763\u4e0b\uff09\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u878d\u5165\u6392\u5e8f\u611f\u77e5\u76d1\u7763\u7684\u635f\u5931\u51fd\u6570\u6765\u63d0\u5347LLM\u5728\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51faSToICaL\uff08Simple Token-Item Calibrated Loss\uff09\u635f\u5931\u51fd\u6570\uff0c\u5728\u70b9\u5f0f\u751f\u6210\u6392\u5e8f\u6846\u67b6\u4e2d\u540c\u65f6\u878d\u5165item\u7ea7\u522b\u548ctoken\u7ea7\u522b\u7684\u6392\u5e8f\u611f\u77e5\u76d1\u7763\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6291\u5236\u65e0\u6548docID\u751f\u6210\u6982\u7387\u5e76\u6539\u8fdb\u5e38\u89c1\u6392\u5e8f\u6307\u6807\u6765\u4f18\u5316LLM\u6392\u5e8f\u6027\u80fd\u3002", "result": "\u5728WordNet\u548cESCI\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSToICaL\u7684\u4e24\u4e2a\u53d8\u4f53\u6210\u529f\u6291\u5236\u4e86\u65e0\u6548docID\u7684\u751f\u6210\u6982\u7387\uff0c\u5e76\u5728top-1\u68c0\u7d22\u4e4b\u5916\u7684\u5e38\u89c1\u6392\u5e8f\u6307\u6807\u4e0a\u53d6\u5f97\u4e86\u6539\u8fdb\u3002", "conclusion": "SToICaL\u635f\u5931\u51fd\u6570\u80fd\u591f\u6709\u6548\u63d0\u5347\u57fa\u4e8eLLM\u7684\u70b9\u5f0f\u751f\u6210\u6392\u5e8f\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u901a\u8fc7token\u548citem\u7ea7\u522b\u7684\u6821\u51c6\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6392\u5e8f\u6548\u679c\uff0c\u4e3aLLM\u5728\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u4f18\u5316\u65b9\u5411\u3002"}}
{"id": "2601.05603", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05603", "abs": "https://arxiv.org/abs/2601.05603", "authors": ["Watheq Mansour", "J. Shane Culpepper", "Joel Mackenzie", "Andrew Yates"], "title": "Revisiting Human-vs-LLM judgments using the TREC Podcast Track", "comment": "The paper has been accepted to appear at ECIR 2026", "summary": "Using large language models (LLMs) to annotate relevance is an increasingly important technique in the information retrieval community. While some studies demonstrate that LLMs can achieve high user agreement with ground truth (human) judgments, other studies have argued for the opposite conclusion. To the best of our knowledge, these studies have primarily focused on classic ad-hoc text search scenarios. In this paper, we conduct an analysis on user agreement between LLM and human experts, and explore the impact disagreement has on system rankings. In contrast to prior studies, we focus on a collection composed of audio files that are transcribed into two-minute segments -- the TREC 2020 and 2021 podcast track. We employ five different LLM models to re-assess all of the query-segment pairs, which were originally annotated by TREC assessors. Furthermore, we re-assess a small subset of pairs where LLM and TREC assessors have the highest disagreement, and found that the human experts tend to agree with LLMs more than with the TREC assessors. Our results reinforce the previous insights of Sormunen in 2002 -- that relying on a single assessor leads to lower user agreement.", "AI": {"tldr": "LLM\u6807\u6ce8\u76f8\u5173\u6027\u5728\u64ad\u5ba2\u68c0\u7d22\u573a\u666f\u4e0b\u7684\u7528\u6237\u4e00\u81f4\u6027\u5206\u6790\uff0c\u53d1\u73b0\u591a\u8bc4\u4f30\u8005\u6bd4\u5355\u4e00\u8bc4\u4f30\u8005\u66f4\u53ef\u9760", "motivation": "\u73b0\u6709\u7814\u7a76\u5bf9LLM\u6807\u6ce8\u76f8\u5173\u6027\u7684\u7528\u6237\u4e00\u81f4\u6027\u5b58\u5728\u4e89\u8bae\uff0c\u4e14\u4e3b\u8981\u5173\u6ce8\u4f20\u7edf\u6587\u672c\u68c0\u7d22\u573a\u666f\uff0c\u9700\u8981\u63a2\u7d22\u5728\u64ad\u5ba2\u97f3\u9891\u8f6c\u5f55\u573a\u666f\u4e0b\u7684\u8868\u73b0", "method": "\u4f7f\u7528TREC 2020-2021\u64ad\u5ba2\u8d5b\u9053\u6570\u636e\u96c6\uff0c\u5c06\u97f3\u9891\u8f6c\u5f55\u4e3a2\u5206\u949f\u7247\u6bb5\uff0c\u75285\u4e2a\u4e0d\u540cLLM\u6a21\u578b\u91cd\u65b0\u8bc4\u4f30\u6240\u6709\u67e5\u8be2-\u7247\u6bb5\u5bf9\uff0c\u5e76\u5bf9LLM\u4e0eTREC\u8bc4\u4f30\u8005\u5206\u6b67\u6700\u5927\u7684\u5b50\u96c6\u8fdb\u884c\u91cd\u65b0\u8bc4\u4f30", "result": "\u4eba\u7c7b\u4e13\u5bb6\u66f4\u503e\u5411\u4e8e\u540c\u610fLLM\u7684\u6807\u6ce8\u800c\u975eTREC\u8bc4\u4f30\u8005\uff0c\u9a8c\u8bc1\u4e86Sormunen\uff082002\uff09\u7684\u53d1\u73b0\uff1a\u4f9d\u8d56\u5355\u4e00\u8bc4\u4f30\u8005\u4f1a\u5bfc\u81f4\u8f83\u4f4e\u7684\u7528\u6237\u4e00\u81f4\u6027", "conclusion": "\u5728\u64ad\u5ba2\u68c0\u7d22\u573a\u666f\u4e0b\uff0cLLM\u6807\u6ce8\u5177\u6709\u8f83\u9ad8\u53ef\u9760\u6027\uff0c\u591a\u8bc4\u4f30\u8005\u673a\u5236\u6bd4\u5355\u4e00\u8bc4\u4f30\u8005\u66f4\u53ef\u9760\uff0c\u4e3aLLM\u5728\u97f3\u9891\u5185\u5bb9\u68c0\u7d22\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u652f\u6301"}}
{"id": "2601.05649", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05649", "abs": "https://arxiv.org/abs/2601.05649", "authors": ["Giulio D'Erasmo", "Cesare Campagnano", "Antonio Mallia", "Pierpaolo Brutti", "Nicola Tonellotto", "Fabrizio Silvestri"], "title": "Statistical Foundations of DIME: Risk Estimation for Practical Index Selection", "comment": "Accepted to EACL 2026 (Main Conference)", "summary": "High-dimensional dense embeddings have become central to modern Information Retrieval, but many dimensions are noisy or redundant. Recently proposed DIME (Dimension IMportance Estimation), provides query-dependent scores to identify informative components of embeddings. DIME relies on a costly grid search to select a priori a dimensionality for all the query corpus's embeddings. Our work provides a statistically grounded criterion that directly identifies the optimal set of dimensions for each query at inference time. Experiments confirm achieving parity of effectiveness and reduces embedding size by an average of $\\sim50\\%$ across different models and datasets at inference time.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7edf\u8ba1\u51c6\u5219\uff0c\u5728\u63a8\u7406\u65f6\u76f4\u63a5\u4e3a\u6bcf\u4e2a\u67e5\u8be2\u8bc6\u522b\u6700\u4f18\u7ef4\u5ea6\u96c6\u5408\uff0c\u65e0\u9700\u9884\u9009\u7ef4\u5ea6\uff0c\u5e73\u5747\u51cf\u5c11\u7ea650%\u5d4c\u5165\u5927\u5c0f", "motivation": "\u9ad8\u7ef4\u5bc6\u96c6\u5d4c\u5165\u5b58\u5728\u566a\u58f0\u548c\u5197\u4f59\u7ef4\u5ea6\uff0c\u73b0\u6709DIME\u65b9\u6cd5\u9700\u8981\u6602\u8d35\u7684\u7f51\u683c\u641c\u7d22\u9884\u9009\u7ef4\u5ea6\uff0c\u4e14\u5bf9\u6240\u6709\u67e5\u8be2\u4f7f\u7528\u76f8\u540c\u7ef4\u5ea6", "method": "\u63d0\u51fa\u7edf\u8ba1\u51c6\u5219\uff0c\u5728\u63a8\u7406\u65f6\u76f4\u63a5\u4e3a\u6bcf\u4e2a\u67e5\u8be2\u8bc6\u522b\u6700\u4f18\u7ef4\u5ea6\u96c6\u5408\uff0c\u65e0\u9700\u9884\u9009\u7ef4\u5ea6", "result": "\u5728\u4e0d\u540c\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\uff0c\u4fdd\u6301\u68c0\u7d22\u6548\u679c\u7684\u540c\u65f6\uff0c\u5e73\u5747\u51cf\u5c11\u7ea650%\u5d4c\u5165\u5927\u5c0f", "conclusion": "\u63d0\u51fa\u7684\u7edf\u8ba1\u51c6\u5219\u80fd\u6709\u6548\u8bc6\u522b\u6bcf\u4e2a\u67e5\u8be2\u7684\u6700\u4f18\u7ef4\u5ea6\uff0c\u663e\u8457\u51cf\u5c11\u5d4c\u5165\u5927\u5c0f\u800c\u4e0d\u635f\u5931\u68c0\u7d22\u6548\u679c"}}
