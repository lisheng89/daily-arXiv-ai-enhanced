{"id": "2510.16334", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.16334", "abs": "https://arxiv.org/abs/2510.16334", "authors": ["Eden Shaveet", "Crystal Su", "Daniel Hsu", "Luis Gravano"], "title": "Investigating the Association Between Text-Based Indications of Foodborne Illness from Yelp Reviews and New York City Health Inspection Outcomes (2023)", "comment": "Presented as a poster at Data Science Day 2024", "summary": "Foodborne illnesses are gastrointestinal conditions caused by consuming\ncontaminated food. Restaurants are critical venues to investigate outbreaks\nbecause they share sourcing, preparation, and distribution of foods. Public\nreporting of illness via formal channels is limited, whereas social media\nplatforms host abundant user-generated content that can provide timely public\nhealth signals. This paper analyzes signals from Yelp reviews produced by a\nHierarchical Sigmoid Attention Network (HSAN) classifier and compares them with\nofficial restaurant inspection outcomes issued by the New York City Department\nof Health and Mental Hygiene (NYC DOHMH) in 2023. We evaluate correlations at\nthe Census tract level, compare distributions of HSAN scores by prevalence of\nC-graded restaurants, and map spatial patterns across NYC. We find minimal\ncorrelation between HSAN signals and inspection scores at the tract level and\nno significant differences by number of C-graded restaurants. We discuss\nimplications and outline next steps toward address-level analyses."}
{"id": "2510.16393", "categories": ["cs.IR", "cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.16393", "abs": "https://arxiv.org/abs/2510.16393", "authors": ["Franco Maria Nardini", "Raffaele Perego", "Nicola Tonellotto", "Salvatore Trani"], "title": "Blending Learning to Rank and Dense Representations for Efficient and Effective Cascades", "comment": null, "summary": "We investigate the exploitation of both lexical and neural relevance signals\nfor ad-hoc passage retrieval. Our exploration involves a large-scale training\ndataset in which dense neural representations of MS-MARCO queries and passages\nare complemented and integrated with 253 hand-crafted lexical features\nextracted from the same corpus. Blending of the relevance signals from the two\ndifferent groups of features is learned by a classical Learning-to-Rank (LTR)\nmodel based on a forest of decision trees. To evaluate our solution, we employ\na pipelined architecture where a dense neural retriever serves as the first\nstage and performs a nearest-neighbor search over the neural representations of\nthe documents. Our LTR model acts instead as the second stage that re-ranks the\nset of candidates retrieved by the first stage to enhance effectiveness. The\nresults of reproducible experiments conducted with state-of-the-art dense\nretrievers on publicly available resources show that the proposed solution\nsignificantly enhances the end-to-end ranking performance while relatively\nminimally impacting efficiency. Specifically, we achieve a boost in nDCG@10 of\nup to 11% with an increase in average query latency of only 4.3%. This confirms\nthe advantage of seamlessly combining two distinct families of signals that\nmutually contribute to retrieval effectiveness."}
{"id": "2510.16597", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.16597", "abs": "https://arxiv.org/abs/2510.16597", "authors": ["Qiyao Peng", "Chen Wang", "Yinghui Wang", "Hongtao Liu", "Xuan Guo", "Wenjun Wang"], "title": "FRONTIER-RevRec: A Large-scale Dataset for Reviewer Recommendation", "comment": null, "summary": "Reviewer recommendation is a critical task for enhancing the efficiency of\nacademic publishing workflows. However, research in this area has been\npersistently hindered by the lack of high-quality benchmark datasets, which are\noften limited in scale, disciplinary scope, and comparative analyses of\ndifferent methodologies. To address this gap, we introduce FRONTIER-RevRec, a\nlarge-scale dataset constructed from authentic peer review records (2007-2025)\nfrom the Frontiers open-access publishing platform\nhttps://www.frontiersin.org/. The dataset contains 177941 distinct reviewers\nand 478379 papers across 209 journals spanning multiple disciplines including\nclinical medicine, biology, psychology, engineering, and social sciences. Our\ncomprehensive evaluation on this dataset reveals that content-based methods\nsignificantly outperform collaborative filtering. This finding is explained by\nour structural analysis, which uncovers fundamental differences between\nacademic recommendation and commercial domains. Notably, approaches leveraging\nlanguage models are particularly effective at capturing the semantic alignment\nbetween a paper's content and a reviewer's expertise. Furthermore, our\nexperiments identify optimal aggregation strategies to enhance the\nrecommendation pipeline. FRONTIER-RevRec is intended to serve as a\ncomprehensive benchmark to advance research in reviewer recommendation and\nfacilitate the development of more effective academic peer review systems. The\nFRONTIER-RevRec dataset is available at:\nhttps://anonymous.4open.science/r/FRONTIER-RevRec-5D05."}
{"id": "2510.16715", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.16715", "abs": "https://arxiv.org/abs/2510.16715", "authors": ["Zulun Zhu", "Haoyu Liu", "Mengke He", "Siqiang Luo"], "title": "Right Answer at the Right Time - Temporal Retrieval-Augmented Generation via Graph Summarization", "comment": null, "summary": "Question answering in temporal knowledge graphs requires retrieval that is\nboth time-consistent and efficient. Existing RAG methods are largely semantic\nand typically neglect explicit temporal constraints, which leads to\ntime-inconsistent answers and inflated token usage. We propose STAR-RAG, a\ntemporal GraphRAG framework that relies on two key ideas: building a\ntime-aligned rule graph and conducting propagation on this graph to narrow the\nsearch space and prioritize semantically relevant, time-consistent evidence.\nThis design enforces temporal proximity during retrieval, reduces the candidate\nset of retrieval results, and lowers token consumption without sacrificing\naccuracy. Compared with existing temporal RAG approaches, STAR-RAG eliminates\nthe need for heavy model training and fine-tuning, thereby reducing\ncomputational cost and significantly simplifying deployment.Extensive\nexperiments on real-world temporal KG datasets show that our method achieves\nimproved answer accuracy while consuming fewer tokens than strong GraphRAG\nbaselines."}
{"id": "2510.16736", "categories": ["cs.IR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.16736", "abs": "https://arxiv.org/abs/2510.16736", "authors": ["Patrizio Dazzi", "William Guglielmo", "Franco Maria Nardini", "Raffaele Perego", "Salvatore Trani"], "title": "Exact Nearest-Neighbor Search on Energy-Efficient FPGA Devices", "comment": null, "summary": "This paper investigates the usage of FPGA devices for energy-efficient exact\nkNN search in high-dimension latent spaces. This work intercepts a relevant\ntrend that tries to support the increasing popularity of learned\nrepresentations based on neural encoder models by making their large-scale\nadoption greener and more inclusive. The paper proposes two different\nenergy-efficient solutions adopting the same FPGA low-level configuration. The\nfirst solution maximizes system throughput by processing the queries of a batch\nin parallel over a streamed dataset not fitting into the FPGA memory. The\nsecond minimizes latency by processing each kNN incoming query in parallel over\nan in-memory dataset. Reproducible experiments on publicly available image and\ntext datasets show that our solution outperforms state-of-the-art CPU-based\ncompetitors regarding throughput, latency, and energy consumption.\nSpecifically, experiments show that the proposed FPGA solutions achieve the\nbest throughput in terms of queries per second and the best-observed latency\nwith scale-up factors of up to 16.6X. Similar considerations can be made\nregarding energy efficiency, where results show that our solutions can achieve\nup to 11.9X energy saving w.r.t. strong CPU-based competitors."}
{"id": "2510.16803", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.16803", "abs": "https://arxiv.org/abs/2510.16803", "authors": ["Zishuai Zhang", "Sihao Yu", "Wenyi Xie", "Ying Nie", "Junfeng Wang", "Zhiming Zheng", "Dawei Yin", "Hainan Zhang"], "title": "An Efficient Framework for Whole-Page Reranking via Single-Modal Supervision", "comment": null, "summary": "The whole-page reranking plays a critical role in shaping the user experience\nof search engines, which integrates retrieval results from multiple modalities,\nsuch as documents, images, videos, and LLM outputs. Existing methods mainly\nrely on large-scale human-annotated data, which is costly to obtain and\ntime-consuming. This is because whole-page annotation is far more complex than\nsingle-modal: it requires assessing the entire result page while accounting for\ncross-modal relevance differences. Thus, how to improve whole-page reranking\nperformance while reducing annotation costs is still a key challenge in\noptimizing search engine result pages(SERP). In this paper, we propose SMAR, a\nnovel whole-page reranking framework that leverages strong Single-modal rankers\nto guide Modal-wise relevance Alignment for effective Reranking, using only\nlimited whole-page annotation to outperform fully-annotated reranking models.\nSpecifically, high-quality single-modal rankers are first trained on data\nspecific to their respective modalities. Then, for each query, we select a\nsubset of their outputs to construct candidate pages and perform human\nannotation at the page level. Finally, we train the whole-page reranker using\nthese limited annotations and enforcing consistency with single-modal\npreferences to maintain ranking quality within each modality. Experiments on\nthe Qilin and Baidu datasets demonstrate that SMAR reduces annotation costs by\nabout 70-90\\% while achieving significant ranking improvements compared to\nbaselines. Further offline and online A/B testing on Baidu APPs also shows\nnotable gains in standard ranking metrics as well as user experience\nindicators, fully validating the effectiveness and practical value of our\napproach in real-world search scenarios."}
{"id": "2510.16804", "categories": ["cs.IR", "H.3.3"], "pdf": "https://arxiv.org/pdf/2510.16804", "abs": "https://arxiv.org/abs/2510.16804", "authors": ["Xiaokai Wei", "Jiajun Wu", "Daiyao Yi", "Reza Shirkavand", "Michelle Gong"], "title": "The Layout Is the Model: On Action-Item Coupling in Generative Recommendation", "comment": null, "summary": "Generative Recommendation (GR) models treat a user's interaction history as a\nsequence to be autoregressively predicted. When both items and actions (e.g.,\nwatch time, purchase, comment) are modeled, the layout-the ordering and\nvisibility of item/action tokens-critically determines what information the\nmodel can use and how it generalizes. We present a unified study of token\nlayouts for GR grounded in first principles: (P1) maximize item/action signal\nin both input/output space, (P2) preserve the conditioning relationship \"action\ngiven item\" and (P3) no information leakage.\n  While interleaved layout (where item and action occupy separate tokens)\nnaturally satisfies these principles, it also bloats sequence length with\nlarger training/inference cost. On the non-interleaved front, we design a novel\nand effective approach, Lagged Action Conditioning (LAC), which appears strange\non the surface but aligns well with the design principles to yield strong\naccuracy. Comprehensive experiments on public datasets and large-scale\nproduction logs evaluate different layout options and empirically verifies the\ndesign principles. Our proposed non-interleaved method, LAC, achieves\ncompetitive or superior quality at substantially lower FLOPs than interleaving.\nOur findings offer actionable guidance for assembling GR systems that are both\naccurate and efficient."}
{"id": "2510.16925", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.16925", "abs": "https://arxiv.org/abs/2510.16925", "authors": ["Zhiding Liu", "Ben Chen", "Mingyue Cheng", "Enchong Chen", "Li Li", "Chenyi Lei", "Wenwu Ou", "Han Li", "Kun Gai"], "title": "Towards Context-aware Reasoning-enhanced Generative Searching in E-commerce", "comment": null, "summary": "Search-based recommendation is one of the most critical application scenarios\nin e-commerce platforms. Users' complex search contexts--such as spatiotemporal\nfactors, historical interactions, and current query's information--constitute\nan essential part of their decision-making, reflecting implicit preferences\nthat complement explicit query terms. Modeling such rich contextual signals and\ntheir intricate associations with candidate items remains a key challenge.\nAlthough numerous efforts have been devoted to building more effective search\nmethods, existing approaches still show limitations in integrating contextual\ninformation, which hinders their ability to fully capture user intent.\n  To address these challenges, we propose a context-aware reasoning-enhanced\ngenerative search framework for better \\textbf{understanding the complicated\ncontext}. Specifically, the framework first unifies heterogeneous user and item\ncontexts into textual representations or text-based semantic identifiers and\naligns them. To overcome the lack of explicit reasoning trajectories, we\nintroduce a self-evolving post-training paradigm that iteratively combines\nsupervised fine-tuning and reinforcement learning to progressively enhance the\nmodel's reasoning capability. In addition, we identify potential biases in\nexisting RL algorithms when applied to search scenarios and present a debiased\nvariant of GRPO to improve ranking performance. Extensive experiments on search\nlog data collected from a real-world e-commerce platform demonstrate that our\napproach achieves superior performance compared with strong baselines,\nvalidating its effectiveness for search-based recommendation."}
{"id": "2510.17228", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.17228", "abs": "https://arxiv.org/abs/2510.17228", "authors": ["Qing Shi", "Jing He", "Qiaosheng Chen", "Gong Cheng"], "title": "DSEBench: A Test Collection for Explainable Dataset Search with Examples", "comment": "34 pages, 5 figures, submitted to Knowledge-Based Systems", "summary": "Dataset search has been an established information retrieval task. Current\nparadigms either retrieve datasets that are relevant to a keyword query or find\ndatasets that are similar to an input target dataset. To allow for their\ncombined specification of information needs, in this article, we investigate\nthe more generalized task of Dataset Search with Examples (DSE) and further\nextend it to Explainable DSE that requires identifying the metadata and content\nfields of a dataset that indicate its relevance to the query and similarity to\nthe target datasets. To facilitate this research, we construct DSEBench, a test\ncollection that provides high-quality dataset- and field-level annotations to\nenable the evaluation of explainable DSE. We also employ a large language model\nto generate numerous annotations to be used for training. We establish\nextensive baselines on DSEBench by adapting and evaluating a variety of sparse,\ndense, and LLM-based retrieval, reranking, and explanation methods."}
{"id": "2510.17245", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.17245", "abs": "https://arxiv.org/abs/2510.17245", "authors": ["Wenyu Mao", "Jiancan Wu", "Guoqing Hu", "Wei Ji", "Xiang Wang"], "title": "On Efficiency-Effectiveness Trade-off of Diffusion-based Recommenders", "comment": null, "summary": "Diffusion models have emerged as a powerful paradigm for generative\nsequential recommendation, which typically generate next items to recommend\nguided by user interaction histories with a multi-step denoising process.\nHowever, the multi-step process relies on discrete approximations, introducing\ndiscretization error that creates a trade-off between computational efficiency\nand recommendation effectiveness. To address this trade-off, we propose TA-Rec,\na two-stage framework that achieves one-step generation by smoothing the\ndenoising function during pretraining while alleviating trajectory deviation by\naligning with user preferences during fine-tuning. Specifically, to improve the\nefficiency without sacrificing the recommendation performance, TA-Rec pretrains\nthe denoising model with Temporal Consistency Regularization (TCR), enforcing\nthe consistency between the denoising results across adjacent steps. Thus, we\ncan smooth the denoising function to map the noise as oracle items in one step\nwith bounded error. To further enhance effectiveness, TA-Rec introduces\nAdaptive Preference Alignment (APA) that aligns the denoising process with user\npreference adaptively based on preference pair similarity and timesteps.\nExtensive experiments prove that TA-Rec's two-stage objective effectively\nmitigates the discretization errors-induced trade-off, enhancing both\nefficiency and effectiveness of diffusion-based recommenders."}
{"id": "2510.17535", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.17535", "abs": "https://arxiv.org/abs/2510.17535", "authors": ["Yumeng Wang", "Jirui Qi", "Catherine Chen", "Panagiotis Eustratiadis", "Suzan Verberne"], "title": "How role-play shapes relevance judgment in zero-shot LLM rankers", "comment": null, "summary": "Large Language Models (LLMs) have emerged as promising zero-shot rankers, but\ntheir performance is highly sensitive to prompt formulation. In particular,\nrole-play prompts, where the model is assigned a functional role or identity,\noften give more robust and accurate relevance rankings. However, the mechanisms\nand diversity of role-play effects remain underexplored, limiting both\neffective use and interpretability. In this work, we systematically examine how\nrole-play variations influence zero-shot LLM rankers. We employ causal\nintervention techniques from mechanistic interpretability to trace how\nrole-play information shapes relevance judgments in LLMs. Our analysis reveals\nthat (1) careful formulation of role descriptions have a large effect on the\nranking quality of the LLM; (2) role-play signals are predominantly encoded in\nearly layers and communicate with task instructions in middle layers, while\nreceiving limited interaction with query or document representations.\nSpecifically, we identify a group of attention heads that encode information\ncritical for role-conditioned relevance. These findings not only shed light on\nthe inner workings of role-play in LLM ranking but also offer guidance for\ndesigning more effective prompts in IR and beyond, pointing toward broader\nopportunities for leveraging role-play in zero-shot applications."}
