<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 9]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Gaussian Mixture Flow Matching with Domain Alignment for Multi-Domain Sequential Recommendation](https://arxiv.org/abs/2510.21021)
*Xiaoxin Ye,Chengkai Huang,Hongtao Huang,Lina Yao*

Main category: cs.IR

TL;DR: GMFlowRec是一个用于多域序列推荐的高效生成框架，通过高斯混合流匹配建模域感知转换轨迹，在JD和Amazon数据集上实现了最先进的性能，NDCG@5提升高达44%。


<details>
  <summary>Details</summary>
Motivation: 用户在多域中的交互行为具有频繁复杂的转换，现有方法忽略了域转换的复杂性，容易在密集域上过拟合而在稀疏域上欠拟合，且难以扩展到更多域。

Method: 使用统一的双掩码Transformer解耦域不变和域特定意图，高斯混合流场捕捉多样化行为模式，域对齐先验支持频繁和稀疏转换。

Result: 在JD和Amazon数据集上的实验表明，GMFlowRec在NDCG@5指标上实现了高达44%的提升，同时通过单一统一骨干网络保持高效率。

Conclusion: GMFlowRec是一个可扩展的实时多域序列推荐框架，能够有效处理域异质性和不平衡问题，在性能和效率方面都表现出色。

Abstract: Users increasingly interact with content across multiple domains, resulting
in sequential behaviors marked by frequent and complex transitions. While
Cross-Domain Sequential Recommendation (CDSR) models two-domain interactions,
Multi-Domain Sequential Recommendation (MDSR) introduces significantly more
domain transitions, compounded by challenges such as domain heterogeneity and
imbalance. Existing approaches often overlook the intricacies of domain
transitions, tend to overfit to dense domains while underfitting sparse ones,
and struggle to scale effectively as the number of domains increases. We
propose \textit{GMFlowRec}, an efficient generative framework for MDSR that
models domain-aware transition trajectories via Gaussian Mixture Flow Matching.
GMFlowRec integrates: (1) a unified dual-masked Transformer to disentangle
domain-invariant and domain-specific intents, (2) a Gaussian Mixture flow field
to capture diverse behavioral patterns, and (3) a domain-aligned prior to
support frequent and sparse transitions. Extensive experiments on JD and Amazon
datasets demonstrate that GMFlowRec achieves state-of-the-art performance with
up to 44\% improvement in NDCG@5, while maintaining high efficiency via a
single unified backbone, making it scalable for real-world multi-domain
sequential recommendation.

</details>


### [2] [Communication Platform for Non-verbal Autistic children in Oman using Android mobile](https://arxiv.org/abs/2510.21028)
*Amna Al-Araimi,Yue Zheng,Haiming Liu*

Main category: cs.IR

TL;DR: 开发一个包含网页面板和Android移动应用的平台，帮助阿曼的非语言自闭症儿童改善沟通能力，通过增强现实框架提供互动活动。


<details>
  <summary>Details</summary>
Motivation: 解决非语言自闭症谱系障碍患者在全球范围内的沟通困难问题，特别是在阿曼地区，现有碎片化方法不适合自闭症儿童的需求。

Method: 整合多种干预措施，开发包含网页面板和Android移动应用的平台，采用增强现实框架进行互动屏幕活动，促进创造性游戏和自我反思。

Result: 提出了一个综合平台方案，能够帮助非语言自闭症儿童改善社交化和沟通能力，提高生活质量。

Conclusion: 综合性的技术平台比碎片化方法更适合自闭症儿童，增强现实框架能有效促进他们的沟通和社交发展。

Abstract: This paper discusses the issue regarding Non-verbal Autism Spectrum Disorder.
It has been observed that this mental disorder is listed in major parts of the
world including the US, UK, and India. To mitigate this type of disorder, a
wide range of smartphones, computers, and artificial intelligence technologies
have been used. This technology has helped the population cope with
socialization and communication needs. Many applications have been developed to
enhance the communication capabilities of non-verbal autistic children. This
thesis project proposes the development of a platform that includes a web panel
and an Android mobile application to assist non-verbal autistic children in
communication, especially in Oman. Different interventions have been merged to
improve the quality of life for people on the autism spectrum. The main problem
identified in this case is that fragmented approaches are not suitable for
autistic children. The augmented reality framework provides the capability to
engage autistic children in creative play and self-reflection through
interactive screen-based activities.

</details>


### [3] [VOGUE: A Multimodal Dataset for Conversational Recommendation in Fashion](https://arxiv.org/abs/2510.21151)
*David Guo,Minqi Sun,Yilun Jiang,Jiazhou Liang,Scott Sanner*

Main category: cs.IR

TL;DR: VOGUE是一个新颖的多模态对话推荐数据集，包含60个真实时尚购物场景的人类对话，配有视觉目录、用户档案和历史记录，以及对话后评分。


<details>
  <summary>Details</summary>
Motivation: 现有多模态对话推荐数据集存在局限性：要么模拟对话，要么忽略用户历史，或者缺乏详细反馈，限制了研究和评估的范围。

Method: 收集60个人类对话，包含共享视觉目录、物品元数据、用户时尚档案和历史，以及对话后评分，支持对话推理的严格评估。

Result: 分析显示视觉对话的独特动态，推荐者经常按特征分组建议物品。多模态大语言模型在整体对齐上接近人类水平，但在重现人类评分分布和泛化偏好推理方面存在系统性错误。

Conclusion: VOGUE既是研究多模态对话系统的独特资源，也是超越当前顶级多模态基础模型推荐能力的挑战数据集。

Abstract: Multimodal conversational recommendation has emerged as a promising paradigm
for delivering personalized experiences through natural dialogue enriched by
visual and contextual grounding. Yet, current multimodal conversational
recommendation datasets remain limited: existing resources either simulate
conversations, omit user history, or fail to collect sufficiently detailed
feedback, all of which constrain the types of research and evaluation they
support.
  To address these gaps, we introduce VOGUE, a novel dataset of 60 humanhuman
dialogues in realistic fashion shopping scenarios. Each dialogue is paired with
a shared visual catalogue, item metadata, user fashion profiles and histories,
and post-conversation ratings from both Seekers and Assistants. This design
enables rigorous evaluation of conversational inference, including not only
alignment between predicted and ground-truth preferences, but also calibration
against full rating distributions and comparison with explicit and implicit
user satisfaction signals.
  Our initial analyses of VOGUE reveal distinctive dynamics of visually
grounded dialogue. For example, recommenders frequently suggest items
simultaneously in feature-based groups, which creates distinct conversational
phases bridged by Seeker critiques and refinements. Benchmarking multimodal
large language models against human recommenders shows that while MLLMs
approach human-level alignment in aggregate, they exhibit systematic
distribution errors in reproducing human ratings and struggle to generalize
preference inference beyond explicitly discussed items. These findings
establish VOGUE as both a unique resource for studying multimodal
conversational systems and as a challenge dataset beyond the current
recommendation capabilities of existing top-tier multimodal foundation models
such as GPT-4o-mini, GPT-5-mini, and Gemini-2.5-Flash.

</details>


### [4] [Bi-Level Optimization for Generative Recommendation: Bridging Tokenization and Generation](https://arxiv.org/abs/2510.21242)
*Yimeng Bai,Chang Liu,Yang Zhang,Dingxian Wang,Frank Yang,Andrew Rabinovich,Wenge Rong,Fuli Feng*

Main category: cs.IR

TL;DR: BLOGER是一个用于生成式推荐的双层优化框架，通过统一优化分词器和推荐器来解决两者分离导致的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 现有的生成式推荐方法通常将分词器和推荐器分开训练，忽视了它们之间的相互依赖关系，导致分词器训练缺乏推荐目标的直接指导，产生次优的标识符，从而降低推荐性能。

Method: 提出BLOGER框架，采用双层优化方法：下层训练推荐器使用分词后的序列，上层基于分词损失和推荐损失优化分词器。使用元学习方法高效求解双层优化，并引入梯度手术来缓解上层更新中的梯度冲突。

Result: 在真实世界数据集上的广泛实验表明，BLOGER持续优于最先进的生成式推荐方法，同时保持实际效率，没有显著增加计算开销。

Conclusion: BLOGER有效弥合了项目分词和自回归生成之间的差距，通过统一优化分词器和推荐器，确保项目标识符既信息丰富又与推荐目标对齐。

Abstract: Generative recommendation is emerging as a transformative paradigm by
directly generating recommended items, rather than relying on matching.
Building such a system typically involves two key components: (1) optimizing
the tokenizer to derive suitable item identifiers, and (2) training the
recommender based on those identifiers. Existing approaches often treat these
components separately--either sequentially or in alternation--overlooking their
interdependence. This separation can lead to misalignment: the tokenizer is
trained without direct guidance from the recommendation objective, potentially
yielding suboptimal identifiers that degrade recommendation performance.
  To address this, we propose BLOGER, a Bi-Level Optimization for GEnerative
Recommendation framework, which explicitly models the interdependence between
the tokenizer and the recommender in a unified optimization process. The lower
level trains the recommender using tokenized sequences, while the upper level
optimizes the tokenizer based on both the tokenization loss and recommendation
loss. We adopt a meta-learning approach to solve this bi-level optimization
efficiently, and introduce gradient surgery to mitigate gradient conflicts in
the upper-level updates, thereby ensuring that item identifiers are both
informative and recommendation-aligned. Extensive experiments on real-world
datasets demonstrate that BLOGER consistently outperforms state-of-the-art
generative recommendation methods while maintaining practical efficiency with
no significant additional computational overhead, effectively bridging the gap
between item tokenization and autoregressive generation.

</details>


### [5] [Pctx: Tokenizing Personalized Context for Generative Recommendation](https://arxiv.org/abs/2510.21276)
*Qiyong Zhong,Jiajie Su,Yunshan Ma,Julian McAuley,Yupeng Hou*

Main category: cs.IR

TL;DR: 提出个性化上下文感知分词器，将用户历史交互融入语义ID生成，使同一物品在不同用户上下文中被分词为不同语义ID，提升生成式推荐的个性化效果。


<details>
  <summary>Details</summary>
Motivation: 现有分词方法静态且非个性化，仅从物品特征派生语义ID，假设统一的物品相似性标准，忽略了用户特定的视角和偏好。

Method: 设计个性化上下文感知分词器，在生成语义ID时融入用户历史交互信息，使同一物品在不同用户上下文中产生不同分词结果。

Result: 在三个公共数据集上实验，相比非个性化动作分词基线，NDCG@10指标提升最高达11.44%。

Conclusion: 个性化上下文感知分词器能够捕捉多种解释标准，使生成式推荐模型产生更个性化的预测，显著提升推荐性能。

Abstract: Generative recommendation (GR) models tokenize each action into a few
discrete tokens (called semantic IDs) and autoregressively generate the next
tokens as predictions, showing advantages such as memory efficiency,
scalability, and the potential to unify retrieval and ranking. Despite these
benefits, existing tokenization methods are static and non-personalized. They
typically derive semantic IDs solely from item features, assuming a universal
item similarity that overlooks user-specific perspectives. However, under the
autoregressive paradigm, semantic IDs with the same prefixes always receive
similar probabilities, so a single fixed mapping implicitly enforces a
universal item similarity standard across all users. In practice, the same item
may be interpreted differently depending on user intentions and preferences. To
address this issue, we propose a personalized context-aware tokenizer that
incorporates a user's historical interactions when generating semantic IDs.
This design allows the same item to be tokenized into different semantic IDs
under different user contexts, enabling GR models to capture multiple
interpretive standards and produce more personalized predictions. Experiments
on three public datasets demonstrate up to 11.44% improvement in NDCG@10 over
non-personalized action tokenization baselines. Our code is available at
https://github.com/YoungZ365/Pctx.

</details>


### [6] [CausalRec: A CausalBoost Attention Model for Sequential Recommendation](https://arxiv.org/abs/2510.21333)
*Yunbo Hou,Tianle Yang,Ruijie Li,Li He,Liang Wang,Weiping Li,Bo Zheng,Guojie Song*

Main category: cs.IR

TL;DR: 提出CausalRec框架，通过因果注意力机制改进序列推荐系统，解决传统方法仅关注项目共现而忽略用户行为动机的问题，在真实数据集上显著提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于相关性的序列推荐系统仅关注项目共现，忽略了用户行为背后的因果动机，导致虚假相关性和不准确的推荐。需要引入因果推理来识别真正影响用户行为的因素。

Method: 提出CausalRec框架，包含因果发现模块和CausalBooster。因果发现模块学习用户行为序列中的因果图，CausalBooster利用发现的因果图改进注意力机制，优先考虑具有因果重要性的行为。

Result: 在真实世界数据集上的实验表明，CausalRec优于多种最先进方法，在命中率(HR)上平均提升7.21%，在归一化折损累计增益(NDCG)上平均提升8.65%。

Conclusion: 这是首个通过注意力机制在序列推荐中融入因果性的模型，证明了因果性在生成更准确可靠推荐中的价值，为推荐系统研究提供了新方向。

Abstract: Recent advances in correlation-based sequential recommendation systems have
demonstrated substantial success. Specifically, the attention-based model
outperforms other RNN-based and Markov chains-based models by capturing both
short- and long-term dependencies more effectively. However, solely focusing on
item co-occurrences overlooks the underlying motivations behind user behaviors,
leading to spurious correlations and potentially inaccurate recommendations. To
address this limitation, we present a novel framework that integrates causal
attention for sequential recommendation, CausalRec. It incorporates a causal
discovery block and a CausalBooster. The causal discovery block learns the
causal graph in user behavior sequences, and we provide a theory to guarantee
the identifiability of the learned causal graph. The CausalBooster utilizes the
discovered causal graph to refine the attention mechanism, prioritizing
behaviors with causal significance. Experimental evaluations on real-world
datasets indicate that CausalRec outperforms several state-of-the-art methods,
with average improvements of 7.21% in Hit Rate (HR) and 8.65% in Normalized
Discounted Cumulative Gain (NDCG). To the best of our knowledge, this is the
first model to incorporate causality through the attention mechanism in
sequential recommendation, demonstrating the value of causality in generating
more accurate and reliable recommendations.

</details>


### [7] [SciNUP: Natural Language User Interest Profiles for Scientific Literature Recommendation](https://arxiv.org/abs/2510.21352)
*Mariam Arustashvili,Krisztian Balog*

Main category: cs.IR

TL;DR: 提出了SciNUP数据集，用于评估基于自然语言用户画像的推荐系统，通过作者发表历史生成自然语言画像和对应真实推荐项，比较了多种基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决基于自然语言用户画像的推荐系统缺乏大规模公开测试数据集的问题，特别是在学术推荐领域。

Method: 创建SciNUP合成数据集，利用作者发表历史生成自然语言画像；比较稀疏检索、稠密检索和基于LLM的重排序等基线方法。

Result: 基线方法性能相当但推荐不同项目，显示互补行为；同时存在较大改进空间，表明需要更有效的基于自然语言的推荐方法。

Conclusion: SciNUP数据集为基于自然语言用户画像的推荐系统研究提供了有价值的资源，推动了该领域的未来发展。

Abstract: The use of natural language (NL) user profiles in recommender systems offers
greater transparency and user control compared to traditional representations.
However, there is scarcity of large-scale, publicly available test collections
for evaluating NL profile-based recommendation. To address this gap, we
introduce SciNUP, a novel synthetic dataset for scholarly recommendation that
leverages authors' publication histories to generate NL profiles and
corresponding ground truth items. We use this dataset to conduct a comparison
of baseline methods, ranging from sparse and dense retrieval approaches to
state-of-the-art LLM-based rerankers. Our results show that while baseline
methods achieve comparable performance, they often retrieve different items,
indicating complementary behaviors. At the same time, considerable headroom for
improvement remains, highlighting the need for effective NL-based
recommendation approaches. The SciNUP dataset thus serves as a valuable
resource for fostering future research and development in this area.

</details>


### [8] [Doc-Researcher: A Unified System for Multimodal Document Parsing and Deep Research](https://arxiv.org/abs/2510.21603)
*Kuicai Dong,Shurui Huang,Fangda Ye,Wei Han,Zhi Zhang,Dexun Li,Wenjun Li,Qu Yang,Gang Wang,Yichao Wang,Chen Zhang,Yong Liu*

Main category: cs.IR

TL;DR: Doc-Researcher是一个统一的多模态深度研究系统，通过多模态解析、系统化检索架构和多代理工作流程，解决了现有系统仅限于文本数据的局限性，在M4DocBench基准上实现了50.6%的准确率，比现有最佳方法提升3.4倍。


<details>
  <summary>Details</summary>
Motivation: 当前深度研究系统仅限于文本网络数据，忽略了多模态文档中嵌入的丰富知识（图表、公式等），需要能够保持视觉语义、结构连贯性和跨模态检索能力的系统。

Method: 系统包含三个组件：1) 深度多模态解析，保持布局结构和视觉语义；2) 支持文本、视觉和混合检索的系统化架构；3) 迭代多代理工作流程，分解复杂查询并综合多文档多模态答案。

Result: 在M4DocBench基准上达到50.6%的准确率，比现有最佳方法提升3.4倍，验证了保持多模态完整性和支持迭代研究的重要性。

Conclusion: 本文建立了一个在多模态文档集合上进行深度研究的新范式，表明有效的文档研究不仅需要更好的检索能力，更需要能够保持多模态完整性的深度解析。

Abstract: Deep Research systems have revolutionized how LLMs solve complex questions
through iterative reasoning and evidence gathering. However, current systems
remain fundamentally constrained to textual web data, overlooking the vast
knowledge embedded in multimodal documents Processing such documents demands
sophisticated parsing to preserve visual semantics (figures, tables, charts,
and equations), intelligent chunking to maintain structural coherence, and
adaptive retrieval across modalities, which are capabilities absent in existing
systems. In response, we present Doc-Researcher, a unified system that bridges
this gap through three integrated components: (i) deep multimodal parsing that
preserves layout structure and visual semantics while creating multi-granular
representations from chunk to document level, (ii) systematic retrieval
architecture supporting text-only, vision-only, and hybrid paradigms with
dynamic granularity selection, and (iii) iterative multi-agent workflows that
decompose complex queries, progressively accumulate evidence, and synthesize
comprehensive answers across documents and modalities. To enable rigorous
evaluation, we introduce M4DocBench, the first benchmark for Multi-modal,
Multi-hop, Multi-document, and Multi-turn deep research. Featuring 158
expert-annotated questions with complete evidence chains across 304 documents,
M4DocBench tests capabilities that existing benchmarks cannot assess.
Experiments demonstrate that Doc-Researcher achieves 50.6% accuracy, 3.4xbetter
than state-of-the-art baselines, validating that effective document research
requires not just better retrieval, but fundamentally deep parsing that
preserve multimodal integrity and support iterative research. Our work
establishes a new paradigm for conducting deep research on multimodal document
collections.

</details>


### [9] [A Data-Centric Approach to Multilingual E-Commerce Product Search: Case Study on Query-Category and Query-Item Relevance](https://arxiv.org/abs/2510.21671)
*Yabo Yin,Yang Xi,Jialong Wang,Shanqi Wang,Jiateng Hu*

Main category: cs.IR

TL;DR: 提出了一个数据中心的框架，通过翻译增强、语义负采样和自验证过滤三种策略改进多语言电商搜索中的查询-类别和查询-商品相关性任务，在CIKM AnalytiCup 2025数据集上显著提升了F1分数。


<details>
  <summary>Details</summary>
Motivation: 解决多语言电商搜索中数据不平衡、标签噪声和低资源语言监督不足的问题，这些挑战阻碍了相关性模型的跨语言泛化能力。

Method: 采用架构无关的数据中心方法：1) 翻译增强为训练中缺失的语言合成示例；2) 语义负采样生成困难负例缓解类别不平衡；3) 自验证过滤检测并移除可能错误标记的实例。

Result: 在CIKM AnalytiCup 2025数据集上，相比强大的LLM基线，该方法持续带来显著的F1分数提升，在官方竞赛中取得了有竞争力的结果。

Conclusion: 系统的数据工程可以与复杂模型修改一样有效，且通常更易于部署，为构建现实世界电商环境中的鲁棒多语言搜索系统提供了可操作的指导。

Abstract: Multilingual e-commerce search suffers from severe data imbalance across
languages, label noise, and limited supervision for low-resource
languages--challenges that impede the cross-lingual generalization of relevance
models despite the strong capabilities of large language models (LLMs). In this
work, we present a practical, architecture-agnostic, data-centric framework to
enhance performance on two core tasks: Query-Category (QC) relevance (matching
queries to product categories) and Query-Item (QI) relevance (matching queries
to product titles). Rather than altering the model, we redesign the training
data through three complementary strategies: (1) translation-based augmentation
to synthesize examples for languages absent in training, (2) semantic negative
sampling to generate hard negatives and mitigate class imbalance, and (3)
self-validation filtering to detect and remove likely mislabeled instances.
Evaluated on the CIKM AnalytiCup 2025 dataset, our approach consistently yields
substantial F1 score improvements over strong LLM baselines, achieving
competitive results in the official competition. Our findings demonstrate that
systematic data engineering can be as impactful as--and often more deployable
than--complex model modifications, offering actionable guidance for building
robust multilingual search systems in the real-world e-commerce settings.

</details>
