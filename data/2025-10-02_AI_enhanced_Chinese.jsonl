{"id": "2510.00125", "categories": ["cs.CL", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.00125", "abs": "https://arxiv.org/abs/2510.00125", "authors": ["Hong kyu Lee", "Ruixuan Liu", "Li Xiong"], "title": "Direct Token Optimization: A Self-contained Approach to Large Language Model Unlearning", "comment": null, "summary": "Machine unlearning is an emerging technique that removes the influence of a\nsubset of training data (forget set) from a model without full retraining, with\napplications including privacy protection, content moderation, and model\ncorrection. The key challenge lies in ensuring that the model completely\nforgets the knowledge of the forget set without compromising its overall\nutility. Existing unlearning methods for large language models (LLMs) often\nutilize auxiliary language models, retain datasets, or even commercial AI\nservices for effective unlearning and maintaining the model utility. However,\ndependence on these external resources is often impractical and could\npotentially introduce additional privacy risks. In this work, we propose direct\ntoken optimization (DTO), a novel self-contained unlearning approach for LLMs\nthat directly optimizes the token level objectives and eliminates the need for\nexternal resources. Given a sequence to unlearn, we identify two categories of\ntokens: target tokens, which capture critical knowledge for unlearning, and the\nremaining non-target tokens, which are crucial for maintaining the model\nutility. The former are used to optimize the unlearning objective, while the\nlatter serve to preserve the model's performance. The experimental results show\nthat the proposed DTO achieves up to 16.8$\\times$ improvement in forget quality\non several benchmark datasets than the latest baselines while maintaining a\ncomparable level of model utility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u76f4\u63a5\u4ee4\u724c\u4f18\u5316\uff08DTO\uff09\u7684\u65b0\u578b\u81ea\u5305\u542b\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u65b9\u6cd5\uff0c\u65e0\u9700\u5916\u90e8\u8d44\u6e90\u5373\u53ef\u6709\u6548\u79fb\u9664\u8bad\u7ec3\u6570\u636e\u5b50\u96c6\u7684\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u9057\u5fd8\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u8f85\u52a9\u8bed\u8a00\u6a21\u578b\u3001\u4fdd\u7559\u6570\u636e\u96c6\u6216\u5546\u4e1aAI\u670d\u52a1\uff0c\u8fd9\u65e2\u4e0d\u5b9e\u7528\u53c8\u53ef\u80fd\u5f15\u5165\u989d\u5916\u7684\u9690\u79c1\u98ce\u9669\u3002", "method": "\u901a\u8fc7\u8bc6\u522b\u5e8f\u5217\u4e2d\u7684\u76ee\u6807\u4ee4\u724c\uff08\u7528\u4e8e\u4f18\u5316\u9057\u5fd8\u76ee\u6807\uff09\u548c\u975e\u76ee\u6807\u4ee4\u724c\uff08\u7528\u4e8e\u4fdd\u6301\u6a21\u578b\u6548\u7528\uff09\uff0c\u76f4\u63a5\u5728\u4ee4\u724c\u7ea7\u522b\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cDTO\u5728\u9057\u5fd8\u8d28\u91cf\u65b9\u9762\u6bd4\u6700\u65b0\u57fa\u7ebf\u65b9\u6cd5\u63d0\u9ad8\u4e8616.8\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u76f8\u5f53\u7684\u6a21\u578b\u6548\u7528\u6c34\u5e73\u3002", "conclusion": "DTO\u662f\u4e00\u79cd\u6709\u6548\u7684\u81ea\u5305\u542b\u9057\u5fd8\u65b9\u6cd5\uff0c\u65e0\u9700\u5916\u90e8\u8d44\u6e90\u5373\u53ef\u5b9e\u73b0\u9ad8\u8d28\u91cf\u7684\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u3002"}}
{"id": "2510.00161", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00161", "abs": "https://arxiv.org/abs/2510.00161", "authors": ["Kimihiro Hasegawa", "Wiradee Imrattanatrai", "Masaki Asada", "Ken Fukuda", "Teruko Mitamura"], "title": "TAMA: Tool-Augmented Multimodal Agent for Procedural Activity Understanding", "comment": "21 pages. Code: https://github.com/kimihiroh/tama", "summary": "Procedural activity assistants potentially support humans in a variety of\nsettings, from our daily lives, e.g., cooking or assembling flat-pack\nfurniture, to professional situations, e.g., manufacturing or biological\nexperiments. Despite its potential use cases, the system development tailored\nfor such an assistant is still underexplored. In this paper, we propose a novel\nframework, called TAMA, a Tool-Augmented Multimodal Agent, for procedural\nactivity understanding. TAMA enables interleaved multimodal reasoning by making\nuse of multimedia-returning tools in a training-free setting. Our experimental\nresult on the multimodal procedural QA dataset, ProMQA-Assembly, shows that our\napproach can improve the performance of vision-language models, especially\nGPT-5 and MiMo-VL. Furthermore, our ablation studies provide empirical support\nfor the effectiveness of two features that characterize our framework,\nmultimedia-returning tools and agentic flexible tool selection. We believe our\nproposed framework and experimental results facilitate the thinking with images\nparadigm for video and multimodal tasks, let alone the development of\nprocedural activity assistants.", "AI": {"tldr": "\u63d0\u51fa\u4e86TAMA\u6846\u67b6\uff0c\u4e00\u79cd\u5de5\u5177\u589e\u5f3a\u7684\u591a\u6a21\u6001\u4ee3\u7406\uff0c\u7528\u4e8e\u7a0b\u5e8f\u6027\u6d3b\u52a8\u7406\u89e3\uff0c\u901a\u8fc7\u591a\u5a92\u4f53\u8fd4\u56de\u5de5\u5177\u5b9e\u73b0\u8bad\u7ec3\u514d\u8d39\u7684\u591a\u6a21\u6001\u63a8\u7406\u3002", "motivation": "\u7a0b\u5e8f\u6027\u6d3b\u52a8\u52a9\u624b\u5728\u65e5\u5e38\u751f\u6d3b\u548c\u4e13\u4e1a\u573a\u666f\u4e2d\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\uff0c\u4f46\u9488\u5bf9\u6b64\u7c7b\u52a9\u624b\u7684\u7cfb\u7edf\u5f00\u53d1\u4ecd\u5904\u4e8e\u63a2\u7d22\u4e0d\u8db3\u7684\u72b6\u6001\u3002", "method": "TAMA\u6846\u67b6\u5229\u7528\u591a\u5a92\u4f53\u8fd4\u56de\u5de5\u5177\u5728\u8bad\u7ec3\u514d\u8d39\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u4ea4\u9519\u591a\u6a21\u6001\u63a8\u7406\uff0c\u5177\u6709\u591a\u5a92\u4f53\u8fd4\u56de\u5de5\u5177\u548c\u7075\u6d3b\u5de5\u5177\u9009\u62e9\u4e24\u4e2a\u5173\u952e\u7279\u5f81\u3002", "result": "\u5728ProMQA-Assembly\u591a\u6a21\u6001\u7a0b\u5e8f\u6027QA\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u63d0\u5347\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08\u7279\u522b\u662fGPT-5\u548cMiMo-VL\uff09\u7684\u6027\u80fd\u3002\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u4e86\u6846\u67b6\u4e24\u4e2a\u7279\u5f81\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u548c\u5b9e\u9a8c\u7ed3\u679c\u6709\u52a9\u4e8e\u63a8\u52a8\u89c6\u9891\u548c\u591a\u6a21\u6001\u4efb\u52a1\u7684\u56fe\u50cf\u601d\u7ef4\u8303\u5f0f\uff0c\u4fc3\u8fdb\u7a0b\u5e8f\u6027\u6d3b\u52a8\u52a9\u624b\u7684\u5f00\u53d1\u3002"}}
{"id": "2510.00172", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00172", "abs": "https://arxiv.org/abs/2510.00172", "authors": ["Amirhossein Abaskohi", "Tianyi Chen", "Miguel Mu\u00f1oz-M\u00e1rmol", "Curtis Fox", "Amrutha Varshini Ramesh", "\u00c9tienne Marcotte", "Xing Han L\u00f9", "Nicolas Chapados", "Spandana Gella", "Christopher Pal", "Alexandre Drouin", "Issam H. Laradji"], "title": "DRBench: A Realistic Benchmark for Enterprise Deep Research", "comment": null, "summary": "We introduce DRBench, a benchmark for evaluating AI agents on complex,\nopen-ended deep research tasks in enterprise settings. Unlike prior benchmarks\nthat focus on simple questions or web-only queries, DRBench evaluates agents on\nmulti-step queries (for example, ``What changes should we make to our product\nroadmap to ensure compliance with this standard?\") that require identifying\nsupporting facts from both the public web and private company knowledge base.\nEach task is grounded in realistic user personas and enterprise context,\nspanning a heterogeneous search space that includes productivity software,\ncloud file systems, emails, chat conversations, and the open web. Tasks are\ngenerated through a carefully designed synthesis pipeline with\nhuman-in-the-loop verification, and agents are evaluated on their ability to\nrecall relevant insights, maintain factual accuracy, and produce coherent,\nwell-structured reports. We release 15 deep research tasks across 10 domains,\nsuch as Sales, Cybersecurity, and Compliance. We demonstrate the effectiveness\nof DRBench by evaluating diverse DR agents across open- and closed-source\nmodels (such as GPT, Llama, and Qwen) and DR strategies, highlighting their\nstrengths, weaknesses, and the critical path for advancing enterprise deep\nresearch. Code is available at https://github.com/ServiceNow/drbench.", "AI": {"tldr": "DRBench\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30AI\u4ee3\u7406\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u6267\u884c\u590d\u6742\u3001\u5f00\u653e\u5f0f\u6df1\u5ea6\u7814\u7a76\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u591a\u6b65\u9aa4\u67e5\u8be2\u548c\u5f02\u6784\u641c\u7d22\u7a7a\u95f4\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u7b80\u5355\u95ee\u9898\u6216\u4ec5\u9650\u7f51\u7edc\u67e5\u8be2\uff0c\u65e0\u6cd5\u8bc4\u4f30AI\u4ee3\u7406\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u5904\u7406\u590d\u6742\u6df1\u5ea6\u7814\u7a76\u4efb\u52a1\u7684\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u5408\u6210\u6d41\u7a0b\u751f\u6210\u4efb\u52a1\uff0c\u6db5\u76d6\u516c\u5171\u7f51\u7edc\u548c\u79c1\u6709\u516c\u53f8\u77e5\u8bc6\u5e93\uff0c\u5305\u62ec\u751f\u4ea7\u529b\u8f6f\u4ef6\u3001\u4e91\u6587\u4ef6\u7cfb\u7edf\u3001\u90ae\u4ef6\u3001\u804a\u5929\u5bf9\u8bdd\u7b49\u5f02\u6784\u641c\u7d22\u7a7a\u95f4\uff0c\u5e76\u91c7\u7528\u4eba\u5de5\u9a8c\u8bc1\u3002", "result": "\u53d1\u5e03\u4e86\u6db5\u76d610\u4e2a\u9886\u57df\uff08\u5982\u9500\u552e\u3001\u7f51\u7edc\u5b89\u5168\u3001\u5408\u89c4\uff09\u768415\u4e2a\u6df1\u5ea6\u7814\u7a76\u4efb\u52a1\uff0c\u8bc4\u4f30\u4e86\u57fa\u4e8eGPT\u3001Llama\u3001Qwen\u7b49\u5f00\u6e90\u548c\u95ed\u6e90\u6a21\u578b\u7684\u4e0d\u540cDR\u4ee3\u7406\u3002", "conclusion": "DRBench\u6709\u6548\u8bc4\u4f30\u4e86\u4f01\u4e1a\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u7684\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u5176\u4f18\u52bf\u548c\u5f31\u70b9\uff0c\u4e3a\u63a8\u8fdb\u4f01\u4e1a\u6df1\u5ea6\u7814\u7a76\u63d0\u4f9b\u4e86\u5173\u952e\u8def\u5f84\u3002"}}
{"id": "2510.00174", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00174", "abs": "https://arxiv.org/abs/2510.00174", "authors": ["Rik Koncel-Kedziorski", "Brihi Joshi", "Tim Paek"], "title": "PrimeX: A Dataset of Worldview, Opinion, and Explanation", "comment": "EMNLP 2025 Main", "summary": "As the adoption of language models advances, so does the need to better\nrepresent individual users to the model. Are there aspects of an individual's\nbelief system that a language model can utilize for improved alignment?\nFollowing prior research, we investigate this question in the domain of opinion\nprediction by developing PrimeX, a dataset of public opinion survey data from\n858 US residents with two additional sources of belief information: written\nexplanations from the respondents for why they hold specific opinions, and the\nPrimal World Belief survey for assessing respondent worldview. We provide an\nextensive initial analysis of our data and show the value of belief\nexplanations and worldview for personalizing language models. Our results\ndemonstrate how the additional belief information in PrimeX can benefit both\nthe NLP and psychological research communities, opening up avenues for further\nstudy.", "AI": {"tldr": "PrimeX\u6570\u636e\u96c6\u5305\u542b858\u540d\u7f8e\u56fd\u5c45\u6c11\u7684\u6c11\u610f\u8c03\u67e5\u6570\u636e\uff0c\u9644\u5e26\u4fe1\u4ef0\u89e3\u91ca\u548c\u4e16\u754c\u89c2\u8bc4\u4f30\uff0c\u7528\u4e8e\u4e2a\u6027\u5316\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u968f\u7740\u8bed\u8a00\u6a21\u578b\u7684\u5e94\u7528\u6269\u5c55\uff0c\u9700\u8981\u66f4\u597d\u5730\u8868\u793a\u4e2a\u4f53\u7528\u6237\u7684\u4fe1\u4ef0\u7cfb\u7edf\u4ee5\u6539\u8fdb\u6a21\u578b\u5bf9\u9f50\u3002", "method": "\u5f00\u53d1PrimeX\u6570\u636e\u96c6\uff0c\u6536\u96c6\u516c\u4f17\u610f\u89c1\u8c03\u67e5\u6570\u636e\uff0c\u5305\u62ec\u53d7\u8bbf\u8005\u7684\u4e66\u9762\u89e3\u91ca\u548c\u539f\u59cb\u4e16\u754c\u4fe1\u4ef0\u8c03\u67e5\u3002", "result": "\u4fe1\u4ef0\u89e3\u91ca\u548c\u4e16\u754c\u89c2\u4fe1\u606f\u5bf9\u4e2a\u6027\u5316\u8bed\u8a00\u6a21\u578b\u6709\u4ef7\u503c\uff0c\u4e3aNLP\u548c\u5fc3\u7406\u5b66\u7814\u7a76\u63d0\u4f9b\u65b0\u9014\u5f84\u3002", "conclusion": "PrimeX\u4e2d\u7684\u989d\u5916\u4fe1\u4ef0\u4fe1\u606f\u6709\u76ca\u4e8eNLP\u548c\u5fc3\u7406\u5b66\u7814\u7a76\u793e\u533a\uff0c\u5f00\u8f9f\u4e86\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u9014\u5f84\u3002"}}
{"id": "2510.00177", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00177", "abs": "https://arxiv.org/abs/2510.00177", "authors": ["Shuyue Stella Li", "Avinandan Bose", "Faeze Brahman", "Simon Shaolei Du", "Pang Wei Koh", "Maryam Fazel", "Yulia Tsvetkov"], "title": "Personalized Reasoning: Just-In-Time Personalization and Why LLMs Fail At It", "comment": "57 pages, 6 figures", "summary": "Current large language model (LLM) development treats task-solving and\npreference alignment as separate challenges, optimizing first for objective\ncorrectness, then for alignment to aggregated human preferences. This paradigm\nfails in human-facing applications where solving a problem correctly is\ninsufficient if the response mismatches the user's needs. This challenge\nintensifies in just-in-time scenarios where no prior user interaction history\nexists due to cold-start conditions or privacy constraints. LLMs need to\nidentify what they don't know about user preferences, strategically elicit\npreference values through questioning, then adapt their reasoning processes and\nresponses accordingly -- a complicated chain of cognitive processes which we\nterm personalized reasoning. We introduce PREFDISCO, an evaluation methodology\nthat transforms static benchmarks into interactive personalization tasks using\npsychologically-grounded personas with sparse preferences. Our framework\ncreates scenarios where identical questions require different reasoning chains\ndepending on user context, as optimal explanation approaches vary by individual\nexpertise and preferences while maintaining factual accuracy. Evaluation of 21\nfrontier models across 10 tasks reveals 29.0% of naive personalization attempts\nproduce worse preference alignment than generic responses, yet generic\nresponses also fail to serve individual user needs effectively. These findings\nsuggest personalized reasoning requires dedicated development rather than\nemerging naturally. PREFDISCO establishes personalized reasoning as a\nmeasurable research frontier and reveals fundamental limitations in current\nLLMs' interactive capabilities, providing a foundation for developing systems\nthat can adapt to individual users in education, healthcare, and technical\ndomains where personalization is critical.", "AI": {"tldr": "PREFDISCO\u662f\u4e00\u4e2a\u8bc4\u4f30\u6846\u67b6\uff0c\u5c06\u9759\u6001\u57fa\u51c6\u8f6c\u5316\u4e3a\u4e2a\u6027\u5316\u63a8\u7406\u4efb\u52a1\uff0c\u63ed\u793a\u5f53\u524dLLMs\u5728\u4e2a\u6027\u5316\u63a8\u7406\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5f53\u524dLLM\u5f00\u53d1\u5c06\u4efb\u52a1\u89e3\u51b3\u548c\u504f\u597d\u5bf9\u9f50\u5206\u5f00\u5904\u7406\uff0c\u4f46\u5728\u9700\u8981\u5373\u65f6\u4e2a\u6027\u5316\u7684\u4eba\u7c7b\u5e94\u7528\u4e2d\uff0c\u8fd9\u79cd\u8303\u5f0f\u4f1a\u5931\u8d25\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u5fc3\u7406\u5b66\u7684\u89d2\u8272\u8bbe\u5b9a\uff0c\u521b\u5efa\u76f8\u540c\u95ee\u9898\u9700\u8981\u4e0d\u540c\u63a8\u7406\u94fe\u7684\u573a\u666f\uff0c\u8bc4\u4f3021\u4e2a\u524d\u6cbf\u6a21\u578b\u572810\u4e2a\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "result": "29.0%\u7684\u4e2a\u6027\u5316\u5c1d\u8bd5\u6bd4\u901a\u7528\u56de\u7b54\u66f4\u5dee\uff0c\u4f46\u901a\u7528\u56de\u7b54\u4e5f\u65e0\u6cd5\u6709\u6548\u6ee1\u8db3\u4e2a\u4f53\u7528\u6237\u9700\u6c42\u3002", "conclusion": "\u4e2a\u6027\u5316\u63a8\u7406\u9700\u8981\u4e13\u95e8\u5f00\u53d1\uff0c\u4e0d\u80fd\u81ea\u7136\u6d8c\u73b0\uff1bPREFDISCO\u4e3a\u5f00\u53d1\u9002\u5e94\u4e2a\u4f53\u7528\u6237\u7684\u7cfb\u7edf\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.00232", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00232", "abs": "https://arxiv.org/abs/2510.00232", "authors": ["Xin Xu", "Xunzhi He", "Churan Zhi", "Ruizhe Chen", "Julian McAuley", "Zexue He"], "title": "BiasFreeBench: a Benchmark for Mitigating Bias in Large Language Model Responses", "comment": "Work in progress", "summary": "Existing studies on bias mitigation methods for large language models (LLMs)\nuse diverse baselines and metrics to evaluate debiasing performance, leading to\ninconsistent comparisons among them. Moreover, their evaluations are mostly\nbased on the comparison between LLMs' probabilities of biased and unbiased\ncontexts, which ignores the gap between such evaluations and real-world use\ncases where users interact with LLMs by reading model responses and expect fair\nand safe outputs rather than LLMs' probabilities. To enable consistent\nevaluation across debiasing methods and bridge this gap, we introduce\nBiasFreeBench, an empirical benchmark that comprehensively compares eight\nmainstream bias mitigation techniques (covering four prompting-based and four\ntraining-based methods) on two test scenarios (multi-choice QA and open-ended\nmulti-turn QA) by reorganizing existing datasets into a unified query-response\nsetting. We further introduce a response-level metric, Bias-Free Score, to\nmeasure the extent to which LLM responses are fair, safe, and\nanti-stereotypical. Debiasing performances are systematically compared and\nanalyzed across key dimensions: the prompting vs. training paradigm, model\nsize, and generalization of different training strategies to unseen bias types.\nWe will publicly release our benchmark, aiming to establish a unified testbed\nfor bias mitigation research.", "AI": {"tldr": "\u63d0\u51fa\u4e86BiasFreeBench\u57fa\u51c6\uff0c\u7528\u4e8e\u7edf\u4e00\u8bc4\u4f30LLM\u53bb\u504f\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u91cd\u7ec4\u73b0\u6709\u6570\u636e\u96c6\u4e3a\u7edf\u4e00\u7684\u67e5\u8be2-\u54cd\u5e94\u8bbe\u7f6e\uff0c\u5e76\u5f15\u5165Bias-Free Score\u6307\u6807\u6765\u8861\u91cf\u6a21\u578b\u54cd\u5e94\u7684\u516c\u5e73\u6027\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u73b0\u6709LLM\u53bb\u504f\u65b9\u6cd5\u4f7f\u7528\u4e0d\u540c\u7684\u57fa\u7ebf\u548c\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\uff0c\u5bfc\u81f4\u6bd4\u8f83\u4e0d\u4e00\u81f4\uff0c\u4e14\u5927\u591a\u57fa\u4e8e\u6a21\u578b\u6982\u7387\u6bd4\u8f83\uff0c\u5ffd\u7565\u4e86\u4e0e\u5b9e\u9645\u7528\u6237\u4ea4\u4e92\u573a\u666f\u7684\u5dee\u8ddd\u3002", "method": "\u6784\u5efaBiasFreeBench\u57fa\u51c6\uff0c\u6bd4\u8f838\u79cd\u4e3b\u6d41\u53bb\u504f\u6280\u672f\uff084\u79cd\u63d0\u793a\u65b9\u6cd5\u548c4\u79cd\u8bad\u7ec3\u65b9\u6cd5\uff09\uff0c\u5728\u4e24\u79cd\u6d4b\u8bd5\u573a\u666f\uff08\u591a\u9009\u9898QA\u548c\u5f00\u653e\u5f0f\u591a\u8f6eQA\uff09\u4e0b\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u7cfb\u7edf\u5730\u6bd4\u8f83\u4e86\u4e0d\u540c\u53bb\u504f\u65b9\u6cd5\u5728\u63d0\u793avs\u8bad\u7ec3\u8303\u5f0f\u3001\u6a21\u578b\u5927\u5c0f\u4ee5\u53ca\u8bad\u7ec3\u7b56\u7565\u5bf9\u672a\u89c1\u504f\u89c1\u7c7b\u578b\u7684\u6cdb\u5316\u80fd\u529b\u7b49\u5173\u952e\u7ef4\u5ea6\u7684\u8868\u73b0\u3002", "conclusion": "\u8be5\u57fa\u51c6\u65e8\u5728\u4e3a\u504f\u89c1\u7f13\u89e3\u7814\u7a76\u5efa\u7acb\u7edf\u4e00\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5e76\u5c06\u516c\u5f00\u53d1\u5e03\u4ee5\u4fc3\u8fdb\u76f8\u5173\u7814\u7a76\u3002"}}
{"id": "2510.00255", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00255", "abs": "https://arxiv.org/abs/2510.00255", "authors": ["Monishwaran Maheswaran", "Marco Carini", "Christian Federmann", "Tony Diaz"], "title": "TASER: Translation Assessment via Systematic Evaluation and Reasoning", "comment": null, "summary": "We introduce TASER (Translation Assessment via Systematic Evaluation and\nReasoning), a metric that uses Large Reasoning Models (LRMs) for automated\ntranslation quality assessment. TASER harnesses the explicit reasoning\ncapabilities of LRMs to conduct systematic, step-by-step evaluation of\ntranslation quality. We evaluate TASER on the WMT24 Metrics Shared Task across\nboth reference-based and reference-free scenarios, demonstrating\nstate-of-the-art performance. In system-level evaluation, TASER achieves the\nhighest soft pairwise accuracy in both reference-based and reference-free\nsettings, outperforming all existing metrics. At the segment level, TASER\nmaintains competitive performance with our reference-free variant ranking as\nthe top-performing metric among all reference-free approaches. Our experiments\nreveal that structured prompting templates yield superior results with LRMs\ncompared to the open-ended approaches that proved optimal for traditional LLMs.\nWe evaluate o3, a large reasoning model from OpenAI, with varying reasoning\nefforts, providing insights into the relationship between reasoning depth and\nevaluation quality. The explicit reasoning process in LRMs offers\ninterpretability and visibility, addressing a key limitation of existing\nautomated metrics. Our results demonstrate that Large Reasoning Models show a\nmeasurable advancement in translation quality assessment, combining improved\naccuracy with transparent evaluation across diverse language pairs.", "AI": {"tldr": "TASER\u662f\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u4f30\u6307\u6807\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u9010\u6b65\u63a8\u7406\u5728WMT24\u8bc4\u6d4b\u4e2d\u53d6\u5f97\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728\u7cfb\u7edf\u548c\u7247\u6bb5\u7ea7\u522b\u90fd\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u7ffb\u8bd1\u8bc4\u4f30\u6307\u6807\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u5927\u578b\u63a8\u7406\u6a21\u578b\u80fd\u591f\u63d0\u4f9b\u663e\u5f0f\u63a8\u7406\u8fc7\u7a0b\uff0c\u6709\u671b\u7ed3\u5408\u51c6\u786e\u6027\u548c\u900f\u660e\u5ea6\u3002", "method": "\u5229\u7528\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u663e\u5f0f\u63a8\u7406\u80fd\u529b\uff0c\u91c7\u7528\u7ed3\u6784\u5316\u63d0\u793a\u6a21\u677f\u8fdb\u884c\u7cfb\u7edf\u5316\u9010\u6b65\u8bc4\u4f30\uff0c\u6d4b\u8bd5\u4e0d\u540c\u63a8\u7406\u6df1\u5ea6\u5bf9\u8bc4\u4f30\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "result": "\u5728WMT24\u8bc4\u6d4b\u4e2d\uff0cTASER\u5728\u57fa\u4e8e\u53c2\u8003\u548c\u65e0\u53c2\u8003\u8bbe\u7f6e\u4e0b\u90fd\u5b9e\u73b0\u4e86\u6700\u9ad8\u7684\u8f6f\u914d\u5bf9\u51c6\u786e\u7387\uff0c\u65e0\u53c2\u8003\u53d8\u4f53\u5728\u6240\u6709\u65e0\u53c2\u8003\u65b9\u6cd5\u4e2d\u6392\u540d\u7b2c\u4e00\u3002", "conclusion": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u4f30\u65b9\u9762\u663e\u793a\u51fa\u53ef\u8861\u91cf\u7684\u8fdb\u6b65\uff0c\u7ed3\u5408\u4e86\u6539\u8fdb\u7684\u51c6\u786e\u6027\u548c\u8de8\u8bed\u8a00\u5bf9\u7684\u900f\u660e\u8bc4\u4f30\u3002"}}
{"id": "2510.00261", "categories": ["cs.CL", "cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.00261", "abs": "https://arxiv.org/abs/2510.00261", "authors": ["Xiaoyu Song", "William Han", "Tony Chen", "Chaojing Duan", "Michael A. Rosenberg", "Emerson Liu", "Ding Zhao"], "title": "Retrieval-Augmented Generation for Electrocardiogram-Language Models", "comment": "5 pages, 2 figures; Submitted to ICASSP 2026", "summary": "Interest in generative Electrocardiogram-Language Models (ELMs) is growing,\nas they can produce textual responses conditioned on ECG signals and textual\nqueries. Unlike traditional classifiers that output label probabilities, ELMs\nare more versatile, supporting domain-specific tasks (e.g., waveform analysis,\ndiagnosis, prognosis) as well as general tasks (e.g., open-ended questions,\ndialogue). Retrieval-Augmented Generation (RAG), widely used in Large Language\nModels (LLMs) to ground LLM outputs in retrieved knowledge, helps reduce\nhallucinations and improve natural language generation (NLG). However, despite\nits promise, no open-source implementation or systematic study of RAG pipeline\ndesign for ELMs currently exists. To address this gap, we present the first\nopen-source RAG pipeline for ELMs, along with baselines and ablation studies\nfor NLG. Experiments on three public datasets show that ELMs with RAG\nconsistently improves performance over non-RAG baselines and highlights key ELM\ndesign considerations. Our code is available at:\nhttps://github.com/willxxy/ECG-Bench.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u7528\u4e8e\u5fc3\u7535\u56fe\u6587\u8bed\u8a00\u6a21\u578b\u7684\u5f00\u6e90\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7ba1\u9053\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660eRAG\u80fd\u6301\u7eed\u63d0\u5347\u6a21\u578b\u6027\u80fd", "motivation": "\u867d\u7136\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5728\u5fc3\u7535\u56fe\u6587\u8bed\u8a00\u6a21\u578b\u9886\u57df\u7f3a\u4e4f\u5f00\u6e90\u5b9e\u73b0\u548c\u7cfb\u7edf\u7814\u7a76\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d", "method": "\u5f00\u53d1\u4e86\u9996\u4e2a\u5f00\u6e90RAG\u7ba1\u9053\u7528\u4e8eELMs\uff0c\u5305\u542b\u57fa\u51c6\u6d4b\u8bd5\u548c\u81ea\u7136\u8bed\u8a00\u751f\u6210\u7684\u6d88\u878d\u7814\u7a76\uff0c\u5728\u4e09\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528RAG\u7684ELMs\u5728\u6027\u80fd\u4e0a\u6301\u7eed\u4f18\u4e8e\u975eRAG\u57fa\u51c6\u6a21\u578b\uff0c\u5e76\u7a81\u51fa\u4e86\u5173\u952e\u7684ELM\u8bbe\u8ba1\u8003\u8651\u56e0\u7d20", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5fc3\u7535\u56fe\u6587\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u9996\u4e2a\u5f00\u6e90RAG\u5b9e\u73b0\uff0c\u8bc1\u660e\u4e86RAG\u5728\u8be5\u9886\u57df\u7684\u6709\u6548\u6027\uff0c\u5e76\u8bc6\u522b\u4e86\u91cd\u8981\u7684\u8bbe\u8ba1\u8003\u91cf"}}
{"id": "2510.00263", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00263", "abs": "https://arxiv.org/abs/2510.00263", "authors": ["Zhuohang Li", "Xiaowei Li", "Chengyu Huang", "Guowang Li", "Katayoon Goshvadi", "Bo Dai", "Dale Schuurmans", "Paul Zhou", "Hamid Palangi", "Yiwen Song", "Palash Goyal", "Murat Kantarcioglu", "Bradley A. Malin", "Yuan Xue"], "title": "Judging with Confidence: Calibrating Autoraters to Preference Distributions", "comment": null, "summary": "The alignment of large language models (LLMs) with human values increasingly\nrelies on using other LLMs as automated judges, or ``autoraters''. However,\ntheir reliability is limited by a foundational issue: they are trained on\ndiscrete preference labels, forcing a single ground truth onto tasks that are\noften subjective, ambiguous, or nuanced. We argue that a reliable autorater\nmust learn to model the full distribution of preferences defined by a target\npopulation. In this paper, we propose a general framework for calibrating\nprobabilistic autoraters to any given preference distribution. We formalize the\nproblem and present two learning methods tailored to different data conditions:\n1) a direct supervised fine-tuning for dense, probabilistic labels, and 2) a\nreinforcement learning approach for sparse, binary labels. Our empirical\nresults show that finetuning autoraters with a distribution-matching objective\nleads to verbalized probability predictions that are better aligned with the\ntarget preference distribution, with improved calibration and significantly\nlower positional bias, all while preserving performance on objective tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u6821\u51c6\u6982\u7387\u81ea\u52a8\u8bc4\u5206\u5668\u7684\u6846\u67b6\uff0c\u4f7f\u5176\u80fd\u591f\u5efa\u6a21\u76ee\u6807\u4eba\u7fa4\u7684\u5b8c\u6574\u504f\u597d\u5206\u5e03\uff0c\u89e3\u51b3\u73b0\u6709LLM\u81ea\u52a8\u8bc4\u5206\u5668\u56e0\u8bad\u7ec3\u4e8e\u79bb\u6563\u6807\u7b7e\u800c\u65e0\u6cd5\u5904\u7406\u4e3b\u89c2\u6027\u4efb\u52a1\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709LLM\u81ea\u52a8\u8bc4\u5206\u5668\u57fa\u4e8e\u79bb\u6563\u504f\u597d\u6807\u7b7e\u8bad\u7ec3\uff0c\u65e0\u6cd5\u5904\u7406\u4e3b\u89c2\u3001\u6a21\u7cca\u6216\u7ec6\u5fae\u7684\u4efb\u52a1\uff0c\u9700\u8981\u5efa\u6a21\u5b8c\u6574\u7684\u504f\u597d\u5206\u5e03\u4ee5\u63d0\u9ad8\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u5b66\u4e60\u65b9\u6cd5\uff1a1) \u9488\u5bf9\u5bc6\u96c6\u6982\u7387\u6807\u7b7e\u7684\u76f4\u63a5\u76d1\u7763\u5fae\u8c03\uff1b2) \u9488\u5bf9\u7a00\u758f\u4e8c\u5143\u6807\u7b7e\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u4f7f\u7528\u5206\u5e03\u5339\u914d\u76ee\u6807\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u4f7f\u7528\u5206\u5e03\u5339\u914d\u76ee\u6807\u5fae\u8c03\u7684\u81ea\u52a8\u8bc4\u5206\u5668\u80fd\u751f\u6210\u4e0e\u76ee\u6807\u504f\u597d\u5206\u5e03\u66f4\u597d\u5bf9\u9f50\u7684\u8a00\u8bed\u5316\u6982\u7387\u9884\u6d4b\uff0c\u6539\u5584\u6821\u51c6\u5ea6\uff0c\u663e\u8457\u964d\u4f4e\u4f4d\u7f6e\u504f\u5dee\uff0c\u540c\u65f6\u4fdd\u6301\u5ba2\u89c2\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u6821\u51c6\u6982\u7387\u81ea\u52a8\u8bc4\u5206\u5668\u6765\u5efa\u6a21\u5b8c\u6574\u504f\u597d\u5206\u5e03\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u9ad8\u5176\u5728\u4e3b\u89c2\u4efb\u52a1\u4e2d\u7684\u53ef\u9760\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u5ba2\u89c2\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2510.00268", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00268", "abs": "https://arxiv.org/abs/2510.00268", "authors": ["Zhexiong Liu", "Diane Litman"], "title": "Efficient Layer-wise LLM Fine-tuning for Revision Intention Prediction", "comment": "In The Conference on Empirical Methods in Natural Language Processing\n  (EMNLP), November 2025", "summary": "Large Language Models (LLMs) have shown extraordinary success across various\ntext generation tasks; however, their potential for simple yet essential text\nclassification remains underexplored, as LLM pre-training tends to emphasize\ngeneration over classification. While LLMs with instruction tuning can\ntransform classification into a generation task, they often struggle to\ncategorize nuanced texts. One such example is text revision, which involves\nnuanced edits between pairs of texts. Although simply fine-tuning LLMs for\nrevision classification seems plausible, it requires a large amount of revision\nannotations, which are exceptionally expensive and scarce in the community. To\naddress this issue, we introduce a plug-and-play layer-wise parameter-efficient\nfine-tuning (PEFT) framework, i.e., IR-Tuning, which fine-tunes a subset of\nimportant LLM layers that are dynamically selected based on their gradient norm\ndistribution, while freezing those of redundant layers. Extensive experiments\nsuggest that IR-Tuning surpasses several layer-wise PEFT baselines over diverse\ntext revisions, while achieving fast convergence, low GPU memory consumption,\nand effectiveness on small revision corpora.", "AI": {"tldr": "\u63d0\u51fa\u4e86IR-Tuning\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u91cd\u8981\u5c42\u8fdb\u884c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff0c\u89e3\u51b3\u4e86LLM\u5728\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\u7684\u95ee\u9898\u3002", "motivation": "LLM\u5728\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u6587\u672c\u5206\u7c7b\u7279\u522b\u662f\u6587\u672c\u4fee\u8ba2\u5206\u7c7b\u7b49\u9700\u8981\u7ec6\u5fae\u7406\u89e3\u7684\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u4f20\u7edf\u5fae\u8c03\u9700\u8981\u5927\u91cf\u6602\u8d35\u6807\u6ce8\u6570\u636e\u3002", "method": "IR-Tuning\u6846\u67b6\uff1a\u57fa\u4e8e\u68af\u5ea6\u8303\u6570\u5206\u5e03\u52a8\u6001\u9009\u62e9\u91cd\u8981LLM\u5c42\u8fdb\u884c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff0c\u51bb\u7ed3\u5197\u4f59\u5c42\uff0c\u5b9e\u73b0plug-and-play\u7684\u5c42\u7ea7PEFT\u3002", "result": "\u5728\u591a\u79cd\u6587\u672c\u4fee\u8ba2\u4efb\u52a1\u4e0a\u8d85\u8d8a\u591a\u4e2a\u5c42\u7ea7PEFT\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5b9e\u73b0\u5feb\u901f\u6536\u655b\u3001\u4f4eGPU\u5185\u5b58\u6d88\u8017\uff0c\u5e76\u5728\u5c0f\u89c4\u6a21\u4fee\u8ba2\u8bed\u6599\u4e0a\u6709\u6548\u3002", "conclusion": "IR-Tuning\u4e3aLLM\u5728\u9700\u8981\u7ec6\u5fae\u7406\u89e3\u7684\u5206\u7c7b\u4efb\u52a1\u4e0a\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\u3002"}}
{"id": "2510.00276", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00276", "abs": "https://arxiv.org/abs/2510.00276", "authors": ["Joe Barrow", "Raj Patel", "Misha Kharkovski", "Ben Davies", "Ryan Schmitt"], "title": "SafePassage: High-Fidelity Information Extraction with Black Box LLMs", "comment": null, "summary": "Black box large language models (LLMs) make information extraction (IE) easy\nto configure, but hard to trust. Unlike traditional information extraction\npipelines, the information \"extracted\" is not guaranteed to be grounded in the\ndocument. To prevent this, this paper introduces the notion of a \"safe\npassage\": context generated by the LLM that is both grounded in the document\nand consistent with the extracted information. This is operationalized via a\nthree-step pipeline, SafePassage, which consists of: (1) an LLM extractor that\ngenerates structured entities and their contexts from a document, (2) a\nstring-based global aligner, and (3) a scoring model. Results show that using\nthese three parts in conjunction reduces hallucinations by up to 85% on\ninformation extraction tasks with minimal risk of flagging non-hallucinations.\nHigh agreement between the SafePassage pipeline and human judgments of\nextraction quality mean that the pipeline can be dually used to evaluate LLMs.\nSurprisingly, results also show that using a transformer encoder fine-tuned on\na small number of task-specific examples can outperform an LLM scoring model at\nflagging unsafe passages. These annotations can be collected in as little as\n1-2 hours.", "AI": {"tldr": "\u63d0\u51fa\u4e86SafePassage\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u5b89\u5168\u6bb5\u843d\u6765\u51cf\u5c11LLM\u5728\u4fe1\u606f\u62bd\u53d6\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u5c06\u5e7b\u89c9\u51cf\u5c11\u9ad8\u8fbe85%", "motivation": "\u9ed1\u76d2\u5927\u8bed\u8a00\u6a21\u578b\u4f7f\u4fe1\u606f\u62bd\u53d6\u6613\u4e8e\u914d\u7f6e\u4f46\u96be\u4ee5\u4fe1\u4efb\uff0c\u62bd\u53d6\u7684\u4fe1\u606f\u4e0d\u80fd\u4fdd\u8bc1\u57fa\u4e8e\u6587\u6863\uff0c\u9700\u8981\u89e3\u51b3\u5e7b\u89c9\u95ee\u9898", "method": "\u4e09\u6b65\u6d41\u6c34\u7ebf\uff1a1) LLM\u63d0\u53d6\u5668\u751f\u6210\u7ed3\u6784\u5316\u5b9e\u4f53\u53ca\u5176\u4e0a\u4e0b\u6587\uff1b2) \u57fa\u4e8e\u5b57\u7b26\u4e32\u7684\u5168\u5c40\u5bf9\u9f50\u5668\uff1b3) \u8bc4\u5206\u6a21\u578b", "result": "\u5c06\u4fe1\u606f\u62bd\u53d6\u4efb\u52a1\u4e2d\u7684\u5e7b\u89c9\u51cf\u5c11\u9ad8\u8fbe85%\uff0c\u4e0e\u4eba\u7c7b\u5224\u65ad\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5fae\u8c03\u7684transformer\u7f16\u7801\u5668\u5728\u6807\u8bb0\u4e0d\u5b89\u5168\u6bb5\u843d\u65b9\u9762\u4f18\u4e8eLLM\u8bc4\u5206\u6a21\u578b", "conclusion": "SafePassage\u80fd\u6709\u6548\u51cf\u5c11\u5e7b\u89c9\uff0c\u53cc\u91cd\u7528\u4e8e\u8bc4\u4f30LLM\uff0c\u5c0f\u6837\u672c\u5fae\u8c03\u7684transformer\u7f16\u7801\u5668\u8868\u73b0\u4f18\u4e8eLLM\u8bc4\u5206\u6a21\u578b"}}
{"id": "2510.00280", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00280", "abs": "https://arxiv.org/abs/2510.00280", "authors": ["Ruochen Li", "Jun Li", "Bailiang Jian", "Kun Yuan", "Youxiang Zhu"], "title": "ReEvalMed: Rethinking Medical Report Evaluation by Aligning Metrics with Real-World Clinical Judgment", "comment": null, "summary": "Automatically generated radiology reports often receive high scores from\nexisting evaluation metrics but fail to earn clinicians' trust. This gap\nreveals fundamental flaws in how current metrics assess the quality of\ngenerated reports. We rethink the design and evaluation of these metrics and\npropose a clinically grounded Meta-Evaluation framework. We define clinically\ngrounded criteria spanning clinical alignment and key metric capabilities,\nincluding discrimination, robustness, and monotonicity. Using a fine-grained\ndataset of ground truth and rewritten report pairs annotated with error types,\nclinical significance labels, and explanations, we systematically evaluate\nexisting metrics and reveal their limitations in interpreting clinical\nsemantics, such as failing to distinguish clinically significant errors,\nover-penalizing harmless variations, and lacking consistency across error\nseverity levels. Our framework offers guidance for building more clinically\nreliable evaluation methods.", "AI": {"tldr": "\u63d0\u51fa\u4e34\u5e8a\u57fa\u7840\u7684\u5143\u8bc4\u4f30\u6846\u67b6\uff0c\u91cd\u65b0\u601d\u8003\u653e\u5c04\u5b66\u62a5\u544a\u81ea\u52a8\u751f\u6210\u7684\u8bc4\u4f30\u6307\u6807\u8bbe\u8ba1\uff0c\u63ed\u793a\u73b0\u6709\u6307\u6807\u5728\u4e34\u5e8a\u8bed\u4e49\u7406\u89e3\u4e0a\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u81ea\u52a8\u751f\u6210\u7684\u653e\u5c04\u5b66\u62a5\u544a\u5728\u73b0\u6709\u8bc4\u4f30\u6307\u6807\u4e2d\u5f97\u5206\u5f88\u9ad8\uff0c\u4f46\u65e0\u6cd5\u83b7\u5f97\u4e34\u5e8a\u533b\u751f\u7684\u4fe1\u4efb\uff0c\u8fd9\u66b4\u9732\u4e86\u5f53\u524d\u8bc4\u4f30\u6307\u6807\u5728\u8861\u91cf\u751f\u6210\u62a5\u544a\u8d28\u91cf\u65b9\u9762\u7684\u6839\u672c\u7f3a\u9677\u3002", "method": "\u5b9a\u4e49\u4e34\u5e8a\u57fa\u7840\u7684\u6807\u51c6\uff0c\u5305\u62ec\u4e34\u5e8a\u5bf9\u9f50\u548c\u5173\u952e\u6307\u6807\u80fd\u529b\uff08\u533a\u5206\u5ea6\u3001\u9c81\u68d2\u6027\u548c\u5355\u8c03\u6027\uff09\uff0c\u4f7f\u7528\u7ec6\u7c92\u5ea6\u6807\u6ce8\u7684\u6570\u636e\u96c6\u7cfb\u7edf\u8bc4\u4f30\u73b0\u6709\u6307\u6807\u3002", "result": "\u53d1\u73b0\u73b0\u6709\u6307\u6807\u5728\u89e3\u91ca\u4e34\u5e8a\u8bed\u4e49\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff1a\u65e0\u6cd5\u533a\u5206\u4e34\u5e8a\u663e\u8457\u9519\u8bef\u3001\u8fc7\u5ea6\u60e9\u7f5a\u65e0\u5bb3\u53d8\u5f02\u3001\u5728\u9519\u8bef\u4e25\u91cd\u7a0b\u5ea6\u7ea7\u522b\u95f4\u7f3a\u4e4f\u4e00\u81f4\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u6784\u5efa\u66f4\u4e34\u5e8a\u53ef\u9760\u7684\u8bc4\u4f30\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2510.00288", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00288", "abs": "https://arxiv.org/abs/2510.00288", "authors": ["\u013dubo\u0161 Kri\u0161", "Jaroslav Kop\u010dan", "Qiwei Peng", "Andrej Ridzik", "Marcel Vesel\u00fd", "Martin Tamajka"], "title": "o-MEGA: Optimized Methods for Explanation Generation and Analysis", "comment": null, "summary": "The proliferation of transformer-based language models has revolutionized NLP\ndomain while simultaneously introduced significant challenges regarding model\ntransparency and trustworthiness. The complexity of achieving explainable\nsystems in this domain is evidenced by the extensive array of explanation\nmethods and evaluation metrics developed by researchers. To address the\nchallenge of selecting optimal explainability approaches, we present\n\\textbf{\\texttt{o-mega}}, a hyperparameter optimization tool designed to\nautomatically identify the most effective explainable AI methods and their\nconfigurations within the semantic matching domain. We evaluate o-mega on a\npost-claim matching pipeline using a curated dataset of social media posts\npaired with refuting claims. Our tool systematically explores different\nexplainable methods and their hyperparameters, demonstrating improved\ntransparency in automated fact-checking systems. As a result, such automated\noptimization of explanation methods can significantly enhance the\ninterpretability of claim-matching models in critical applications such as\nmisinformation detection, contributing to more trustworthy and transparent AI\nsystems.", "AI": {"tldr": "\u63d0\u51fa\u4e86o-mega\u5de5\u5177\uff0c\u7528\u4e8e\u81ea\u52a8\u4f18\u5316\u53ef\u89e3\u91caAI\u65b9\u6cd5\u5728\u8bed\u4e49\u5339\u914d\u9886\u57df\u7684\u914d\u7f6e\uff0c\u63d0\u5347\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u3002", "motivation": "\u89e3\u51b3\u57fa\u4e8etransformer\u7684\u8bed\u8a00\u6a21\u578b\u5728\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6\u65b9\u9762\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u53ef\u89e3\u91ca\u65b9\u6cd5\u9009\u62e9\u4e0a\u7684\u590d\u6742\u6027\u3002", "method": "\u5f00\u53d1\u4e86o-mega\u8d85\u53c2\u6570\u4f18\u5316\u5de5\u5177\uff0c\u7cfb\u7edf\u63a2\u7d22\u4e0d\u540c\u7684\u53ef\u89e3\u91ca\u65b9\u6cd5\u53ca\u5176\u8d85\u53c2\u6570\u914d\u7f6e\uff0c\u5728\u793e\u4ea4\u5a92\u4f53\u5e16\u5b50\u4e0e\u53cd\u9a73\u58f0\u660e\u5339\u914d\u7684\u7ba1\u9053\u4e2d\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5de5\u5177\u80fd\u591f\u81ea\u52a8\u8bc6\u522b\u6700\u6709\u6548\u7684\u53ef\u89e3\u91caAI\u65b9\u6cd5\u548c\u914d\u7f6e\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u3002", "conclusion": "\u8fd9\u79cd\u81ea\u52a8\u4f18\u5316\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u589e\u5f3a\u5173\u952e\u5e94\u7528\u4e2d\u58f0\u660e\u5339\u914d\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u53ef\u4fe1\u548c\u900f\u660e\u7684AI\u7cfb\u7edf\u3002"}}
{"id": "2510.00311", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00311", "abs": "https://arxiv.org/abs/2510.00311", "authors": ["Bowen Wei", "Yuan Shen Tay", "Howard Liu", "Jinhao Pan", "Kun Luo", "Ziwei Zhu", "Chris Jordan"], "title": "CORTEX: Collaborative LLM Agents for High-Stakes Alert Triage", "comment": null, "summary": "Security Operations Centers (SOCs) are overwhelmed by tens of thousands of\ndaily alerts, with only a small fraction corresponding to genuine attacks. This\noverload creates alert fatigue, leading to overlooked threats and analyst\nburnout. Classical detection pipelines are brittle and context-poor, while\nrecent LLM-based approaches typically rely on a single model to interpret logs,\nretrieve context, and adjudicate alerts end-to-end -- an approach that\nstruggles with noisy enterprise data and offers limited transparency. We\npropose CORTEX, a multi-agent LLM architecture for high-stakes alert triage in\nwhich specialized agents collaborate over real evidence: a behavior-analysis\nagent inspects activity sequences, evidence-gathering agents query external\nsystems, and a reasoning agent synthesizes findings into an auditable decision.\nTo support training and evaluation, we release a dataset of fine-grained SOC\ninvestigations from production environments, capturing step-by-step analyst\nactions and linked tool outputs. Across diverse enterprise scenarios, CORTEX\nsubstantially reduces false positives and improves investigation quality over\nstate-of-the-art single-agent LLMs.", "AI": {"tldr": "\u63d0\u51faCORTEX\u591a\u667a\u80fd\u4f53LLM\u67b6\u6784\uff0c\u7528\u4e8eSOC\u8b66\u62a5\u5206\u7c7b\uff0c\u901a\u8fc7\u4e13\u4e1a\u5316\u667a\u80fd\u4f53\u534f\u4f5c\u5904\u7406\u771f\u5b9e\u8bc1\u636e\uff0c\u663e\u8457\u51cf\u5c11\u8bef\u62a5\u5e76\u63d0\u9ad8\u8c03\u67e5\u8d28\u91cf", "motivation": "SOC\u9762\u4e34\u6bcf\u65e5\u6570\u4e07\u8b66\u62a5\u8fc7\u8f7d\u95ee\u9898\uff0c\u4f20\u7edf\u68c0\u6d4b\u7ba1\u9053\u8106\u5f31\u4e14\u7f3a\u4e4f\u4e0a\u4e0b\u6587\uff0c\u73b0\u6709LLM\u65b9\u6cd5\u4f7f\u7528\u5355\u4e00\u6a21\u578b\u5904\u7406\u6240\u6709\u4efb\u52a1\uff0c\u96be\u4ee5\u5e94\u5bf9\u5608\u6742\u7684\u4f01\u4e1a\u6570\u636e\u4e14\u900f\u660e\u5ea6\u6709\u9650", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53LLM\u67b6\u6784\uff0c\u5305\u542b\u884c\u4e3a\u5206\u6790\u667a\u80fd\u4f53\u68c0\u67e5\u6d3b\u52a8\u5e8f\u5217\u3001\u8bc1\u636e\u6536\u96c6\u667a\u80fd\u4f53\u67e5\u8be2\u5916\u90e8\u7cfb\u7edf\u3001\u63a8\u7406\u667a\u80fd\u4f53\u7efc\u5408\u53d1\u73b0\u5f62\u6210\u53ef\u5ba1\u8ba1\u51b3\u7b56", "result": "\u5728\u591a\u6837\u5316\u4f01\u4e1a\u573a\u666f\u4e2d\uff0cCORTEX\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u5355\u667a\u80fd\u4f53LLM\u663e\u8457\u51cf\u5c11\u8bef\u62a5\u5e76\u63d0\u9ad8\u8c03\u67e5\u8d28\u91cf", "conclusion": "\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u65b9\u6cd5\u5728SOC\u8b66\u62a5\u5206\u7c7b\u4e2d\u4f18\u4e8e\u5355\u6a21\u578b\u65b9\u6cd5\uff0c\u63d0\u4f9b\u66f4\u597d\u7684\u900f\u660e\u5ea6\u548c\u5904\u7406\u80fd\u529b"}}
{"id": "2510.00444", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00444", "abs": "https://arxiv.org/abs/2510.00444", "authors": ["Zijun Wu", "Yongchang Hao", "Lili Mou"], "title": "TokMem: Tokenized Procedural Memory for Large Language Models", "comment": null, "summary": "Large language models rely heavily on prompts to specify tasks, recall\nknowledge and guide reasoning. However, this reliance is inefficient as prompts\nmust be re-read at each step, scale poorly across tasks, and lack mechanisms\nfor modular reuse. We introduce TokMem, a tokenized procedural memory that\nstores recurring procedures as compact, trainable embeddings. Each memory token\nencodes both an address to a procedure and a control signal that steers\ngeneration, enabling targeted behavior with constant-size overhead. To support\ncontinual adaptation, TokMem keeps the backbone model frozen, allowing new\nprocedures to be added without interfering with existing ones. We evaluate\nTokMem on 1,000 tasks for atomic recall, and on function-calling tasks for\ncompositional recall, where it consistently outperforms retrieval-augmented\ngeneration while avoiding repeated context overhead, and fine-tuning with far\nfewer parameters. These results establish TokMem as a scalable and modular\nalternative to prompt engineering and fine-tuning, offering an explicit\nprocedural memory for LLMs.", "AI": {"tldr": "TokMem\u662f\u4e00\u79cd\u6807\u8bb0\u5316\u7a0b\u5e8f\u8bb0\u5fc6\uff0c\u5c06\u91cd\u590d\u7a0b\u5e8f\u5b58\u50a8\u4e3a\u7d27\u51d1\u53ef\u8bad\u7ec3\u7684\u5d4c\u5165\uff0c\u901a\u8fc7\u8bb0\u5fc6\u4ee4\u724c\u7f16\u7801\u7a0b\u5e8f\u5730\u5740\u548c\u63a7\u5236\u4fe1\u53f7\uff0c\u5728\u4fdd\u6301\u9aa8\u5e72\u6a21\u578b\u51bb\u7ed3\u7684\u540c\u65f6\u5b9e\u73b0\u6301\u7eed\u9002\u5e94\uff0c\u663e\u8457\u4f18\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u5fae\u8c03\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fc7\u5ea6\u4f9d\u8d56\u63d0\u793a\u6765\u6307\u5b9a\u4efb\u52a1\u3001\u56de\u5fc6\u77e5\u8bc6\u548c\u5f15\u5bfc\u63a8\u7406\uff0c\u4f46\u8fd9\u79cd\u4f9d\u8d56\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u5728\u6bcf\u4e2a\u6b65\u9aa4\u91cd\u65b0\u8bfb\u53d6\u63d0\u793a\uff0c\u8de8\u4efb\u52a1\u6269\u5c55\u6027\u5dee\uff0c\u4e14\u7f3a\u4e4f\u6a21\u5757\u5316\u91cd\u7528\u673a\u5236\u3002", "method": "\u5f15\u5165TokMem\u6807\u8bb0\u5316\u7a0b\u5e8f\u8bb0\u5fc6\uff0c\u5c06\u91cd\u590d\u7a0b\u5e8f\u5b58\u50a8\u4e3a\u7d27\u51d1\u53ef\u8bad\u7ec3\u7684\u5d4c\u5165\u3002\u6bcf\u4e2a\u8bb0\u5fc6\u4ee4\u724c\u7f16\u7801\u7a0b\u5e8f\u5730\u5740\u548c\u63a7\u5236\u4fe1\u53f7\uff0c\u5f15\u5bfc\u751f\u6210\u8fc7\u7a0b\u3002\u4fdd\u6301\u9aa8\u5e72\u6a21\u578b\u51bb\u7ed3\uff0c\u652f\u6301\u6301\u7eed\u6dfb\u52a0\u65b0\u7a0b\u5e8f\u800c\u4e0d\u5e72\u6270\u73b0\u6709\u7a0b\u5e8f\u3002", "result": "\u57281000\u4e2a\u539f\u5b50\u56de\u5fc6\u4efb\u52a1\u548c\u51fd\u6570\u8c03\u7528\u4efb\u52a1\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0cTokMem\u59cb\u7ec8\u4f18\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff0c\u907f\u514d\u4e86\u91cd\u590d\u4e0a\u4e0b\u6587\u5f00\u9500\uff0c\u4e14\u6bd4\u5fae\u8c03\u4f7f\u7528\u66f4\u5c11\u7684\u53c2\u6570\u3002", "conclusion": "TokMem\u4e3aLLMs\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u548c\u6a21\u5757\u5316\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u53d6\u4ee3\u63d0\u793a\u5de5\u7a0b\u548c\u5fae\u8c03\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u663e\u5f0f\u7684\u7a0b\u5e8f\u8bb0\u5fc6\u673a\u5236\u3002"}}
{"id": "2510.00446", "categories": ["cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.00446", "abs": "https://arxiv.org/abs/2510.00446", "authors": ["Yuling Shi", "Yichun Qian", "Hongyu Zhang", "Beijun Shen", "Xiaodong Gu"], "title": "LongCodeZip: Compress Long Context for Code Language Models", "comment": "Accepted to ASE 2025. Code available at\n  https://github.com/YerbaPage/LongCodeZip", "summary": "Code generation under long contexts is becoming increasingly critical as\nLarge Language Models (LLMs) are required to reason over extensive information\nin the codebase. While recent advances enable code LLMs to process long inputs,\nhigh API costs and generation latency remain substantial bottlenecks. Existing\ncontext pruning techniques, such as LLMLingua, achieve promising results for\ngeneral text but overlook code-specific structures and dependencies, leading to\nsuboptimal performance in programming tasks. In this paper, we propose\nLongCodeZip, a novel plug-and-play code compression framework designed\nspecifically for code LLMs. LongCodeZip employs a dual-stage strategy: (1)\ncoarse-grained compression, which identifies and ranks function-level chunks\nusing conditional perplexity with respect to the instruction, retaining only\nthe most relevant functions; and (2) fine-grained compression, which segments\nretained functions into blocks based on perplexity and selects an optimal\nsubset under an adaptive token budget to maximize relevance. Evaluations across\nmultiple tasks, including code completion, summarization, and question\nanswering, show that LongCodeZip consistently outperforms baseline methods,\nachieving up to a 5.6x compression ratio without degrading task performance. By\neffectively reducing context size while preserving essential information,\nLongCodeZip enables LLMs to better scale to real-world, large-scale code\nscenarios, advancing the efficiency and capability of code intelligence\napplications.", "AI": {"tldr": "LongCodeZip\u662f\u4e00\u4e2a\u4e13\u95e8\u4e3a\u4ee3\u7801LLMs\u8bbe\u8ba1\u7684\u5373\u63d2\u5373\u7528\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u9636\u6bb5\u538b\u7f29\u7b56\u7565\u663e\u8457\u51cf\u5c11\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u5728\u4e0d\u964d\u4f4e\u4efb\u52a1\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u8fbe5.6\u500d\u7684\u538b\u7f29\u6bd4\u3002", "motivation": "\u73b0\u6709\u4e0a\u4e0b\u6587\u526a\u679d\u6280\u672f\u5982LLMLingua\u5728\u901a\u7528\u6587\u672c\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5ffd\u7565\u4e86\u4ee3\u7801\u7279\u5b9a\u7684\u7ed3\u6784\u548c\u4f9d\u8d56\u5173\u7cfb\uff0c\u5bfc\u81f4\u5728\u7f16\u7a0b\u4efb\u52a1\u4e2d\u6027\u80fd\u4e0d\u4f73\u3002\u9ad8API\u6210\u672c\u548c\u751f\u6210\u5ef6\u8fdf\u662f\u4ee3\u7801LLMs\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u7684\u4e3b\u8981\u74f6\u9888\u3002", "method": "\u91c7\u7528\u53cc\u9636\u6bb5\u538b\u7f29\u7b56\u7565\uff1a1) \u7c97\u7c92\u5ea6\u538b\u7f29\uff0c\u4f7f\u7528\u6761\u4ef6\u56f0\u60d1\u5ea6\u8bc6\u522b\u548c\u6392\u5e8f\u51fd\u6570\u7ea7\u5757\uff0c\u4ec5\u4fdd\u7559\u6700\u76f8\u5173\u51fd\u6570\uff1b2) \u7ec6\u7c92\u5ea6\u538b\u7f29\uff0c\u5c06\u4fdd\u7559\u51fd\u6570\u57fa\u4e8e\u56f0\u60d1\u5ea6\u5206\u5272\u6210\u5757\uff0c\u5728\u81ea\u9002\u5e94token\u9884\u7b97\u4e0b\u9009\u62e9\u6700\u4f18\u5b50\u96c6\u4ee5\u6700\u5927\u5316\u76f8\u5173\u6027\u3002", "result": "\u5728\u4ee3\u7801\u8865\u5168\u3001\u6458\u8981\u548c\u95ee\u7b54\u7b49\u591a\u4e2a\u4efb\u52a1\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cLongCodeZip\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u4e0d\u964d\u4f4e\u4efb\u52a1\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u8fbe5.6\u500d\u7684\u538b\u7f29\u6bd4\u3002", "conclusion": "\u901a\u8fc7\u6709\u6548\u51cf\u5c11\u4e0a\u4e0b\u6587\u5927\u5c0f\u540c\u65f6\u4fdd\u7559\u5173\u952e\u4fe1\u606f\uff0cLongCodeZip\u4f7fLLMs\u80fd\u591f\u66f4\u597d\u5730\u6269\u5c55\u5230\u73b0\u5b9e\u4e16\u754c\u7684\u5927\u89c4\u6a21\u4ee3\u7801\u573a\u666f\uff0c\u63d0\u5347\u4e86\u4ee3\u7801\u667a\u80fd\u5e94\u7528\u7684\u6548\u7387\u548c\u80fd\u529b\u3002"}}
{"id": "2510.00449", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00449", "abs": "https://arxiv.org/abs/2510.00449", "authors": ["Koki Ryu", "Hitomi Yanaka"], "title": "Enhancing Rating Prediction with Off-the-Shelf LLMs Using In-Context User Reviews", "comment": "Accepted to EMNLP 2025 PALS Workshop", "summary": "Personalizing the outputs of large language models (LLMs) to align with\nindividual user preferences is an active research area. However, previous\nstudies have mainly focused on classification or ranking tasks and have not\nconsidered Likert-scale rating prediction, a regression task that requires both\nlanguage and mathematical reasoning to be solved effectively. This task has\nsignificant industrial applications, but the utilization of LLMs remains\nunderexplored, particularly regarding the capabilities of off-the-shelf LLMs.\nThis study investigates the performance of off-the-shelf LLMs on rating\nprediction, providing different in-context information. Through comprehensive\nexperiments with eight models across three datasets, we demonstrate that\nuser-written reviews significantly improve the rating prediction performance of\nLLMs. This result is comparable to traditional methods like matrix\nfactorization, highlighting the potential of LLMs as a promising solution for\nthe cold-start problem. We also find that the reviews for concrete items are\nmore effective than general preference descriptions that are not based on any\nspecific item. Furthermore, we discover that prompting LLMs to first generate a\nhypothetical review enhances the rating prediction performance. Our code is\navailable at https://github.com/ynklab/rating-prediction-with-reviews.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u4e86\u73b0\u6210\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bc4\u5206\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u7528\u6237\u8bc4\u8bba\u80fd\u663e\u8457\u63d0\u5347\u9884\u6d4b\u6027\u80fd\uff0c\u6548\u679c\u4e0e\u4f20\u7edf\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\u76f8\u5f53\uff0c\u5e76\u80fd\u89e3\u51b3\u51b7\u542f\u52a8\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5206\u7c7b\u6216\u6392\u5e8f\u4efb\u52a1\uff0c\u800c\u5ffd\u7565\u4e86\u9700\u8981\u8bed\u8a00\u548c\u6570\u5b66\u63a8\u7406\u7684Likert\u8bc4\u5206\u9884\u6d4b\u4efb\u52a1\uff0c\u8be5\u4efb\u52a1\u5177\u6709\u91cd\u8981\u5de5\u4e1a\u5e94\u7528\u4ef7\u503c\uff0c\u4f46\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6b64\u9886\u57df\u7684\u6f5c\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u4f7f\u75288\u4e2a\u73b0\u6210\u5927\u8bed\u8a00\u6a21\u578b\u57283\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7efc\u5408\u5b9e\u9a8c\uff0c\u63d0\u4f9b\u4e0d\u540c\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5305\u62ec\u7528\u6237\u8bc4\u8bba\u548c\u504f\u597d\u63cf\u8ff0\uff0c\u5e76\u5c1d\u8bd5\u8ba9\u6a21\u578b\u9996\u5148\u751f\u6210\u5047\u8bbe\u6027\u8bc4\u8bba\u3002", "result": "\u7528\u6237\u64b0\u5199\u7684\u8bc4\u8bba\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u5206\u9884\u6d4b\u6027\u80fd\uff0c\u6548\u679c\u4e0e\u4f20\u7edf\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\u76f8\u5f53\uff1b\u57fa\u4e8e\u5177\u4f53\u7269\u54c1\u7684\u8bc4\u8bba\u6bd4\u4e00\u822c\u504f\u597d\u63cf\u8ff0\u66f4\u6709\u6548\uff1b\u9996\u5148\u751f\u6210\u5047\u8bbe\u6027\u8bc4\u8bba\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "\u73b0\u6210\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bc4\u5206\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u7528\u6237\u8bc4\u8bba\u662f\u63d0\u5347\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\uff0c\u8fd9\u4e3a\u89e3\u51b3\u51b7\u542f\u52a8\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.00482", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00482", "abs": "https://arxiv.org/abs/2510.00482", "authors": ["Yawen Xue", "Masaya Tsunokake", "Yuta Koreeda", "Ekant Muljibhai Amin", "Takashi Sumiyoshi", "Yasuhiro Sogawa"], "title": "Agent Fine-tuning through Distillation for Domain-specific LLMs in Microdomains", "comment": "Accepted by AIxB 2025", "summary": "Agentic large language models (LLMs) have become prominent for autonomously\ninteracting with external environments and performing multi-step reasoning\ntasks. Most approaches leverage these capabilities via in-context learning with\nfew-shot prompts, but this often results in lengthy inputs and higher\ncomputational costs. Agent fine-tuning offers an alternative by enabling LLMs\nto internalize procedural reasoning and domain-specific knowledge through\ntraining on relevant data and demonstration trajectories. While prior studies\nhave focused on general domains, their effectiveness in specialized technical\nmicrodomains remains unclear. This paper explores agent fine-tuning for domain\nadaptation within Hitachi's JP1 middleware, a microdomain for specialized IT\noperations. We fine-tuned LLMs using JP1-specific datasets derived from domain\nmanuals and distilled reasoning trajectories generated by LLMs themselves,\nenhancing decision making accuracy and search efficiency. During inference, we\nused an agentic prompt with retrieval-augmented generation and introduced a\ncontext-answer extractor to improve information relevance. On JP1 certification\nexam questions, our method achieved a 14% performance improvement over the base\nmodel, demonstrating the potential of agent fine-tuning for domain-specific\nreasoning in complex microdomains.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u7d22\u4e86\u5728\u65e5\u7acbJP1\u4e2d\u95f4\u4ef6\u8fd9\u4e00\u4e13\u4e1aIT\u8fd0\u7ef4\u5fae\u9886\u57df\u4e2d\uff0c\u901a\u8fc7\u4ee3\u7406\u5fae\u8c03\u65b9\u6cd5\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9886\u57df\u9002\u5e94\u80fd\u529b\uff0c\u5728JP1\u8ba4\u8bc1\u8003\u8bd5\u95ee\u9898\u4e0a\u6bd4\u57fa\u7840\u6a21\u578b\u6027\u80fd\u63d0\u534714%\u3002", "motivation": "\u73b0\u6709\u4ee3\u7406\u5927\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u4f46\u5b58\u5728\u8f93\u5165\u5197\u957f\u3001\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002\u4ee3\u7406\u5fae\u8c03\u80fd\u8ba9\u6a21\u578b\u901a\u8fc7\u8bad\u7ec3\u5185\u5316\u7a0b\u5e8f\u6027\u63a8\u7406\u548c\u9886\u57df\u77e5\u8bc6\uff0c\u4f46\u5728\u4e13\u4e1a\u5fae\u9886\u57df\u4e2d\u7684\u6709\u6548\u6027\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u4f7f\u7528JP1\u7279\u5b9a\u6570\u636e\u96c6\uff08\u9886\u57df\u624b\u518c\u548cLLM\u751f\u6210\u7684\u63a8\u7406\u8f68\u8ff9\uff09\u5bf9LLM\u8fdb\u884c\u5fae\u8c03\uff0c\u63a8\u7406\u65f6\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u4e0a\u4e0b\u6587-\u7b54\u6848\u63d0\u53d6\u5668\u6765\u63d0\u9ad8\u4fe1\u606f\u76f8\u5173\u6027\u3002", "result": "\u5728JP1\u8ba4\u8bc1\u8003\u8bd5\u95ee\u9898\u4e0a\uff0c\u8be5\u65b9\u6cd5\u6bd4\u57fa\u7840\u6a21\u578b\u6027\u80fd\u63d0\u534714%\uff0c\u8bc1\u660e\u4e86\u4ee3\u7406\u5fae\u8c03\u5728\u590d\u6742\u5fae\u9886\u57df\u4e2d\u9886\u57df\u7279\u5b9a\u63a8\u7406\u7684\u6f5c\u529b\u3002", "conclusion": "\u4ee3\u7406\u5fae\u8c03\u662f\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e13\u4e1a\u5fae\u9886\u57df\u4e2d\u63a8\u7406\u80fd\u529b\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u6280\u672f\u9886\u57df\u5982IT\u8fd0\u7ef4\u4e2d\u5177\u6709\u663e\u8457\u6548\u679c\u3002"}}
{"id": "2510.00496", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00496", "abs": "https://arxiv.org/abs/2510.00496", "authors": ["Pengzhou Cheng", "Lingzhong Dong", "Zeng Wu", "Zongru Wu", "Xiangru Tang", "Chengwei Qin", "Zhuosheng Zhang", "Gongshen Liu"], "title": "Agent-ScanKit: Unraveling Memory and Reasoning of Multimodal Agents via Sensitivity Perturbations", "comment": "23 pages, 10 figures, 7 tables", "summary": "Although numerous strategies have recently been proposed to enhance the\nautonomous interaction capabilities of multimodal agents in graphical user\ninterface (GUI), their reliability remains limited when faced with complex or\nout-of-domain tasks. This raises a fundamental question: Are existing\nmultimodal agents reasoning spuriously? In this paper, we propose\n\\textbf{Agent-ScanKit}, a systematic probing framework to unravel the memory\nand reasoning capabilities of multimodal agents under controlled perturbations.\nSpecifically, we introduce three orthogonal probing paradigms: visual-guided,\ntext-guided, and structure-guided, each designed to quantify the contributions\nof memorization and reasoning without requiring access to model internals. In\nfive publicly available GUI benchmarks involving 18 multimodal agents, the\nresults demonstrate that mechanical memorization often outweighs systematic\nreasoning. Most of the models function predominantly as retrievers of\ntraining-aligned knowledge, exhibiting limited generalization. Our findings\nunderscore the necessity of robust reasoning modeling for multimodal agents in\nreal-world scenarios, offering valuable insights toward the development of\nreliable multimodal agents.", "AI": {"tldr": "\u63d0\u51fa\u4e86Agent-ScanKit\u6846\u67b6\u6765\u63a2\u6d4b\u591a\u6a21\u6001\u4ee3\u7406\u7684\u8bb0\u5fc6\u548c\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u5728GUI\u4efb\u52a1\u4e2d\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u673a\u68b0\u8bb0\u5fc6\u800c\u975e\u7cfb\u7edf\u63a8\u7406\u3002", "motivation": "\u73b0\u6709GUI\u591a\u6a21\u6001\u4ee3\u7406\u5728\u590d\u6742\u6216\u8de8\u57df\u4efb\u52a1\u4e2d\u53ef\u9760\u6027\u6709\u9650\uff0c\u9700\u8981\u63a2\u7a76\u5176\u662f\u5426\u8fdb\u884c\u865a\u5047\u63a8\u7406\u3002", "method": "\u63d0\u51faAgent-ScanKit\u6846\u67b6\uff0c\u5305\u542b\u89c6\u89c9\u5f15\u5bfc\u3001\u6587\u672c\u5f15\u5bfc\u548c\u7ed3\u6784\u5f15\u5bfc\u4e09\u79cd\u6b63\u4ea4\u63a2\u6d4b\u8303\u5f0f\uff0c\u91cf\u5316\u8bb0\u5fc6\u548c\u63a8\u7406\u7684\u8d21\u732e\u3002", "result": "\u57285\u4e2a\u516c\u5f00GUI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c18\u4e2a\u591a\u6a21\u6001\u4ee3\u7406\u4e3b\u8981\u4f5c\u4e3a\u8bad\u7ec3\u5bf9\u9f50\u77e5\u8bc6\u7684\u68c0\u7d22\u5668\uff0c\u8868\u73b0\u51fa\u6709\u9650\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u591a\u6a21\u6001\u4ee3\u7406\u9700\u8981\u66f4\u5f3a\u5927\u7684\u63a8\u7406\u5efa\u6a21\u624d\u80fd\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u53ef\u9760\u5e94\u7528\u3002"}}
{"id": "2510.00499", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00499", "abs": "https://arxiv.org/abs/2510.00499", "authors": ["Xingjian Zhao", "Zhe Xu", "Luozhijie Jin", "Yang Wang", "Hanfu Chen", "Yaozhou Jiang", "Ke Chen", "Ruixiao Li", "Mingshu Chen", "Ruiming Wang", "Wenbo Zhang", "Yiyang Zhang", "Donghua Yu", "Yang Gao", "Xiaogui Yang", "Yitian Gong", "Yuanfan Xu", "Qinyuan Cheng", "Zhaoye Fei", "Shimin Li", "Yaqian Zhou", "Xuanjing Huang", "Xipeng Qiu"], "title": "MOSS-Speech: Towards True Speech-to-Speech Models Without Text Guidance", "comment": null, "summary": "Spoken dialogue systems often rely on cascaded pipelines that transcribe,\nprocess, and resynthesize speech. While effective, this design discards\nparalinguistic cues and limits expressivity. Recent end-to-end methods reduce\nlatency and better preserve these cues, yet still rely on text intermediates,\ncreating a fundamental bottleneck. We present MOSS-Speech, a true\nspeech-to-speech large language model that directly understands and generates\nspeech without relying on text guidance. Our approach combines a modality-based\nlayer-splitting architecture with a frozen pre-training strategy, preserving\nthe reasoning and knowledge of pretrained text LLMs while adding native speech\ncapabilities. Experiments show that our model achieves state-of-the-art results\nin spoken question answering and delivers comparable speech-to-speech\nperformance relative to existing text-guided systems, while still maintaining\ncompetitive text performance. By narrowing the gap between text-guided and\ndirect speech generation, our work establishes a new paradigm for expressive\nand efficient end-to-end speech interaction.", "AI": {"tldr": "MOSS-Speech\u662f\u9996\u4e2a\u771f\u6b63\u7684\u8bed\u97f3\u5230\u8bed\u97f3\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u65e0\u9700\u6587\u672c\u4e2d\u95f4\u4ef6\uff0c\u76f4\u63a5\u7406\u89e3\u548c\u751f\u6210\u8bed\u97f3\uff0c\u5728\u4fdd\u7559\u9884\u8bad\u7ec3\u6587\u672cLLM\u63a8\u7406\u80fd\u529b\u7684\u540c\u65f6\u589e\u52a0\u539f\u751f\u8bed\u97f3\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u7ea7\u8054\u8bed\u97f3\u7cfb\u7edf\u4e22\u5f03\u526f\u8bed\u8a00\u7ebf\u7d22\u4e14\u9650\u5236\u8868\u8fbe\u6027\uff0c\u73b0\u6709\u7aef\u5230\u7aef\u65b9\u6cd5\u4ecd\u4f9d\u8d56\u6587\u672c\u4e2d\u95f4\u4ef6\u9020\u6210\u74f6\u9888\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u6a21\u6001\u7684\u5c42\u5206\u5272\u67b6\u6784\u548c\u51bb\u7ed3\u9884\u8bad\u7ec3\u7b56\u7565\uff0c\u7ed3\u5408\u9884\u8bad\u7ec3\u6587\u672cLLM\u7684\u63a8\u7406\u77e5\u8bc6\u4e0e\u539f\u751f\u8bed\u97f3\u80fd\u529b\u3002", "result": "\u5728\u53e3\u8bed\u95ee\u7b54\u4efb\u52a1\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u8bed\u97f3\u5230\u8bed\u97f3\u6027\u80fd\u4e0e\u73b0\u6709\u6587\u672c\u5f15\u5bfc\u7cfb\u7edf\u76f8\u5f53\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u6587\u672c\u6027\u80fd\u3002", "conclusion": "\u7f29\u5c0f\u4e86\u6587\u672c\u5f15\u5bfc\u4e0e\u76f4\u63a5\u8bed\u97f3\u751f\u6210\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u8868\u8fbe\u6027\u5f3a\u4e14\u9ad8\u6548\u7684\u7aef\u5230\u7aef\u8bed\u97f3\u4ea4\u4e92\u5efa\u7acb\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2510.00507", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00507", "abs": "https://arxiv.org/abs/2510.00507", "authors": ["Yurun Chen", "Xavier Hu", "Yuhan Liu", "Ziqi Wang", "Zeyi Liao", "Lin Chen", "Feng Wei", "Yuxi Qian", "Bo Zheng", "Keting Yin", "Shengyu Zhang"], "title": "Graph2Eval: Automatic Multimodal Task Generation for Agents via Knowledge Graphs", "comment": "20 pages, 10 figures", "summary": "As multimodal LLM-driven agents continue to advance in autonomy and\ngeneralization, evaluation based on static datasets can no longer adequately\nassess their true capabilities in dynamic environments and diverse tasks.\nExisting LLM-based synthetic data methods are largely designed for LLM training\nand evaluation, and thus cannot be directly applied to agent tasks that require\ntool use and interactive capabilities. While recent studies have explored\nautomatic agent task generation with LLMs, most efforts remain limited to text\nor image analysis, without systematically modeling multi-step interactions in\nweb environments. To address these challenges, we propose Graph2Eval, a\nknowledge graph-based framework that automatically generates both multimodal\ndocument comprehension tasks and web interaction tasks, enabling comprehensive\nevaluation of agents' reasoning, collaboration, and interactive capabilities.\nIn our approach, knowledge graphs constructed from multi-source external data\nserve as the task space, where we translate semantic relations into structured\nmultimodal tasks using subgraph sampling, task templates, and meta-paths. A\nmulti-stage filtering pipeline based on node reachability, LLM scoring, and\nsimilarity analysis is applied to guarantee the quality and executability of\nthe generated tasks. Furthermore, Graph2Eval supports end-to-end evaluation of\nmultiple agent types (Single-Agent, Multi-Agent, Web Agent) and measures\nreasoning, collaboration, and interaction capabilities. We instantiate the\nframework with Graph2Eval-Bench, a curated dataset of 1,319 tasks spanning\ndocument comprehension and web interaction scenarios. Experiments show that\nGraph2Eval efficiently generates tasks that differentiate agent and model\nperformance, revealing gaps in reasoning, collaboration, and web interaction\nacross different settings and offering a new perspective for agent evaluation.", "AI": {"tldr": "Graph2Eval\u662f\u4e00\u4e2a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u751f\u6210\u591a\u6a21\u6001\u6587\u6863\u7406\u89e3\u548c\u7f51\u9875\u4ea4\u4e92\u4efb\u52a1\uff0c\u4ee5\u5168\u9762\u8bc4\u4f30\u667a\u80fd\u4f53\u7684\u63a8\u7406\u3001\u534f\u4f5c\u548c\u4ea4\u4e92\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eLLM\u7684\u5408\u6210\u6570\u636e\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9LLM\u8bad\u7ec3\u548c\u8bc4\u4f30\u8bbe\u8ba1\uff0c\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u4e8e\u9700\u8981\u5de5\u5177\u4f7f\u7528\u548c\u4ea4\u4e92\u80fd\u529b\u7684\u667a\u80fd\u4f53\u4efb\u52a1\u3002\u73b0\u6709\u7814\u7a76\u5927\u591a\u5c40\u9650\u4e8e\u6587\u672c\u6216\u56fe\u50cf\u5206\u6790\uff0c\u7f3a\u4e4f\u5bf9\u7f51\u9875\u73af\u5883\u4e2d\u591a\u6b65\u4ea4\u4e92\u7684\u7cfb\u7edf\u5efa\u6a21\u3002", "method": "\u4ece\u591a\u6e90\u5916\u90e8\u6570\u636e\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u4f5c\u4e3a\u4efb\u52a1\u7a7a\u95f4\uff0c\u901a\u8fc7\u5b50\u56fe\u91c7\u6837\u3001\u4efb\u52a1\u6a21\u677f\u548c\u5143\u8def\u5f84\u5c06\u8bed\u4e49\u5173\u7cfb\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u591a\u6a21\u6001\u4efb\u52a1\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u8282\u70b9\u53ef\u8fbe\u6027\u3001LLM\u8bc4\u5206\u548c\u76f8\u4f3c\u6027\u5206\u6790\u7684\u591a\u9636\u6bb5\u8fc7\u6ee4\u7ba1\u9053\u4fdd\u8bc1\u4efb\u52a1\u8d28\u91cf\u548c\u53ef\u6267\u884c\u6027\u3002", "result": "\u6784\u5efa\u4e86Graph2Eval-Bench\u6570\u636e\u96c6\uff0c\u5305\u542b1,319\u4e2a\u6db5\u76d6\u6587\u6863\u7406\u89e3\u548c\u7f51\u9875\u4ea4\u4e92\u573a\u666f\u7684\u4efb\u52a1\u3002\u5b9e\u9a8c\u8868\u660eGraph2Eval\u80fd\u6709\u6548\u751f\u6210\u533a\u5206\u667a\u80fd\u4f53\u548c\u6a21\u578b\u6027\u80fd\u7684\u4efb\u52a1\uff0c\u63ed\u793a\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u63a8\u7406\u3001\u534f\u4f5c\u548c\u7f51\u9875\u4ea4\u4e92\u80fd\u529b\u7684\u5dee\u8ddd\u3002", "conclusion": "Graph2Eval\u4e3a\u667a\u80fd\u4f53\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u80fd\u591f\u5168\u9762\u8bc4\u4f30\u591a\u79cd\u667a\u80fd\u4f53\u7c7b\u578b\uff08\u5355\u667a\u80fd\u4f53\u3001\u591a\u667a\u80fd\u4f53\u3001\u7f51\u9875\u667a\u80fd\u4f53\uff09\u7684\u63a8\u7406\u3001\u534f\u4f5c\u548c\u4ea4\u4e92\u80fd\u529b\u3002"}}
{"id": "2510.00508", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00508", "abs": "https://arxiv.org/abs/2510.00508", "authors": ["Yongchao Long", "Xian Wu", "Yingying Zhang", "Xianbin Wen", "Yuxi Zhou", "Shenda Hong"], "title": "Copy-Paste to Mitigate Large Language Model Hallucinations", "comment": null, "summary": "While Retrieval-Augmented Generation (RAG) enables large language models\n(LLMs) to generate contextually grounded responses, contextual faithfulness\nremains challenging as LLMs may not consistently trust provided context,\nleading to hallucinations that undermine reliability. We observe an inverse\ncorrelation between response copying degree and context-unfaithful\nhallucinations on RAGTruth, suggesting that higher copying degrees reduce\nhallucinations by fostering genuine contextual belief. We propose CopyPasteLLM,\nobtained through two-stage high-copying response preference training. We design\nthree prompting methods to enhance copying degree, demonstrating that\nhigh-copying responses achieve superior contextual faithfulness and\nhallucination control. These approaches enable a fully automated pipeline that\ntransforms generated responses into high-copying preference data for training\nCopyPasteLLM. On FaithEval, ConFiQA and PubMedQA, CopyPasteLLM achieves best\nperformance in both counterfactual and original contexts, remarkably with 12.2%\nto 24.5% accuracy improvements on FaithEval over the best baseline, while\nrequiring only 365 training samples -- 1/50th of baseline data. To elucidate\nCopyPasteLLM's effectiveness, we propose the Context-Parameter Copying\nCapturing algorithm. Interestingly, this reveals that CopyPasteLLM recalibrates\nreliance on internal parametric knowledge rather than external knowledge during\ngeneration. All codes are available at\nhttps://github.com/longyongchao/CopyPasteLLM", "AI": {"tldr": "CopyPasteLLM\u901a\u8fc7\u4e24\u9636\u6bb5\u9ad8\u590d\u5236\u54cd\u5e94\u504f\u597d\u8bad\u7ec3\u63d0\u5347\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e2d\u7684\u4e0a\u4e0b\u6587\u5fe0\u5b9e\u5ea6\uff0c\u51cf\u5c11\u5e7b\u89c9\u3002\u8be5\u65b9\u6cd5\u4ec5\u9700365\u4e2a\u8bad\u7ec3\u6837\u672c\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e2dLLMs\u4e0d\u4fe1\u4efb\u63d0\u4f9b\u4e0a\u4e0b\u6587\u5bfc\u81f4\u7684\u4e0a\u4e0b\u6587\u4e0d\u5fe0\u5b9e\u548c\u5e7b\u89c9\u95ee\u9898\uff0c\u89c2\u5bdf\u5230\u54cd\u5e94\u590d\u5236\u7a0b\u5ea6\u4e0e\u4e0a\u4e0b\u6587\u4e0d\u5fe0\u5b9e\u5e7b\u89c9\u5b58\u5728\u8d1f\u76f8\u5173\u3002", "method": "\u63d0\u51faCopyPasteLLM\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u9ad8\u590d\u5236\u54cd\u5e94\u504f\u597d\u8bad\u7ec3\uff0c\u8bbe\u8ba1\u4e09\u79cd\u63d0\u793a\u65b9\u6cd5\u589e\u5f3a\u590d\u5236\u7a0b\u5ea6\uff0c\u6784\u5efa\u5168\u81ea\u52a8\u7ba1\u9053\u5c06\u751f\u6210\u54cd\u5e94\u8f6c\u6362\u4e3a\u9ad8\u590d\u5236\u504f\u597d\u6570\u636e\u3002", "result": "\u5728FaithEval\u3001ConFiQA\u548cPubMedQA\u4e0a\u53d6\u5f97\u6700\u4f73\u6027\u80fd\uff0cFaithEval\u51c6\u786e\u7387\u6bd4\u6700\u4f73\u57fa\u7ebf\u63d0\u534712.2%\u81f324.5%\uff0c\u4ec5\u9700365\u4e2a\u8bad\u7ec3\u6837\u672c\uff08\u57fa\u7ebf\u6570\u636e\u76841/50\uff09\u3002", "conclusion": "CopyPasteLLM\u901a\u8fc7\u91cd\u65b0\u6821\u51c6\u5bf9\u5185\u90e8\u53c2\u6570\u77e5\u8bc6\u7684\u4f9d\u8d56\u800c\u975e\u5916\u90e8\u77e5\u8bc6\u6765\u63d0\u5347\u4e0a\u4e0b\u6587\u5fe0\u5b9e\u5ea6\uff0c\u9ad8\u590d\u5236\u54cd\u5e94\u80fd\u6709\u6548\u63a7\u5236\u5e7b\u89c9\u5e76\u6539\u5584\u53ef\u9760\u6027\u3002"}}
{"id": "2510.00510", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00510", "abs": "https://arxiv.org/abs/2510.00510", "authors": ["Jiarun Liu", "Shiyue Xu", "Shangkun Liu", "Yang Li", "Wen Liu", "Min Liu", "Xiaoqing Zhou", "Hanmin Wang", "Shilin Jia", "zhen Wang", "Shaohua Tian", "Hanhao Li", "Junbo Zhang", "Yongli Yu", "Peng Cao", "Haofen Wang"], "title": "JoyAgent-JDGenie: Technical Report on the GAIA", "comment": null, "summary": "Large Language Models are increasingly deployed as autonomous agents for\ncomplex real-world tasks, yet existing systems often focus on isolated\nimprovements without a unifying design for robustness and adaptability. We\npropose a generalist agent architecture that integrates three core components:\na collective multi-agent framework combining planning and execution agents with\ncritic model voting, a hierarchical memory system spanning working, semantic,\nand procedural layers, and a refined tool suite for search, code execution, and\nmultimodal parsing. Evaluated on a comprehensive benchmark, our framework\nconsistently outperforms open-source baselines and approaches the performance\nof proprietary systems. These results demonstrate the importance of\nsystem-level integration and highlight a path toward scalable, resilient, and\nadaptive AI assistants capable of operating across diverse domains and tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u6574\u5408\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u3001\u5206\u5c42\u8bb0\u5fc6\u7cfb\u7edf\u548c\u5de5\u5177\u5957\u4ef6\uff0c\u5728\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u5f00\u6e90\u57fa\u7ebf\u5e76\u63a5\u8fd1\u4e13\u6709\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7cfb\u7edf\u901a\u5e38\u4e13\u6ce8\u4e8e\u5b64\u7acb\u6539\u8fdb\uff0c\u7f3a\u4e4f\u7edf\u4e00\u8bbe\u8ba1\u6765\u786e\u4fdd\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\uff0c\u800c\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u90e8\u7f72\u4e3a\u5904\u7406\u590d\u6742\u73b0\u5b9e\u4efb\u52a1\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u3002", "method": "\u96c6\u6210\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u96c6\u4f53\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff08\u89c4\u5212\u4e0e\u6267\u884c\u667a\u80fd\u4f53\u7ed3\u5408\u6279\u5224\u6a21\u578b\u6295\u7968\uff09\u3001\u5206\u5c42\u8bb0\u5fc6\u7cfb\u7edf\uff08\u5de5\u4f5c\u8bb0\u5fc6\u3001\u8bed\u4e49\u8bb0\u5fc6\u548c\u7a0b\u5e8f\u8bb0\u5fc6\uff09\u3001\u4ee5\u53ca\u7528\u4e8e\u641c\u7d22\u3001\u4ee3\u7801\u6267\u884c\u548c\u591a\u6a21\u6001\u89e3\u6790\u7684\u7cbe\u70bc\u5de5\u5177\u5957\u4ef6\u3002", "result": "\u5728\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u6846\u67b6\u59cb\u7ec8\u4f18\u4e8e\u5f00\u6e90\u57fa\u7ebf\uff0c\u5e76\u63a5\u8fd1\u4e13\u6709\u7cfb\u7edf\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u8bc1\u660e\u4e86\u7cfb\u7edf\u7ea7\u96c6\u6210\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u6784\u5efa\u53ef\u6269\u5c55\u3001\u6709\u5f39\u6027\u4e14\u80fd\u9002\u5e94\u4e0d\u540c\u9886\u57df\u548c\u4efb\u52a1\u7684AI\u52a9\u624b\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2510.00514", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00514", "abs": "https://arxiv.org/abs/2510.00514", "authors": ["Samuel Pfisterer", "Florian Gr\u00f6tschla", "Luca A. Lanzend\u00f6rfer", "Florian Yan", "Roger Wattenhofer"], "title": "EuroSpeech: A Multilingual Speech Corpus", "comment": "Published in the 39th Conference on Neural Information Processing\n  Systems (NeurIPS 2025) Track on Datasets and Benchmark", "summary": "Recent progress in speech processing has highlighted that high-quality\nperformance across languages requires substantial training data for each\nindividual language. While existing multilingual datasets cover many languages,\nthey often contain insufficient data for most languages. Thus, trained models\nperform poorly on the majority of the supported languages. Our work addresses\nthis challenge by introducing a scalable pipeline for constructing speech\ndatasets from parliamentary recordings. The proposed pipeline includes robust\ncomponents for media retrieval and a two-stage alignment algorithm designed to\nhandle non-verbatim transcripts and long-form audio. Applying this pipeline to\nrecordings from 22 European parliaments, we extract over 61k hours of aligned\nspeech segments, achieving substantial per-language coverage with 19 languages\nexceeding 1k hours and 22 languages exceeding 500 hours of high-quality speech\ndata. We obtain an average 41.8\\% reduction in word error rates over baselines\nwhen finetuning an existing ASR model on our dataset, demonstrating the\nusefulness of our approach.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u4ece\u8bae\u4f1a\u5f55\u97f3\u6784\u5efa\u8bed\u97f3\u6570\u636e\u96c6\u7684\u53ef\u6269\u5c55\u6d41\u7a0b\uff0c\u5305\u542b\u5a92\u4f53\u68c0\u7d22\u548c\u4e24\u9636\u6bb5\u5bf9\u9f50\u7b97\u6cd5\uff0c\u5e94\u7528\u4e8e22\u4e2a\u6b27\u6d32\u8bae\u4f1a\uff0c\u63d0\u53d6\u8d85\u8fc761k\u5c0f\u65f6\u5bf9\u9f50\u8bed\u97f3\uff0c\u663e\u8457\u63d0\u5347ASR\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u591a\u8bed\u8a00\u6570\u636e\u96c6\u5bf9\u5927\u591a\u6570\u8bed\u8a00\u6570\u636e\u4e0d\u8db3\uff0c\u5bfc\u81f4\u8bad\u7ec3\u6a21\u578b\u5728\u591a\u6570\u652f\u6301\u8bed\u8a00\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u6784\u5efa\u5305\u542b\u5a92\u4f53\u68c0\u7d22\u548c\u4e24\u9636\u6bb5\u5bf9\u9f50\u7b97\u6cd5\u7684\u53ef\u6269\u5c55\u6d41\u7a0b\uff0c\u5904\u7406\u975e\u9010\u5b57\u8f6c\u5f55\u548c\u957f\u97f3\u9891\uff0c\u5e94\u7528\u4e8e22\u4e2a\u6b27\u6d32\u8bae\u4f1a\u5f55\u97f3\u3002", "result": "\u63d0\u53d6\u8d85\u8fc761k\u5c0f\u65f6\u5bf9\u9f50\u8bed\u97f3\uff0c19\u79cd\u8bed\u8a00\u8d85\u8fc71k\u5c0f\u65f6\uff0c22\u79cd\u8bed\u8a00\u8d85\u8fc7500\u5c0f\u65f6\uff0c\u5fae\u8c03\u73b0\u6709ASR\u6a21\u578b\u4f7f\u8bcd\u9519\u8bef\u7387\u5e73\u5747\u964d\u4f4e41.8%\u3002", "conclusion": "\u8be5\u6d41\u7a0b\u80fd\u6709\u6548\u6784\u5efa\u9ad8\u8d28\u91cf\u591a\u8bed\u8a00\u8bed\u97f3\u6570\u636e\u96c6\uff0c\u663e\u8457\u63d0\u5347ASR\u6027\u80fd\u3002"}}
{"id": "2510.00526", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00526", "abs": "https://arxiv.org/abs/2510.00526", "authors": ["Gaotang Li", "Ruizhong Qiu", "Xiusi Chen", "Heng Ji", "Hanghang Tong"], "title": "Beyond Log Likelihood: Probability-Based Objectives for Supervised Fine-Tuning across the Model Capability Continuum", "comment": "23 pages, 4 figures", "summary": "Supervised fine-tuning (SFT) is the standard approach for post-training large\nlanguage models (LLMs), yet it often shows limited generalization. We trace\nthis limitation to its default training objective: negative log likelihood\n(NLL). While NLL is classically optimal when training from scratch,\npost-training operates in a different paradigm and could violate its optimality\nassumptions, where models already encode task-relevant priors and supervision\ncan be long and noisy. To this end, we study a general family of\nprobability-based objectives and characterize their effectiveness under\ndifferent conditions. Through comprehensive experiments and extensive ablation\nstudies across 7 model backbones, 14 benchmarks, and 3 domains, we uncover a\ncritical dimension that governs objective behavior: the model-capability\ncontinuum. Near the model-strong end, prior-leaning objectives that downweight\nlow-probability tokens (e.g., $-p$, $-p^{10}$, thresholded variants)\nconsistently outperform NLL; toward the model-weak end, NLL dominates; in\nbetween, no single objective prevails. Our theoretical analysis further\nelucidates how objectives trade places across the continuum, providing a\nprincipled foundation for adapting objectives to model capability. Our code is\navailable at https://github.com/GaotangLi/Beyond-Log-Likelihood.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u540e\u8bad\u7ec3\u9636\u6bb5\uff0c\u8d1f\u5bf9\u6570\u4f3c\u7136\uff08NLL\uff09\u76ee\u6807\u51fd\u6570\u5b58\u5728\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u5e94\u6839\u636e\u6a21\u578b\u80fd\u529b\u8fde\u7eed\u4f53\u9009\u62e9\u4e0d\u540c\u7684\u6982\u7387\u76ee\u6807\u51fd\u6570\u3002", "motivation": "\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u662f\u540e\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6807\u51c6\u65b9\u6cd5\uff0c\u4f46\u5176\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u662f\u56e0\u4e3aNLL\u76ee\u6807\u5728\u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3\u65f6\u662f\u6700\u4f18\u7684\uff0c\u4f46\u5728\u540e\u8bad\u7ec3\u9636\u6bb5\u53ef\u80fd\u8fdd\u53cd\u5176\u6700\u4f18\u6027\u5047\u8bbe\uff0c\u56e0\u4e3a\u6a21\u578b\u5df2\u7ecf\u7f16\u7801\u4e86\u4efb\u52a1\u76f8\u5173\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u4e14\u76d1\u7763\u4fe1\u53f7\u53ef\u80fd\u5197\u957f\u4e14\u5608\u6742\u3002", "method": "\u7814\u7a76\u4e86\u4e00\u7c7b\u57fa\u4e8e\u6982\u7387\u7684\u76ee\u6807\u51fd\u6570\u65cf\uff0c\u901a\u8fc77\u4e2a\u6a21\u578b\u9aa8\u5e72\u300114\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c3\u4e2a\u9886\u57df\u7684\u7efc\u5408\u5b9e\u9a8c\u548c\u6d88\u878d\u7814\u7a76\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u6761\u4ef6\u4e0b\u76ee\u6807\u51fd\u6570\u7684\u6709\u6548\u6027\u3002\u91cd\u70b9\u5173\u6ce8\u6a21\u578b\u80fd\u529b\u8fde\u7eed\u4f53\u8fd9\u4e00\u5173\u952e\u7ef4\u5ea6\u3002", "result": "\u53d1\u73b0\u76ee\u6807\u51fd\u6570\u7684\u884c\u4e3a\u53d7\u6a21\u578b\u80fd\u529b\u8fde\u7eed\u4f53\u652f\u914d\uff1a\u5728\u6a21\u578b\u80fd\u529b\u5f3a\u7684\u4e00\u7aef\uff0c\u503e\u5411\u4e8e\u5148\u9a8c\u7684\u6982\u7387\u76ee\u6807\u51fd\u6570\uff08\u5982$-p$\u3001$-p^{10}$\u53ca\u5176\u9608\u503c\u53d8\u4f53\uff09\u6301\u7eed\u4f18\u4e8eNLL\uff1b\u5728\u6a21\u578b\u80fd\u529b\u5f31\u7684\u4e00\u7aef\uff0cNLL\u5360\u4e3b\u5bfc\uff1b\u5728\u4e2d\u95f4\u533a\u57df\uff0c\u6ca1\u6709\u5355\u4e00\u76ee\u6807\u51fd\u6570\u5360\u4f18\u3002", "conclusion": "\u7406\u8bba\u5206\u6790\u9610\u660e\u4e86\u76ee\u6807\u51fd\u6570\u5728\u8fde\u7eed\u4f53\u4e0a\u7684\u6743\u8861\u5173\u7cfb\uff0c\u4e3a\u6839\u636e\u6a21\u578b\u80fd\u529b\u81ea\u9002\u5e94\u9009\u62e9\u76ee\u6807\u51fd\u6570\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002\u5efa\u8bae\u5728\u540e\u8bad\u7ec3\u9636\u6bb5\u5e94\u6839\u636e\u6a21\u578b\u80fd\u529b\u9009\u62e9\u5408\u9002\u7684\u76ee\u6807\u51fd\u6570\uff0c\u800c\u975e\u9ed8\u8ba4\u4f7f\u7528NLL\u3002"}}
{"id": "2510.00536", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00536", "abs": "https://arxiv.org/abs/2510.00536", "authors": ["Kung-Hsiang Huang", "Haoyi Qiu", "Yutong Dai", "Caiming Xiong", "Chien-Sheng Wu"], "title": "GUI-KV: Efficient GUI Agents via KV Cache with Spatio-Temporal Awareness", "comment": null, "summary": "Graphical user interface (GUI) agents built on vision-language models have\nemerged as a promising approach to automate human-computer workflows. However,\nthey also face the inefficiency challenge as they process long sequences of\nhigh-resolution screenshots and solving long-horizon tasks, making inference\nslow, costly and memory-bound. While key-value (KV) caching can mitigate this,\nstoring the full cache is prohibitive for image-heavy contexts. Existing\ncache-compression methods are sub-optimal as they do not account for the\nspatial and temporal redundancy of GUIs. In this work, we first analyze\nattention patterns in GUI agent workloads and find that, unlike in natural\nimages, attention sparsity is uniformly high across all transformer layers.\nThis insight motivates a simple uniform budget allocation strategy, which we\nshow empirically outperforms more complex layer-varying schemes. Building on\nthis, we introduce GUI-KV, a plug-and-play KV cache compression method for GUI\nagents that requires no retraining. GUI-KV combines two novel techniques: (i)\nspatial saliency guidance, which augments attention scores with the L2 norm of\nhidden states to better preserve semantically important visual tokens, and (ii)\ntemporal redundancy scoring, which projects previous frames' keys onto the\ncurrent frame's key subspace to preferentially prune redundant history. Across\nstandard GUI agent benchmarks and models, GUI-KV outperforms competitive KV\ncompression baselines, closely matching full-cache accuracy at modest budgets.\nNotably, in a 5-screenshot setting on the AgentNetBench benchmark, GUI-KV\nreduces decoding FLOPs by 38.9% while increasing step accuracy by 4.1% over the\nfull-cache baseline. These results demonstrate that exploiting GUI-specific\nredundancies enables efficient and reliable agent performance.", "AI": {"tldr": "GUI-KV\uff1a\u4e00\u79cd\u9488\u5bf9GUI\u4ee3\u7406\u7684KV\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\uff0c\u901a\u8fc7\u7a7a\u95f4\u663e\u8457\u6027\u5f15\u5bfc\u548c\u65f6\u95f4\u5197\u4f59\u8bc4\u5206\u6280\u672f\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "GUI\u4ee3\u7406\u5904\u7406\u9ad8\u5206\u8fa8\u7387\u622a\u56fe\u65f6\u9762\u4e34\u6548\u7387\u6311\u6218\uff0c\u73b0\u6709\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528GUI\u7684\u7a7a\u95f4\u548c\u65f6\u95f4\u5197\u4f59\u7279\u6027\u3002", "method": "\u7ed3\u5408\u7a7a\u95f4\u663e\u8457\u6027\u5f15\u5bfc\uff08\u901a\u8fc7\u9690\u85cf\u72b6\u6001L2\u8303\u6570\u589e\u5f3a\u6ce8\u610f\u529b\u5206\u6570\uff09\u548c\u65f6\u95f4\u5197\u4f59\u8bc4\u5206\uff08\u5c06\u5386\u53f2\u5e27\u952e\u6295\u5f71\u5230\u5f53\u524d\u5e27\u952e\u5b50\u7a7a\u95f4\uff09\uff0c\u91c7\u7528\u7edf\u4e00\u7684\u9884\u7b97\u5206\u914d\u7b56\u7565\u3002", "result": "\u5728AgentNetBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c5\u622a\u56fe\u8bbe\u7f6e\u4e0b\u51cf\u5c1138.9%\u89e3\u7801FLOPs\uff0c\u540c\u65f6\u63d0\u9ad84.1%\u6b65\u9aa4\u51c6\u786e\u7387\u3002", "conclusion": "\u5229\u7528GUI\u7279\u5b9a\u5197\u4f59\u7279\u6027\u53ef\u5b9e\u73b0\u9ad8\u6548\u53ef\u9760\u7684\u4ee3\u7406\u6027\u80fd\uff0cGUI-KV\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u6709\u6548\u538b\u7f29KV\u7f13\u5b58\u3002"}}
{"id": "2510.00546", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00546", "abs": "https://arxiv.org/abs/2510.00546", "authors": ["Minjae Oh", "Sangjun Song", "Seungkyu Lee", "Sungmin Jo", "Yohan Jo"], "title": "ThinkBrake: Mitigating Overthinking in Tool Reasoning", "comment": null, "summary": "Small reasoning models (SRMs) often overthink during tool use: they reach a\ncorrect tool-argument configuration, then continue reasoning and overwrite it\nwith an incorrect final call. We diagnose overthinking via oracle rollouts that\ninject </think> at sentence boundaries. On the Berkeley Function Calling\nLeaderboard (BFCL), this oracle termination lifts average accuracy from 85.8\\%\nto 94.2\\% while reducing tokens by 80-94\\%, revealing substantial recoverable\nheadroom and potential redundant reasoning. While prior work on concise\nreasoning has largely targeted mathematics, tool reasoning remains\nunderexplored. We adapt various early-termination baselines to tool use and\nintroduce ThinkBrake, a training-free decoding heuristic. ThinkBrake monitors\nthe log-probability margin between </think> and the current top token at\nsentence boundaries and triggers termination when this margin becomes small.\nAcross BFCL's single turn, non-live and live splits, ThinkBrake preserves or\nimproves accuracy while reducing tokens up to 25\\%, outperforming various\nbaselines.", "AI": {"tldr": "\u8be5\u8bba\u6587\u53d1\u73b0\u5c0f\u63a8\u7406\u6a21\u578b\u5728\u5de5\u5177\u4f7f\u7528\u65f6\u5b58\u5728\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u63d0\u51fa\u4e86ThinkBrake\u89e3\u7801\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u901a\u8fc7\u76d1\u63a7\u53e5\u5b50\u8fb9\u754c\u5904\u7684\u6982\u7387\u5dee\u5f02\u6765\u89e6\u53d1\u63d0\u524d\u7ec8\u6b62\uff0c\u5728\u4fdd\u6301\u6216\u63d0\u9ad8\u51c6\u786e\u7387\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u63a8\u7406token\u6570\u91cf\u3002", "motivation": "\u5c0f\u63a8\u7406\u6a21\u578b\u5728\u5de5\u5177\u4f7f\u7528\u65f6\u7ecf\u5e38\u8fc7\u5ea6\u601d\u8003\uff1a\u5b83\u4eec\u5df2\u7ecf\u8fbe\u5230\u4e86\u6b63\u786e\u7684\u5de5\u5177\u53c2\u6570\u914d\u7f6e\uff0c\u4f46\u7ee7\u7eed\u63a8\u7406\u5e76\u7528\u9519\u8bef\u7684\u6700\u7ec8\u8c03\u7528\u8986\u76d6\u5b83\u3002\u8fd9\u79cd\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\u5728\u5de5\u5177\u63a8\u7406\u9886\u57df\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u901a\u8fc7oracle rollout\u5728\u53e5\u5b50\u8fb9\u754c\u6ce8\u5165</think>\u6765\u8bca\u65ad\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86ThinkBrake\u8bad\u7ec3\u65e0\u5173\u7684\u89e3\u7801\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u76d1\u63a7\u53e5\u5b50\u8fb9\u754c\u5904</think>\u4e0e\u5f53\u524dtop token\u4e4b\u95f4\u7684\u5bf9\u6570\u6982\u7387\u5dee\u5f02\uff0c\u5f53\u5dee\u5f02\u53d8\u5c0f\u65f6\u89e6\u53d1\u7ec8\u6b62\u3002", "result": "\u5728Berkeley Function Calling Leaderboard\u4e0a\uff0coracle\u7ec8\u6b62\u5c06\u5e73\u5747\u51c6\u786e\u7387\u4ece85.8%\u63d0\u5347\u523094.2%\uff0c\u540c\u65f6\u51cf\u5c1180-94%\u7684token\u3002ThinkBrake\u5728\u5355\u8f6e\u3001\u975e\u5b9e\u65f6\u548c\u5b9e\u65f6\u5206\u5272\u4e2d\u4fdd\u6301\u6216\u63d0\u9ad8\u51c6\u786e\u7387\uff0c\u540c\u65f6\u51cf\u5c11\u9ad8\u8fbe25%\u7684token\uff0c\u4f18\u4e8e\u5404\u79cd\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8fc7\u5ea6\u601d\u8003\u662f\u5c0f\u63a8\u7406\u6a21\u578b\u5de5\u5177\u4f7f\u7528\u4e2d\u7684\u663e\u8457\u95ee\u9898\uff0c\u901a\u8fc7\u9002\u5f53\u7684\u63d0\u524d\u7ec8\u6b62\u7b56\u7565\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\uff0cThinkBrake\u65b9\u6cd5\u4e3a\u6b64\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.00567", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00567", "abs": "https://arxiv.org/abs/2510.00567", "authors": ["Yubo Xie", "Chenkai Wang", "Zongyang Ma", "Fahui Miao"], "title": "Are Large Language Models Chronically Online Surfers? A Dataset for Chinese Internet Meme Explanation", "comment": "Accepted to EMNLP 2025 Main Conference. 22 pages, 3 figures, 13\n  tables. GitHub: github.com/yuboxie/chime", "summary": "Large language models (LLMs) are trained on vast amounts of text from the\nInternet, but do they truly understand the viral content that rapidly spreads\nonline -- commonly known as memes? In this paper, we introduce CHIME, a dataset\nfor CHinese Internet Meme Explanation. The dataset comprises popular\nphrase-based memes from the Chinese Internet, annotated with detailed\ninformation on their meaning, origin, example sentences, types, etc. To\nevaluate whether LLMs understand these memes, we designed two tasks. In the\nfirst task, we assessed the models' ability to explain a given meme, identify\nits origin, and generate appropriate example sentences. The results show that\nwhile LLMs can explain the meanings of some memes, their performance declines\nsignificantly for culturally and linguistically nuanced meme types.\nAdditionally, they consistently struggle to provide accurate origins for the\nmemes. In the second task, we created a set of multiple-choice questions (MCQs)\nrequiring LLMs to select the most appropriate meme to fill in a blank within a\ncontextual sentence. While the evaluated models were able to provide correct\nanswers, their performance remains noticeably below human levels. We have made\nCHIME public and hope it will facilitate future research on computational meme\nunderstanding.", "AI": {"tldr": "\u63d0\u51fa\u4e86CHIME\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30LLMs\u5bf9\u4e2d\u6587\u7f51\u7edc\u6d41\u884c\u8bed\u7684\u7406\u89e3\u80fd\u529b\uff0c\u53d1\u73b0LLMs\u5728\u89e3\u91ca\u6587\u5316\u80cc\u666f\u590d\u6742\u7684\u6d41\u884c\u8bed\u548c\u8ffd\u6eaf\u8d77\u6e90\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u771f\u6b63\u7406\u89e3\u5728\u4e92\u8054\u7f51\u4e0a\u8fc5\u901f\u4f20\u64ad\u7684\u75c5\u6bd2\u5f0f\u5185\u5bb9\u2014\u2014\u7f51\u7edc\u6d41\u884c\u8bed\uff0c\u7279\u522b\u662f\u4e2d\u6587\u8bed\u5883\u4e0b\u7684\u6587\u5316\u5185\u6db5\u3002", "method": "\u6784\u5efaCHIME\u4e2d\u6587\u7f51\u7edc\u6d41\u884c\u8bed\u89e3\u91ca\u6570\u636e\u96c6\uff0c\u5305\u542b\u6d41\u884c\u8bed\u7684\u542b\u4e49\u3001\u8d77\u6e90\u3001\u4f8b\u53e5\u7b49\u4fe1\u606f\uff0c\u5e76\u8bbe\u8ba1\u4e24\u4e2a\u4efb\u52a1\uff1a\u89e3\u91ca\u4efb\u52a1\u548c\u591a\u9009\u9898\u4efb\u52a1\u6765\u8bc4\u4f30LLMs\u7684\u7406\u89e3\u80fd\u529b\u3002", "result": "LLMs\u80fd\u591f\u89e3\u91ca\u90e8\u5206\u6d41\u884c\u8bed\u7684\u542b\u4e49\uff0c\u4f46\u5728\u6587\u5316\u548c\u8bed\u8a00\u7ec6\u5fae\u5dee\u522b\u7684\u6d41\u884c\u8bed\u7c7b\u578b\u4e0a\u8868\u73b0\u663e\u8457\u4e0b\u964d\uff0c\u4e14\u96be\u4ee5\u51c6\u786e\u63d0\u4f9b\u6d41\u884c\u8bed\u7684\u8d77\u6e90\u3002\u591a\u9009\u9898\u4efb\u52a1\u4e2d\u6a21\u578b\u8868\u73b0\u867d\u6b63\u786e\u4f46\u4ecd\u4f4e\u4e8e\u4eba\u7c7b\u6c34\u5e73\u3002", "conclusion": "\u5f53\u524dLLMs\u5bf9\u4e2d\u6587\u7f51\u7edc\u6d41\u884c\u8bed\u7684\u7406\u89e3\u80fd\u529b\u6709\u9650\uff0c\u7279\u522b\u662f\u5728\u6587\u5316\u80cc\u666f\u548c\u8d77\u6e90\u8ffd\u6eaf\u65b9\u9762\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff0cCHIME\u6570\u636e\u96c6\u53ef\u4e3a\u672a\u6765\u8ba1\u7b97\u6d41\u884c\u8bed\u7406\u89e3\u7814\u7a76\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2510.00568", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00568", "abs": "https://arxiv.org/abs/2510.00568", "authors": ["Shiyu Li", "Yang Tang", "Yifan Wang", "Peiming Li", "Xi Chen"], "title": "ReSeek: A Self-Correcting Framework for Search Agents with Instructive Rewards", "comment": "19 pages", "summary": "Search agents powered by Large Language Models (LLMs) have demonstrated\nsignificant potential in tackling knowledge-intensive tasks. Reinforcement\nlearning (RL) has emerged as a powerful paradigm for training these agents to\nperform complex, multi-step reasoning. However, prior RL-based methods often\nrely on sparse or rule-based rewards, which can lead agents to commit to\nsuboptimal or erroneous reasoning paths without the ability to recover. To\naddress these limitations, we propose ReSeek, a novel self-correcting framework\nfor training search agents. Our framework introduces a self-correction\nmechanism that empowers the agent to dynamically identify and recover from\nerroneous search paths during an episode. By invoking a special JUDGE action,\nthe agent can judge the information and re-plan its search strategy. To guide\nthis process, we design a dense, instructive process reward function, which\ndecomposes into a correctness reward for retrieving factual information and a\nutility reward for finding information genuinely useful for the query.\nFurthermore, to mitigate the risk of data contamination in existing datasets,\nwe introduce FictionalHot, a new and challenging benchmark with recently\ncurated questions requiring complex reasoning. Being intuitively reasonable and\npractically simple, extensive experiments show that agents trained with ReSeek\nsignificantly outperform SOTA baselines in task success rate and path\nfaithfulness.", "AI": {"tldr": "\u63d0\u51faReSeek\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u6821\u6b63\u673a\u5236\u8ba9\u641c\u7d22\u4ee3\u7406\u80fd\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u52a8\u6001\u8bc6\u522b\u548c\u7ea0\u6b63\u9519\u8bef\u641c\u7d22\u8def\u5f84\uff0c\u663e\u8457\u63d0\u5347\u4efb\u52a1\u6210\u529f\u7387\u548c\u8def\u5f84\u5fe0\u5b9e\u5ea6\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u641c\u7d22\u4ee3\u7406\u65b9\u6cd5\u4f9d\u8d56\u7a00\u758f\u6216\u57fa\u4e8e\u89c4\u5219\u7684\u5956\u52b1\uff0c\u5bfc\u81f4\u4ee3\u7406\u5bb9\u6613\u9677\u5165\u6b21\u4f18\u6216\u9519\u8bef\u63a8\u7406\u8def\u5f84\u4e14\u65e0\u6cd5\u6062\u590d\u3002", "method": "\u5f15\u5165\u81ea\u6821\u6b63\u673a\u5236\uff0c\u4ee3\u7406\u53ef\u901a\u8fc7JUDGE\u52a8\u4f5c\u5224\u65ad\u4fe1\u606f\u5e76\u91cd\u65b0\u89c4\u5212\u641c\u7d22\u7b56\u7565\uff1b\u8bbe\u8ba1\u5bc6\u96c6\u7684\u8fc7\u7a0b\u5956\u52b1\u51fd\u6570\uff0c\u5206\u89e3\u4e3a\u6b63\u786e\u6027\u5956\u52b1\u548c\u6548\u7528\u5956\u52b1\uff1b\u6784\u5efa\u65b0\u57fa\u51c6FictionalHot\u907f\u514d\u6570\u636e\u6c61\u67d3\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528ReSeek\u8bad\u7ec3\u7684\u4ee3\u7406\u5728\u4efb\u52a1\u6210\u529f\u7387\u548c\u8def\u5f84\u5fe0\u5b9e\u5ea6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "ReSeek\u6846\u67b6\u901a\u8fc7\u81ea\u6821\u6b63\u673a\u5236\u548c\u5bc6\u96c6\u8fc7\u7a0b\u5956\u52b1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u641c\u7d22\u4ee3\u7406\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u9519\u8bef\u8def\u5f84\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2510.00579", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00579", "abs": "https://arxiv.org/abs/2510.00579", "authors": ["Li Li", "Ziyi Wang", "Yongliang Wu", "Jianfei Cai", "Xu Yang"], "title": "CoT Vectors: Transferring and Probing the Reasoning Mechanisms of LLMs", "comment": "22 pages, 7 figures", "summary": "Chain-of-Thought (CoT) prompting has emerged as a powerful approach to\nenhancing the reasoning capabilities of Large Language Models (LLMs). However,\nexisting implementations, such as in-context learning and fine-tuning, remain\ncostly and inefficient. To improve CoT reasoning at a lower cost, and inspired\nby the task vector paradigm, we introduce CoT Vectors, compact representations\nthat encode task-general, multi-step reasoning knowledge. Through experiments\nwith Extracted CoT Vectors, we observe pronounced layer-wise instability,\nmanifesting as a U-shaped performance curve that reflects a systematic\nthree-stage reasoning process in LLMs. To address this limitation, we propose\nLearnable CoT Vectors, optimized under a teacher-student framework to provide\nmore stable and robust guidance. Extensive evaluations across diverse\nbenchmarks and models demonstrate that CoT Vectors not only outperform existing\nbaselines but also achieve performance comparable to parameter-efficient\nfine-tuning methods, while requiring fewer trainable parameters. Moreover, by\ntreating CoT Vectors as a probe, we uncover how their effectiveness varies due\nto latent space structure, information density, acquisition mechanisms, and\npre-training differences, offering new insights into the functional\norganization of multi-step reasoning in LLMs. The source code will be released.", "AI": {"tldr": "\u63d0\u51faCoT Vectors\u65b9\u6cd5\uff0c\u901a\u8fc7\u7d27\u51d1\u5411\u91cf\u7f16\u7801\u591a\u6b65\u63a8\u7406\u77e5\u8bc6\uff0c\u89e3\u51b3\u73b0\u6709CoT\u65b9\u6cd5\u6210\u672c\u9ad8\u3001\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709Chain-of-Thought\uff08CoT\uff09\u63d0\u793a\u65b9\u6cd5\uff08\u5982\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u5fae\u8c03\uff09\u6210\u672c\u9ad8\u6602\u4e14\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u7ecf\u6d4e\u9ad8\u6548\u7684\u63a8\u7406\u589e\u5f3a\u65b9\u6cd5\u3002", "method": "\u5f15\u5165CoT Vectors\u4f5c\u4e3a\u7d27\u51d1\u8868\u793a\uff0c\u7f16\u7801\u4efb\u52a1\u901a\u7528\u7684\u591a\u6b65\u63a8\u7406\u77e5\u8bc6\u3002\u9996\u5148\u63d0\u53d6CoT Vectors\u5e76\u89c2\u5bdf\u5230\u5c42\u95f4\u4e0d\u7a33\u5b9a\u6027\uff0c\u7136\u540e\u63d0\u51fa\u53ef\u5b66\u4e60\u7684CoT Vectors\uff0c\u5728\u5e08\u751f\u6846\u67b6\u4e0b\u4f18\u5316\u4ee5\u63d0\u4f9b\u66f4\u7a33\u5b9a\u7684\u6307\u5bfc\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u6a21\u578b\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cCoT Vectors\u4e0d\u4ec5\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u800c\u4e14\u4e0e\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u6027\u80fd\u76f8\u5f53\uff0c\u540c\u65f6\u9700\u8981\u66f4\u5c11\u7684\u53ef\u8bad\u7ec3\u53c2\u6570\u3002", "conclusion": "CoT Vectors\u4f5c\u4e3a\u4e00\u79cd\u63a2\u6d4b\u5de5\u5177\uff0c\u63ed\u793a\u4e86\u5176\u6709\u6548\u6027\u53d7\u6f5c\u5728\u7a7a\u95f4\u7ed3\u6784\u3001\u4fe1\u606f\u5bc6\u5ea6\u3001\u83b7\u53d6\u673a\u5236\u548c\u9884\u8bad\u7ec3\u5dee\u5f02\u7684\u5f71\u54cd\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u591a\u6b65\u63a8\u7406\u7684\u529f\u80fd\u7ec4\u7ec7\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002"}}
{"id": "2510.00582", "categories": ["cs.CL", "cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2510.00582", "abs": "https://arxiv.org/abs/2510.00582", "authors": ["Sangmin Lee", "Woongjib Choi", "Jihyun Kim", "Hong-Goo Kang"], "title": "SAGE-LD: Towards Scalable and Generalizable End-to-End Language Diarization via Simulated Data Augmentation", "comment": null, "summary": "In this paper, we present a neural spoken language diarization model that\nsupports an unconstrained span of languages within a single framework. Our\napproach integrates a learnable query-based architecture grounded in\nmultilingual awareness, with large-scale pretraining on simulated\ncode-switching data. By jointly leveraging these two components, our method\novercomes the limitations of conventional approaches in data scarcity and\narchitecture optimization, and generalizes effectively to real-world\nmultilingual settings across diverse environments. Experimental results\ndemonstrate that our approach achieves state-of-the-art performance on several\nlanguage diarization benchmarks, with a relative performance improvement of 23%\nto 52% over previous methods. We believe that this work not only advances\nresearch in language diarization but also establishes a foundational framework\nfor code-switching speech technologies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u652f\u6301\u591a\u8bed\u8a00\u7684\u795e\u7ecf\u8bed\u97f3\u8bed\u8a00\u65e5\u8bb0\u5316\u6a21\u578b\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u67e5\u8be2\u67b6\u6784\u548c\u5927\u89c4\u6a21\u4ee3\u7801\u5207\u6362\u9884\u8bad\u7ec3\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f9723%-52%\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u6570\u636e\u7a00\u7f3a\u548c\u67b6\u6784\u4f18\u5316\u65b9\u9762\u7684\u9650\u5236\uff0c\u6784\u5efa\u80fd\u591f\u6709\u6548\u6cdb\u5316\u5230\u771f\u5b9e\u4e16\u754c\u591a\u8bed\u8a00\u73af\u5883\u7684\u8bed\u8a00\u65e5\u8bb0\u5316\u6846\u67b6\u3002", "method": "\u96c6\u6210\u53ef\u5b66\u4e60\u7684\u57fa\u4e8e\u67e5\u8be2\u7684\u591a\u8bed\u8a00\u611f\u77e5\u67b6\u6784\uff0c\u5e76\u5728\u6a21\u62df\u4ee3\u7801\u5207\u6362\u6570\u636e\u4e0a\u8fdb\u884c\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u3002", "result": "\u5728\u591a\u4e2a\u8bed\u8a00\u65e5\u8bb0\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u76f8\u5bf9\u6027\u80fd\u63d0\u534723%\u81f352%\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e0d\u4ec5\u63a8\u8fdb\u4e86\u8bed\u8a00\u65e5\u8bb0\u5316\u7814\u7a76\uff0c\u8fd8\u4e3a\u4ee3\u7801\u5207\u6362\u8bed\u97f3\u6280\u672f\u5efa\u7acb\u4e86\u57fa\u7840\u6846\u67b6\u3002"}}
{"id": "2510.00629", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00629", "abs": "https://arxiv.org/abs/2510.00629", "authors": ["Teisovi Angami", "Kevisino Khate"], "title": "Tenyidie Syllabification corpus creation and deep learning applications", "comment": "17 pages", "summary": "The Tenyidie language is a low-resource language of the Tibeto-Burman family\nspoken by the Tenyimia Community of Nagaland in the north-eastern part of India\nand is considered a major language in Nagaland. It is tonal,\nSubject-Object-Verb, and highly agglutinative in nature. Being a low-resource\nlanguage, very limited research on Natural Language Processing (NLP) has been\nconducted. To the best of our knowledge, no work on syllabification has been\nreported for this language. Among the many NLP tasks, syllabification or\nsyllabication is an important task in which the given word syllables are\nidentified. The contribution of this work is the creation of 10,120 syllabified\nTenyidie words and the application of the Deep Learning techniques on the\ncreated corpus. In this paper, we have applied LSTM, BLSTM, BLSTM+CRF, and\nEncoder-decoder deep learning architectures on our created dataset. In our\ndataset split of 80:10:10 (train:validation:test) set, we achieved the highest\naccuracy of 99.21% with BLSTM model on the test set. This work will find its\napplication in numerous other NLP applications, such as morphological analysis,\npart-of-speech tagging, machine translation, etc, for the Tenyidie Language.\n  Keywords: Tenyidie; NLP; syllabification; deep learning; LSTM; BLSTM; CRF;\nEncoder-decoder", "AI": {"tldr": "\u672c\u6587\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00Tenyidie\u521b\u5efa\u4e8610,120\u4e2a\u97f3\u8282\u5316\u8bcd\u6c47\u6570\u636e\u96c6\uff0c\u5e76\u5e94\u7528\u591a\u79cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u97f3\u8282\u5212\u5206\uff0c\u5176\u4e2dBLSTM\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u523099.21%\u7684\u6700\u9ad8\u51c6\u786e\u7387\u3002", "motivation": "Tenyidie\u662f\u5370\u5ea6\u90a3\u52a0\u5170\u90a6\u7684\u4e00\u79cd\u4f4e\u8d44\u6e90\u85cf\u7f05\u8bed\u7cfb\u8bed\u8a00\uff0c\u6b64\u524d\u6ca1\u6709\u97f3\u8282\u5212\u5206\u76f8\u5173\u7814\u7a76\u3002\u97f3\u8282\u5212\u5206\u662fNLP\u4e2d\u7684\u91cd\u8981\u4efb\u52a1\uff0c\u5bf9\u5f62\u6001\u5206\u6790\u3001\u8bcd\u6027\u6807\u6ce8\u3001\u673a\u5668\u7ffb\u8bd1\u7b49\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5e94\u7528\u4e86LSTM\u3001BLSTM\u3001BLSTM+CRF\u548c\u7f16\u7801\u5668-\u89e3\u7801\u5668\u56db\u79cd\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff0c\u572880:10:10\u5212\u5206\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002", "result": "\u5728\u6d4b\u8bd5\u96c6\u4e0a\uff0cBLSTM\u6a21\u578b\u53d6\u5f97\u4e8699.21%\u7684\u6700\u9ad8\u51c6\u786e\u7387\uff0c\u8868\u660e\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728Tenyidie\u8bed\u8a00\u97f3\u8282\u5212\u5206\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3aTenyidie\u8bed\u8a00\u521b\u5efa\u4e86\u9996\u4e2a\u97f3\u8282\u5212\u5206\u6570\u636e\u96c6\u548c\u57fa\u51c6\uff0c\u4e3a\u540e\u7eedNLP\u5e94\u7528\u5982\u5f62\u6001\u5206\u6790\u3001\u8bcd\u6027\u6807\u6ce8\u3001\u673a\u5668\u7ffb\u8bd1\u7b49\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.00647", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00647", "abs": "https://arxiv.org/abs/2510.00647", "authors": ["Jinlan Fu", "Shenzhen Huangfu", "Hao Fei", "Yichong Huang", "Xiaoyu Shen", "Xipeng Qiu", "See-Kiong Ng"], "title": "MCM-DPO: Multifaceted Cross-Modal Direct Preference Optimization for Alt-text Generation", "comment": "Accepted by ACM MM 2025", "summary": "The alt-text generation task produces concise, context-relevant descriptions\nof images, enabling blind and low-vision users to access online images. Despite\nthe capabilities of large vision-language models, alt-text generation\nperformance remains limited due to noisy user annotations, inconsistent\nstandards, and MLLMs' insensitivity to contextual information. Previous efforts\nto fine-tune MLLMs using supervised fine-tuning (SFT) have struggled, as SFT\nrelies on accurate target annotations, which are often flawed in user-generated\nalt-text. To address this, we propose Multi-faceted Cross-modal Direct\nPreference Optimization (MCM-DPO), which improves alt-text generation by\nlearning to identify better options in preference pairs without requiring\nprecise annotations. MCM-DPO optimizes preferences across single, paired, and\nmulti-preference dimensions, covering textual, visual, and cross-modal factors.\nIn light of the scarcity of high-quality annotated and preference-labeled\ndatasets for alt-text, we constructed two large-scale, high-quality datasets\nnamed TAlt and PAlt, sourced from Twitter and Pinterest. These datasets include\n202k annotated alt-text samples and 18k preference pairs that cover diverse\npreference dimensions, aiming to support further research in this domain.\nExperimental results show that our proposed MCM-DPO method consistently\noutperforms both DPO and SFT, establishing a new state of the art in alt-text\ngeneration. We release the code and data here:\nhttps://github.com/LVUGAI/MCM-DPO", "AI": {"tldr": "\u63d0\u51fa\u4e86MCM-DPO\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u7ef4\u5ea6\u504f\u597d\u4f18\u5316\u6539\u8fdb\u66ff\u4ee3\u6587\u672c\u751f\u6210\uff0c\u65e0\u9700\u7cbe\u786e\u6807\u6ce8\uff0c\u5728Twitter\u548cPinterest\u4e0a\u6784\u5efa\u4e86\u4e24\u4e2a\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u6570\u636e\u96c6TAlt\u548cPAlt\u3002", "motivation": "\u73b0\u6709\u66ff\u4ee3\u6587\u672c\u751f\u6210\u6027\u80fd\u53d7\u9650\uff0c\u539f\u56e0\u5305\u62ec\u7528\u6237\u6807\u6ce8\u566a\u58f0\u3001\u6807\u51c6\u4e0d\u4e00\u81f4\u4ee5\u53ca\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u4e0a\u4e0b\u6587\u4fe1\u606f\u4e0d\u654f\u611f\u3002\u76d1\u7763\u5fae\u8c03\u4f9d\u8d56\u51c6\u786e\u7684\u76ee\u6807\u6807\u6ce8\uff0c\u800c\u7528\u6237\u751f\u6210\u7684\u66ff\u4ee3\u6587\u672c\u5f80\u5f80\u5b58\u5728\u7f3a\u9677\u3002", "method": "\u63d0\u51fa\u591a\u7ef4\u5ea6\u8de8\u6a21\u6001\u76f4\u63a5\u504f\u597d\u4f18\u5316(MCM-DPO)\uff0c\u901a\u8fc7\u8bc6\u522b\u504f\u597d\u5bf9\u4e2d\u7684\u66f4\u597d\u9009\u9879\u6765\u4f18\u5316\u66ff\u4ee3\u6587\u672c\u751f\u6210\uff0c\u6db5\u76d6\u6587\u672c\u3001\u89c6\u89c9\u548c\u8de8\u6a21\u6001\u56e0\u7d20\u7684\u5355\u7ef4\u5ea6\u3001\u914d\u5bf9\u548c\u591a\u7ef4\u5ea6\u504f\u597d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cMCM-DPO\u65b9\u6cd5\u5728\u66ff\u4ee3\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e2d\u6301\u7eed\u4f18\u4e8eDPO\u548cSFT\uff0c\u5efa\u7acb\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "MCM-DPO\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u66ff\u4ee3\u6587\u672c\u751f\u6210\u4e2d\u7684\u6807\u6ce8\u8d28\u91cf\u95ee\u9898\uff0c\u901a\u8fc7\u504f\u597d\u5b66\u4e60\u63d0\u5347\u4e86\u751f\u6210\u6027\u80fd\uff0c\u540c\u65f6\u53d1\u5e03\u7684\u6570\u636e\u96c6\u5c06\u652f\u6301\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2510.00662", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00662", "abs": "https://arxiv.org/abs/2510.00662", "authors": ["Fran\u00e7ois Ledoyen", "Ga\u00ebl Dias", "Jeremie Pantin", "Alexis Lechervy", "Fabrice Maurel", "Youssef Chahir"], "title": "Facilitating Cognitive Accessibility with LLMs: A Multi-Task Approach to Easy-to-Read Text Generation", "comment": "EMNLP 2025", "summary": "Simplifying complex texts is essential for ensuring equitable access to\ninformation, especially for individuals with cognitive impairments. The\nEasy-to-Read (ETR) initiative offers a framework for making content accessible\nto the neurodivergent population, but the manual creation of such texts remains\ntime-consuming and resource-intensive. In this work, we investigate the\npotential of large language models (LLMs) to automate the generation of ETR\ncontent. To address the scarcity of aligned corpora and the specificity of ETR\nconstraints, we propose a multi-task learning (MTL) approach that trains models\njointly on text summarization, text simplification, and ETR generation. We\nexplore two different strategies: multi-task retrieval-augmented generation\n(RAG) for in-context learning, and MTL-LoRA for parameter-efficient\nfine-tuning. Our experiments with Mistral-7B and LLaMA-3-8B, based on ETR-fr, a\nnew high-quality dataset, demonstrate the benefits of multi-task setups over\nsingle-task baselines across all configurations. Moreover, results show that\nthe RAG-based strategy enables generalization in out-of-domain settings, while\nMTL-LoRA outperforms all learning strategies within in-domain configurations.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210\u6613\u8bfb\u6587\u672c\u7684\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u591a\u4efb\u52a1\u5b66\u4e60\u6846\u67b6\uff0c\u5728Mistral-7B\u548cLLaMA-3-8B\u6a21\u578b\u4e0a\u9a8c\u8bc1\u4e86\u591a\u4efb\u52a1\u8bbe\u7f6e\u4f18\u4e8e\u5355\u4efb\u52a1\u57fa\u7ebf\u3002", "motivation": "\u7b80\u5316\u590d\u6742\u6587\u672c\u5bf9\u4e8e\u786e\u4fdd\u8ba4\u77e5\u969c\u788d\u8005\u5e73\u7b49\u83b7\u53d6\u4fe1\u606f\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u624b\u52a8\u521b\u5efa\u6613\u8bfb\u6587\u672c\u8017\u65f6\u8017\u529b\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u591a\u4efb\u52a1\u5b66\u4e60\u65b9\u6cd5\uff0c\u8054\u5408\u8bad\u7ec3\u6587\u672c\u6458\u8981\u3001\u6587\u672c\u7b80\u5316\u548c\u6613\u8bfb\u6587\u672c\u751f\u6210\u4efb\u52a1\uff0c\u63a2\u7d22\u4e86\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u548c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u4e24\u79cd\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u57fa\u4e8e\u65b0\u6784\u5efa\u7684\u9ad8\u8d28\u91cf\u6570\u636e\u96c6ETR-fr\uff0c\u663e\u793a\u591a\u4efb\u52a1\u8bbe\u7f6e\u5728\u6240\u6709\u914d\u7f6e\u4e2d\u90fd\u4f18\u4e8e\u5355\u4efb\u52a1\u57fa\u7ebf\uff0cRAG\u7b56\u7565\u5728\u57df\u5916\u8bbe\u7f6e\u4e2d\u8868\u73b0\u826f\u597d\uff0cMTL-LoRA\u5728\u57df\u5185\u914d\u7f6e\u4e2d\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u591a\u4efb\u52a1\u5b66\u4e60\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347\u6613\u8bfb\u6587\u672c\u7684\u81ea\u52a8\u751f\u6210\u8d28\u91cf\uff0c\u4e3a\u8ba4\u77e5\u969c\u788d\u4eba\u7fa4\u63d0\u4f9b\u66f4\u597d\u7684\u4fe1\u606f\u83b7\u53d6\u9014\u5f84\u3002"}}
{"id": "2510.00691", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00691", "abs": "https://arxiv.org/abs/2510.00691", "authors": ["Fran\u00e7ois Ledoyen", "Ga\u00ebl Dias", "Alexis Lechervy", "Jeremie Pantin", "Fabrice Maurel", "Youssef Chahir", "Elisa Gouzonnat", "M\u00e9lanie Berthelot", "Stanislas Moravac", "Armony Altinier", "Amy Khairalla"], "title": "Inclusive Easy-to-Read Generation for Individuals with Cognitive Impairments", "comment": "ECAI 2025", "summary": "Ensuring accessibility for individuals with cognitive impairments is\nessential for autonomy, self-determination, and full citizenship. However,\nmanual Easy-to-Read (ETR) text adaptations are slow, costly, and difficult to\nscale, limiting access to crucial information in healthcare, education, and\ncivic life. AI-driven ETR generation offers a scalable solution but faces key\nchallenges, including dataset scarcity, domain adaptation, and balancing\nlightweight learning of Large Language Models (LLMs). In this paper, we\nintroduce ETR-fr, the first dataset for ETR text generation fully compliant\nwith European ETR guidelines. We implement parameter-efficient fine-tuning on\nPLMs and LLMs to establish generative baselines. To ensure high-quality and\naccessible outputs, we introduce an evaluation framework based on automatic\nmetrics supplemented by human assessments. The latter is conducted using a\n36-question evaluation form that is aligned with the guidelines. Overall\nresults show that PLMs perform comparably to LLMs and adapt effectively to\nout-of-domain texts.", "AI": {"tldr": "\u63d0\u51fa\u4e86ETR-fr\u6570\u636e\u96c6\uff0c\u8fd9\u662f\u9996\u4e2a\u5b8c\u5168\u7b26\u5408\u6b27\u6d32\u6613\u8bfb\u6587\u672c\u6307\u5357\u7684\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u5728PLM\u548cLLM\u4e0a\u5efa\u7acb\u751f\u6210\u57fa\u7ebf\uff0c\u5e76\u5f15\u5165\u5305\u542b\u81ea\u52a8\u6307\u6807\u548c\u4eba\u5de5\u8bc4\u4f30\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "motivation": "\u4e3a\u8ba4\u77e5\u969c\u788d\u4eba\u58eb\u63d0\u4f9b\u53ef\u8bbf\u95ee\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u624b\u52a8\u6613\u8bfb\u6587\u672c\u6539\u7f16\u7f13\u6162\u3001\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u6269\u5c55\u3002AI\u9a71\u52a8\u7684\u6613\u8bfb\u6587\u672c\u751f\u6210\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u9762\u4e34\u6570\u636e\u96c6\u7a00\u7f3a\u3001\u9886\u57df\u9002\u5e94\u548c\u5e73\u8861LLM\u8f7b\u91cf\u5b66\u4e60\u7b49\u6311\u6218\u3002", "method": "\u5f15\u5165ETR-fr\u6570\u636e\u96c6\uff0c\u5b9e\u65bd\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u5728PLM\u548cLLM\u4e0a\u5efa\u7acb\u751f\u6210\u57fa\u7ebf\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u81ea\u52a8\u6307\u6807\u548c\u4eba\u5de5\u8bc4\u4f30\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u540e\u8005\u4f7f\u7528\u4e0e\u6307\u5357\u5bf9\u9f50\u768436\u95ee\u9898\u8bc4\u4f30\u8868\u3002", "result": "\u603b\u4f53\u7ed3\u679c\u663e\u793aPLM\u4e0eLLM\u8868\u73b0\u76f8\u5f53\uff0c\u5e76\u80fd\u6709\u6548\u9002\u5e94\u9886\u57df\u5916\u6587\u672c\u3002", "conclusion": "PLM\u5728\u6613\u8bfb\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0eLLM\u76f8\u5f53\uff0c\u4e14\u80fd\u6709\u6548\u5904\u7406\u9886\u57df\u5916\u6587\u672c\uff0c\u4e3a\u6613\u8bfb\u6587\u672c\u751f\u6210\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.00694", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.00694", "abs": "https://arxiv.org/abs/2510.00694", "authors": ["Harethah Abu Shairah", "Somayah AlHarbi", "Abdulaziz AlHussein", "Sameer Alsabea", "Omar Shaqaqi", "Hebah AlShamlan", "Omar Knio", "George Turkiyyah"], "title": "ALARB: An Arabic Legal Argument Reasoning Benchmark", "comment": "Accepted paper at ArabicNLP 2025", "summary": "We introduce ALARB, a dataset and suite of tasks designed to evaluate the\nreasoning capabilities of large language models (LLMs) within the Arabic legal\ndomain. While existing Arabic benchmarks cover some knowledge-intensive tasks\nsuch as retrieval and understanding, substantial datasets focusing specifically\non multistep reasoning for Arabic LLMs, especially in open-ended contexts, are\nlacking. The dataset comprises over 13K commercial court cases from Saudi\nArabia, with each case including the facts presented, the reasoning of the\ncourt, the verdict, as well as the cited clauses extracted from the regulatory\ndocuments. We define a set of challenging tasks leveraging this dataset and\nreflecting the complexity of real-world legal reasoning, including verdict\nprediction, completion of reasoning chains in multistep legal arguments, and\nidentification of relevant regulations based on case facts. We benchmark a\nrepresentative selection of current open and closed Arabic LLMs on these tasks\nand demonstrate the dataset's utility for instruction tuning. Notably, we show\nthat instruction-tuning a modest 12B parameter model using ALARB significantly\nenhances its performance in verdict prediction and Arabic verdict generation,\nreaching a level comparable to that of GPT-4o.", "AI": {"tldr": "ALARB\u662f\u4e00\u4e2a\u963f\u62c9\u4f2f\u8bed\u6cd5\u5f8b\u63a8\u7406\u6570\u636e\u96c6\uff0c\u5305\u542b13K+\u6c99\u7279\u5546\u4e1a\u6cd5\u5ead\u6848\u4f8b\uff0c\u7528\u4e8e\u8bc4\u4f30LLMs\u5728\u963f\u62c9\u4f2f\u6cd5\u5f8b\u9886\u57df\u7684\u591a\u6b65\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u6307\u4ee4\u8c03\u4f18\u53ef\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u963f\u62c9\u4f2f\u8bed\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u68c0\u7d22\u548c\u7406\u89e3\u4efb\u52a1\uff0c\u7f3a\u4e4f\u4e13\u95e8\u9488\u5bf9\u591a\u6b65\u63a8\u7406\u7684\u6570\u636e\u96c6\uff0c\u7279\u522b\u662f\u5728\u5f00\u653e\u5f0f\u7684\u963f\u62c9\u4f2f\u8bed\u6cd5\u5f8b\u63a8\u7406\u9886\u57df\u3002", "method": "\u6784\u5efa\u5305\u542b13K+\u6c99\u7279\u5546\u4e1a\u6cd5\u5ead\u6848\u4f8b\u7684\u6570\u636e\u96c6\uff0c\u6bcf\u4e2a\u6848\u4f8b\u5305\u542b\u6848\u4ef6\u4e8b\u5b9e\u3001\u6cd5\u5ead\u63a8\u7406\u3001\u5224\u51b3\u7ed3\u679c\u548c\u5f15\u7528\u6761\u6b3e\uff0c\u5e76\u8bbe\u8ba1\u5224\u51b3\u9884\u6d4b\u3001\u63a8\u7406\u94fe\u8865\u5168\u548c\u76f8\u5173\u6cd5\u89c4\u8bc6\u522b\u7b49\u4efb\u52a1\u3002", "result": "\u6307\u4ee4\u8c03\u4f18\u4e00\u4e2a12B\u53c2\u6570\u6a21\u578b\u4f7f\u7528ALARB\u6570\u636e\u96c6\u540e\uff0c\u5728\u5224\u51b3\u9884\u6d4b\u548c\u963f\u62c9\u4f2f\u8bed\u5224\u51b3\u751f\u6210\u4efb\u52a1\u4e0a\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u8fbe\u5230\u4e0eGPT-4o\u76f8\u5f53\u7684\u6c34\u5e73\u3002", "conclusion": "ALARB\u6570\u636e\u96c6\u586b\u8865\u4e86\u963f\u62c9\u4f2f\u8bed\u6cd5\u5f8b\u63a8\u7406\u57fa\u51c6\u7684\u7a7a\u767d\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u63d0\u5347LLMs\u6cd5\u5f8b\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u901a\u8fc7\u6307\u4ee4\u8c03\u4f18\u53ef\u4ee5\u5b9e\u73b0\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2510.00810", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00810", "abs": "https://arxiv.org/abs/2510.00810", "authors": ["Jenny Kunz", "Iben Nyholm Debess", "Annika Simonsen"], "title": "Family Matters: Language Transfer and Merging for Adapting Small LLMs to Faroese", "comment": null, "summary": "We investigate how to adapt small, efficient LLMs to Faroese, a low-resource\nNorth Germanic language. Starting from English models, we continue pre-training\non related Scandinavian languages, either individually or combined via merging,\nbefore fine-tuning on Faroese. We compare full fine-tuning with\nparameter-efficient tuning using LoRA, evaluating their impact on both\nlinguistic accuracy and text comprehension. Due to the lack of existing Faroese\nevaluation data, we construct two new minimal-pair benchmarks from adapted and\nnewly collected datasets and complement them with human evaluations by Faroese\nlinguists. Our results demonstrate that transfer from related languages is\ncrucial, though the optimal source language depends on the task: Icelandic\nenhances linguistic accuracy, whereas Danish boosts comprehension. Similarly,\nthe choice between full fine-tuning and LoRA is task-dependent: LoRA improves\nlinguistic acceptability and slightly increases human evaluation scores on the\nbase model, while full fine-tuning yields stronger comprehension performance\nand better preserves model capabilities during downstream fine-tuning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u5982\u4f55\u5c06\u5c0f\u578b\u9ad8\u6548LLM\u9002\u914d\u5230\u6cd5\u7f57\u8bed\u8fd9\u4e00\u4f4e\u8d44\u6e90\u5317\u65e5\u8033\u66fc\u8bed\u3002\u901a\u8fc7\u4ece\u82f1\u8bed\u6a21\u578b\u51fa\u53d1\uff0c\u5728\u76f8\u5173\u65af\u582a\u7684\u7eb3\u7ef4\u4e9a\u8bed\u8a00\u4e0a\u7ee7\u7eed\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u5bf9\u6cd5\u7f57\u8bed\u8fdb\u884c\u5fae\u8c03\uff0c\u6bd4\u8f83\u4e86\u5168\u53c2\u6570\u5fae\u8c03\u4e0eLoRA\u53c2\u6570\u9ad8\u6548\u8c03\u4f18\u7684\u6548\u679c\u3002", "motivation": "\u89e3\u51b3\u4f4e\u8d44\u6e90\u8bed\u8a00\u6cd5\u7f57\u8bed\u7f3a\u4e4f\u9002\u914dLLM\u7684\u95ee\u9898\uff0c\u63a2\u7d22\u5982\u4f55\u5229\u7528\u76f8\u5173\u8bed\u8a00\u8d44\u6e90\u6765\u63d0\u5347\u6a21\u578b\u5728\u6cd5\u7f57\u8bed\u4e0a\u7684\u8868\u73b0\u3002", "method": "\u4ece\u82f1\u8bed\u6a21\u578b\u5f00\u59cb\uff0c\u5728\u76f8\u5173\u65af\u582a\u7684\u7eb3\u7ef4\u4e9a\u8bed\u8a00\u4e0a\u8fdb\u884c\u7ee7\u7eed\u9884\u8bad\u7ec3\uff08\u5355\u72ec\u6216\u5408\u5e76\uff09\uff0c\u7136\u540e\u5bf9\u6cd5\u7f57\u8bed\u8fdb\u884c\u5fae\u8c03\uff0c\u6bd4\u8f83\u5168\u53c2\u6570\u5fae\u8c03\u4e0eLoRA\u65b9\u6cd5\uff0c\u5e76\u6784\u5efa\u65b0\u7684\u6cd5\u7f57\u8bed\u8bc4\u4f30\u57fa\u51c6\u548c\u4eba\u5de5\u8bc4\u4f30\u3002", "result": "\u76f8\u5173\u8bed\u8a00\u8fc1\u79fb\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6700\u4f73\u6e90\u8bed\u8a00\u56e0\u4efb\u52a1\u800c\u5f02\uff1a\u51b0\u5c9b\u8bed\u63d0\u5347\u8bed\u8a00\u51c6\u786e\u6027\uff0c\u4e39\u9ea6\u8bed\u589e\u5f3a\u7406\u89e3\u80fd\u529b\u3002LoRA\u5728\u57fa\u7840\u6a21\u578b\u4e0a\u6539\u5584\u8bed\u8a00\u53ef\u63a5\u53d7\u6027\uff0c\u5168\u53c2\u6570\u5fae\u8c03\u5728\u7406\u89e3\u4efb\u52a1\u4e0a\u8868\u73b0\u66f4\u597d\u4e14\u5728\u4e0b\u6e38\u5fae\u8c03\u4e2d\u66f4\u597d\u5730\u4fdd\u7559\u6a21\u578b\u80fd\u529b\u3002", "conclusion": "\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u9002\u914dLLM\u65f6\uff0c\u76f8\u5173\u8bed\u8a00\u8fc1\u79fb\u7b56\u7565\u548c\u5fae\u8c03\u65b9\u6cd5\u7684\u9009\u62e9\u5e94\u6839\u636e\u5177\u4f53\u4efb\u52a1\u9700\u6c42\u8fdb\u884c\u6743\u8861\uff0c\u4e0d\u540c\u8bed\u8a00\u548c\u4e0d\u540c\u65b9\u6cd5\u5728\u4e0d\u540c\u4efb\u52a1\u4e0a\u5404\u6709\u4f18\u52bf\u3002"}}
{"id": "2510.00829", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00829", "abs": "https://arxiv.org/abs/2510.00829", "authors": ["Yanming Sun", "Runzhe Zhan", "Chi Seng Cheang", "Han Wu", "Xuebo Liu", "Yuyao Niu", "Fengying Ye", "Kaixin Lan", "Lidia S. Chao", "Derek F. Wong"], "title": "Exposing the Cracks: Vulnerabilities of Retrieval-Augmented LLM-based Machine Translation", "comment": null, "summary": "\\textbf{RE}trieval-\\textbf{A}ugmented \\textbf{L}LM-based \\textbf{M}achine\n\\textbf{T}ranslation (REAL-MT) shows promise for knowledge-intensive tasks like\nidiomatic translation, but its reliability under noisy retrieval contexts\nremains poorly understood despite this being a common challenge in real-world\ndeployment. To address this gap, we propose a noise synthesis framework and new\nmetrics to evaluate the robustness of REAL-MT systematically. Using this\nframework, we instantiate REAL-MT with Qwen-series models, including standard\nLLMs and large reasoning models (LRMs) with enhanced reasoning, and evaluate\ntheir performance on idiomatic translation across high-, medium-, and\nlow-resource language pairs under synthesized noise. Our results show that\nlow-resource language pairs, which rely more heavily on retrieved context,\ndegrade more severely under noise than high-resource ones and often produce\nnonsensical translations. Although LRMs possess enhanced reasoning\ncapabilities, they show no improvement in error correction and are even more\nsusceptible to noise, tending to rationalize incorrect contexts. We find that\nthis stems from an attention shift away from the source idiom to noisy content,\nwhile confidence increases despite declining accuracy, indicating poor\ncalibration. To mitigate these issues, we investigate training-free and\nfine-tuning strategies, which improve robustness at the cost of performance in\nclean contexts, revealing a fundamental trade-off. Our findings highlight the\nlimitations of current approaches, underscoring the need for self-verifying\nintegration mechanisms.", "AI": {"tldr": "REAL-MT\u5728\u566a\u58f0\u68c0\u7d22\u73af\u5883\u4e0b\u53ef\u9760\u6027\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u5bf9\u4e2d\u8868\u73b0\u66f4\u5dee\uff0c\u5373\u4f7f\u589e\u5f3a\u63a8\u7406\u6a21\u578b\u4e5f\u65e0\u6cd5\u7ea0\u6b63\u9519\u8bef\uff0c\u53cd\u800c\u66f4\u5bb9\u6613\u53d7\u566a\u58f0\u5f71\u54cd\u3002", "motivation": "\u89e3\u51b3\u68c0\u7d22\u589e\u5f3aLLM\u673a\u5668\u7ffb\u8bd1\u5728\u771f\u5b9e\u90e8\u7f72\u4e2d\u9762\u4e34\u566a\u58f0\u68c0\u7d22\u73af\u5883\u65f6\u53ef\u9760\u6027\u672a\u77e5\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u566a\u58f0\u5408\u6210\u6846\u67b6\u548c\u65b0\u6307\u6807\uff0c\u4f7f\u7528Qwen\u7cfb\u5217\u6a21\u578b\uff08\u5305\u62ec\u6807\u51c6LLM\u548c\u589e\u5f3a\u63a8\u7406\u6a21\u578b\uff09\u5728\u4e0d\u540c\u8d44\u6e90\u8bed\u8a00\u5bf9\u4e0a\u8bc4\u4f30REAL-MT\u7684\u9c81\u68d2\u6027\u3002", "result": "\u4f4e\u8d44\u6e90\u8bed\u8a00\u5bf9\u5728\u566a\u58f0\u4e0b\u9000\u5316\u66f4\u4e25\u91cd\uff0c\u4ea7\u751f\u65e0\u610f\u4e49\u7ffb\u8bd1\uff1b\u589e\u5f3a\u63a8\u7406\u6a21\u578b\u65e0\u6cd5\u7ea0\u6b63\u9519\u8bef\u4e14\u66f4\u6613\u53d7\u566a\u58f0\u5f71\u54cd\uff1b\u6ce8\u610f\u529b\u4ece\u6e90\u4e60\u8bed\u8f6c\u5411\u566a\u58f0\u5185\u5bb9\uff0c\u7f6e\u4fe1\u5ea6\u589e\u52a0\u4f46\u51c6\u786e\u6027\u4e0b\u964d\u3002", "conclusion": "\u5f53\u524d\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u5728\u6027\u80fd\u548c\u9c81\u68d2\u6027\u4e4b\u95f4\u6743\u8861\uff0c\u4e9f\u9700\u81ea\u9a8c\u8bc1\u96c6\u6210\u673a\u5236\u3002"}}
{"id": "2510.00857", "categories": ["cs.CL", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.00857", "abs": "https://arxiv.org/abs/2510.00857", "authors": ["Adi Simhi", "Jonathan Herzig", "Martin Tutek", "Itay Itzhak", "Idan Szpektor", "Yonatan Belinkov"], "title": "ManagerBench: Evaluating the Safety-Pragmatism Trade-off in Autonomous LLMs", "comment": null, "summary": "As large language models (LLMs) evolve from conversational assistants into\nautonomous agents, evaluating the safety of their actions becomes critical.\nPrior safety benchmarks have primarily focused on preventing generation of\nharmful content, such as toxic text. However, they overlook the challenge of\nagents taking harmful actions when the most effective path to an operational\ngoal conflicts with human safety. To address this gap, we introduce\nManagerBench, a benchmark that evaluates LLM decision-making in realistic,\nhuman-validated managerial scenarios. Each scenario forces a choice between a\npragmatic but harmful action that achieves an operational goal, and a safe\naction that leads to worse operational performance. A parallel control set,\nwhere potential harm is directed only at inanimate objects, measures a model's\npragmatism and identifies its tendency to be overly safe. Our findings indicate\nthat the frontier LLMs perform poorly when navigating this safety-pragmatism\ntrade-off. Many consistently choose harmful options to advance their\noperational goals, while others avoid harm only to become overly safe and\nineffective. Critically, we find this misalignment does not stem from an\ninability to perceive harm, as models' harm assessments align with human\njudgments, but from flawed prioritization. ManagerBench is a challenging\nbenchmark for a core component of agentic behavior: making safe choices when\noperational goals and alignment values incentivize conflicting actions.\nBenchmark & code available at https://github.com/technion-cs-nlp/ManagerBench.", "AI": {"tldr": "ManagerBench\u662f\u4e00\u4e2a\u8bc4\u4f30LLM\u5728\u7ba1\u7406\u573a\u666f\u4e2d\u5b89\u5168\u51b3\u7b56\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u8ba9\u6a21\u578b\u5728\u5b9e\u7528\u4f46\u6709\u5bb3\u7684\u884c\u52a8\u4e0e\u5b89\u5168\u4f46\u4f4e\u6548\u7684\u884c\u52a8\u4e4b\u95f4\u505a\u9009\u62e9\uff0c\u6765\u6d4b\u8bd5\u5176\u5b89\u5168\u6027\u4e0e\u5b9e\u7528\u6027\u7684\u5e73\u8861\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u9632\u6b62\u751f\u6210\u6709\u5bb3\u5185\u5bb9\uff0c\u4f46\u5ffd\u7565\u4e86\u5f53\u5b9e\u73b0\u64cd\u4f5c\u76ee\u6807\u7684\u6700\u6709\u6548\u8def\u5f84\u4e0e\u4eba\u7c7b\u5b89\u5168\u51b2\u7a81\u65f6\uff0cLLM\u4ee3\u7406\u53ef\u80fd\u91c7\u53d6\u6709\u5bb3\u884c\u52a8\u7684\u95ee\u9898\u3002", "method": "\u521b\u5efa\u5305\u542b\u4eba\u7c7b\u9a8c\u8bc1\u7684\u7ba1\u7406\u573a\u666f\uff0c\u6bcf\u4e2a\u573a\u666f\u8feb\u4f7f\u5728\u5b9e\u7528\u4f46\u6709\u5bb3\u7684\u884c\u52a8\u4e0e\u5b89\u5168\u4f46\u4f4e\u6548\u7684\u884c\u52a8\u4e4b\u95f4\u505a\u9009\u62e9\u3002\u540c\u65f6\u8bbe\u7f6e\u5e73\u884c\u63a7\u5236\u96c6\u6765\u6d4b\u91cf\u6a21\u578b\u7684\u5b9e\u7528\u4e3b\u4e49\u503e\u5411\u3002", "result": "\u524d\u6cbfLLM\u5728\u5b89\u5168-\u5b9e\u7528\u6027\u6743\u8861\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u8bb8\u591a\u6a21\u578b\u4e3a\u63a8\u8fdb\u64cd\u4f5c\u76ee\u6807\u6301\u7eed\u9009\u62e9\u6709\u5bb3\u9009\u9879\uff0c\u800c\u5176\u4ed6\u6a21\u578b\u5219\u8fc7\u5ea6\u5b89\u5168\u4e14\u4f4e\u6548\u3002\u6a21\u578b\u80fd\u591f\u51c6\u786e\u611f\u77e5\u5371\u5bb3\uff0c\u4f46\u5b58\u5728\u4f18\u5148\u7ea7\u6392\u5e8f\u95ee\u9898\u3002", "conclusion": "ManagerBench\u662f\u8bc4\u4f30\u667a\u80fd\u4f53\u6838\u5fc3\u884c\u4e3a\u7ec4\u4ef6\u7684\u6311\u6218\u6027\u57fa\u51c6\uff1a\u5f53\u64cd\u4f5c\u76ee\u6807\u4e0e\u5bf9\u9f50\u4ef7\u503c\u6fc0\u52b1\u51b2\u7a81\u884c\u52a8\u65f6\u505a\u51fa\u5b89\u5168\u9009\u62e9\u3002"}}
{"id": "2510.00861", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.00861", "abs": "https://arxiv.org/abs/2510.00861", "authors": ["Ziliang Wang", "Kang An", "Xuhui Zheng", "Faqiang Qian", "Weikun Zhang", "Cijun Ouyang", "Jialu Cai", "Yuhang Wang", "Yichao Wu"], "title": "Erase to Improve: Erasable Reinforcement Learning for Search-Augmented LLMs", "comment": "10 pages, 4 figures", "summary": "While search-augmented large language models (LLMs) exhibit impressive\ncapabilities, their reliability in complex multi-hop reasoning remains limited.\nThis limitation arises from three fundamental challenges: decomposition errors,\nwhere tasks are incorrectly broken down; retrieval missing, where key evidence\nfails to be retrieved; and reasoning errors, where flawed logic propagates\nthrough the reasoning chain. A single failure in any of these stages can derail\nthe final answer. We propose Erasable Reinforcement Learning (ERL), a novel\nframework that transforms fragile reasoning into a robust process. ERL\nexplicitly identifies faulty steps, erases them, and regenerates reasoning in\nplace, preventing defective logic from propagating through the reasoning chain.\nThis targeted correction mechanism turns brittle reasoning into a more\nresilient process. Models trained with ERL, termed ESearch, achieve substantial\nimprovements on HotpotQA, MuSiQue, 2Wiki, and Bamboogle, with the 3B model\nachieving +8.48% EM and +11.56% F1, and the 7B model achieving +5.38% EM and\n+7.22% F1 over previous state-of-the-art(SOTA) results. These findings suggest\nthat erasable reinforcement learning provides a powerful paradigm shift for\nrobust multi-step reasoning in LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u53ef\u64e6\u9664\u5f3a\u5316\u5b66\u4e60\uff08ERL\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u8bc6\u522b\u3001\u64e6\u9664\u548c\u91cd\u65b0\u751f\u6210\u9519\u8bef\u63a8\u7406\u6b65\u9aa4\uff0c\u663e\u8457\u63d0\u5347\u641c\u7d22\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u591a\u8df3\u63a8\u7406\u4e2d\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u641c\u7d22\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u591a\u8df3\u63a8\u7406\u4e2d\u5b58\u5728\u4e09\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u5206\u89e3\u9519\u8bef\u3001\u68c0\u7d22\u7f3a\u5931\u548c\u63a8\u7406\u9519\u8bef\uff0c\u4efb\u4e00\u73af\u8282\u7684\u5931\u8d25\u90fd\u4f1a\u5bfc\u81f4\u6700\u7ec8\u7b54\u6848\u9519\u8bef\u3002", "method": "ERL\u6846\u67b6\u660e\u786e\u8bc6\u522b\u9519\u8bef\u6b65\u9aa4\uff0c\u64e6\u9664\u8fd9\u4e9b\u6b65\u9aa4\u5e76\u91cd\u65b0\u751f\u6210\u63a8\u7406\uff0c\u9632\u6b62\u9519\u8bef\u903b\u8f91\u5728\u63a8\u7406\u94fe\u4e2d\u4f20\u64ad\u3002", "result": "\u5728HotpotQA\u3001MuSiQue\u30012Wiki\u548cBamboogle\u6570\u636e\u96c6\u4e0a\uff0c3B\u6a21\u578b\u6bd4\u4e4b\u524dSOTA\u63d0\u53478.48% EM\u548c11.56% F1\uff0c7B\u6a21\u578b\u63d0\u53475.38% EM\u548c7.22% F1\u3002", "conclusion": "\u53ef\u64e6\u9664\u5f3a\u5316\u5b66\u4e60\u4e3aLLMs\u4e2d\u7684\u9c81\u68d2\u591a\u6b65\u63a8\u7406\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u8303\u5f0f\u8f6c\u53d8\u3002"}}
{"id": "2510.00880", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00880", "abs": "https://arxiv.org/abs/2510.00880", "authors": ["Loris Bergeron", "Ioana Buhnila", "J\u00e9r\u00f4me Fran\u00e7ois", "Radu State"], "title": "HalluGuard: Evidence-Grounded Small Reasoning Models to Mitigate Hallucinations in Retrieval-Augmented Generation", "comment": null, "summary": "Large Language Models (LLMs) excel in many NLP tasks but remain prone to\nhallucinations, limiting trust in real-world applications. We present\nHalluGuard, a 4B-parameter Small Reasoning Model (SRM) for mitigating\nhallucinations in Retrieval-Augmented Generation (RAG). HalluGuard classifies\ndocument-claim pairs as grounded or hallucinated and produces evidence-grounded\njustifications for transparency. Our approach combines (i) a domain-agnostic\nsynthetic dataset derived from FineWeb and refined through multi-stage curation\nand data reformation, (ii) synthetic grounded and hallucinated claims, and\n(iii) preference-based fine-tuning with Odds Ratio Preference Optimization to\ndistill large-model reasoning into a smaller backbone. On the RAGTruth subset\nof the LLM-AggreFact benchmark, HalluGuard achieves 84.0% balanced accuracy\n(BAcc), rivaling specialized models, MiniCheck (7B; 84.0%) and Granite Guardian\n3.3 (8B; 82.2%) while using roughly half their parameters. Over the full\nbenchmark it reaches 75.7% BAcc, matching larger general-purpose LLMs such as\nGPT-4o (75.9%). We will release HalluGuard and datasets under Apache 2.0 upon\nacceptance.", "AI": {"tldr": "HalluGuard\u662f\u4e00\u4e2a4B\u53c2\u6570\u7684\u5c0f\u578b\u63a8\u7406\u6a21\u578b\uff0c\u4e13\u95e8\u7528\u4e8e\u7f13\u89e3\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u7c7b\u6587\u6863-\u58f0\u660e\u5bf9\u5e76\u63d0\u4f9b\u8bc1\u636e\u4f9d\u636e\u7684\u63a8\u7406\uff0c\u5728\u4fdd\u6301\u8f83\u5c0f\u53c2\u6570\u91cf\u7684\u540c\u65f6\u8fbe\u5230\u4e0e\u66f4\u5927\u6a21\u578b\u76f8\u5f53\u7684\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728NLP\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\uff0c\u9650\u5236\u4e86\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u4fe1\u5ea6\u3002\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u9488\u5bf9\u5e7b\u89c9\u68c0\u6d4b\u7684\u9ad8\u6548\u6a21\u578b\u3002", "method": "\u7ed3\u5408\u9886\u57df\u65e0\u5173\u7684\u5408\u6210\u6570\u636e\u96c6\u3001\u5408\u6210\u7684\u57fa\u7840\u548c\u5e7b\u89c9\u58f0\u660e\uff0c\u4ee5\u53ca\u57fa\u4e8e\u504f\u597d\u7684\u5fae\u8c03(Odds Ratio Preference Optimization)\uff0c\u5c06\u5927\u6a21\u578b\u63a8\u7406\u80fd\u529b\u84b8\u998f\u5230\u5c0f\u578b\u9aa8\u5e72\u7f51\u7edc\u4e2d\u3002", "result": "\u5728RAGTruth\u5b50\u96c6\u4e0a\u8fbe\u523084.0%\u7684\u5e73\u8861\u51c6\u786e\u7387\uff0c\u4e0eMiniCheck(7B)\u548cGranite Guardian 3.3(8B)\u76f8\u5f53\uff1b\u5728\u6574\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523075.7% BAcc\uff0c\u4e0eGPT-4o(75.9%)\u76f8\u5f53\uff0c\u4f46\u53c2\u6570\u91cf\u53ea\u6709\u4e00\u534a\u3002", "conclusion": "HalluGuard\u8bc1\u660e\u4e86\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6570\u636e\u5408\u6210\u548c\u504f\u597d\u4f18\u5316\uff0c\u53ef\u4ee5\u6784\u5efa\u53c2\u6570\u6548\u7387\u9ad8\u4e14\u6027\u80fd\u4f18\u5f02\u7684\u5e7b\u89c9\u68c0\u6d4b\u6a21\u578b\uff0c\u4e3aRAG\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.00890", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00890", "abs": "https://arxiv.org/abs/2510.00890", "authors": ["Zhen Yin", "Shenghua Wang"], "title": "Span-level Detection of AI-generated Scientific Text via Contrastive Learning and Structural Calibration", "comment": null, "summary": "The rapid adoption of large language models (LLMs) in scientific writing\nraises serious concerns regarding authorship integrity and the reliability of\nscholarly publications. Existing detection approaches mainly rely on\ndocument-level classification or surface-level statistical cues; however, they\nneglect fine-grained span localization, exhibit weak calibration, and often\nfail to generalize across disciplines and generators. To address these\nlimitations, we present Sci-SpanDet, a structure-aware framework for detecting\nAI-generated scholarly texts. The proposed method combines section-conditioned\nstylistic modeling with multi-level contrastive learning to capture nuanced\nhuman-AI differences while mitigating topic dependence, thereby enhancing\ncross-domain robustness. In addition, it integrates BIO-CRF sequence labeling\nwith pointer-based boundary decoding and confidence calibration to enable\nprecise span-level detection and reliable probability estimates. Extensive\nexperiments on a newly constructed cross-disciplinary dataset of 100,000\nannotated samples generated by multiple LLM families (GPT, Qwen, DeepSeek,\nLLaMA) demonstrate that Sci-SpanDet achieves state-of-the-art performance, with\nF1(AI) of 80.17, AUROC of 92.63, and Span-F1 of 74.36. Furthermore, it shows\nstrong resilience under adversarial rewriting and maintains balanced accuracy\nacross IMRaD sections and diverse disciplines, substantially surpassing\nexisting baselines. To ensure reproducibility and to foster further research on\nAI-generated text detection in scholarly documents, the curated dataset and\nsource code will be publicly released upon publication.", "AI": {"tldr": "Sci-SpanDet\u662f\u4e00\u4e2a\u7528\u4e8e\u68c0\u6d4b\u5b66\u672f\u6587\u672c\u4e2dAI\u751f\u6210\u5185\u5bb9\u7684\u7ed3\u6784\u611f\u77e5\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u5206\u6bb5\u6761\u4ef6\u98ce\u683c\u5efa\u6a21\u548c\u591a\u7ea7\u5bf9\u6bd4\u5b66\u4e60\uff0c\u5b9e\u73b0\u4e86\u8de8\u9886\u57df\u7684\u9c81\u68d2\u68c0\u6d4b\u548c\u7cbe\u786e\u7684\u7247\u6bb5\u7ea7\u5b9a\u4f4d\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u5199\u4f5c\u4e2d\u7684\u5feb\u901f\u5e94\u7528\uff0c\u5f15\u53d1\u4e86\u5173\u4e8e\u4f5c\u8005\u8eab\u4efd\u5b8c\u6574\u6027\u548c\u5b66\u672f\u51fa\u7248\u7269\u53ef\u9760\u6027\u7684\u4e25\u91cd\u62c5\u5fe7\u3002\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u6587\u6863\u7ea7\u5206\u7c7b\u6216\u8868\u9762\u7edf\u8ba1\u7ebf\u7d22\uff0c\u4f46\u5ffd\u89c6\u4e86\u7ec6\u7c92\u5ea6\u7247\u6bb5\u5b9a\u4f4d\u3001\u6821\u51c6\u80fd\u529b\u5f31\uff0c\u4e14\u96be\u4ee5\u8de8\u5b66\u79d1\u548c\u751f\u6210\u5668\u6cdb\u5316\u3002", "method": "\u7ed3\u5408\u5206\u6bb5\u6761\u4ef6\u98ce\u683c\u5efa\u6a21\u4e0e\u591a\u7ea7\u5bf9\u6bd4\u5b66\u4e60\u6765\u6355\u6349\u7ec6\u5fae\u7684\u4eba\u7c7b-AI\u5dee\u5f02\u5e76\u51cf\u8f7b\u4e3b\u9898\u4f9d\u8d56\u6027\uff1b\u96c6\u6210BIO-CRF\u5e8f\u5217\u6807\u6ce8\u4e0e\u57fa\u4e8e\u6307\u9488\u7684\u8fb9\u754c\u89e3\u7801\u548c\u7f6e\u4fe1\u5ea6\u6821\u51c6\uff0c\u5b9e\u73b0\u7cbe\u786e\u7684\u7247\u6bb5\u7ea7\u68c0\u6d4b\u548c\u53ef\u9760\u7684\u6982\u7387\u4f30\u8ba1\u3002", "result": "\u5728\u5305\u542b10\u4e07\u4e2a\u6807\u6ce8\u6837\u672c\u7684\u65b0\u5efa\u8de8\u5b66\u79d1\u6570\u636e\u96c6\u4e0a\uff0cSci-SpanDet\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff1aAI\u68c0\u6d4bF1\u4e3a80.17\uff0cAUROC\u4e3a92.63\uff0c\u7247\u6bb5\u7ea7F1\u4e3a74.36\u3002\u5728\u5bf9\u6297\u6027\u91cd\u5199\u4e0b\u8868\u73b0\u51fa\u5f3a\u97e7\u6027\uff0c\u5728IMRaD\u5404\u7ae0\u8282\u548c\u4e0d\u540c\u5b66\u79d1\u95f4\u4fdd\u6301\u5e73\u8861\u51c6\u786e\u7387\u3002", "conclusion": "Sci-SpanDet\u663e\u8457\u8d85\u8d8a\u4e86\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e3a\u5b66\u672f\u6587\u6863\u4e2dAI\u751f\u6210\u6587\u672c\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002\u6570\u636e\u96c6\u548c\u6e90\u4ee3\u7801\u5c06\u5728\u53d1\u8868\u540e\u516c\u5f00\uff0c\u4ee5\u786e\u4fdd\u53ef\u91cd\u73b0\u6027\u5e76\u4fc3\u8fdb\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2510.00919", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00919", "abs": "https://arxiv.org/abs/2510.00919", "authors": ["Shunfeng Zheng", "Yudi Zhang", "Meng Fang", "Zihan Zhang", "Zhitan Wu", "Mykola Pechenizkiy", "Ling Chen"], "title": "Benchmarking Foundation Models with Retrieval-Augmented Generation in Olympic-Level Physics Problem Solving", "comment": null, "summary": "Retrieval-augmented generation (RAG) with foundation models has achieved\nstrong performance across diverse tasks, but their capacity for expert-level\nreasoning-such as solving Olympiad-level physics problems-remains largely\nunexplored. Inspired by the way students prepare for competitions by reviewing\npast problems, we investigate the potential of RAG to enhance physics reasoning\nin foundation models. We introduce PhoPile, a high-quality multimodal dataset\nspecifically designed for Olympiad-level physics, enabling systematic study of\nretrieval-based reasoning. PhoPile includes diagrams, graphs, and equations,\ncapturing the inherently multimodal nature of physics problem solving. Using\nPhoPile, we benchmark RAG-augmented foundation models, covering both large\nlanguage models (LLMs) and large multimodal models (LMMs) with multiple\nretrievers. Our results demonstrate that integrating retrieval with physics\ncorpora can improve model performance, while also highlighting challenges that\nmotivate further research in retrieval-augmented physics reasoning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u5728\u89e3\u51b3\u5965\u6797\u5339\u514b\u7269\u7406\u95ee\u9898\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u4e86PhoPile\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u5e76\u9a8c\u8bc1\u4e86RAG\u80fd\u63d0\u5347\u57fa\u7840\u6a21\u578b\u5728\u7269\u7406\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u63a2\u7d22RAG\u5728\u4e13\u5bb6\u7ea7\u7269\u7406\u63a8\u7406\uff08\u5982\u89e3\u51b3\u5965\u6797\u5339\u514b\u7269\u7406\u95ee\u9898\uff09\u4e2d\u7684\u6f5c\u529b\uff0c\u53d7\u5b66\u751f\u901a\u8fc7\u590d\u4e60\u8fc7\u5f80\u95ee\u9898\u51c6\u5907\u7ade\u8d5b\u7684\u542f\u53d1\u3002", "method": "\u5f15\u5165PhoPile\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u5305\u542b\u56fe\u8868\u3001\u56fe\u5f62\u548c\u65b9\u7a0b\uff0c\u7cfb\u7edf\u6027\u5730\u7814\u7a76\u57fa\u4e8e\u68c0\u7d22\u7684\u63a8\u7406\uff0c\u5e76\u5728LLMs\u548cLMMs\u4e0a\u4f7f\u7528\u591a\u79cd\u68c0\u7d22\u5668\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5c06\u68c0\u7d22\u4e0e\u7269\u7406\u8bed\u6599\u5e93\u96c6\u6210\u53ef\u4ee5\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u4e5f\u7a81\u663e\u4e86\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u6311\u6218\u3002", "conclusion": "RAG\u5728\u589e\u5f3a\u7269\u7406\u63a8\u7406\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u4ecd\u6709\u6311\u6218\u9700\u8981\u89e3\u51b3\uff0c\u4e3a\u68c0\u7d22\u589e\u5f3a\u7684\u7269\u7406\u63a8\u7406\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2510.00931", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00931", "abs": "https://arxiv.org/abs/2510.00931", "authors": ["Ammar Khairi", "Daniel D'souza", "Marzieh Fadaee", "Julia Kreutzer"], "title": "Making, not Taking, the Best of N", "comment": null, "summary": "Obtaining high-quality generations in modern LLMs has largely been framed as\na selection problem: identifying a single winning generation from a diverse\npool of N samples, the Best-of-N (BoN). Yet, this approach is inherently\nzero-sum, discarding diverse and potentially useful information from the pool.\nInstead, we explore a collaborative setup, where all candidates can potentially\ncontribute to the final winning generation. To this end, we propose Fusion-of-N\n(FusioN): a method that uses a general LLM judge to synthesize the most\ninformative elements of each sample into a single final answer. We compare\nFusioN to BoN in two settings, (i) test-time scaling, where we sample and\naggregate from a single model at test-time (ii) synthetic data generation,\nwhere we fuse samples from a pool of diverse teachers to improve a student\nmodel. We extensively benchmark both setups across 11 languages, 3 diverse\ntasks and varying model scales. Across the bench, FusioN consistently\noutperforms BoN showing versatility and robustness both in test-time scaling\nand in downstream gains from synthetic data generation. We also perform\nextensive analysis on FusioN, where it shows surprising strengths and\nrobustness under challenging settings. These results show that we should shift\nhow we think about evaluating and utilizing LLM generations from a monolithic\nmeasure of quality, to embracing their polylithic nature. This shift allows us\nto integrate diverse strengths, unlock latent potential, and achieve\nimprovements that were previously inaccessible through selection alone.", "AI": {"tldr": "\u63d0\u51faFusion-of-N\u65b9\u6cd5\uff0c\u901a\u8fc7\u878d\u5408\u591a\u4e2aLLM\u751f\u6210\u6837\u672c\u7684\u6700\u4f18\u90e8\u5206\u6765\u521b\u5efa\u6700\u7ec8\u7b54\u6848\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684Best-of-N\u9009\u62e9\u65b9\u6cd5\u83b7\u5f97\u66f4\u597d\u6548\u679c", "motivation": "\u4f20\u7edfBest-of-N\u65b9\u6cd5\u53ea\u9009\u62e9\u5355\u4e2a\u6700\u4f73\u751f\u6210\u6837\u672c\uff0c\u4e22\u5f03\u4e86\u5176\u4ed6\u6837\u672c\u4e2d\u7684\u6709\u7528\u4fe1\u606f\uff0c\u5b58\u5728\u96f6\u548c\u95ee\u9898", "method": "\u4f7f\u7528\u901a\u7528LLM\u8bc4\u5224\u5668\u6765\u5408\u6210\u6bcf\u4e2a\u6837\u672c\u4e2d\u6700\u5177\u4fe1\u606f\u91cf\u7684\u5143\u7d20\uff0c\u5f62\u6210\u5355\u4e00\u6700\u7ec8\u7b54\u6848", "result": "\u572811\u79cd\u8bed\u8a00\u30013\u4e2a\u591a\u6837\u5316\u4efb\u52a1\u548c\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0a\uff0cFusioN\u59cb\u7ec8\u4f18\u4e8eBoN\uff0c\u5728\u6d4b\u8bd5\u65f6\u6269\u5c55\u548c\u5408\u6210\u6570\u636e\u751f\u6210\u4e2d\u5747\u8868\u73b0\u51fa\u8272", "conclusion": "\u5e94\u4ece\u5355\u4e00\u8d28\u91cf\u8bc4\u4f30\u8f6c\u5411\u62e5\u62b1\u751f\u6210\u7684\u591a\u9762\u6027\uff0c\u901a\u8fc7\u878d\u5408\u591a\u6837\u5316\u4f18\u52bf\u6765\u89e3\u9501\u6f5c\u5728\u80fd\u529b"}}
{"id": "2510.00962", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00962", "abs": "https://arxiv.org/abs/2510.00962", "authors": ["Eileen Pan", "Anna Seo Gyeong Choi", "Maartje ter Hoeve", "Skyler Seto", "Allison Koenecke"], "title": "Analyzing Dialectical Biases in LLMs for Knowledge and Reasoning Benchmarks", "comment": "EMNLP Findings 2025, 12 pages, 11 tables, 3 figures", "summary": "Large language models (LLMs) are ubiquitous in modern day natural language\nprocessing. However, previous work has shown degraded LLM performance for\nunder-represented English dialects. We analyze the effects of typifying\n\"standard\" American English language questions as non-\"standard\" dialectal\nvariants on multiple choice question answering tasks and find up to a 20%\nreduction in accuracy. Additionally, we investigate the grammatical basis of\nunder-performance in non-\"standard\" English questions. We find that individual\ngrammatical rules have varied effects on performance, but some are more\nconsequential than others: three specific grammar rules (existential \"it\", zero\ncopula, and y'all) can explain the majority of performance degradation observed\nin multiple dialects. We call for future work to investigate bias mitigation\nmethods focused on individual, high-impact grammatical structures.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u975e\u6807\u51c6\u82f1\u8bed\u65b9\u8a00\u4e0a\u7684\u8868\u73b0\u663e\u8457\u4e0b\u964d\uff0c\u67d0\u4e9b\u7279\u5b9a\u8bed\u6cd5\u89c4\u5219\uff08\u5b58\u5728\u6027it\u3001\u96f6\u7cfb\u8bcd\u3001y'all\uff09\u662f\u6027\u80fd\u4e0b\u964d\u7684\u4e3b\u8981\u539f\u56e0\u3002", "motivation": "\u5206\u6790\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u975e\u6807\u51c6\u82f1\u8bed\u65b9\u8a00\u65f6\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u7279\u522b\u662f\u8bc6\u522b\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u7684\u5177\u4f53\u8bed\u6cd5\u56e0\u7d20\u3002", "method": "\u901a\u8fc7\u5c06\u6807\u51c6\u7f8e\u56fd\u82f1\u8bed\u95ee\u9898\u8f6c\u5316\u4e3a\u975e\u6807\u51c6\u65b9\u8a00\u53d8\u4f53\uff0c\u5728\u591a\u9879\u9009\u62e9\u95ee\u7b54\u4efb\u52a1\u4e2d\u6d4b\u8bd5\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u5206\u6790\u4e0d\u540c\u8bed\u6cd5\u89c4\u5219\u7684\u5f71\u54cd\u3002", "result": "\u975e\u6807\u51c6\u82f1\u8bed\u95ee\u9898\u5bfc\u81f4\u51c6\u786e\u7387\u4e0b\u964d\u9ad8\u8fbe20%\uff0c\u5176\u4e2d\u4e09\u4e2a\u7279\u5b9a\u8bed\u6cd5\u89c4\u5219\uff08\u5b58\u5728\u6027it\u3001\u96f6\u7cfb\u8bcd\u3001y'all\uff09\u53ef\u4ee5\u89e3\u91ca\u5927\u591a\u6570\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u547c\u5401\u672a\u6765\u7814\u7a76\u5173\u6ce8\u9488\u5bf9\u4e2a\u522b\u9ad8\u5f71\u54cd\u529b\u8bed\u6cd5\u7ed3\u6784\u7684\u504f\u89c1\u7f13\u89e3\u65b9\u6cd5\u3002"}}
{"id": "2510.01028", "categories": ["cs.CL", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.01028", "abs": "https://arxiv.org/abs/2510.01028", "authors": ["Ruqian Zhang", "Yijiao Zhang", "Juan Shen", "Zhongyi Zhu", "Annie Qu"], "title": "Syntax-Guided Diffusion Language Models with User-Integrated Personalization", "comment": null, "summary": "Large language models have made revolutionary progress in generating\nhuman-like text, yet their outputs often tend to be generic, exhibiting\ninsufficient structural diversity, which limits personalized expression. Recent\nadvances in diffusion models have opened new opportunities for improving\nlanguage generation beyond the limitations of autoregressive paradigms. In this\nwork, we propose a syntax-guided diffusion language model that integrates\nstructural supervision and personalized conditioning to enhance text quality,\ndiversity, and controllability. We introduce a cascaded framework that\ngenerates syntactic guidance before conditional text generation, and further\ngeneralize it to a novel noncascaded architecture for better alignment between\nstructure and content. By incorporating syntactic information in the generating\nprocess, the proposed model better captures the lexical and structural\ncharacteristics of stylistic sentence construction. To enable fine-grained\npersonalization, we develop a shared representation mechanism that facilitates\ninformation integration across users, supporting both faithful stylistic\ngeneration and generalizable zero-shot inference. Extensive experiments on\nmultiple tasks demonstrate the superiority of our approach in fluency,\ndiversity, and stylistic fidelity. Further qualitative analyses highlight its\ninterpretability and flexibility in learning personalized patterns.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8bed\u6cd5\u5f15\u5bfc\u7684\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u6784\u76d1\u7763\u548c\u4e2a\u6027\u5316\u6761\u4ef6\u589e\u5f3a\u6587\u672c\u8d28\u91cf\u3001\u591a\u6837\u6027\u548c\u53ef\u63a7\u6027\uff0c\u5305\u542b\u7ea7\u8054\u548c\u975e\u7ea7\u8054\u4e24\u79cd\u67b6\u6784\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u6587\u672c\u5f80\u5f80\u8fc7\u4e8e\u901a\u7528\uff0c\u7f3a\u4e4f\u7ed3\u6784\u591a\u6837\u6027\uff0c\u9650\u5236\u4e86\u4e2a\u6027\u5316\u8868\u8fbe\u3002\u6269\u6563\u6a21\u578b\u4e3a\u8d85\u8d8a\u81ea\u56de\u5f52\u8303\u5f0f\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a\u3002", "method": "\u5f15\u5165\u8bed\u6cd5\u5f15\u5bfc\u7684\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff0c\u91c7\u7528\u7ea7\u8054\u6846\u67b6\u5148\u751f\u6210\u8bed\u6cd5\u6307\u5bfc\u518d\u8fdb\u884c\u6761\u4ef6\u6587\u672c\u751f\u6210\uff0c\u5e76\u63a8\u5e7f\u5230\u975e\u7ea7\u8054\u67b6\u6784\u4ee5\u66f4\u597d\u5bf9\u9f50\u7ed3\u6784\u548c\u5185\u5bb9\u3002\u901a\u8fc7\u5171\u4eab\u8868\u793a\u673a\u5236\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u4e2a\u6027\u5316\u3002", "result": "\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6d41\u7545\u6027\u3001\u591a\u6837\u6027\u548c\u98ce\u683c\u4fdd\u771f\u5ea6\u65b9\u9762\u5177\u6709\u4f18\u8d8a\u6027\u3002\u5b9a\u6027\u5206\u6790\u7a81\u51fa\u4e86\u5176\u5728\u5b66\u4e60\u4e2a\u6027\u5316\u6a21\u5f0f\u65b9\u9762\u7684\u53ef\u89e3\u91ca\u6027\u548c\u7075\u6d3b\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u8bed\u6cd5\u5f15\u5bfc\u6269\u6563\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u6574\u5408\u7ed3\u6784\u76d1\u7763\u548c\u4e2a\u6027\u5316\u6761\u4ef6\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6587\u672c\u751f\u6210\u7684\u8d28\u91cf\u3001\u591a\u6837\u6027\u548c\u53ef\u63a7\u6027\u3002"}}
{"id": "2510.01048", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.01048", "abs": "https://arxiv.org/abs/2510.01048", "authors": ["Nils Feldhus", "Laura Kopf"], "title": "Interpreting Language Models Through Concept Descriptions: A Survey", "comment": "Accepted at The Eight Workshop on Analyzing and Interpreting Neural\n  Networks for NLP (BlackboxNLP), co-located with EMNLP 2025", "summary": "Understanding the decision-making processes of neural networks is a central\ngoal of mechanistic interpretability. In the context of Large Language Models\n(LLMs), this involves uncovering the underlying mechanisms and identifying the\nroles of individual model components such as neurons and attention heads, as\nwell as model abstractions such as the learned sparse features extracted by\nSparse Autoencoders (SAEs). A rapidly growing line of work tackles this\nchallenge by using powerful generator models to produce open-vocabulary,\nnatural language concept descriptions for these components. In this paper, we\nprovide the first survey of the emerging field of concept descriptions for\nmodel components and abstractions. We chart the key methods for generating\nthese descriptions, the evolving landscape of automated and human metrics for\nevaluating them, and the datasets that underpin this research. Our synthesis\nreveals a growing demand for more rigorous, causal evaluation. By outlining the\nstate of the art and identifying key challenges, this survey provides a roadmap\nfor future research toward making models more transparent.", "AI": {"tldr": "\u8fd9\u662f\u5173\u4e8e\u795e\u7ecf\u7f51\u7edc\u53ef\u89e3\u91ca\u6027\u9886\u57df\u7684\u9996\u7bc7\u7efc\u8ff0\u8bba\u6587\uff0c\u805a\u7126\u4e8e\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7ec4\u4ef6\u548c\u62bd\u8c61\u751f\u6210\u6982\u5ff5\u63cf\u8ff0\u7684\u65b9\u6cd5\u3001\u8bc4\u4f30\u6307\u6807\u548c\u6570\u636e\u96c6\u3002", "motivation": "\u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u51b3\u7b56\u8fc7\u7a0b\u662f\u53ef\u89e3\u91ca\u6027\u7684\u6838\u5fc3\u76ee\u6807\uff0c\u9700\u8981\u63ed\u793a\u5e95\u5c42\u673a\u5236\u5e76\u8bc6\u522b\u6a21\u578b\u7ec4\u4ef6\u7684\u4f5c\u7528\u3002\u968f\u7740\u4f7f\u7528\u751f\u6210\u6a21\u578b\u4e3a\u7ec4\u4ef6\u751f\u6210\u81ea\u7136\u8bed\u8a00\u6982\u5ff5\u63cf\u8ff0\u7684\u7814\u7a76\u5feb\u901f\u589e\u957f\uff0c\u6709\u5fc5\u8981\u5bf9\u8fd9\u4e00\u65b0\u5174\u9886\u57df\u8fdb\u884c\u7cfb\u7edf\u68b3\u7406\u3002", "method": "\u901a\u8fc7\u8c03\u67e5\u73b0\u6709\u6587\u732e\uff0c\u68b3\u7406\u4e86\u751f\u6210\u6982\u5ff5\u63cf\u8ff0\u7684\u5173\u952e\u65b9\u6cd5\u3001\u81ea\u52a8\u5316\u4e0e\u4eba\u5de5\u8bc4\u4f30\u6307\u6807\u7684\u6f14\u53d8\uff0c\u4ee5\u53ca\u652f\u6491\u8be5\u7814\u7a76\u7684\u6570\u636e\u96c6\u3002", "result": "\u7efc\u5408\u53d1\u73b0\u8be5\u9886\u57df\u5bf9\u66f4\u4e25\u8c28\u7684\u56e0\u679c\u8bc4\u4f30\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6280\u672f\u73b0\u72b6\u548c\u5173\u952e\u6311\u6218\u3002", "conclusion": "\u672c\u7efc\u8ff0\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u8def\u7ebf\u56fe\uff0c\u65e8\u5728\u63a8\u52a8\u6a21\u578b\u66f4\u52a0\u900f\u660e\u5316\uff0c\u901a\u8fc7\u7cfb\u7edf\u68b3\u7406\u6982\u5ff5\u63cf\u8ff0\u751f\u6210\u65b9\u6cd5\u3001\u8bc4\u4f30\u6807\u51c6\u548c\u6570\u636e\u96c6\uff0c\u4e3a\u8be5\u9886\u57df\u53d1\u5c55\u6307\u660e\u65b9\u5411\u3002"}}
{"id": "2510.01052", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01052", "abs": "https://arxiv.org/abs/2510.01052", "authors": ["Samin Mahdipour Aghabagher", "Saeedeh Momtazi"], "title": "Hybrid Dialogue State Tracking for Persian Chatbots: A Language Model-Based Approach", "comment": "22 pages, 1 figure. Submitted to Natural Language Engineering", "summary": "Dialogue State Tracking (DST) is an essential element of conversational AI\nwith the objective of deeply understanding the conversation context and leading\nit toward answering user requests. Due to high demands for open-domain and\nmulti-turn chatbots, the traditional rule-based DST is not efficient enough,\nsince it cannot provide the required adaptability and coherence for human-like\nexperiences in complex conversations. This study proposes a hybrid DST model\nthat utilizes rule-based methods along with language models, including BERT for\nslot filling and intent detection, XGBoost for intent validation, GPT for DST,\nand online agents for real-time answer generation. This model is uniquely\ndesigned to be evaluated on a comprehensive Persian multi-turn dialogue dataset\nand demonstrated significantly improved accuracy and coherence over existing\nmethods in Persian-based chatbots. The results demonstrate how effectively a\nhybrid approach may improve DST capabilities, paving the way for conversational\nAI systems that are more customized, adaptable, and human-like.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u5bf9\u8bdd\u72b6\u6001\u8ddf\u8e2a\u6a21\u578b\uff0c\u7ed3\u5408\u89c4\u5219\u65b9\u6cd5\u548c\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u6ce2\u65af\u8bed\u591a\u8f6e\u5bf9\u8bdd\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\u548c\u8fde\u8d2f\u6027\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684DST\u65b9\u6cd5\u5728\u5f00\u653e\u57df\u548c\u591a\u8f6e\u804a\u5929\u673a\u5668\u4eba\u4e2d\u6548\u7387\u4e0d\u8db3\uff0c\u65e0\u6cd5\u4e3a\u590d\u6742\u5bf9\u8bdd\u63d0\u4f9b\u8db3\u591f\u9002\u5e94\u6027\u548c\u8fde\u8d2f\u6027\u3002", "method": "\u6df7\u5408DST\u6a21\u578b\uff1a\u4f7f\u7528BERT\u8fdb\u884c\u69fd\u586b\u5145\u548c\u610f\u56fe\u68c0\u6d4b\uff0cXGBoost\u8fdb\u884c\u610f\u56fe\u9a8c\u8bc1\uff0cGPT\u8fdb\u884cDST\uff0c\u5728\u7ebf\u4ee3\u7406\u8fdb\u884c\u5b9e\u65f6\u7b54\u6848\u751f\u6210\u3002", "result": "\u5728\u6ce2\u65af\u8bed\u591a\u8f6e\u5bf9\u8bdd\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u8fde\u8d2f\u6027\u3002", "conclusion": "\u6df7\u5408\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347DST\u80fd\u529b\uff0c\u4e3a\u66f4\u5b9a\u5236\u5316\u3001\u9002\u5e94\u6027\u66f4\u5f3a\u3001\u66f4\u4eba\u6027\u5316\u7684\u5bf9\u8bddAI\u7cfb\u7edf\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2510.01076", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.01076", "abs": "https://arxiv.org/abs/2510.01076", "authors": ["Haonan Wang", "Junfeng Sun", "Mingjia Zhao", "Wei Liu"], "title": "Research on the Integration of Embodied Intelligence and Reinforcement Learning in Textual Domains", "comment": "4 pages", "summary": "This article addresses embodied intelligence and reinforcement learning\nintegration in the field of text processing, aiming to enhance text handling\nwith more intelligence on the basis of embodied intelligence's perception and\naction superiority and reinforcement learning's decision optimization\ncapability. Through detailed theoretical explanation and experimental\nexploration, a novel integration model is introduced. This model has been\ndemonstrated to be very effective in a wide range oftext processing tasks,\nvalidating its applicative potential", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5177\u8eab\u667a\u80fd\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u65b0\u578b\u6587\u672c\u5904\u7406\u6a21\u578b\uff0c\u901a\u8fc7\u5177\u8eab\u667a\u80fd\u7684\u611f\u77e5\u884c\u52a8\u4f18\u52bf\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u51b3\u7b56\u4f18\u5316\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6587\u672c\u5904\u7406\u7684\u667a\u80fd\u5316\u6c34\u5e73\u3002", "motivation": "\u65e8\u5728\u5229\u7528\u5177\u8eab\u667a\u80fd\u5728\u611f\u77e5\u548c\u884c\u52a8\u65b9\u9762\u7684\u4f18\u52bf\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u7684\u51b3\u7b56\u4f18\u5316\u80fd\u529b\uff0c\u63d0\u5347\u6587\u672c\u5904\u7406\u7684\u667a\u80fd\u5316\u6c34\u5e73\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u9610\u8ff0\u548c\u5b9e\u9a8c\u63a2\u7d22\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5177\u8eab\u667a\u80fd\u4e0e\u5f3a\u5316\u5b66\u4e60\u76f8\u7ed3\u5408\u7684\u65b0\u578b\u96c6\u6210\u6a21\u578b\u3002", "result": "\u8be5\u6a21\u578b\u5728\u5e7f\u6cdb\u7684\u6587\u672c\u5904\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u9a8c\u8bc1\u4e86\u5176\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u7ed3\u5408\u5177\u8eab\u667a\u80fd\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u96c6\u6210\u6a21\u578b\u80fd\u591f\u6709\u6548\u63d0\u5347\u6587\u672c\u5904\u7406\u7684\u667a\u80fd\u5316\u6c34\u5e73\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2510.01145", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.01145", "abs": "https://arxiv.org/abs/2510.01145", "authors": ["Sukairaj Hafiz Imam", "Tadesse Destaw Belay", "Kedir Yassin Husse", "Ibrahim Said Ahmad", "Idris Abdulmumin", "Hadiza Ali Umar", "Muhammad Yahuza Bello", "Joyce Nakatumba-Nabende", "Seid Muhie Yimam", "Shamsuddeen Hassan Muhammad"], "title": "Automatic Speech Recognition (ASR) for African Low-Resource Languages: A Systematic Literature Review", "comment": null, "summary": "ASR has achieved remarkable global progress, yet African low-resource\nlanguages remain rigorously underrepresented, producing barriers to digital\ninclusion across the continent with more than +2000 languages. This systematic\nliterature review (SLR) explores research on ASR for African languages with a\nfocus on datasets, models and training methods, evaluation techniques,\nchallenges, and recommends future directions. We employ the PRISMA 2020\nprocedures and search DBLP, ACM Digital Library, Google Scholar, Semantic\nScholar, and arXiv for studies published between January 2020 and July 2025. We\ninclude studies related to ASR datasets, models or metrics for African\nlanguages, while excluding non-African, duplicates, and low-quality studies\n(score <3/5). We screen 71 out of 2,062 records and we record a total of 74\ndatasets across 111 languages, encompassing approximately 11,206 hours of\nspeech. Fewer than 15% of research provided reproducible materials, and dataset\nlicensing is not clear. Self-supervised and transfer learning techniques are\npromising, but are hindered by limited pre-training data, inadequate coverage\nof dialects, and the availability of resources. Most of the researchers use\nWord Error Rate (WER), with very minimal use of linguistically informed scores\nsuch as Character Error Rate (CER) or Diacritic Error Rate (DER), and thus with\nlimited application in tonal and morphologically rich languages. The existing\nevidence on ASR systems is inconsistent, hindered by issues like dataset\navailability, poor annotations, licensing uncertainties, and limited\nbenchmarking. Nevertheless, the rise of community-driven initiatives and\nmethodological advancements indicates a pathway for improvement. Sustainable\ndevelopment for this area will also include stakeholder partnership, creation\nof ethically well-balanced datasets, use of lightweight modelling techniques,\nand active benchmarking.", "AI": {"tldr": "\u8fd9\u7bc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u5206\u6790\u4e862020-2025\u5e74\u95f4\u975e\u6d32\u4f4e\u8d44\u6e90\u8bed\u8a00\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b(ASR)\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u53d1\u73b0\u6570\u636e\u96c6\u7a00\u7f3a\u3001\u6a21\u578b\u53ef\u590d\u73b0\u6027\u5dee\u3001\u8bc4\u4f30\u6307\u6807\u5355\u4e00\u7b49\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u793e\u533a\u9a71\u52a8\u3001\u4f26\u7406\u6570\u636e\u96c6\u548c\u8f7b\u91cf\u5efa\u6a21\u7b49\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u975e\u6d32\u62e5\u67092000\u591a\u79cd\u8bed\u8a00\uff0c\u4f46\u5728ASR\u7814\u7a76\u4e2d\u4ee3\u8868\u6027\u4e25\u91cd\u4e0d\u8db3\uff0c\u8fd9\u963b\u788d\u4e86\u6570\u5b57\u5305\u5bb9\u6027\u53d1\u5c55\u3002\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u975e\u6d32\u8bed\u8a00ASR\u7684\u7814\u7a76\u73b0\u72b6\u3001\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\u3002", "method": "\u91c7\u7528PRISMA 2020\u65b9\u6cd5\uff0c\u68c0\u7d22DBLP\u3001ACM Digital Library\u7b49\u6570\u636e\u5e93\uff0c\u7b5b\u9009\u51fa71\u7bc7\u76f8\u5173\u7814\u7a76\uff0c\u5206\u679074\u4e2a\u6570\u636e\u96c6\u8986\u76d6111\u79cd\u8bed\u8a00\u7ea611,206\u5c0f\u65f6\u8bed\u97f3\u6570\u636e\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a\u4ec5\u4e0d\u523015%\u7684\u7814\u7a76\u63d0\u4f9b\u53ef\u590d\u73b0\u6750\u6599\uff1b\u6570\u636e\u96c6\u8bb8\u53ef\u4e0d\u660e\u786e\uff1b\u81ea\u76d1\u7763\u548c\u8fc1\u79fb\u5b66\u4e60\u6709\u6f5c\u529b\u4f46\u53d7\u9650\u4e8e\u9884\u8bad\u7ec3\u6570\u636e\uff1b\u8bc4\u4f30\u4e3b\u8981\u4f7f\u7528WER\uff0c\u7f3a\u4e4f\u5bf9\u97f3\u8c03\u548c\u5f62\u6001\u4e30\u5bcc\u8bed\u8a00\u7684\u4e13\u95e8\u6307\u6807\u3002", "conclusion": "\u975e\u6d32\u8bed\u8a00ASR\u53d1\u5c55\u9762\u4e34\u6570\u636e\u96c6\u53ef\u7528\u6027\u3001\u6807\u6ce8\u8d28\u91cf\u3001\u8bb8\u53ef\u4e0d\u786e\u5b9a\u6027\u7b49\u6311\u6218\uff0c\u4f46\u793e\u533a\u9a71\u52a8\u5021\u8bae\u548c\u65b9\u6cd5\u8fdb\u6b65\u63d0\u4f9b\u4e86\u6539\u8fdb\u8def\u5f84\uff0c\u9700\u8981\u5229\u76ca\u76f8\u5173\u8005\u5408\u4f5c\u3001\u4f26\u7406\u6570\u636e\u96c6\u521b\u5efa\u548c\u8f7b\u91cf\u5efa\u6a21\u6280\u672f\u3002"}}
{"id": "2510.01146", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.01146", "abs": "https://arxiv.org/abs/2510.01146", "authors": ["David Anugraha", "Shou-Yi Hung", "Zilu Tang", "Annie En-Shiun Lee", "Derry Tanti Wijaya", "Genta Indra Winata"], "title": "mR3: Multilingual Rubric-Agnostic Reward Reasoning Models", "comment": null, "summary": "Evaluation using Large Language Model (LLM) judges has been widely adopted in\nEnglish and shown to be effective for automatic evaluation. However, their\nperformance does not generalize well to non-English settings, and it remains\nunclear what constitutes effective multilingual training for such judges. In\nthis paper, we introduce mR3, a massively multilingual, rubric-agnostic reward\nreasoning model trained on 72 languages, achieving the broadest language\ncoverage in reward modeling to date. We present a comprehensive study of data\nand curriculum selection for training to identify effective strategies and data\nsources for building high-quality reward models, including the integration of\ntarget-language reasoning datasets. Our approach attains state-of-the-art\nperformance on multilingual reward model benchmarks, surpassing much larger\nmodels (i.e., GPT-OSS-120B) while being up to 9x smaller, and its effectiveness\nis further confirmed through extensive ablation studies. Our models, data, and\ncode are available as open source at https://github.com/rubricreward/mr3.", "AI": {"tldr": "mR3\u662f\u4e00\u4e2a\u591a\u8bed\u8a00\u5956\u52b1\u63a8\u7406\u6a21\u578b\uff0c\u572872\u79cd\u8bed\u8a00\u4e0a\u8bad\u7ec3\uff0c\u662f\u76ee\u524d\u8986\u76d6\u8bed\u8a00\u6700\u5e7f\u7684\u5956\u52b1\u6a21\u578b\uff0c\u5728\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u66f4\u5927\u6a21\u578b\u4e14\u5c3a\u5bf8\u5c0f9\u500d\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u5728\u82f1\u8bed\u4e2d\u6709\u6548\uff0c\u4f46\u5728\u975e\u82f1\u8bed\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u4e0d\u6e05\u695a\u5982\u4f55\u6709\u6548\u8fdb\u884c\u591a\u8bed\u8a00\u8bad\u7ec3\u3002", "method": "\u63d0\u51famR3\u6a21\u578b\uff0c\u901a\u8fc7\u6570\u636e\u9009\u62e9\u548c\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\uff0c\u6574\u5408\u76ee\u6807\u8bed\u8a00\u63a8\u7406\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u8986\u76d672\u79cd\u8bed\u8a00\u7684\u5956\u52b1\u6a21\u578b\u3002", "result": "\u5728\u591a\u8bed\u8a00\u5956\u52b1\u6a21\u578b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u8d85\u8d8aGPT-OSS-120B\u7b49\u66f4\u5927\u6a21\u578b\uff0c\u540c\u65f6\u6a21\u578b\u5c3a\u5bf8\u5c0f9\u500d\u3002", "conclusion": "mR3\u8bc1\u660e\u4e86\u6784\u5efa\u9ad8\u8d28\u91cf\u591a\u8bed\u8a00\u5956\u52b1\u6a21\u578b\u7684\u6709\u6548\u7b56\u7565\uff0c\u6a21\u578b\u3001\u6570\u636e\u548c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2510.01152", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.01152", "abs": "https://arxiv.org/abs/2510.01152", "authors": ["Mustafa Omer Gul", "Claire Cardie", "Tanya Goyal"], "title": "Pay-Per-Search Models are Abstention Models", "comment": "21 pages, with 10 dedicated to citations and appendix. 9 tables and 9\n  figures. Preprint, under review", "summary": "LLMs cannot reliably recognize their parametric knowledge boundaries and\noften hallucinate answers to outside-of-boundary questions. In contrast, humans\nrecognize their limitations and can either seek external help for such\nquestions or abstain. In this paper, we introduce MASH (Modeling Abstention via\nSelective Help-seeking), a training framework that readily extracts abstentions\nfrom LLMs. Our key idea is that any external help-seeking by an LLM, i.e.\nsearch tool use, can serve as a proxy for abstention if the external help\n(search) is appropriately penalized while simultaneously rewarding answer\naccuracy. MASH operationalizes this idea using reinforcement learning with a\npay-per-search reward.\n  We run experiments on three knowledge-intensive QA datasets. Our results show\nthat MASH substantially improves upon the selective help-seeking performance of\nprior efficient search approaches; on multi-hop datasets, MASH improves answer\naccuracy by 7.6%. Furthermore, MASH demonstrates strong off-the-shelf\nabstention -- it can distinguish between unanswerable/answerable questions and\nselectively generate responses for answerable questions -- showcasing behavior\nanalogous to specialized abstention approaches. We emphasize that contrary to\nprior abstention methods, MASH does not require pre-determining knowledge\nboundaries to construct training data. Instead, MASH's abstentions are a\nby-product of training for the auxiliary selective help-seeking task. Overall,\nwe show that MASH training effectively aligns search tool use with parametric\nknowledge, which can be successfully leveraged for making abstention decisions.", "AI": {"tldr": "MASH\u662f\u4e00\u4e2a\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u60e9\u7f5a\u5916\u90e8\u641c\u7d22\u4f7f\u7528\u540c\u65f6\u5956\u52b1\u7b54\u6848\u51c6\u786e\u6027\uff0c\u8ba9LLM\u5b66\u4f1a\u5728\u8d85\u51fa\u77e5\u8bc6\u8fb9\u754c\u65f6\u5bfb\u6c42\u5e2e\u52a9\u6216\u5f03\u6743\uff0c\u4ece\u800c\u6709\u6548\u8bc6\u522b\u77e5\u8bc6\u8fb9\u754c\u5e76\u51cf\u5c11\u5e7b\u89c9\u3002", "motivation": "LLM\u65e0\u6cd5\u53ef\u9760\u8bc6\u522b\u81ea\u8eab\u77e5\u8bc6\u8fb9\u754c\uff0c\u7ecf\u5e38\u5bf9\u8d85\u51fa\u8fb9\u754c\u7684\u95ee\u9898\u4ea7\u751f\u5e7b\u89c9\u56de\u7b54\uff0c\u800c\u4eba\u7c7b\u80fd\u591f\u8ba4\u8bc6\u5230\u81ea\u8eab\u5c40\u9650\u5e76\u5bfb\u6c42\u5916\u90e8\u5e2e\u52a9\u6216\u5f03\u6743\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6309\u6b21\u641c\u7d22\u4ed8\u8d39\u7684\u5956\u52b1\u673a\u5236\uff0c\u60e9\u7f5a\u5916\u90e8\u641c\u7d22\u4f7f\u7528\u540c\u65f6\u5956\u52b1\u51c6\u786e\u7b54\u6848\uff0c\u8bad\u7ec3LLM\u9009\u62e9\u6027\u5bfb\u6c42\u5e2e\u52a9\u3002", "result": "\u5728\u4e09\u4e2a\u77e5\u8bc6\u5bc6\u96c6\u578bQA\u6570\u636e\u96c6\u4e0a\uff0cMASH\u663e\u8457\u4f18\u4e8e\u5148\u524d\u7684\u9ad8\u6548\u641c\u7d22\u65b9\u6cd5\uff1b\u5728\u591a\u8df3\u6570\u636e\u96c6\u4e0a\u7b54\u6848\u51c6\u786e\u7387\u63d0\u9ad87.6%\uff0c\u5e76\u80fd\u6709\u6548\u533a\u5206\u53ef\u56de\u7b54/\u4e0d\u53ef\u56de\u7b54\u95ee\u9898\u3002", "conclusion": "MASH\u8bad\u7ec3\u6709\u6548\u5bf9\u9f50\u4e86\u641c\u7d22\u5de5\u5177\u4f7f\u7528\u4e0e\u53c2\u6570\u77e5\u8bc6\uff0c\u53ef\u6210\u529f\u7528\u4e8e\u5f03\u6743\u51b3\u7b56\uff0c\u4e14\u65e0\u9700\u9884\u5148\u786e\u5b9a\u77e5\u8bc6\u8fb9\u754c\u6765\u6784\u5efa\u8bad\u7ec3\u6570\u636e\u3002"}}
{"id": "2510.01157", "categories": ["cs.CL", "cs.CR", "cs.SD"], "pdf": "https://arxiv.org/pdf/2510.01157", "abs": "https://arxiv.org/abs/2510.01157", "authors": ["Alexandrine Fortier", "Thomas Thebaud", "Jes\u00fas Villalba", "Najim Dehak", "Patrick Cardinal"], "title": "Backdoor Attacks Against Speech Language Models", "comment": null, "summary": "Large Language Models (LLMs) and their multimodal extensions are becoming\nincreasingly popular. One common approach to enable multimodality is to cascade\ndomain-specific encoders with an LLM, making the resulting model inherit\nvulnerabilities from all of its components. In this work, we present the first\nsystematic study of audio backdoor attacks against speech language models. We\ndemonstrate its effectiveness across four speech encoders and three datasets,\ncovering four tasks: automatic speech recognition (ASR), speech emotion\nrecognition, and gender and age prediction. The attack consistently achieves\nhigh success rates, ranging from 90.76% to 99.41%. To better understand how\nbackdoors propagate, we conduct a component-wise analysis to identify the most\nvulnerable stages of the pipeline. Finally, we propose a fine-tuning-based\ndefense that mitigates the threat of poisoned pretrained encoders.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u9488\u5bf9\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u7684\u97f3\u9891\u540e\u95e8\u653b\u51fb\uff0c\u5c55\u793a\u4e86\u5728\u56db\u4e2a\u8bed\u97f3\u7f16\u7801\u5668\u548c\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u6709\u6548\u6027\uff0c\u653b\u51fb\u6210\u529f\u7387\u9ad8\u8fbe90.76%-99.41%\u3002\u901a\u8fc7\u7ec4\u4ef6\u5206\u6790\u8bc6\u522b\u4e86\u7ba1\u9053\u4e2d\u6700\u8106\u5f31\u7684\u9636\u6bb5\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u5fae\u8c03\u7684\u9632\u5fa1\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u53ca\u5176\u591a\u6a21\u6001\u6269\u5c55\u7684\u666e\u53ca\uff0c\u901a\u8fc7\u7ea7\u8054\u9886\u57df\u7279\u5b9a\u7f16\u7801\u5668\u4e0eLLM\u5b9e\u73b0\u591a\u6a21\u6001\u7684\u65b9\u6cd5\u4f7f\u6a21\u578b\u7ee7\u627f\u4e86\u6240\u6709\u7ec4\u4ef6\u7684\u6f0f\u6d1e\u3002\u672c\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u63a2\u7d22\u97f3\u9891\u540e\u95e8\u653b\u51fb\u5bf9\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u7684\u5a01\u80c1\u3002", "method": "\u5bf9\u56db\u4e2a\u8bed\u97f3\u7f16\u7801\u5668\u548c\u4e09\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u97f3\u9891\u540e\u95e8\u653b\u51fb\u5b9e\u9a8c\uff0c\u8986\u76d6\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u3001\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u3001\u6027\u522b\u548c\u5e74\u9f84\u9884\u6d4b\u56db\u4e2a\u4efb\u52a1\u3002\u901a\u8fc7\u7ec4\u4ef6\u5206\u6790\u8bc6\u522b\u7ba1\u9053\u8106\u5f31\u9636\u6bb5\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u5fae\u8c03\u7684\u9632\u5fa1\u65b9\u6cd5\u3002", "result": "\u653b\u51fb\u5728\u56db\u4e2a\u4efb\u52a1\u4e2d\u5747\u53d6\u5f97\u9ad8\u6210\u529f\u7387\uff0c\u8303\u56f4\u4ece90.76%\u523099.41%\u3002\u7ec4\u4ef6\u5206\u6790\u63ed\u793a\u4e86\u7ba1\u9053\u4e2d\u6700\u6613\u53d7\u653b\u51fb\u7684\u9636\u6bb5\u3002\u63d0\u51fa\u7684\u5fae\u8c03\u9632\u5fa1\u65b9\u6cd5\u6709\u6548\u7f13\u89e3\u4e86\u9884\u8bad\u7ec3\u7f16\u7801\u5668\u4e2d\u6bd2\u7684\u5a01\u80c1\u3002", "conclusion": "\u97f3\u9891\u540e\u95e8\u653b\u51fb\u5bf9\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u653b\u51fb\u6210\u529f\u7387\u6781\u9ad8\u3002\u901a\u8fc7\u7ec4\u4ef6\u5206\u6790\u8bc6\u522b\u4e86\u5173\u952e\u8106\u5f31\u70b9\uff0c\u63d0\u51fa\u7684\u5fae\u8c03\u9632\u5fa1\u4e3a\u7f13\u89e3\u6b64\u7c7b\u5a01\u80c1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.01164", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.01164", "abs": "https://arxiv.org/abs/2510.01164", "authors": ["Zhengliang Shi", "Ruotian Ma", "Jen-tse Huang", "Xinbei Ma", "Xingyu Chen", "Mengru Wang", "Qu Yang", "Yue Wang", "Fanghua Ye", "Ziyang Chen", "Shanyi Wang", "Cixing Li", "Wenxuan Wang", "Zhaopeng Tu", "Xiaolong Li", "Zhaochun Ren", "Linus"], "title": "Social Welfare Function Leaderboard: When LLM Agents Allocate Social Welfare", "comment": null, "summary": "Large language models (LLMs) are increasingly entrusted with high-stakes\ndecisions that affect human welfare. However, the principles and values that\nguide these models when distributing scarce societal resources remain largely\nunexamined. To address this, we introduce the Social Welfare Function (SWF)\nBenchmark, a dynamic simulation environment where an LLM acts as a sovereign\nallocator, distributing tasks to a heterogeneous community of recipients. The\nbenchmark is designed to create a persistent trade-off between maximizing\ncollective efficiency (measured by Return on Investment) and ensuring\ndistributive fairness (measured by the Gini coefficient). We evaluate 20\nstate-of-the-art LLMs and present the first leaderboard for social welfare\nallocation. Our findings reveal three key insights: (i) A model's general\nconversational ability, as measured by popular leaderboards, is a poor\npredictor of its allocation skill. (ii) Most LLMs exhibit a strong default\nutilitarian orientation, prioritizing group productivity at the expense of\nsevere inequality. (iii) Allocation strategies are highly vulnerable, easily\nperturbed by output-length constraints and social-influence framing. These\nresults highlight the risks of deploying current LLMs as societal\ndecision-makers and underscore the need for specialized benchmarks and targeted\nalignment for AI governance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u793e\u4f1a\u798f\u5229\u51fd\u6570\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30LLMs\u5728\u8d44\u6e90\u5206\u914d\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5927\u591a\u6570\u6a21\u578b\u504f\u5411\u529f\u5229\u4e3b\u4e49\uff0c\u5bfc\u81f4\u4e25\u91cd\u4e0d\u5e73\u7b49\uff0c\u4e14\u5206\u914d\u7b56\u7565\u6613\u53d7\u5e72\u6270\u3002", "motivation": "\u968f\u7740LLMs\u88ab\u7528\u4e8e\u9ad8\u98ce\u9669\u51b3\u7b56\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u5728\u7a00\u7f3a\u793e\u4f1a\u8d44\u6e90\u5206\u914d\u4e2d\u7684\u539f\u5219\u548c\u4ef7\u503c\u89c2\u3002", "method": "\u5f15\u5165\u793e\u4f1a\u798f\u5229\u51fd\u6570\u57fa\u51c6\uff0c\u6a21\u62dfLLMs\u4f5c\u4e3a\u4e3b\u6743\u5206\u914d\u8005\u5411\u5f02\u8d28\u793e\u533a\u5206\u914d\u4efb\u52a1\uff0c\u5728\u96c6\u4f53\u6548\u7387\u548c\u5206\u914d\u516c\u5e73\u6027\u4e4b\u95f4\u5efa\u7acb\u6301\u4e45\u6743\u8861\u3002", "result": "\u8bc4\u4f3020\u4e2a\u5148\u8fdbLLMs\u53d1\u73b0\uff1a\u5bf9\u8bdd\u80fd\u529b\u4e0d\u80fd\u9884\u6d4b\u5206\u914d\u6280\u80fd\uff1b\u591a\u6570\u6a21\u578b\u9ed8\u8ba4\u529f\u5229\u4e3b\u4e49\u53d6\u5411\uff1b\u5206\u914d\u7b56\u7565\u6613\u53d7\u8f93\u51fa\u957f\u5ea6\u548c\u793e\u4f1a\u5f71\u54cd\u6846\u67b6\u5e72\u6270\u3002", "conclusion": "\u5f53\u524dLLMs\u4f5c\u4e3a\u793e\u4f1a\u51b3\u7b56\u8005\u5b58\u5728\u98ce\u9669\uff0c\u9700\u8981\u4e13\u95e8\u57fa\u51c6\u548c\u9488\u5bf9\u6027\u5bf9\u9f50\u6765\u6539\u8fdbAI\u6cbb\u7406\u3002"}}
{"id": "2510.01165", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.01165", "abs": "https://arxiv.org/abs/2510.01165", "authors": ["Oussama Gabouj", "Kamel Charaf", "Ivan Zakazov", "Nicolas Baldwin", "Robert West"], "title": "GRAD: Generative Retrieval-Aligned Demonstration Sampler for Efficient Few-Shot Reasoning", "comment": "EMNLP 2025 (findings)", "summary": "Large Language Models (LLMs) achieve strong performance across diverse tasks,\nbut their effectiveness often depends on the quality of the provided context.\nRetrieval-Augmented Generation (RAG) enriches prompts with external\ninformation, but its reliance on static databases constrains adaptability and\ncan result in irrelevant demonstrations. In this work, we propose a Generative\nRetrieval-Aligned Demonstrator (GRAD), a dynamic demonstration-based approach\nwhere an LLM model is trained to generate input-specific concise\ndemonstrations. By tailoring demonstrations to each input, our method offers\nbetter contextual support than traditional RAG approaches. We demonstrate the\nsuperiority of GRAD under budget constraints, where we limit both the number of\ntokens used per demonstration and the number of tokens used for the final\noutput. Trained solely on a math dataset, GRAD consistently outperforms strong\nbaselines on Qwen2.5-14B across mathematical reasoning and advanced STEM\nquestions, highlighting GRAD's robust generalization to out-of-distribution\n(OOD) domains such as physics, chemistry, and computer science. Furthermore, we\nshow that demonstrations generated by trained smaller models can effectively\nguide larger target models, reducing training costs while maintaining\ncompetitive accuracy. Overall, this work introduces a scalable demonstration\ngenerator model presenting the first step toward a dynamic few-shot learning\nparadigm in resource-constrained settings. We release the code used for the\nproject.", "AI": {"tldr": "\u63d0\u51faGRAD\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bad\u7ec3LLM\u751f\u6210\u7279\u5b9a\u8f93\u5165\u7684\u7b80\u6d01\u6f14\u793a\uff0c\u5728\u9884\u7b97\u9650\u5236\u4e0b\u4f18\u4e8e\u4f20\u7edfRAG\u65b9\u6cd5\uff0c\u5728\u6570\u5b66\u63a8\u7406\u548cSTEM\u95ee\u9898\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u80fd\u6cdb\u5316\u5230OOD\u9886\u57df\u3002", "motivation": "\u4f20\u7edfRAG\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u6570\u636e\u5e93\uff0c\u7f3a\u4e4f\u9002\u5e94\u6027\u4e14\u53ef\u80fd\u5bfc\u81f4\u4e0d\u76f8\u5173\u7684\u6f14\u793a\uff0c\u9650\u5236\u4e86LLM\u7684\u6027\u80fd\u8868\u73b0\u3002", "method": "\u8bad\u7ec3LLM\u6a21\u578b\u751f\u6210\u8f93\u5165\u7279\u5b9a\u7684\u7b80\u6d01\u6f14\u793a\uff0c\u52a8\u6001\u5730\u4e3a\u6bcf\u4e2a\u8f93\u5165\u63d0\u4f9b\u5b9a\u5236\u5316\u7684\u4e0a\u4e0b\u6587\u652f\u6301\u3002", "result": "\u5728Qwen2.5-14B\u4e0a\uff0cGRAD\u5728\u6570\u5b66\u63a8\u7406\u548c\u9ad8\u7ea7STEM\u95ee\u9898\u4e0a\u6301\u7eed\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u80fd\u6709\u6548\u6cdb\u5316\u5230\u7269\u7406\u3001\u5316\u5b66\u3001\u8ba1\u7b97\u673a\u79d1\u5b66\u7b49OOD\u9886\u57df\u3002", "conclusion": "GRAD\u5f15\u5165\u4e86\u53ef\u6269\u5c55\u7684\u6f14\u793a\u751f\u6210\u5668\u6a21\u578b\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u52a8\u6001\u5c11\u6837\u672c\u5b66\u4e60\u8303\u5f0f\u8fc8\u51fa\u4e86\u7b2c\u4e00\u6b65\u3002"}}
{"id": "2510.01171", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01171", "abs": "https://arxiv.org/abs/2510.01171", "authors": ["Jiayi Zhang", "Simon Yu", "Derek Chong", "Anthony Sicilia", "Michael R. Tomz", "Christopher D. Manning", "Weiyan Shi"], "title": "Verbalized Sampling: How to Mitigate Mode Collapse and Unlock LLM Diversity", "comment": "82 pages, 26 figures, 34 tables. Code is available at\n  https://github.com/CHATS-lab/verbalize-sampling", "summary": "Post-training alignment often reduces LLM diversity, leading to a phenomenon\nknown as mode collapse. Unlike prior work that attributes this effect to\nalgorithmic limitations, we identify a fundamental, pervasive data-level\ndriver: typicality bias in preference data, whereby annotators systematically\nfavor familiar text as a result of well-established findings in cognitive\npsychology. We formalize this bias theoretically, verify it on preference\ndatasets empirically, and show that it plays a central role in mode collapse.\nMotivated by this analysis, we introduce Verbalized Sampling, a simple,\ntraining-free prompting strategy to circumvent mode collapse. VS prompts the\nmodel to verbalize a probability distribution over a set of responses (e.g.,\n``Generate 5 jokes about coffee and their corresponding probabilities'').\nComprehensive experiments show that VS significantly improves performance\nacross creative writing (poems, stories, jokes), dialogue simulation,\nopen-ended QA, and synthetic data generation, without sacrificing factual\naccuracy and safety. For instance, in creative writing, VS increases diversity\nby 1.6-2.1x over direct prompting. We further observe an emergent trend that\nmore capable models benefit more from VS. In sum, our work provides a new\ndata-centric perspective on mode collapse and a practical inference-time remedy\nthat helps unlock pre-trained generative diversity.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u540e\u8bad\u7ec3\u5bf9\u9f50\u5bfc\u81f4LLM\u591a\u6837\u6027\u51cf\u5c11\uff08\u6a21\u5f0f\u5d29\u6e83\uff09\u7684\u6839\u672c\u539f\u56e0\u662f\u504f\u597d\u6570\u636e\u4e2d\u7684\u5178\u578b\u6027\u504f\u5dee\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u63d0\u793a\u7b56\u7565\u2014\u2014\u8a00\u8bed\u5316\u91c7\u6837\uff0c\u80fd\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u521b\u610f\u5199\u4f5c\u3001\u5bf9\u8bdd\u7b49\u4efb\u52a1\u4e2d\u7684\u591a\u6837\u6027\u8868\u73b0\u3002", "motivation": "\u540e\u8bad\u7ec3\u5bf9\u9f50\u7ecf\u5e38\u964d\u4f4eLLM\u7684\u591a\u6837\u6027\uff0c\u5bfc\u81f4\u6a21\u5f0f\u5d29\u6e83\u73b0\u8c61\u3002\u4e0e\u4e4b\u524d\u5c06\u8fd9\u79cd\u73b0\u8c61\u5f52\u56e0\u4e8e\u7b97\u6cd5\u9650\u5236\u7684\u7814\u7a76\u4e0d\u540c\uff0c\u672c\u6587\u8bc6\u522b\u4e86\u4e00\u4e2a\u6839\u672c\u6027\u7684\u3001\u666e\u904d\u5b58\u5728\u7684\u6570\u636e\u5c42\u9762\u9a71\u52a8\u56e0\u7d20\uff1a\u504f\u597d\u6570\u636e\u4e2d\u7684\u5178\u578b\u6027\u504f\u5dee\u3002", "method": "\u672c\u6587\u9996\u5148\u4ece\u7406\u8bba\u4e0a\u5f62\u5f0f\u5316\u4e86\u5178\u578b\u6027\u504f\u5dee\uff0c\u5e76\u5728\u504f\u597d\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u8bc1\u9a8c\u8bc1\u3002\u7136\u540e\u63d0\u51fa\u4e86\u8a00\u8bed\u5316\u91c7\u6837\uff08Verbalized Sampling\uff09\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u7b80\u5355\u7684\u65e0\u9700\u8bad\u7ec3\u7684\u63d0\u793a\u7b56\u7565\uff0c\u8ba9\u6a21\u578b\u5bf9\u4e00\u7ec4\u56de\u7b54\u8fdb\u884c\u6982\u7387\u5206\u5e03\u7684\u8a00\u8bed\u5316\u8868\u8fbe\u3002", "result": "\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cVS\u663e\u8457\u63d0\u5347\u4e86\u521b\u610f\u5199\u4f5c\uff08\u8bd7\u6b4c\u3001\u6545\u4e8b\u3001\u7b11\u8bdd\uff09\u3001\u5bf9\u8bdd\u6a21\u62df\u3001\u5f00\u653e\u5f0f\u95ee\u7b54\u548c\u5408\u6210\u6570\u636e\u751f\u6210\u7b49\u4efb\u52a1\u7684\u8868\u73b0\uff0c\u5728\u4e0d\u727a\u7272\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u5b89\u5168\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u5c06\u521b\u610f\u5199\u4f5c\u7684\u591a\u6837\u6027\u63d0\u9ad8\u4e861.6-2.1\u500d\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u6a21\u5f0f\u5d29\u6e83\u63d0\u4f9b\u4e86\u65b0\u7684\u6570\u636e\u4e2d\u5fc3\u89c6\u89d2\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u63a8\u7406\u65f6\u8865\u6551\u63aa\u65bd\uff0c\u6709\u52a9\u4e8e\u91ca\u653e\u9884\u8bad\u7ec3\u751f\u6210\u6a21\u578b\u7684\u591a\u6837\u6027\u6f5c\u529b\u3002\u66f4\u5f3a\u5927\u7684\u6a21\u578b\u4eceVS\u4e2d\u83b7\u76ca\u66f4\u591a\uff0c\u663e\u793a\u51fa\u4e00\u79cd\u65b0\u5174\u8d8b\u52bf\u3002"}}
{"id": "2510.01172", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.01172", "abs": "https://arxiv.org/abs/2510.01172", "authors": ["Qingyuan Liu", "Jia-Chen Gu", "Yunzhi Yao", "Hong Wang", "Nanyun Peng"], "title": "Energy-Regularized Sequential Model Editing on Hyperspheres", "comment": "The code is available at https://github.com/PlusLabNLP/SPHERE. arXiv\n  admin note: text overlap with arXiv:2410.02355 by other authors", "summary": "Large language models (LLMs) require constant updates to remain aligned with\nevolving real-world knowledge. Model editing offers a lightweight alternative\nto retraining, but sequential editing often destabilizes representations and\ninduces catastrophic forgetting. In this work, we seek to better understand and\nmitigate performance degradation caused by sequential editing. We hypothesize\nthat hyperspherical uniformity, a property that maintains uniform distribution\nof neuron weights on a hypersphere, helps the model remain stable, retain prior\nknowledge, while still accommodate new updates. We use Hyperspherical Energy\n(HE) to quantify neuron uniformity during editing, and examine its correlation\nwith editing performance. Empirical studies across widely used editing methods\nreveals a strong correlation between HE dynamics and editing performance, with\nediting failures consistently coinciding with high HE fluctuations. We further\ntheoretically prove that HE dynamics impose a lower bound on the degradation of\npretrained knowledge, highlighting why HE stability is crucial for knowledge\nretention. Motivated by these insights, we propose SPHERE (Sparse Projection\nfor Hyperspherical Energy-Regularized Editing), an HE-driven regularization\nstrategy that stabilizes neuron weight distributions, ultimately preserving\nprior knowledge while enabling reliable sequential updates. Specifically,\nSPHERE identifies a sparse space complementary to the principal hyperspherical\ndirections of the pretrained weight matrices and projects new knowledge onto\nit, attenuating perturbations on the principal directions. Extensive\nexperiments on LLaMA3 (8B) and Qwen2.5 (7B) show that SPHERE outperforms the\nbest baseline in editing capability by an average of 16.41%, while most\nfaithfully preserving general model performance, thereby offering a principled\npath toward reliable large-scale knowledge editing.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSPHERE\u65b9\u6cd5\uff0c\u901a\u8fc7\u8d85\u7403\u9762\u80fd\u91cf\u6b63\u5219\u5316\u6765\u7a33\u5b9a\u795e\u7ecf\u5143\u6743\u91cd\u5206\u5e03\uff0c\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u987a\u5e8f\u7f16\u8f91\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u539f\u6709\u77e5\u8bc6\u7684\u540c\u65f6\u53ef\u9760\u5730\u66f4\u65b0\u65b0\u77e5\u8bc6\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u9700\u8981\u6301\u7eed\u66f4\u65b0\u4ee5\u4fdd\u6301\u4e0e\u73b0\u5b9e\u4e16\u754c\u77e5\u8bc6\u540c\u6b65\uff0c\u4f46\u987a\u5e8f\u7f16\u8f91\u5f80\u5f80\u4f1a\u5bfc\u81f4\u8868\u793a\u4e0d\u7a33\u5b9a\u548c\u707e\u96be\u6027\u9057\u5fd8\u3002\u672c\u6587\u65e8\u5728\u7406\u89e3\u548c\u7f13\u89e3\u987a\u5e8f\u7f16\u8f91\u5bfc\u81f4\u7684\u6027\u80fd\u9000\u5316\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u8d85\u7403\u9762\u80fd\u91cf\u91cf\u5316\u7f16\u8f91\u8fc7\u7a0b\u4e2d\u7684\u795e\u7ecf\u5143\u5747\u5300\u6027\uff0c\u63d0\u51faSPHERE\u65b9\u6cd5\u2014\u2014\u4e00\u79cdHE\u9a71\u52a8\u7684\u6b63\u5219\u5316\u7b56\u7565\uff0c\u8bc6\u522b\u4e0e\u9884\u8bad\u7ec3\u6743\u91cd\u77e9\u9635\u4e3b\u8d85\u7403\u9762\u65b9\u5411\u4e92\u8865\u7684\u7a00\u758f\u7a7a\u95f4\uff0c\u5e76\u5c06\u65b0\u77e5\u8bc6\u6295\u5f71\u5230\u8be5\u7a7a\u95f4\u3002", "result": "\u5728LLaMA3\u548cQwen2.5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSPHERE\u5728\u7f16\u8f91\u80fd\u529b\u4e0a\u5e73\u5747\u4f18\u4e8e\u6700\u4f73\u57fa\u7ebf16.41%\uff0c\u540c\u65f6\u6700\u5fe0\u5b9e\u5730\u4fdd\u6301\u6a21\u578b\u7684\u4e00\u822c\u6027\u80fd\u3002", "conclusion": "SPHERE\u63d0\u4f9b\u4e86\u4e00\u79cd\u539f\u5219\u6027\u8def\u5f84\uff0c\u5b9e\u73b0\u53ef\u9760\u7684\u5927\u89c4\u6a21\u77e5\u8bc6\u7f16\u8f91\uff0c\u901a\u8fc7\u7a33\u5b9a\u8d85\u7403\u9762\u80fd\u91cf\u6765\u4fdd\u6301\u5148\u9a8c\u77e5\u8bc6\u540c\u65f6\u652f\u6301\u987a\u5e8f\u66f4\u65b0\u3002"}}
