{"id": "2602.09386", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.09386", "abs": "https://arxiv.org/abs/2602.09386", "authors": ["Yukun Zhang", "Si Dong", "Xu Wang", "Bo Chen", "Qinglin Jia", "Shengzhe Wang", "Jinlong Jiao", "Runhan Li", "Jiaqing Liu", "Chaoyi Ma", "Ruiming Tang", "Guorui Zhou", "Han Li", "Kun Gai"], "title": "SMES: Towards Scalable Multi-Task Recommendation via Expert Sparsity", "comment": null, "summary": "Industrial recommender systems typically rely on multi-task learning to estimate diverse user feedback signals and aggregate them for ranking. Recent advances in model scaling have shown promising gains in recommendation. However, naively increasing model capacity imposes prohibitive online inference costs and often yields diminishing returns for sparse tasks with skewed label distributions. This mismatch between uniform parameter scaling and heterogeneous task capacity demands poses a fundamental challenge for scalable multi-task recommendation. In this work, we investigate parameter sparsification as a principled scaling paradigm and identify two critical obstacles when applying sparse Mixture-of-Experts (MoE) to multi-task recommendation: exploded expert activation that undermines instance-level sparsity and expert load skew caused by independent task-wise routing. To address these challenges, we propose SMES, a scalable sparse MoE framework with progressive expert routing. SMES decomposes expert activation into a task-shared expert subset jointly selected across tasks and task-adaptive private experts, explicitly bounding per-instance expert execution while preserving task-specific capacity. In addition, SMES introduces a global multi-gate load-balancing regularizer that stabilizes training by regulating aggregated expert utilization across all tasks. SMES has been deployed in Kuaishou large-scale short-video services, supporting over 400 million daily active users. Extensive online experiments demonstrate stable improvements, with GAUC gain of 0.29% and a 0.31% uplift in user watch time.", "AI": {"tldr": "SMES\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u7a00\u758fMoE\u6846\u67b6\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u4e13\u5bb6\u8def\u7531\u89e3\u51b3\u591a\u4efb\u52a1\u63a8\u8350\u4e2d\u4e13\u5bb6\u6fc0\u6d3b\u7206\u70b8\u548c\u8d1f\u8f7d\u503e\u659c\u95ee\u9898\uff0c\u5728\u5feb\u624b\u5927\u89c4\u6a21\u77ed\u89c6\u9891\u670d\u52a1\u4e2d\u90e8\u7f72\u5e76\u53d6\u5f97\u663e\u8457\u6548\u679c\u63d0\u5347\u3002", "motivation": "\u5de5\u4e1a\u63a8\u8350\u7cfb\u7edf\u901a\u5e38\u4f9d\u8d56\u591a\u4efb\u52a1\u5b66\u4e60\u6765\u4f30\u8ba1\u591a\u6837\u5316\u7684\u7528\u6237\u53cd\u9988\u4fe1\u53f7\u3002\u7136\u800c\uff0c\u7b80\u5355\u5730\u589e\u52a0\u6a21\u578b\u5bb9\u91cf\u4f1a\u5e26\u6765\u8fc7\u9ad8\u7684\u5728\u7ebf\u63a8\u7406\u6210\u672c\uff0c\u5e76\u4e14\u5bf9\u4e8e\u6807\u7b7e\u5206\u5e03\u7a00\u758f\u7684\u4efb\u52a1\u5f80\u5f80\u6536\u76ca\u9012\u51cf\u3002\u5747\u5300\u53c2\u6570\u6269\u5c55\u4e0e\u5f02\u6784\u4efb\u52a1\u5bb9\u91cf\u9700\u6c42\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u662f\u591a\u4efb\u52a1\u63a8\u8350\u53ef\u6269\u5c55\u6027\u7684\u6839\u672c\u6311\u6218\u3002", "method": "\u63d0\u51faSMES\u6846\u67b6\uff0c\u91c7\u7528\u6e10\u8fdb\u5f0f\u4e13\u5bb6\u8def\u7531\uff1a\u5c06\u4e13\u5bb6\u6fc0\u6d3b\u5206\u89e3\u4e3a\u8de8\u4efb\u52a1\u8054\u5408\u9009\u62e9\u7684\u4efb\u52a1\u5171\u4eab\u4e13\u5bb6\u5b50\u96c6\u548c\u4efb\u52a1\u81ea\u9002\u5e94\u79c1\u6709\u4e13\u5bb6\uff0c\u660e\u786e\u9650\u5236\u6bcf\u4e2a\u5b9e\u4f8b\u7684\u4e13\u5bb6\u6267\u884c\u540c\u65f6\u4fdd\u7559\u4efb\u52a1\u7279\u5b9a\u5bb9\u91cf\u3002\u6b64\u5916\uff0c\u5f15\u5165\u5168\u5c40\u591a\u95e8\u8d1f\u8f7d\u5747\u8861\u6b63\u5219\u5316\u5668\uff0c\u901a\u8fc7\u8c03\u8282\u6240\u6709\u4efb\u52a1\u7684\u805a\u5408\u4e13\u5bb6\u5229\u7528\u7387\u6765\u7a33\u5b9a\u8bad\u7ec3\u3002", "result": "SMES\u5df2\u5728\u5feb\u624b\u5927\u89c4\u6a21\u77ed\u89c6\u9891\u670d\u52a1\u4e2d\u90e8\u7f72\uff0c\u652f\u6301\u8d85\u8fc74\u4ebf\u65e5\u6d3b\u7528\u6237\u3002\u5728\u7ebf\u5b9e\u9a8c\u663e\u793a\u7a33\u5b9a\u6539\u8fdb\uff1aGAUC\u589e\u76ca0.29%\uff0c\u7528\u6237\u89c2\u770b\u65f6\u95f4\u63d0\u53470.31%\u3002", "conclusion": "SMES\u901a\u8fc7\u53c2\u6570\u7a00\u758f\u5316\u4f5c\u4e3a\u539f\u5219\u6027\u6269\u5c55\u8303\u5f0f\uff0c\u89e3\u51b3\u4e86\u591a\u4efb\u52a1\u63a8\u8350\u4e2d\u7a00\u758fMoE\u5e94\u7528\u7684\u5173\u952e\u969c\u788d\uff0c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u7684\u9ad8\u6548\u63a8\u8350\u7cfb\u7edf\u3002"}}
{"id": "2602.09387", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.09387", "abs": "https://arxiv.org/abs/2602.09387", "authors": ["Fangye Wang", "Guowei Yang", "Xiaojiang Zhou", "Song Yang", "Pengjie Wang"], "title": "Query-Mixed Interest Extraction and Heterogeneous Interaction: A Scalable CTR Model for Industrial Recommender Systems", "comment": null, "summary": "Learning effective feature interactions is central to modern recommender systems, yet remains challenging in industrial settings due to sparse multi-field inputs and ultra-long user behavior sequences. While recent scaling efforts have improved model capacity, they often fail to construct both context-aware and context-independent user intent from the long-term and real-time behavior sequence. Meanwhile, recent work also suffers from inefficient and homogeneous interaction mechanisms, leading to suboptimal prediction performance. To address these limitations, we propose HeMix, a scalable ranking model that unifies adaptive sequence tokenization and heterogeneous interaction structure. Specifically, HeMix introduces a Query-Mixed Interest Extraction module that jointly models context-aware and context-independent user interests via dynamic and fixed queries over global and real-time behavior sequences. For interaction, we replace self-attention with the HeteroMixer block, enabling efficient, multi-granularity cross-feature interactions that adopt the multi-head token fusion, heterogeneous interaction and group-aligned reconstruction pipelines. HeMix demonstrates favorable scaling behavior, driven by the HeteroMixer block, where increasing model scale via parameter expansion leads to steady improvements in recommendation accuracy. Experiments on industrial-scale datasets show that HeMix scales effectively and consistently outperforms strong baselines. Most importantly, HeMix has been deployed on the AMAP platform, delivering significant online gains: +0.61% GMV, +2.32% PV_CTR, and +0.81% UV_CVR.", "AI": {"tldr": "HeMix\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u63a8\u8350\u6392\u5e8f\u6a21\u578b\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5e8f\u5217\u6807\u8bb0\u5316\u548c\u5f02\u6784\u4ea4\u4e92\u7ed3\u6784\u7edf\u4e00\u5efa\u6a21\uff0c\u5728\u5de5\u4e1a\u573a\u666f\u4e2d\u663e\u8457\u63d0\u5347\u63a8\u8350\u6548\u679c\u3002", "motivation": "\u5de5\u4e1a\u63a8\u8350\u7cfb\u7edf\u4e2d\uff0c\u7a00\u758f\u591a\u5b57\u6bb5\u8f93\u5165\u548c\u8d85\u957f\u7528\u6237\u884c\u4e3a\u5e8f\u5217\u4f7f\u5f97\u7279\u5f81\u4ea4\u4e92\u5b66\u4e60\u9762\u4e34\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u5efa\u6a21\u4e0a\u4e0b\u6587\u76f8\u5173\u548c\u4e0a\u4e0b\u6587\u65e0\u5173\u7684\u7528\u6237\u610f\u56fe\uff0c\u4e14\u4ea4\u4e92\u673a\u5236\u6548\u7387\u4f4e\u4e0b\u3001\u540c\u8d28\u5316\uff0c\u5bfc\u81f4\u9884\u6d4b\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u63d0\u51faHeMix\u6a21\u578b\uff0c\u5305\u542bQuery-Mixed\u5174\u8da3\u63d0\u53d6\u6a21\u5757\uff08\u901a\u8fc7\u52a8\u6001\u548c\u56fa\u5b9a\u67e5\u8be2\u8054\u5408\u5efa\u6a21\u4e0a\u4e0b\u6587\u76f8\u5173\u548c\u4e0a\u4e0b\u6587\u65e0\u5173\u7684\u7528\u6237\u5174\u8da3\uff09\u548cHeteroMixer\u5757\uff08\u66ff\u4ee3\u81ea\u6ce8\u610f\u529b\uff0c\u5b9e\u73b0\u9ad8\u6548\u591a\u7c92\u5ea6\u8de8\u7279\u5f81\u4ea4\u4e92\uff0c\u91c7\u7528\u591a\u5934\u4ee4\u724c\u878d\u5408\u3001\u5f02\u6784\u4ea4\u4e92\u548c\u7ec4\u5bf9\u9f50\u91cd\u5efa\u6d41\u7a0b\uff09\u3002", "result": "\u5728\u5de5\u4e1a\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\uff0cHeMix\u5c55\u73b0\u51fa\u826f\u597d\u7684\u6269\u5c55\u6027\uff0c\u6a21\u578b\u89c4\u6a21\u6269\u5927\u80fd\u7a33\u5b9a\u63d0\u5347\u63a8\u8350\u51c6\u786e\u6027\u3002\u90e8\u7f72\u5728AMAP\u5e73\u53f0\u540e\u83b7\u5f97\u663e\u8457\u5728\u7ebf\u6536\u76ca\uff1aGMV\u63d0\u53470.61%\uff0cPV_CTR\u63d0\u53472.32%\uff0cUV_CVR\u63d0\u53470.81%\u3002", "conclusion": "HeMix\u901a\u8fc7\u7edf\u4e00\u7684\u81ea\u9002\u5e94\u5e8f\u5217\u6807\u8bb0\u5316\u548c\u5f02\u6784\u4ea4\u4e92\u7ed3\u6784\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5de5\u4e1a\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u7279\u5f81\u4ea4\u4e92\u5b66\u4e60\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u7684\u9ad8\u6027\u80fd\u63a8\u8350\u3002"}}
{"id": "2602.09401", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.09401", "abs": "https://arxiv.org/abs/2602.09401", "authors": ["Ruochen Yang", "Yueyang Liu", "Zijie Zhuang", "Changxin Lao", "Yuhui Zhang", "Jiangxia Cao", "Jia Xu", "Xiang Chen", "Haoke Xiao", "Xiangyu Wu", "Xiaoyou Zhou", "Xiao Lv", "Shuang Yang", "Tingwen Liu", "Zhaojie Liu", "Han Li", "Kun Gai"], "title": "SARM: LLM-Augmented Semantic Anchor for End-to-End Live-Streaming Ranking", "comment": null, "summary": "Large-scale live-streaming recommendation requires precise modeling of non-stationary content semantics under strict real-time serving constraints. In industrial deployment, two common approaches exhibit fundamental limitations: discrete semantic abstractions sacrifice descriptive precision through clustering, while dense multimodal embeddings are extracted independently and remain weakly aligned with ranking optimization, limiting fine-grained content-aware ranking. To address these limitations, we propose \\textbf{SARM}, an end-to-end ranking architecture that integrates natural-language semantic anchors directly into ranking optimization, enabling fine-grained author representations conditioned on multimodal content. Each semantic anchor is represented as learnable text tokens jointly optimized with ranking features, allowing the model to adapt content descriptions to ranking objectives. A lightweight dual-token gated design captures domain-specific live-streaming semantics, while an asymmetric deployment strategy preserves low-latency online training and serving. Extensive offline evaluation and large-scale A/B tests show consistent improvements over production baselines. SARM is fully deployed and serves over 400 million users daily.", "AI": {"tldr": "SARM\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u76f4\u64ad\u63a8\u8350\u6392\u5e8f\u67b6\u6784\uff0c\u901a\u8fc7\u5c06\u81ea\u7136\u8bed\u8a00\u8bed\u4e49\u951a\u70b9\u76f4\u63a5\u96c6\u6210\u5230\u6392\u5e8f\u4f18\u5316\u4e2d\uff0c\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u76f4\u64ad\u63a8\u8350\u4e2d\u975e\u5e73\u7a33\u5185\u5bb9\u8bed\u4e49\u5efa\u6a21\u7684\u6311\u6218\u3002", "motivation": "\u5de5\u4e1a\u90e8\u7f72\u4e2d\u4e24\u79cd\u5e38\u89c1\u65b9\u6cd5\u5b58\u5728\u6839\u672c\u9650\u5236\uff1a\u79bb\u6563\u8bed\u4e49\u62bd\u8c61\u901a\u8fc7\u805a\u7c7b\u727a\u7272\u4e86\u63cf\u8ff0\u7cbe\u5ea6\uff0c\u800c\u5bc6\u96c6\u591a\u6a21\u6001\u5d4c\u5165\u72ec\u7acb\u63d0\u53d6\u4e14\u4e0e\u6392\u5e8f\u4f18\u5316\u5f31\u5bf9\u9f50\uff0c\u9650\u5236\u4e86\u7ec6\u7c92\u5ea6\u5185\u5bb9\u611f\u77e5\u6392\u5e8f\u3002", "method": "\u63d0\u51faSARM\u67b6\u6784\uff0c\u5c06\u53ef\u5b66\u4e60\u7684\u6587\u672ctoken\u4f5c\u4e3a\u8bed\u4e49\u951a\u70b9\u4e0e\u6392\u5e8f\u7279\u5f81\u8054\u5408\u4f18\u5316\uff1b\u91c7\u7528\u8f7b\u91cf\u7ea7\u53cctoken\u95e8\u63a7\u8bbe\u8ba1\u6355\u83b7\u7279\u5b9a\u9886\u57df\u76f4\u64ad\u8bed\u4e49\uff1b\u4f7f\u7528\u975e\u5bf9\u79f0\u90e8\u7f72\u7b56\u7565\u4fdd\u6301\u4f4e\u5ef6\u8fdf\u5728\u7ebf\u8bad\u7ec3\u548c\u670d\u52a1\u3002", "result": "\u79bb\u7ebf\u8bc4\u4f30\u548c\u5927\u89c4\u6a21A/B\u6d4b\u8bd5\u663e\u793a\u76f8\u5bf9\u4e8e\u751f\u4ea7\u57fa\u7ebf\u6709\u6301\u7eed\u6539\u8fdb\uff1bSARM\u5df2\u5b8c\u5168\u90e8\u7f72\uff0c\u6bcf\u65e5\u670d\u52a1\u8d85\u8fc74\u4ebf\u7528\u6237\u3002", "conclusion": "SARM\u901a\u8fc7\u5c06\u81ea\u7136\u8bed\u8a00\u8bed\u4e49\u951a\u70b9\u76f4\u63a5\u96c6\u6210\u5230\u6392\u5e8f\u4f18\u5316\u4e2d\uff0c\u5b9e\u73b0\u4e86\u7ec6\u7c92\u5ea6\u7684\u4f5c\u8005\u8868\u793a\uff0c\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u76f4\u64ad\u63a8\u8350\u4e2d\u5185\u5bb9\u8bed\u4e49\u5efa\u6a21\u7684\u6311\u6218\uff0c\u5e76\u5728\u5de5\u4e1a\u90e8\u7f72\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6548\u679c\u3002"}}
{"id": "2602.09445", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.09445", "abs": "https://arxiv.org/abs/2602.09445", "authors": ["Sunwoo Kim", "Hyunjin Hwang", "Kijung Shin"], "title": "Personalized Parameter-Efficient Fine-Tuning of Foundation Models for Multimodal Recommendation", "comment": "To be published at The Web Conference 2026 (WWW 2026)", "summary": "In recent years, substantial research has integrated multimodal item metadata into recommender systems, often by using pre-trained multimodal foundation models to encode such data. Since these models are not originally trained for recommendation tasks, recent works efficiently adapt them via parameter-efficient fine-tuning (PEFT). However, even with PEFT, item embeddings from multimodal foundation models remain user-blind: item embeddings are not conditioned on user interests, despite the fact that users with diverse interests attend to different item aspects. To address this limitation, we propose PerPEFT, a personalized PEFT strategy for multimodal recommendation. Specifically, PerPEFT groups users by interest and assigns a distinct PEFT module to each group, enabling each module to capture the fine-grained item aspects most predictive of that group`s purchase decisions. We further introduce a specialized training technique that strengthens this user-group conditioning. Notably, PerPEFT is PEFT-agnostic and can be paired with any PEFT method applicable to multimodal foundation models. Through extensive experiments, we show that (1) PerPEFT outperforms the strongest baseline by up to 15.3% (NDCG@20) and (2) delivers consistent gains across diverse PEFT variants. It is noteworthy that, even with personalization, PEFT remains lightweight, adding only 1.3% of the parameter count of the foundation model. We provide our code and datasets at https://github.com/kswoo97/PerPEFT.", "AI": {"tldr": "PerPEFT\uff1a\u4e00\u79cd\u4e2a\u6027\u5316\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u7b56\u7565\uff0c\u901a\u8fc7\u7528\u6237\u5174\u8da3\u5206\u7ec4\u4e3a\u4e0d\u540c\u7528\u6237\u7fa4\u4f53\u5206\u914d\u72ec\u7acb\u7684PEFT\u6a21\u5757\uff0c\u4f7f\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u80fd\u6839\u636e\u7528\u6237\u5174\u8da3\u751f\u6210\u4e2a\u6027\u5316\u7269\u54c1\u5d4c\u5165\uff0c\u663e\u8457\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u7684\u63a8\u8350\u7cfb\u7edf\u867d\u7136\u4f7f\u7528\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PEFT\uff09\u6765\u9002\u5e94\u63a8\u8350\u4efb\u52a1\uff0c\u4f46\u7269\u54c1\u5d4c\u5165\u4ecd\u7136\u662f\u7528\u6237\u65e0\u5173\u7684\uff0c\u6ca1\u6709\u8003\u8651\u4e0d\u540c\u7528\u6237\u5174\u8da3\u5173\u6ce8\u4e0d\u540c\u7269\u54c1\u65b9\u9762\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faPerPEFT\u4e2a\u6027\u5316PEFT\u7b56\u7565\uff1a1\uff09\u6309\u7528\u6237\u5174\u8da3\u5bf9\u7528\u6237\u8fdb\u884c\u5206\u7ec4\uff1b2\uff09\u4e3a\u6bcf\u4e2a\u7528\u6237\u7ec4\u5206\u914d\u72ec\u7acb\u7684PEFT\u6a21\u5757\uff0c\u4f7f\u6bcf\u4e2a\u6a21\u5757\u80fd\u6355\u6349\u5bf9\u8be5\u7ec4\u8d2d\u4e70\u51b3\u7b56\u6700\u76f8\u5173\u7684\u7ec6\u7c92\u5ea6\u7269\u54c1\u65b9\u9762\uff1b3\uff09\u5f15\u5165\u4e13\u95e8\u7684\u8bad\u7ec3\u6280\u672f\u6765\u589e\u5f3a\u8fd9\u79cd\u7528\u6237\u7ec4\u6761\u4ef6\u5316\u3002", "result": "PerPEFT\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u5f02\uff1a1\uff09\u6bd4\u6700\u5f3a\u57fa\u7ebf\u63d0\u5347\u9ad8\u8fbe15.3%\uff08NDCG@20\uff09\uff1b2\uff09\u5728\u4e0d\u540cPEFT\u53d8\u4f53\u4e0a\u90fd\u80fd\u5e26\u6765\u4e00\u81f4\u7684\u6027\u80fd\u589e\u76ca\uff1b3\uff09\u5373\u4f7f\u5b9e\u73b0\u4e2a\u6027\u5316\uff0cPEFT\u4ecd\u7136\u8f7b\u91cf\uff0c\u4ec5\u589e\u52a0\u57fa\u7840\u6a21\u578b\u53c2\u6570\u91cf\u76841.3%\u3002", "conclusion": "PerPEFT\u901a\u8fc7\u7528\u6237\u5174\u8da3\u5206\u7ec4\u7684\u4e2a\u6027\u5316PEFT\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u4e2d\u7269\u54c1\u5d4c\u5165\u7528\u6237\u65e0\u5173\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u53c2\u6570\u9ad8\u6548\u6027\uff0c\u662f\u4e00\u79cd\u901a\u7528\u4e14\u6709\u6548\u7684\u591a\u6a21\u6001\u63a8\u8350\u65b9\u6cd5\u3002"}}
{"id": "2602.09448", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.09448", "abs": "https://arxiv.org/abs/2602.09448", "authors": ["Xincan Feng", "Noriki Nishida", "Yusuke Sakai", "Yuji Matsumoto"], "title": "The Wisdom of Many Queries: Complexity-Diversity Principle for Dense Retriever Training", "comment": "Under review", "summary": "Prior work reports conflicting results on query diversity in synthetic data generation for dense retrieval. We identify this conflict and design Q-D metrics to quantify diversity's impact, making the problem measurable. Through experiments on 4 benchmark types (31 datasets), we find query diversity especially benefits multi-hop retrieval. Deep analysis on multi-hop data reveals that diversity benefit correlates strongly with query complexity ($r$$\\geq$0.95, $p$$<$0.05 in 12/14 conditions), measured by content words (CW). We formalize this as the Complexity-Diversity Principle (CDP): query complexity determines optimal diversity. CDP provides actionable thresholds (CW$>$10: use diversity; CW$<$7: avoid it). Guided by CDP, we propose zero-shot multi-query synthesis for multi-hop tasks, achieving state-of-the-art performance.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u67e5\u8be2\u591a\u6837\u6027\u5bf9\u5bc6\u96c6\u68c0\u7d22\u7684\u5f71\u54cd\u53d6\u51b3\u4e8e\u67e5\u8be2\u590d\u6742\u5ea6\uff0c\u63d0\u51fa\u590d\u6742\u5ea6-\u591a\u6837\u6027\u539f\u5219\uff08CDP\uff09\uff0c\u4e3a\u591a\u8df3\u68c0\u7d22\u4efb\u52a1\u63d0\u4f9b\u96f6\u6837\u672c\u591a\u67e5\u8be2\u5408\u6210\u65b9\u6cd5\uff0c\u5b9e\u73b0SOTA\u6027\u80fd\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u5728\u5408\u6210\u6570\u636e\u751f\u6210\u4e2d\u67e5\u8be2\u591a\u6837\u6027\u5bf9\u5bc6\u96c6\u68c0\u7d22\u7684\u5f71\u54cd\u5b58\u5728\u77db\u76fe\u7ed3\u679c\uff0c\u9700\u8981\u91cf\u5316\u591a\u6837\u6027\u5f71\u54cd\u5e76\u4f7f\u5176\u53ef\u6d4b\u91cf\u3002", "method": "\u8bbe\u8ba1Q-D\u6307\u6807\u91cf\u5316\u591a\u6837\u6027\u5f71\u54cd\uff0c\u57284\u79cd\u57fa\u51c6\u7c7b\u578b\uff0831\u4e2a\u6570\u636e\u96c6\uff09\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6df1\u5165\u5206\u6790\u591a\u8df3\u6570\u636e\uff0c\u53d1\u73b0\u591a\u6837\u6027\u6536\u76ca\u4e0e\u67e5\u8be2\u590d\u6742\u5ea6\u5f3a\u76f8\u5173\uff0c\u63d0\u51fa\u590d\u6742\u5ea6-\u591a\u6837\u6027\u539f\u5219\uff08CDP\uff09\u3002", "result": "\u67e5\u8be2\u591a\u6837\u6027\u7279\u522b\u6709\u5229\u4e8e\u591a\u8df3\u68c0\u7d22\uff0c\u591a\u6837\u6027\u6536\u76ca\u4e0e\u67e5\u8be2\u590d\u6742\u5ea6\u5f3a\u76f8\u5173\uff08r\u22650.95\uff0cp<0.05\uff0c12/14\u6761\u4ef6\u4e0b\uff09\uff0cCDP\u63d0\u4f9b\u53ef\u64cd\u4f5c\u9608\u503c\uff08CW>10\uff1a\u4f7f\u7528\u591a\u6837\u6027\uff1bCW<7\uff1a\u907f\u514d\uff09\u3002", "conclusion": "\u67e5\u8be2\u590d\u6742\u5ea6\u51b3\u5b9a\u6700\u4f73\u591a\u6837\u6027\u6c34\u5e73\uff0c\u57fa\u4e8eCDP\u63d0\u51fa\u7684\u96f6\u6837\u672c\u591a\u67e5\u8be2\u5408\u6210\u65b9\u6cd5\u5728\u591a\u8df3\u4efb\u52a1\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\u3002"}}
{"id": "2602.09616", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09616", "abs": "https://arxiv.org/abs/2602.09616", "authors": ["Zeinab Sadat Taghavi", "Ali Modarressi", "Hinrich Schutze", "Andreas Marfurt"], "title": "With Argus Eyes: Assessing Retrieval Gaps via Uncertainty Scoring to Detect and Remedy Retrieval Blind Spots", "comment": "8 pages", "summary": "Reliable retrieval-augmented generation (RAG) systems depend fundamentally on the retriever's ability to find relevant information. We show that neural retrievers used in RAG systems have blind spots, which we define as the failure to retrieve entities that are relevant to the query, but have low similarity to the query embedding. We investigate the training-induced biases that cause such blind spot entities to be mapped to inaccessible parts of the embedding space, resulting in low retrievability. Using a large-scale dataset constructed from Wikidata relations and first paragraphs of Wikipedia, and our proposed Retrieval Probability Score (RPS), we show that blind spot risk in standard retrievers (e.g., CONTRIEVER, REASONIR) can be predicted pre-index from entity embedding geometry, avoiding expensive retrieval evaluations. To address these blind spots, we introduce ARGUS, a pipeline that enables the retrievability of high-risk (low-RPS) entities through targeted document augmentation from a knowledge base (KB), first paragraphs of Wikipedia, in our case. Extensive experiments on BRIGHT, IMPLIRET, and RAR-B show that ARGUS achieves consistent improvements across all evaluated retrievers (averaging +3.4 nDCG@5 and +4.5 nDCG@10 absolute points), with substantially larger gains in challenging subsets. These results establish that preemptively remedying blind spots is critical for building robust and trustworthy RAG systems (Code and Data).", "AI": {"tldr": "\u8bba\u6587\u53d1\u73b0\u795e\u7ecf\u68c0\u7d22\u5668\u5b58\u5728\"\u76f2\u70b9\"\u95ee\u9898\uff0c\u5373\u65e0\u6cd5\u68c0\u7d22\u5230\u4e0e\u67e5\u8be2\u76f8\u5173\u4f46\u5d4c\u5165\u76f8\u4f3c\u5ea6\u4f4e\u7684\u5b9e\u4f53\uff0c\u5e76\u63d0\u51faARGUS\u65b9\u6cd5\u901a\u8fc7\u9488\u5bf9\u6027\u6587\u6863\u589e\u5f3a\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "motivation": "\u53ef\u9760\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7cfb\u7edf\u4f9d\u8d56\u4e8e\u68c0\u7d22\u5668\u67e5\u627e\u76f8\u5173\u4fe1\u606f\u7684\u80fd\u529b\u3002\u7814\u7a76\u53d1\u73b0\u795e\u7ecf\u68c0\u7d22\u5668\u5b58\u5728\"\u76f2\u70b9\"\u95ee\u9898\uff0c\u5373\u65e0\u6cd5\u68c0\u7d22\u5230\u4e0e\u67e5\u8be2\u76f8\u5173\u4f46\u5d4c\u5165\u76f8\u4f3c\u5ea6\u4f4e\u7684\u5b9e\u4f53\uff0c\u8fd9\u4f1a\u5f71\u54cdRAG\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "method": "1) \u63d0\u51fa\u68c0\u7d22\u6982\u7387\u5206\u6570(RPS)\u6765\u9884\u6d4b\u76f2\u70b9\u98ce\u9669\uff1b2) \u5f15\u5165ARGUS\u7ba1\u9053\uff0c\u901a\u8fc7\u4ece\u77e5\u8bc6\u5e93(\u5982\u7ef4\u57fa\u767e\u79d1\u9996\u6bb5)\u8fdb\u884c\u9488\u5bf9\u6027\u6587\u6863\u589e\u5f3a\uff0c\u63d0\u9ad8\u9ad8\u98ce\u9669(\u4f4eRPS)\u5b9e\u4f53\u7684\u53ef\u68c0\u7d22\u6027\u3002", "result": "\u5728BRIGHT\u3001IMPLIRET\u548cRAR-B\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cARGUS\u5728\u6240\u6709\u8bc4\u4f30\u7684\u68c0\u7d22\u5668\u4e0a\u90fd\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb(\u5e73\u5747+3.4 nDCG@5\u548c+4.5 nDCG@10)\uff0c\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u5b50\u96c6\u4e0a\u63d0\u5347\u66f4\u5927\u3002", "conclusion": "\u9884\u5148\u4fee\u590d\u68c0\u7d22\u76f2\u70b9\u5bf9\u4e8e\u6784\u5efa\u9c81\u68d2\u53ef\u4fe1\u7684RAG\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002ARGUS\u65b9\u6cd5\u901a\u8fc7\u9488\u5bf9\u6027\u6587\u6863\u589e\u5f3a\u6709\u6548\u63d0\u9ad8\u4e86\u9ad8\u98ce\u9669\u5b9e\u4f53\u7684\u53ef\u68c0\u7d22\u6027\u3002"}}
{"id": "2602.09744", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.09744", "abs": "https://arxiv.org/abs/2602.09744", "authors": ["Jie Jiang", "Yang Wu", "Qian Li", "Yuling Xiong", "Yihang Su", "Junbang Huo", "Longfei Lu", "Jun Zhang", "Huan Yu"], "title": "DiffuReason: Bridging Latent Reasoning and Generative Refinement for Sequential Recommendation", "comment": null, "summary": "Latent reasoning has emerged as a promising paradigm for sequential recommendation, enabling models to capture complex user intent through multi-step deliberation. Yet existing approaches often rely on deterministic latent chains that accumulate noise and overlook the uncertainty inherent in user intent, and they are typically trained in staged pipelines that hinder joint optimization and exploration. To address these challenges, we propose DiffuReason, a unified \"Think-then-Diffuse\" framework for sequential recommendation. It integrates multi-step Thinking Tokens for latent reasoning, diffusion-based refinement for denoising intermediate representations, and end-to-end Group Relative Policy Optimization (GRPO) alignment to optimize for ranking performance. In the Think stage, the model generates Thinking Tokens that reason over user history to form an initial intent hypothesis. In the Diffuse stage, rather than treating this hypothesis as the final output, we refine it through a diffusion process that models user intent as a probabilistic distribution, providing iterative denoising against reasoning noise. Finally, GRPO-based reinforcement learning enables the reasoning and refinement modules to co-evolve throughout training, without the constraints of staged optimization. Extensive experiments on four benchmarks demonstrate that DiffuReason consistently improves diverse backbone architectures. Online A/B tests on a large-scale industrial platform further validate its practical effectiveness.", "AI": {"tldr": "DiffuReason\u662f\u4e00\u4e2a\u7528\u4e8e\u5e8f\u5217\u63a8\u8350\u7684\"Think-then-Diffuse\"\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6b65\u63a8\u7406\u4ee4\u724c\u8fdb\u884c\u6f5c\u5728\u63a8\u7406\uff0c\u6269\u6563\u8fc7\u7a0b\u53bb\u566a\uff0c\u4ee5\u53ca\u7aef\u5230\u7aef\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5e8f\u5217\u63a8\u8350\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1) \u4f7f\u7528\u786e\u5b9a\u6027\u6f5c\u5728\u94fe\u4f1a\u7d2f\u79ef\u566a\u58f0\u4e14\u5ffd\u7565\u4e86\u7528\u6237\u610f\u56fe\u7684\u4e0d\u786e\u5b9a\u6027\uff1b2) \u91c7\u7528\u5206\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\u963b\u788d\u4e86\u8054\u5408\u4f18\u5316\u548c\u63a2\u7d22\u3002\u9700\u8981\u4e00\u79cd\u80fd\u5904\u7406\u63a8\u7406\u566a\u58f0\u5e76\u652f\u6301\u7aef\u5230\u7aef\u4f18\u5316\u7684\u7edf\u4e00\u6846\u67b6\u3002", "method": "\u63d0\u51faDiffuReason\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u9636\u6bb5\uff1a1) Think\u9636\u6bb5\uff1a\u751f\u6210Thinking Tokens\u5bf9\u7528\u6237\u5386\u53f2\u8fdb\u884c\u591a\u6b65\u63a8\u7406\uff0c\u5f62\u6210\u521d\u59cb\u610f\u56fe\u5047\u8bbe\uff1b2) Diffuse\u9636\u6bb5\uff1a\u901a\u8fc7\u6269\u6563\u8fc7\u7a0b\u5c06\u610f\u56fe\u5efa\u6a21\u4e3a\u6982\u7387\u5206\u5e03\uff0c\u5bf9\u63a8\u7406\u7ed3\u679c\u8fdb\u884c\u8fed\u4ee3\u53bb\u566a\uff1b3) GRPO\u5f3a\u5316\u5b66\u4e60\uff1a\u4f7f\u7528Group Relative Policy Optimization\u5b9e\u73b0\u7aef\u5230\u7aef\u5bf9\u9f50\uff0c\u4f18\u5316\u6392\u5e8f\u6027\u80fd\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDiffuReason\u80fd\u6301\u7eed\u63d0\u5347\u591a\u79cd\u9aa8\u5e72\u67b6\u6784\u7684\u6027\u80fd\u3002\u5728\u5927\u578b\u5de5\u4e1a\u5e73\u53f0\u4e0a\u7684\u5728\u7ebfA/B\u6d4b\u8bd5\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u5176\u5b9e\u9645\u6709\u6548\u6027\u3002", "conclusion": "DiffuReason\u901a\u8fc7\u6574\u5408\u591a\u6b65\u63a8\u7406\u3001\u6269\u6563\u53bb\u566a\u548c\u7aef\u5230\u7aef\u5f3a\u5316\u5b66\u4e60\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5e8f\u5217\u63a8\u8350\u65b9\u6cd5\u4e2d\u63a8\u7406\u566a\u58f0\u7d2f\u79ef\u548c\u5206\u9636\u6bb5\u4f18\u5316\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u5904\u7406\u7528\u6237\u610f\u56fe\u4e0d\u786e\u5b9a\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7edf\u4e00\u6846\u67b6\u3002"}}
{"id": "2602.09829", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.09829", "abs": "https://arxiv.org/abs/2602.09829", "authors": ["Yang Wu", "Haoze Wang", "Qian Li", "Jun Zhang", "Huan Yu", "Jie Jiang"], "title": "Internalizing Multi-Agent Reasoning for Accurate and Efficient LLM-based Recommendation", "comment": null, "summary": "Large Language Models (LLMs) are reshaping recommender systems by leveraging extensive world knowledge and semantic reasoning to interpret user intent. However, effectively integrating these capabilities with collaborative signals while avoiding prohibitive inference latency remains a critical bottleneck. To address this, we propose a trajectory-driven internalization framework to develop a Single-agent Trajectory-Aligned Recommender (STAR). Specifically, to internalize complex reasoning capabilities into a single efficient model, we first design a multi-agent teacher system capable of multi-turn tool usage and reflection. This teacher utilizes a Collaborative Signal Translation mechanism to explicitly convert latent behavioral patterns into descriptive natural language evidence to enhance reasoning accuracy. Subsequently, a trajectory-driven distillation pipeline transfers this agentic logic, including planning, tool usage, and self-reflection, into the compact STAR model. Extensive experiments demonstrate that STAR surpasses its teacher by 8.7% to 39.5% while eliminating iterative latency, paving the way for real-time, reasoning-enhanced recommendation.", "AI": {"tldr": "STAR\u6846\u67b6\u901a\u8fc7\u8f68\u8ff9\u9a71\u52a8\u5185\u5316\u65b9\u6cd5\uff0c\u5c06\u591a\u667a\u80fd\u4f53\u6559\u5e08\u7cfb\u7edf\u7684\u590d\u6742\u63a8\u7406\u80fd\u529b\u84b8\u998f\u5230\u5355\u4e00\u9ad8\u6548\u63a8\u8350\u6a21\u578b\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u540c\u65f6\u6d88\u9664\u8fed\u4ee3\u5ef6\u8fdf\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u80fd\u4e3a\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e16\u754c\u77e5\u8bc6\u548c\u8bed\u4e49\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5982\u4f55\u6709\u6548\u6574\u5408\u534f\u540c\u4fe1\u53f7\u5e76\u907f\u514d\u8fc7\u9ad8\u63a8\u7406\u5ef6\u8fdf\u6210\u4e3a\u5173\u952e\u74f6\u9888\u3002", "method": "\u63d0\u51fa\u8f68\u8ff9\u9a71\u52a8\u5185\u5316\u6846\u67b6\uff1a1) \u8bbe\u8ba1\u591a\u667a\u80fd\u4f53\u6559\u5e08\u7cfb\u7edf\uff0c\u4f7f\u7528\u534f\u540c\u4fe1\u53f7\u7ffb\u8bd1\u673a\u5236\u5c06\u884c\u4e3a\u6a21\u5f0f\u8f6c\u6362\u4e3a\u81ea\u7136\u8bed\u8a00\u8bc1\u636e\uff1b2) \u901a\u8fc7\u8f68\u8ff9\u9a71\u52a8\u84b8\u998f\u7ba1\u9053\u5c06\u667a\u80fd\u4f53\u903b\u8f91\uff08\u89c4\u5212\u3001\u5de5\u5177\u4f7f\u7528\u3001\u81ea\u6211\u53cd\u601d\uff09\u8f6c\u79fb\u5230\u7d27\u51d1\u7684STAR\u6a21\u578b\u4e2d\u3002", "result": "STAR\u6a21\u578b\u6027\u80fd\u8d85\u8d8a\u5176\u6559\u5e08\u7cfb\u7edf8.7%\u81f339.5%\uff0c\u540c\u65f6\u6d88\u9664\u4e86\u8fed\u4ee3\u5ef6\u8fdf\uff0c\u4e3a\u5b9e\u65f6\u63a8\u7406\u589e\u5f3a\u63a8\u8350\u94fa\u5e73\u9053\u8def\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u901a\u8fc7\u8f68\u8ff9\u9a71\u52a8\u5185\u5316\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5c06\u590d\u6742\u7684\u591a\u667a\u80fd\u4f53\u63a8\u7406\u80fd\u529b\u6709\u6548\u84b8\u998f\u5230\u5355\u4e00\u9ad8\u6548\u6a21\u578b\u4e2d\uff0c\u5b9e\u73b0\u9ad8\u6027\u80fd\u7684\u5b9e\u65f6\u63a8\u7406\u589e\u5f3a\u63a8\u8350\u3002"}}
{"id": "2602.09901", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.09901", "abs": "https://arxiv.org/abs/2602.09901", "authors": ["Jianzhao Huang", "Xiaorui Huang", "Fei Zhao", "Yunpeng Liu", "Hui Zhang", "Fangcheng Shi", "Congfeng Li", "Zechen Sun", "Yi Wu", "Yao Hu", "Yunhan Bai", "Shaosheng Cao"], "title": "QP-OneModel: A Unified Generative LLM for Multi-Task Query Understanding in Xiaohongshu Search", "comment": null, "summary": "Query Processing (QP) bridges user intent and content supply in large-scale Social Network Service (SNS) search engines. Traditional QP systems rely on pipelines of isolated discriminative models (e.g., BERT), suffering from limited semantic understanding and high maintenance overhead. While Large Language Models (LLMs) offer a potential solution, existing approaches often optimize sub-tasks in isolation, neglecting intrinsic semantic synergy and necessitating independent iterations. Moreover, standard generative methods often lack grounding in SNS scenarios, failing to bridge the gap between open-domain corpora and informal SNS linguistic patterns, while struggling to adhere to rigorous business definitions. We present QP-OneModel, a Unified Generative LLM for Multi-Task Query Understanding in the SNS domain. We reformulate heterogeneous sub-tasks into a unified sequence generation paradigm, adopting a progressive three-stage alignment strategy culminating in multi-reward Reinforcement Learning. Furthermore, QP-OneModel generates intent descriptions as a novel high-fidelity semantic signal, effectively augmenting downstream tasks such as query rewriting and ranking. Offline evaluations show QP-OneModel achieves a 7.35% overall gain over discriminative baselines, with significant F1 boosts in NER (+9.01%) and Term Weighting (+9.31%). It also exhibits superior generalization, surpassing a 32B model by 7.60% accuracy on unseen tasks. Fully deployed at Xiaohongshu, online A/B tests confirm its industrial value, optimizing retrieval relevance (DCG) by 0.21% and lifting user retention by 0.044%.", "AI": {"tldr": "QP-OneModel\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u751f\u6210\u5f0fLLM\uff0c\u7528\u4e8e\u793e\u4ea4\u7f51\u7edc\u641c\u7d22\u4e2d\u7684\u591a\u4efb\u52a1\u67e5\u8be2\u7406\u89e3\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u5bf9\u9f50\u7b56\u7565\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u67e5\u8be2\u5904\u7406\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u67e5\u8be2\u5904\u7406\u7cfb\u7edf\u4f7f\u7528\u5b64\u7acb\u7684\u5224\u522b\u6a21\u578b\uff0c\u5b58\u5728\u8bed\u4e49\u7406\u89e3\u6709\u9650\u3001\u7ef4\u62a4\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002\u73b0\u6709LLM\u65b9\u6cd5\u5f80\u5f80\u5b64\u7acb\u4f18\u5316\u5b50\u4efb\u52a1\uff0c\u7f3a\u4e4f\u8bed\u4e49\u534f\u540c\uff0c\u4e14\u96be\u4ee5\u9002\u5e94\u793e\u4ea4\u7f51\u7edc\u573a\u666f\u7684\u975e\u6b63\u5f0f\u8bed\u8a00\u6a21\u5f0f\u548c\u4e1a\u52a1\u5b9a\u4e49\u3002", "method": "\u5c06\u5f02\u6784\u5b50\u4efb\u52a1\u91cd\u65b0\u8868\u8ff0\u4e3a\u7edf\u4e00\u7684\u5e8f\u5217\u751f\u6210\u8303\u5f0f\uff0c\u91c7\u7528\u6e10\u8fdb\u5f0f\u4e09\u9636\u6bb5\u5bf9\u9f50\u7b56\u7565\uff0c\u6700\u7ec8\u901a\u8fc7\u591a\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u4f18\u5316\u3002\u751f\u6210\u610f\u56fe\u63cf\u8ff0\u4f5c\u4e3a\u65b0\u7684\u9ad8\u4fdd\u771f\u8bed\u4e49\u4fe1\u53f7\uff0c\u589e\u5f3a\u4e0b\u6e38\u4efb\u52a1\u3002", "result": "\u79bb\u7ebf\u8bc4\u4f30\u663e\u793a\u6574\u4f53\u6027\u80fd\u63d0\u53477.35%\uff0cNER\u4efb\u52a1F1\u63d0\u53479.01%\uff0cTerm Weighting\u63d0\u53479.31%\u3002\u5728\u672a\u89c1\u4efb\u52a1\u4e0a\u51c6\u786e\u7387\u6bd432B\u6a21\u578b\u9ad87.60%\u3002\u5728\u7ebfA/B\u6d4b\u8bd5\u663e\u793a\u68c0\u7d22\u76f8\u5173\u6027\u63d0\u53470.21%\uff0c\u7528\u6237\u7559\u5b58\u63d0\u53470.044%\u3002", "conclusion": "QP-OneModel\u901a\u8fc7\u7edf\u4e00\u7684\u751f\u6210\u5f0fLLM\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u793e\u4ea4\u7f51\u7edc\u67e5\u8be2\u5904\u7406\u4e2d\u7684\u8bed\u4e49\u7406\u89e3\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u5728\u5b9e\u9645\u5de5\u4e1a\u90e8\u7f72\u4e2d\u7684\u4ef7\u503c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u67e5\u8be2\u7406\u89e3\u6027\u80fd\u3002"}}
{"id": "2602.09935", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.09935", "abs": "https://arxiv.org/abs/2602.09935", "authors": ["Vojt\u011bch Van\u010dura", "Martin Spi\u0161\u00e1k", "Rodrigo Alves", "Ladislav Pe\u0161ka"], "title": "Efficient Learning of Sparse Representations from Interactions", "comment": "In the proceedings of the Web Conference (WWW) 2026 (4 pages)", "summary": "Behavioral patterns captured in embeddings learned from interaction data are pivotal across various stages of production recommender systems. However, in the initial retrieval stage, practitioners face an inherent tradeoff between embedding expressiveness and the scalability and latency of serving components, resulting in the need for representations that are both compact and expressive. To address this challenge, we propose a training strategy for learning high-dimensional sparse embedding layers in place of conventional dense ones, balancing efficiency, representational expressiveness, and interpretability. To demonstrate our approach, we modified the production-grade collaborative filtering autoencoder ELSA, achieving up to 10x reduction in embedding size with no loss of recommendation accuracy, and up to 100x reduction with only a 2.5% loss. Moreover, the active embedding dimensions reveal an interpretable inverted-index structure that segments items in a way directly aligned with the model's latent space, thereby enabling integration of segment-level recommendation functionality (e.g., 2D homepage layouts) within the candidate retrieval model itself. Source codes, additional results, as well as a live demo are available at https://github.com/zombak79/compressed_elsa", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8bad\u7ec3\u9ad8\u7ef4\u7a00\u758f\u5d4c\u5165\u5c42\u7684\u65b9\u6cd5\uff0c\u66ff\u4ee3\u4f20\u7edf\u5bc6\u96c6\u5d4c\u5165\uff0c\u5728\u68c0\u7d22\u9636\u6bb5\u5b9e\u73b0\u5d4c\u5165\u538b\u7f29\u4e0e\u8868\u8fbe\u80fd\u529b\u7684\u5e73\u8861\uff0c\u5728\u63a8\u8350\u51c6\u786e\u5ea6\u51e0\u4e4e\u4e0d\u53d8\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b010-100\u500d\u7684\u5d4c\u5165\u5c3a\u5bf8\u7f29\u51cf\u3002", "motivation": "\u5728\u751f\u4ea7\u63a8\u8350\u7cfb\u7edf\u7684\u521d\u59cb\u68c0\u7d22\u9636\u6bb5\uff0c\u5b58\u5728\u5d4c\u5165\u8868\u8fbe\u80fd\u529b\u4e0e\u7cfb\u7edf\u53ef\u6269\u5c55\u6027\u3001\u5ef6\u8fdf\u4e4b\u95f4\u7684\u56fa\u6709\u6743\u8861\uff0c\u9700\u8981\u65e2\u7d27\u51d1\u53c8\u5177\u6709\u8868\u8fbe\u80fd\u529b\u7684\u8868\u793a\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u8bad\u7ec3\u7b56\u7565\uff0c\u5b66\u4e60\u9ad8\u7ef4\u7a00\u758f\u5d4c\u5165\u5c42\u66ff\u4ee3\u4f20\u7edf\u5bc6\u96c6\u5d4c\u5165\uff0c\u4fee\u6539\u751f\u4ea7\u7ea7\u534f\u540c\u8fc7\u6ee4\u81ea\u7f16\u7801\u5668ELSA\uff0c\u5b9e\u73b0\u5d4c\u5165\u538b\u7f29\u3002", "result": "\u5b9e\u73b0\u5d4c\u5165\u5c3a\u5bf810\u500d\u7f29\u51cf\u65f6\u63a8\u8350\u51c6\u786e\u5ea6\u65e0\u635f\u5931\uff0c100\u500d\u7f29\u51cf\u65f6\u4ec5\u635f\u59312.5%\uff1b\u6d3b\u8dc3\u5d4c\u5165\u7ef4\u5ea6\u63ed\u793a\u4e86\u53ef\u89e3\u91ca\u7684\u5012\u6392\u7d22\u5f15\u7ed3\u6784\uff0c\u53ef\u76f4\u63a5\u4e0e\u6a21\u578b\u6f5c\u5728\u7a7a\u95f4\u5bf9\u9f50\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u63a8\u8350\u51c6\u786e\u5ea6\u7684\u540c\u65f6\u663e\u8457\u538b\u7f29\u5d4c\u5165\u5c3a\u5bf8\uff0c\u7a00\u758f\u5d4c\u5165\u7ed3\u6784\u5177\u6709\u53ef\u89e3\u91ca\u6027\uff0c\u53ef\u76f4\u63a5\u96c6\u6210\u5206\u6bb5\u7ea7\u63a8\u8350\u529f\u80fd\u5230\u5019\u9009\u68c0\u7d22\u6a21\u578b\u4e2d\u3002"}}
{"id": "2602.10016", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10016", "abs": "https://arxiv.org/abs/2602.10016", "authors": ["Bojian Hou", "Xiaolong Liu", "Xiaoyi Liu", "Jiaqi Xu", "Yasmine Badr", "Mengyue Hang", "Sudhanshu Chanpuriya", "Junqing Zhou", "Yuhang Yang", "Han Xu", "Qiuling Suo", "Laming Chen", "Yuxi Hu", "Jiasheng Zhang", "Huaqing Xiong", "Yuzhen Huang", "Chao Chen", "Yue Dong", "Yi Yang", "Shuo Chang", "Xiaorui Gan", "Wenlin Chen", "Santanu Kolay", "Darren Liu", "Jade Nie", "Chunzhi Yang", "Jiyan Yang", "Huayu Li"], "title": "Kunlun: Establishing Scaling Laws for Massive-Scale Recommendation Systems through Unified Architecture Design", "comment": "10 pages, 4 figures", "summary": "Deriving predictable scaling laws that govern the relationship between model performance and computational investment is crucial for designing and allocating resources in massive-scale recommendation systems. While such laws are established for large language models, they remain challenging for recommendation systems, especially those processing both user history and context features. We identify poor scaling efficiency as the main barrier to predictable power-law scaling, stemming from inefficient modules with low Model FLOPs Utilization (MFU) and suboptimal resource allocation. We introduce Kunlun, a scalable architecture that systematically improves model efficiency and resource allocation. Our low-level optimizations include Generalized Dot-Product Attention (GDPA), Hierarchical Seed Pooling (HSP), and Sliding Window Attention. Our high-level innovations feature Computation Skip (CompSkip) and Event-level Personalization. These advances increase MFU from 17% to 37% on NVIDIA B200 GPUs and double scaling efficiency over state-of-the-art methods. Kunlun is now deployed in major Meta Ads models, delivering significant production impact.", "AI": {"tldr": "Kunlun\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u63a8\u8350\u7cfb\u7edf\u67b6\u6784\uff0c\u901a\u8fc7\u63d0\u9ad8\u6a21\u578b\u6548\u7387\u548c\u8d44\u6e90\u5206\u914d\u6765\u6539\u5584\u7f29\u653e\u6548\u7387\uff0c\u5b9e\u73b0\u4e86\u4ece17%\u523037%\u7684MFU\u63d0\u5347\uff0c\u5e76\u5728Meta Ads\u4e2d\u90e8\u7f72\u5e94\u7528\u3002", "motivation": "\u63a8\u8350\u7cfb\u7edf\u7f3a\u4e4f\u53ef\u9884\u6d4b\u7684\u7f29\u653e\u5b9a\u5f8b\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u7528\u6237\u5386\u53f2\u548c\u4e0a\u4e0b\u6587\u7279\u5f81\u65f6\u3002\u7f29\u653e\u6548\u7387\u4f4e\u4e0b\u662f\u4e3b\u8981\u969c\u788d\uff0c\u6e90\u4e8e\u4f4e\u6548\u6a21\u5757\u548c\u6b21\u4f18\u8d44\u6e90\u5206\u914d\u3002", "method": "\u63d0\u51faKunlun\u67b6\u6784\uff0c\u5305\u542b\u4f4e\u5c42\u4f18\u5316\uff08\u5e7f\u4e49\u70b9\u79ef\u6ce8\u610f\u529b\u3001\u5206\u5c42\u79cd\u5b50\u6c60\u5316\u3001\u6ed1\u52a8\u7a97\u53e3\u6ce8\u610f\u529b\uff09\u548c\u9ad8\u5c42\u521b\u65b0\uff08\u8ba1\u7b97\u8df3\u8fc7\u3001\u4e8b\u4ef6\u7ea7\u4e2a\u6027\u5316\uff09\u3002", "result": "\u5728NVIDIA B200 GPU\u4e0a\u5c06MFU\u4ece17%\u63d0\u5347\u523037%\uff0c\u7f29\u653e\u6548\u7387\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u9ad8\u4e00\u500d\uff0c\u5df2\u5728Meta Ads\u4e3b\u8981\u6a21\u578b\u4e2d\u90e8\u7f72\u5e76\u4ea7\u751f\u663e\u8457\u751f\u4ea7\u5f71\u54cd\u3002", "conclusion": "Kunlun\u901a\u8fc7\u7cfb\u7edf\u6027\u7684\u6548\u7387\u548c\u8d44\u6e90\u5206\u914d\u6539\u8fdb\uff0c\u89e3\u51b3\u4e86\u63a8\u8350\u7cfb\u7edf\u7f29\u653e\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u53ef\u9884\u6d4b\u7684\u7f29\u653e\u5b9a\u5f8b\uff0c\u5e76\u5728\u5b9e\u9645\u751f\u4ea7\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2602.10024", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.10024", "abs": "https://arxiv.org/abs/2602.10024", "authors": ["Dawn Lawrie", "Sean MacAvaney", "James Mayfield", "Luca Soldaini", "Eugene Yang", "Andrew Yates"], "title": "Overview of the TREC 2025 RAGTIME Track", "comment": "10 pages, 3 figures, notebook version of the RAGTIME 2025 overview paper", "summary": "The principal goal of the RAG TREC Instrument for Multilingual Evaluation (RAGTIME) track at TREC is to study report generation from multilingual source documents. The track has created a document collection containing Arabic, Chinese, English, and Russian news stories. RAGTIME includes three task types: Multilingual Report Generation, English Report Generation, and Multilingual Information Retrieval (MLIR). A total of 125 runs were submitted by 13 participating teams (and as baselines by the track coordinators) for three tasks. This overview describes these three tasks and presents the available results.", "AI": {"tldr": "RAGTIME\u662fTREC\u7684\u591a\u8bed\u8a00\u8bc4\u4f30\u8d5b\u9053\uff0c\u4e13\u6ce8\u4e8e\u4ece\u591a\u8bed\u8a00\u65b0\u95fb\u6587\u6863\u751f\u6210\u62a5\u544a\uff0c\u5305\u542b\u4e09\u4e2a\u4efb\u52a1\u7c7b\u578b\uff0c\u5171\u670913\u4e2a\u56e2\u961f\u63d0\u4ea4\u4e86125\u4e2a\u8fd0\u884c\u7ed3\u679c\u3002", "motivation": "\u7814\u7a76\u4ece\u591a\u8bed\u8a00\u6e90\u6587\u6863\u751f\u6210\u62a5\u544a\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u9488\u5bf9\u963f\u62c9\u4f2f\u8bed\u3001\u4e2d\u6587\u3001\u82f1\u8bed\u548c\u4fc4\u8bed\u65b0\u95fb\u6587\u6863\u7684\u62a5\u544a\u751f\u6210\u3002", "method": "\u521b\u5efa\u5305\u542b\u56db\u79cd\u8bed\u8a00\u65b0\u95fb\u6587\u6863\u7684\u6587\u6863\u96c6\u5408\uff0c\u8bbe\u7acb\u4e09\u4e2a\u4efb\u52a1\u7c7b\u578b\uff1a\u591a\u8bed\u8a00\u62a5\u544a\u751f\u6210\u3001\u82f1\u8bed\u62a5\u544a\u751f\u6210\u548c\u591a\u8bed\u8a00\u4fe1\u606f\u68c0\u7d22\uff0c\u9080\u8bf7\u7814\u7a76\u56e2\u961f\u53c2\u4e0e\u8bc4\u4f30\u3002", "result": "\u5171\u670913\u4e2a\u53c2\u4e0e\u56e2\u961f\uff08\u52a0\u4e0a\u8d5b\u9053\u534f\u8c03\u5458\u63d0\u4f9b\u7684\u57fa\u7ebf\uff09\u4e3a\u4e09\u4e2a\u4efb\u52a1\u63d0\u4ea4\u4e86125\u4e2a\u8fd0\u884c\u7ed3\u679c\u3002", "conclusion": "\u8be5\u6982\u8ff0\u63cf\u8ff0\u4e86RAGTIME\u8d5b\u9053\u7684\u4e09\u4e2a\u4efb\u52a1\u5e76\u5448\u73b0\u4e86\u53ef\u7528\u7ed3\u679c\uff0c\u4e3a\u591a\u8bed\u8a00\u62a5\u544a\u751f\u6210\u7814\u7a76\u63d0\u4f9b\u4e86\u8bc4\u4f30\u6846\u67b6\u548c\u6570\u636e\u3002"}}
