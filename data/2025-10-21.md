<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 11]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Investigating the Association Between Text-Based Indications of Foodborne Illness from Yelp Reviews and New York City Health Inspection Outcomes (2023)](https://arxiv.org/abs/2510.16334)
*Eden Shaveet,Crystal Su,Daniel Hsu,Luis Gravano*

Main category: cs.IR

TL;DR: 该研究分析了Yelp评论中的食品安全信号与纽约市官方餐厅检查结果之间的相关性，发现在人口普查区层面两者相关性很小。


<details>
  <summary>Details</summary>
Motivation: 餐厅是食源性疾病爆发调查的关键场所，社交媒体上的用户生成内容可以提供及时的公共卫生信号，而官方报告渠道有限。

Method: 使用分层Sigmoid注意力网络(HSAN)分类器分析Yelp评论信号，并与纽约市卫生部门2023年的官方餐厅检查结果进行比较，在人口普查区层面评估相关性。

Result: 在人口普查区层面，HSAN信号与检查分数之间相关性很小，且C级餐厅数量不同的区域在HSAN分数分布上没有显著差异。

Conclusion: 社交媒体信号与官方检查结果在宏观层面相关性有限，需要进一步进行地址级别的分析。

Abstract: Foodborne illnesses are gastrointestinal conditions caused by consuming
contaminated food. Restaurants are critical venues to investigate outbreaks
because they share sourcing, preparation, and distribution of foods. Public
reporting of illness via formal channels is limited, whereas social media
platforms host abundant user-generated content that can provide timely public
health signals. This paper analyzes signals from Yelp reviews produced by a
Hierarchical Sigmoid Attention Network (HSAN) classifier and compares them with
official restaurant inspection outcomes issued by the New York City Department
of Health and Mental Hygiene (NYC DOHMH) in 2023. We evaluate correlations at
the Census tract level, compare distributions of HSAN scores by prevalence of
C-graded restaurants, and map spatial patterns across NYC. We find minimal
correlation between HSAN signals and inspection scores at the tract level and
no significant differences by number of C-graded restaurants. We discuss
implications and outline next steps toward address-level analyses.

</details>


### [2] [Blending Learning to Rank and Dense Representations for Efficient and Effective Cascades](https://arxiv.org/abs/2510.16393)
*Franco Maria Nardini,Raffaele Perego,Nicola Tonellotto,Salvatore Trani*

Main category: cs.IR

TL;DR: 本文提出了一种结合词汇和神经相关性信号的混合检索方法，使用学习排序模型融合253个手工词汇特征和密集神经表示，显著提升了检索效果。


<details>
  <summary>Details</summary>
Motivation: 探索如何有效结合词汇和神经两种不同的相关性信号来提升检索性能，利用两者的互补优势。

Method: 采用两阶段架构：第一阶段使用密集神经检索器进行最近邻搜索，第二阶段使用基于决策树森林的学习排序模型对候选结果重新排序，融合253个手工词汇特征和神经表示。

Result: 在公开数据集上的实验显示，该方法显著提升了端到端排序性能，nDCG@10提升高达11%，而平均查询延迟仅增加4.3%。

Conclusion: 无缝结合两种不同信号家族能够相互促进检索效果，在保持效率的同时显著提升检索质量。

Abstract: We investigate the exploitation of both lexical and neural relevance signals
for ad-hoc passage retrieval. Our exploration involves a large-scale training
dataset in which dense neural representations of MS-MARCO queries and passages
are complemented and integrated with 253 hand-crafted lexical features
extracted from the same corpus. Blending of the relevance signals from the two
different groups of features is learned by a classical Learning-to-Rank (LTR)
model based on a forest of decision trees. To evaluate our solution, we employ
a pipelined architecture where a dense neural retriever serves as the first
stage and performs a nearest-neighbor search over the neural representations of
the documents. Our LTR model acts instead as the second stage that re-ranks the
set of candidates retrieved by the first stage to enhance effectiveness. The
results of reproducible experiments conducted with state-of-the-art dense
retrievers on publicly available resources show that the proposed solution
significantly enhances the end-to-end ranking performance while relatively
minimally impacting efficiency. Specifically, we achieve a boost in nDCG@10 of
up to 11% with an increase in average query latency of only 4.3%. This confirms
the advantage of seamlessly combining two distinct families of signals that
mutually contribute to retrieval effectiveness.

</details>


### [3] [FRONTIER-RevRec: A Large-scale Dataset for Reviewer Recommendation](https://arxiv.org/abs/2510.16597)
*Qiyao Peng,Chen Wang,Yinghui Wang,Hongtao Liu,Xuan Guo,Wenjun Wang*

Main category: cs.IR

TL;DR: 提出了FRONTIER-RevRec数据集，这是一个基于Frontiers开放获取出版平台真实同行评审记录的大规模审稿人推荐基准数据集，包含177941名审稿人和478379篇论文，涵盖209种期刊。


<details>
  <summary>Details</summary>
Motivation: 解决审稿人推荐研究领域缺乏高质量基准数据集的问题，现有数据集通常规模小、学科范围有限，且缺乏不同方法的比较分析。

Method: 基于Frontiers平台2007-2025年的真实同行评审记录构建大规模数据集，并进行全面的评估分析，比较基于内容的方法和协同过滤方法的效果。

Result: 基于内容的方法显著优于协同过滤，语言模型方法在捕捉论文内容与审稿人专业知识的语义对齐方面特别有效，并确定了优化推荐流程的最佳聚合策略。

Conclusion: FRONTIER-RevRec数据集可作为审稿人推荐研究的综合基准，促进更有效的学术同行评审系统的发展。

Abstract: Reviewer recommendation is a critical task for enhancing the efficiency of
academic publishing workflows. However, research in this area has been
persistently hindered by the lack of high-quality benchmark datasets, which are
often limited in scale, disciplinary scope, and comparative analyses of
different methodologies. To address this gap, we introduce FRONTIER-RevRec, a
large-scale dataset constructed from authentic peer review records (2007-2025)
from the Frontiers open-access publishing platform
https://www.frontiersin.org/. The dataset contains 177941 distinct reviewers
and 478379 papers across 209 journals spanning multiple disciplines including
clinical medicine, biology, psychology, engineering, and social sciences. Our
comprehensive evaluation on this dataset reveals that content-based methods
significantly outperform collaborative filtering. This finding is explained by
our structural analysis, which uncovers fundamental differences between
academic recommendation and commercial domains. Notably, approaches leveraging
language models are particularly effective at capturing the semantic alignment
between a paper's content and a reviewer's expertise. Furthermore, our
experiments identify optimal aggregation strategies to enhance the
recommendation pipeline. FRONTIER-RevRec is intended to serve as a
comprehensive benchmark to advance research in reviewer recommendation and
facilitate the development of more effective academic peer review systems. The
FRONTIER-RevRec dataset is available at:
https://anonymous.4open.science/r/FRONTIER-RevRec-5D05.

</details>


### [4] [Right Answer at the Right Time - Temporal Retrieval-Augmented Generation via Graph Summarization](https://arxiv.org/abs/2510.16715)
*Zulun Zhu,Haoyu Liu,Mengke He,Siqiang Luo*

Main category: cs.IR

TL;DR: STAR-RAG是一个时间感知的图检索增强生成框架，通过构建时间对齐规则图进行传播，在保证准确性的同时减少token消耗，无需模型训练即可部署。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法主要基于语义检索，往往忽略显式时间约束，导致时间不一致的答案和过高的token使用量。

Method: 构建时间对齐规则图，在该图上进行传播以缩小搜索空间，优先选择语义相关且时间一致的证据。

Result: 在真实世界时间知识图谱数据集上的实验表明，该方法在消耗更少token的同时实现了更高的答案准确性。

Conclusion: STAR-RAG通过时间对齐规则图传播有效实施时间邻近性约束，减少候选检索结果，降低token消耗而不牺牲准确性，且无需繁重模型训练即可部署。

Abstract: Question answering in temporal knowledge graphs requires retrieval that is
both time-consistent and efficient. Existing RAG methods are largely semantic
and typically neglect explicit temporal constraints, which leads to
time-inconsistent answers and inflated token usage. We propose STAR-RAG, a
temporal GraphRAG framework that relies on two key ideas: building a
time-aligned rule graph and conducting propagation on this graph to narrow the
search space and prioritize semantically relevant, time-consistent evidence.
This design enforces temporal proximity during retrieval, reduces the candidate
set of retrieval results, and lowers token consumption without sacrificing
accuracy. Compared with existing temporal RAG approaches, STAR-RAG eliminates
the need for heavy model training and fine-tuning, thereby reducing
computational cost and significantly simplifying deployment.Extensive
experiments on real-world temporal KG datasets show that our method achieves
improved answer accuracy while consuming fewer tokens than strong GraphRAG
baselines.

</details>


### [5] [Exact Nearest-Neighbor Search on Energy-Efficient FPGA Devices](https://arxiv.org/abs/2510.16736)
*Patrizio Dazzi,William Guglielmo,Franco Maria Nardini,Raffaele Perego,Salvatore Trani*

Main category: cs.IR

TL;DR: 本文研究了使用FPGA设备在高维潜在空间中进行节能精确kNN搜索的方法，提出了两种基于相同FPGA底层配置的节能解决方案，在吞吐量、延迟和能耗方面优于CPU方案。


<details>
  <summary>Details</summary>
Motivation: 支持基于神经编码器模型的学习表示的大规模应用，使其更加环保和包容，通过FPGA实现节能的精确kNN搜索。

Method: 提出了两种FPGA解决方案：第一种通过并行处理批量查询来最大化系统吞吐量，处理无法放入FPGA内存的流式数据集；第二种通过并行处理每个kNN查询来最小化延迟，处理内存中的数据集。

Result: 实验显示FPGA解决方案在查询吞吐量、延迟和能耗方面均优于CPU方案，吞吐量提升最高达16.6倍，能耗节省最高达11.9倍。

Conclusion: FPGA设备能够有效实现高维潜在空间中精确kNN搜索的节能优化，在吞吐量、延迟和能耗方面显著优于CPU方案。

Abstract: This paper investigates the usage of FPGA devices for energy-efficient exact
kNN search in high-dimension latent spaces. This work intercepts a relevant
trend that tries to support the increasing popularity of learned
representations based on neural encoder models by making their large-scale
adoption greener and more inclusive. The paper proposes two different
energy-efficient solutions adopting the same FPGA low-level configuration. The
first solution maximizes system throughput by processing the queries of a batch
in parallel over a streamed dataset not fitting into the FPGA memory. The
second minimizes latency by processing each kNN incoming query in parallel over
an in-memory dataset. Reproducible experiments on publicly available image and
text datasets show that our solution outperforms state-of-the-art CPU-based
competitors regarding throughput, latency, and energy consumption.
Specifically, experiments show that the proposed FPGA solutions achieve the
best throughput in terms of queries per second and the best-observed latency
with scale-up factors of up to 16.6X. Similar considerations can be made
regarding energy efficiency, where results show that our solutions can achieve
up to 11.9X energy saving w.r.t. strong CPU-based competitors.

</details>


### [6] [An Efficient Framework for Whole-Page Reranking via Single-Modal Supervision](https://arxiv.org/abs/2510.16803)
*Zishuai Zhang,Sihao Yu,Wenyi Xie,Ying Nie,Junfeng Wang,Zhiming Zheng,Dawei Yin,Hainan Zhang*

Main category: cs.IR

TL;DR: SMAR是一个新颖的全页重排框架，利用高质量单模态排序器指导模态间相关性对齐，仅需有限的全页标注即可超越完全标注的重排模型性能


<details>
  <summary>Details</summary>
Motivation: 全页重排对搜索引擎用户体验至关重要，但现有方法依赖大规模人工标注，成本高且耗时。全页标注比单模态标注复杂得多，需要评估整个结果页面并考虑跨模态相关性差异

Method: 首先针对各自模态训练高质量单模态排序器，然后为每个查询选择其输出的子集构建候选页面并进行页面级人工标注，最后使用这些有限标注训练全页重排器，并强制与单模态偏好保持一致以维持各模态内的排序质量

Result: 在Qilin和Baidu数据集上的实验表明，SMAR将标注成本降低约70-90%，同时相比基线实现了显著的排序改进。在百度APP上的离线和在线A/B测试也显示标准排序指标和用户体验指标均有显著提升

Conclusion: SMAR框架在现实搜索场景中验证了其有效性和实用价值，能够在显著降低标注成本的同时提升全页重排性能

Abstract: The whole-page reranking plays a critical role in shaping the user experience
of search engines, which integrates retrieval results from multiple modalities,
such as documents, images, videos, and LLM outputs. Existing methods mainly
rely on large-scale human-annotated data, which is costly to obtain and
time-consuming. This is because whole-page annotation is far more complex than
single-modal: it requires assessing the entire result page while accounting for
cross-modal relevance differences. Thus, how to improve whole-page reranking
performance while reducing annotation costs is still a key challenge in
optimizing search engine result pages(SERP). In this paper, we propose SMAR, a
novel whole-page reranking framework that leverages strong Single-modal rankers
to guide Modal-wise relevance Alignment for effective Reranking, using only
limited whole-page annotation to outperform fully-annotated reranking models.
Specifically, high-quality single-modal rankers are first trained on data
specific to their respective modalities. Then, for each query, we select a
subset of their outputs to construct candidate pages and perform human
annotation at the page level. Finally, we train the whole-page reranker using
these limited annotations and enforcing consistency with single-modal
preferences to maintain ranking quality within each modality. Experiments on
the Qilin and Baidu datasets demonstrate that SMAR reduces annotation costs by
about 70-90\% while achieving significant ranking improvements compared to
baselines. Further offline and online A/B testing on Baidu APPs also shows
notable gains in standard ranking metrics as well as user experience
indicators, fully validating the effectiveness and practical value of our
approach in real-world search scenarios.

</details>


### [7] [The Layout Is the Model: On Action-Item Coupling in Generative Recommendation](https://arxiv.org/abs/2510.16804)
*Xiaokai Wei,Jiajun Wu,Daiyao Yi,Reza Shirkavand,Michelle Gong*

Main category: cs.IR

TL;DR: 本文研究了生成式推荐模型中的token布局问题，提出了基于三个设计原则的统一框架，并设计了一种新颖的非交错布局方法LAC，在保持准确性的同时显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 生成式推荐模型将用户交互历史视为序列进行自回归预测，当同时建模物品和动作时，token的布局（排序和可见性）决定了模型能使用什么信息以及如何泛化。

Method: 提出了基于三个设计原则的统一token布局研究：最大化物品/动作信号、保持"动作给定物品"的条件关系、无信息泄漏。设计了Lagged Action Conditioning (LAC)方法，这是一种表面奇怪但符合设计原则的非交错布局。

Result: 在公共数据集和大规模生产日志上的综合实验验证了设计原则。提出的非交错方法LAC在显著降低FLOPs的情况下，实现了与交错布局相当或更优的质量。

Conclusion: 研究结果为构建既准确又高效的生成式推荐系统提供了可行的指导，LAC方法在保持性能的同时大幅提升了效率。

Abstract: Generative Recommendation (GR) models treat a user's interaction history as a
sequence to be autoregressively predicted. When both items and actions (e.g.,
watch time, purchase, comment) are modeled, the layout-the ordering and
visibility of item/action tokens-critically determines what information the
model can use and how it generalizes. We present a unified study of token
layouts for GR grounded in first principles: (P1) maximize item/action signal
in both input/output space, (P2) preserve the conditioning relationship "action
given item" and (P3) no information leakage.
  While interleaved layout (where item and action occupy separate tokens)
naturally satisfies these principles, it also bloats sequence length with
larger training/inference cost. On the non-interleaved front, we design a novel
and effective approach, Lagged Action Conditioning (LAC), which appears strange
on the surface but aligns well with the design principles to yield strong
accuracy. Comprehensive experiments on public datasets and large-scale
production logs evaluate different layout options and empirically verifies the
design principles. Our proposed non-interleaved method, LAC, achieves
competitive or superior quality at substantially lower FLOPs than interleaving.
Our findings offer actionable guidance for assembling GR systems that are both
accurate and efficient.

</details>


### [8] [Towards Context-aware Reasoning-enhanced Generative Searching in E-commerce](https://arxiv.org/abs/2510.16925)
*Zhiding Liu,Ben Chen,Mingyue Cheng,Enchong Chen,Li Li,Chenyi Lei,Wenwu Ou,Han Li,Kun Gai*

Main category: cs.IR

TL;DR: 提出了一种上下文感知推理增强的生成搜索框架，通过统一异构上下文信息、自演化的后训练范式以及去偏的强化学习算法，提升电商搜索推荐的性能。


<details>
  <summary>Details</summary>
Motivation: 电商搜索推荐中，用户的复杂搜索上下文（时空因素、历史交互、当前查询信息）反映了重要的隐式偏好，但现有方法在整合这些上下文信息方面存在局限，无法充分捕捉用户意图。

Method: 1. 将异构用户和物品上下文统一为文本表示或基于文本的语义标识符并对其对齐；2. 引入自演化的后训练范式，迭代结合监督微调和强化学习来增强模型推理能力；3. 提出去偏的GRPO变体来改善排序性能。

Result: 在真实电商平台的搜索日志数据上进行广泛实验，表明该方法相比强基线实现了更优越的性能，验证了其在搜索推荐中的有效性。

Conclusion: 该上下文感知推理增强的生成搜索框架能够更好地理解复杂上下文，有效提升电商搜索推荐的性能。

Abstract: Search-based recommendation is one of the most critical application scenarios
in e-commerce platforms. Users' complex search contexts--such as spatiotemporal
factors, historical interactions, and current query's information--constitute
an essential part of their decision-making, reflecting implicit preferences
that complement explicit query terms. Modeling such rich contextual signals and
their intricate associations with candidate items remains a key challenge.
Although numerous efforts have been devoted to building more effective search
methods, existing approaches still show limitations in integrating contextual
information, which hinders their ability to fully capture user intent.
  To address these challenges, we propose a context-aware reasoning-enhanced
generative search framework for better \textbf{understanding the complicated
context}. Specifically, the framework first unifies heterogeneous user and item
contexts into textual representations or text-based semantic identifiers and
aligns them. To overcome the lack of explicit reasoning trajectories, we
introduce a self-evolving post-training paradigm that iteratively combines
supervised fine-tuning and reinforcement learning to progressively enhance the
model's reasoning capability. In addition, we identify potential biases in
existing RL algorithms when applied to search scenarios and present a debiased
variant of GRPO to improve ranking performance. Extensive experiments on search
log data collected from a real-world e-commerce platform demonstrate that our
approach achieves superior performance compared with strong baselines,
validating its effectiveness for search-based recommendation.

</details>


### [9] [DSEBench: A Test Collection for Explainable Dataset Search with Examples](https://arxiv.org/abs/2510.17228)
*Qing Shi,Jing He,Qiaosheng Chen,Gong Cheng*

Main category: cs.IR

TL;DR: 本文提出了可解释的数据集搜索与示例（Explainable DSE）任务，构建了DSEBench测试集，并使用大语言模型生成训练标注，评估了多种检索和解释方法。


<details>
  <summary>Details</summary>
Motivation: 现有数据集搜索方法要么基于关键词查询，要么基于目标数据集相似性，需要结合这两种信息需求的统一框架。

Method: 构建DSEBench测试集，使用LLM生成训练标注，评估稀疏、稠密和LLM基础的检索、重排序及解释方法。

Result: 建立了DSEBench上的广泛基线，为可解释DSE研究提供了评估基准。

Conclusion: 提出的可解释DSE任务和DSEBench测试集为数据集搜索研究提供了新的方向和评估标准。

Abstract: Dataset search has been an established information retrieval task. Current
paradigms either retrieve datasets that are relevant to a keyword query or find
datasets that are similar to an input target dataset. To allow for their
combined specification of information needs, in this article, we investigate
the more generalized task of Dataset Search with Examples (DSE) and further
extend it to Explainable DSE that requires identifying the metadata and content
fields of a dataset that indicate its relevance to the query and similarity to
the target datasets. To facilitate this research, we construct DSEBench, a test
collection that provides high-quality dataset- and field-level annotations to
enable the evaluation of explainable DSE. We also employ a large language model
to generate numerous annotations to be used for training. We establish
extensive baselines on DSEBench by adapting and evaluating a variety of sparse,
dense, and LLM-based retrieval, reranking, and explanation methods.

</details>


### [10] [On Efficiency-Effectiveness Trade-off of Diffusion-based Recommenders](https://arxiv.org/abs/2510.17245)
*Wenyu Mao,Jiancan Wu,Guoqing Hu,Wei Ji,Xiang Wang*

Main category: cs.IR

TL;DR: TA-Rec是一个两阶段框架，通过预训练时的时序一致性正则化平滑去噪函数实现一步生成，并通过微调时的自适应偏好对齐减轻轨迹偏差，解决扩散模型在序列推荐中效率与效果之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在序列推荐中通常需要多步去噪过程，这依赖于离散近似并引入离散化误差，导致计算效率和推荐效果之间的权衡问题。

Method: 提出TA-Rec两阶段框架：1）预训练阶段使用时序一致性正则化平滑去噪函数；2）微调阶段引入自适应偏好对齐，基于偏好对相似性和时间步长自适应地对齐去噪过程与用户偏好。

Result: 大量实验证明TA-Rec的两阶段目标有效减轻了离散化误差引起的权衡问题，提升了基于扩散的推荐器的效率和效果。

Conclusion: TA-Rec通过两阶段框架成功解决了扩散模型在序列推荐中的效率与效果权衡问题，实现了高效且有效的一步生成推荐。

Abstract: Diffusion models have emerged as a powerful paradigm for generative
sequential recommendation, which typically generate next items to recommend
guided by user interaction histories with a multi-step denoising process.
However, the multi-step process relies on discrete approximations, introducing
discretization error that creates a trade-off between computational efficiency
and recommendation effectiveness. To address this trade-off, we propose TA-Rec,
a two-stage framework that achieves one-step generation by smoothing the
denoising function during pretraining while alleviating trajectory deviation by
aligning with user preferences during fine-tuning. Specifically, to improve the
efficiency without sacrificing the recommendation performance, TA-Rec pretrains
the denoising model with Temporal Consistency Regularization (TCR), enforcing
the consistency between the denoising results across adjacent steps. Thus, we
can smooth the denoising function to map the noise as oracle items in one step
with bounded error. To further enhance effectiveness, TA-Rec introduces
Adaptive Preference Alignment (APA) that aligns the denoising process with user
preference adaptively based on preference pair similarity and timesteps.
Extensive experiments prove that TA-Rec's two-stage objective effectively
mitigates the discretization errors-induced trade-off, enhancing both
efficiency and effectiveness of diffusion-based recommenders.

</details>


### [11] [How role-play shapes relevance judgment in zero-shot LLM rankers](https://arxiv.org/abs/2510.17535)
*Yumeng Wang,Jirui Qi,Catherine Chen,Panagiotis Eustratiadis,Suzan Verberne*

Main category: cs.IR

TL;DR: 本文系统研究了角色扮演提示对零样本LLM排序器的影响，通过因果干预技术揭示了角色描述在早期层编码、与任务指令在中间层交互的机制，并识别了关键注意力头。


<details>
  <summary>Details</summary>
Motivation: 角色扮演提示能提升LLM排序器的鲁棒性和准确性，但其作用机制和多样性尚未充分探索，限制了有效使用和可解释性。

Method: 采用机械可解释性的因果干预技术，追踪角色扮演信息如何塑造LLM中的相关性判断，分析不同角色描述变体的影响。

Result: 发现角色描述对排序质量有显著影响；角色信号主要在早期层编码，在中间层与任务指令交互，但与查询/文档表征交互有限；识别了编码角色条件相关性信息的关键注意力头。

Conclusion: 研究揭示了角色扮演在LLM排序中的内部工作机制，为IR及其他领域设计更有效的提示提供了指导，展示了在零样本应用中利用角色扮演的广阔机会。

Abstract: Large Language Models (LLMs) have emerged as promising zero-shot rankers, but
their performance is highly sensitive to prompt formulation. In particular,
role-play prompts, where the model is assigned a functional role or identity,
often give more robust and accurate relevance rankings. However, the mechanisms
and diversity of role-play effects remain underexplored, limiting both
effective use and interpretability. In this work, we systematically examine how
role-play variations influence zero-shot LLM rankers. We employ causal
intervention techniques from mechanistic interpretability to trace how
role-play information shapes relevance judgments in LLMs. Our analysis reveals
that (1) careful formulation of role descriptions have a large effect on the
ranking quality of the LLM; (2) role-play signals are predominantly encoded in
early layers and communicate with task instructions in middle layers, while
receiving limited interaction with query or document representations.
Specifically, we identify a group of attention heads that encode information
critical for role-conditioned relevance. These findings not only shed light on
the inner workings of role-play in LLM ranking but also offer guidance for
designing more effective prompts in IR and beyond, pointing toward broader
opportunities for leveraging role-play in zero-shot applications.

</details>
