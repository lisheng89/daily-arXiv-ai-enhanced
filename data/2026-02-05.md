<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 10]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Nemotron ColEmbed V2: Top-Performing Late Interaction embedding models for Visual Document Retrieval](https://arxiv.org/abs/2602.03992)
*Gabriel de Souza P. Moreira,Ronay Ak,Mengyao Xu,Oliver Holworthy,Benedikt Schifferer,Zhiding Yu,Yauhen Babakhin,Radek Osmulski,Jiarui Cai,Ryan Chesler,Bo Liu,Even Oldridge*

Main category: cs.IR

TL;DR: Nemotron ColEmbed V2是一个用于视觉文档检索的VLM嵌入模型家族，在ViDoRe基准测试中达到SOTA性能，8B模型在ViDoRe V3排行榜上排名第一。


<details>
  <summary>Details</summary>
Motivation: 随着视觉文档检索需求的增长，需要更好的VLM嵌入模型来替代传统的OCR文本提取方法，以保留视觉信息并简化索引流程。

Method: 基于预训练的VLMs构建了三个变体（3B、4B、8B参数），采用了集群采样、困难负样本挖掘、双向注意力、延迟交互和模型融合等技术。

Result: 8B模型在ViDoRe V3排行榜上排名第一，平均NDCG@10达到63.42，展示了在视觉文档检索任务上的卓越性能。

Conclusion: Nemotron ColEmbed V2系列模型为视觉文档检索提供了有效的解决方案，通过多种技术优化实现了SOTA性能，同时讨论了延迟交互机制带来的计算和存储工程挑战。

Abstract: Retrieval-Augmented Generation (RAG) systems have been popular for generative applications, powering language models by injecting external knowledge. Companies have been trying to leverage their large catalog of documents (e.g. PDFs, presentation slides) in such RAG pipelines, whose first step is the retrieval component. Dense retrieval has been a popular approach, where embedding models are used to generate a dense representation of the user query that is closer to relevant content embeddings. More recently, VLM-based embedding models have become popular for visual document retrieval, as they preserve visual information and simplify the indexing pipeline compared to OCR text extraction.
  Motivated by the growing demand for visual document retrieval, we introduce Nemotron ColEmbed V2, a family of models that achieve state-of-the-art performance on the ViDoRe benchmarks. We release three variants - with 3B, 4B, and 8B parameters - based on pre-trained VLMs: NVIDIA Eagle 2 with Llama 3.2 3B backbone, Qwen3-VL-4B-Instruct and Qwen3-VL-8B-Instruct, respectively. The 8B model ranks first on the ViDoRe V3 leaderboard as of February 03, 2026, achieving an average NDCG@10 of 63.42.
  We describe the main techniques used across data processing, training, and post-training - such as cluster-based sampling, hard-negative mining, bidirectional attention, late interaction, and model merging - that helped us build our top-performing models. We also discuss compute and storage engineering challenges posed by the late interaction mechanism and present experiments on how to balance accuracy and storage with lower dimension embeddings.

</details>


### [2] [Following the TRAIL: Predicting and Explaining Tomorrow's Hits with a Fine-Tuned LLM](https://arxiv.org/abs/2602.04225)
*Yinan Zhang,Zhixi Chen,Jiazheng Jing,Zhiqi Shen*

Main category: cs.IR

TL;DR: TRAIL是一个微调的LLM，联合预测短期物品流行度并生成忠实自然语言解释，通过对比学习对齐分数和解释与结构化趋势信号。


<details>
  <summary>Details</summary>
Motivation: LLM在推荐系统中应用困难：难以从大规模稀疏用户-物品日志中提取用户偏好，实时全目录排序耗时；现有推荐系统多只关注排序而忽视解释，解释可提高预测准确性和用户可信度。

Method: TRAIL采用对比学习，使用正负样本对，将模型分数和解释与结构化趋势信号对齐，实现准确且可解释的流行度预测。

Result: 广泛实验表明TRAIL优于强基线，能生成连贯且有充分依据的解释。

Conclusion: TRAIL通过联合预测短期物品流行度和生成忠实解释，解决了LLM在推荐系统中的挑战，实现了准确且可解释的推荐。

Abstract: Large Language Models (LLMs) have been widely applied across multiple domains for their broad knowledge and strong reasoning capabilities. However, applying them to recommendation systems is challenging since it is hard for LLMs to extract user preferences from large, sparse user-item logs, and real-time per-user ranking over the full catalog is too time-consuming to be practical. Moreover, many existing recommender systems focus solely on ranking items while overlooking explanations, which could help improve predictive accuracy and make recommendations more convincing to users. Inspired by recent works that achieve strong recommendation performance by forecasting near-term item popularity, we propose TRAIL (TRend and explAnation Integrated Learner). TRAIL is a fine-tuned LLM that jointly predicts short-term item popularity and generates faithful natural-language explanations. It employs contrastive learning with positive and negative pairs to align its scores and explanations with structured trend signals, yielding accurate and explainable popularity predictions. Extensive experiments show that TRAIL outperforms strong baselines and produces coherent, well-grounded explanations.

</details>


### [3] [LILaC: Late Interacting in Layered Component Graph for Open-domain Multimodal Multihop Retrieval](https://arxiv.org/abs/2602.04263)
*Joohyung Yun,Doyup Lee,Wook-Shin Han*

Main category: cs.IR

TL;DR: LILaC是一个多模态文档检索框架，通过分层组件图和基于边缘的子图检索方法，解决固定粒度检索单元和多跳推理问题，在五个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 多模态文档检索面临两个主要挑战：1) 固定单一粒度检索单元导致的无关内容干扰；2) 支持多跳推理需要有效捕捉文档内和跨文档组件间的语义关系。

Method: 提出LILaC框架，包含两个核心创新：1) 分层组件图，在粗粒度和细粒度两个层次显式表示多模态信息；2) 基于晚交互的子图检索方法，先识别粗粒度节点进行高效候选生成，再通过晚交互进行细粒度推理。

Result: 在五个基准测试中，LILaC实现了最先进的检索性能，且无需额外微调。

Conclusion: LILaC通过分层表示和基于边缘的检索方法，有效解决了多模态文档检索中的粒度问题和多跳推理挑战，取得了优异的检索性能。

Abstract: Multimodal document retrieval aims to retrieve query-relevant components from documents composed of textual, tabular, and visual elements. An effective multimodal retriever needs to handle two main challenges: (1) mitigate the effect of irrelevant contents caused by fixed, single-granular retrieval units, and (2) support multihop reasoning by effectively capturing semantic relationships among components within and across documents. To address these challenges, we propose LILaC, a multimodal retrieval framework featuring two core innovations. First, we introduce a layered component graph, explicitly representing multimodal information at two layers - each representing coarse and fine granularity - facilitating efficient yet precise reasoning. Second, we develop a late-interaction-based subgraph retrieval method, an edge-based approach that initially identifies coarse-grained nodes for efficient candidate generation, then performs fine-grained reasoning via late interaction. Extensive experiments demonstrate that LILaC achieves state-of-the-art retrieval performance on all five benchmarks, notably without additional fine-tuning. We make the artifacts publicly available at github.com/joohyung00/lilac.

</details>


### [4] [MiniRec: Data-Efficient Reinforcement Learning for LLM-based Recommendation](https://arxiv.org/abs/2602.04278)
*Lin Wang,Yang Zhang,Jingfan Chen,Xiaoyan Zhao,Fengbin Zhu,Qing Li,Tat-Seng Chua*

Main category: cs.IR

TL;DR: MiniRec：针对基于RL的LLM推荐系统的高效数据选择框架，通过奖励对齐和轨迹感知的样本选择，大幅降低训练成本同时保持性能


<details>
  <summary>Details</summary>
Motivation: 基于强化学习的LLM推荐系统面临训练效率低下的挑战，现有数据选择方法（基于可学习性或代表性）与RL学习动态不匹配，导致性能不佳

Method: 提出MiniRec框架：1) 使用奖励信号评估样本可学习性，修剪太简单（奖励过高）或太难（奖励持续低）的样本；2) 通过样本梯度与近似"理想"全局RL优化轨迹的对齐评估代表性；3) 强制多样性以减少冗余；4) 结合从易到难的课程学习策略

Result: 大量实验证明MiniRec的有效性，显著降低训练成本同时基本保持性能，凸显了奖励对齐、轨迹感知数据选择在基于RL的LLM推荐中的重要性

Conclusion: MiniRec为基于RL的LLM推荐系统提供了一种高效的数据选择框架，通过奖励对齐和优化轨迹感知的方法，解决了现有数据选择方法与RL学习动态不匹配的问题，实现了训练成本的大幅降低

Abstract: The integration of reinforcement learning (RL) into large language models (LLMs) has opened new opportunities for recommender systems by eliciting reasoning and improving user preference modeling. However, RL-based LLM recommendation faces significant efficiency challenges, making full-data training costly. Existing data selection methods define sample value based on learnability or representativeness, yet their loss- or gradient-driven or dataset coverage-driven criteria often misalign with RL learning dynamics, resulting in suboptimal performance. To address this, we propose MiniRec, a data selection framework tailored for RL-based LLM recommendation. MiniRec evaluates sample learnability using key RL signals -- rewards -- pruning samples that are too easy (too high reward) or too difficult (consistently low reward). It assesses representativeness by aligning sample gradients with the approximated "ideal" global RL optimization trajectory, selecting samples that mainly drive model updates, and it also enforces diversity to reduce redundancy. Combined with a curriculum learning strategy from easy to hard samples, MiniRec significantly reduces training cost while largely preserving performance. Extensive experiments demonstrate MiniRec's effectiveness, highlighting the importance of reward-aligned, trajectory-informed data selection in RL-based LLM recommendation.

</details>


### [5] [SDR-CIR: Semantic Debias Retrieval Framework for Training-Free Zero-Shot Composed Image Retrieval](https://arxiv.org/abs/2602.04451)
*Yi Sun,Jinyu Xu,Qing Xie,Jiachen Li,Yanchun Ma,Yongjian Liu*

Main category: cs.IR

TL;DR: SDR-CIR提出了一种无需训练、基于语义去偏排序的零样本组合图像检索方法，通过选择性思维链和两步去偏策略减少语义偏差，在三个标准基准上达到一流性能。


<details>
  <summary>Details</summary>
Motivation: 现有零样本组合图像检索方法使用多模态大语言模型生成目标图像描述进行检索，但由于模糊匹配特性，生成的描述容易产生语义偏差，影响检索准确性。

Method: 提出SDR-CIR方法：1）选择性思维链引导MLLM提取与修改文本相关的视觉内容，减少源头的视觉噪声；2）语义去偏排序包括锚定步骤（融合参考图像特征和目标描述特征）和去偏步骤（建模参考图像对描述的视觉语义贡献作为惩罚项）。

Result: 在三个标准CIR基准测试中，SDR-CIR在单阶段方法中达到了最先进的性能，同时保持了高效率。

Conclusion: SDR-CIR通过补充被忽略的线索同时抑制冗余信息，有效减轻了语义偏差，提高了组合图像检索的性能，代码已开源。

Abstract: Composed Image Retrieval (CIR) aims to retrieve a target image from a query composed of a reference image and modification text. Recent training-free zero-shot methods often employ Multimodal Large Language Models (MLLMs) with Chain-of-Thought (CoT) to compose a target image description for retrieval. However, due to the fuzzy matching nature of ZS-CIR, the generated description is prone to semantic bias relative to the target image. We propose SDR-CIR, a training-free Semantic Debias Ranking method based on CoT reasoning. First, Selective CoT guides the MLLM to extract visual content relevant to the modification text during image understanding, thereby reducing visual noise at the source. We then introduce a Semantic Debias Ranking with two steps, Anchor and Debias, to mitigate semantic bias. In the Anchor step, we fuse reference image features with target description features to reinforce useful semantics and supplement omitted cues. In the Debias step, we explicitly model the visual semantic contribution of the reference image to the description and incorporate it into the similarity score as a penalty term. By supplementing omitted cues while suppressing redundancy, SDR-CIR mitigates semantic bias and improves retrieval performance. Experiments on three standard CIR benchmarks show that SDR-CIR achieves state-of-the-art results among one-stage methods while maintaining high efficiency. The code is publicly available at https://github.com/suny105/SDR-CIR.

</details>


### [6] [DOS: Dual-Flow Orthogonal Semantic IDs for Recommendation in Meituan](https://arxiv.org/abs/2602.04460)
*Junwei Yin,Senjie Kou,Changhao Li,Shuli Wang,Xue Wei,Yinqiu Huang,Yinhua Zhu,Haitao Wang,Xingxing Wang*

Main category: cs.IR

TL;DR: 提出DOS方法解决语义ID在生成推荐系统中的两个主要问题：上下文感知不足导致语义ID码本空间与生成空间不匹配，以及次优量化方法加剧LLM语义损失。


<details>
  <summary>Details</summary>
Motivation: 现有语义ID方法存在两个主要局限：1) 生成任务缺乏上下文感知，导致语义ID码本空间与生成空间存在差距，产生次优推荐；2) 次优的量化方法加剧了LLM的语义损失。

Method: 提出双流正交语义ID（DOS）方法：1) 采用用户-物品双流框架，利用协同信号对齐语义ID码本空间与生成空间；2) 引入正交残差量化方案，将语义空间旋转到适当方向以最大化语义保留。

Result: 通过大量离线实验和在线A/B测试证明了DOS的有效性，该方法已在美团移动应用中成功部署，为数亿用户提供服务。

Conclusion: DOS方法通过双流框架和正交量化有效解决了语义ID在生成推荐系统中的关键问题，实现了语义空间与生成空间的对齐以及语义损失的最小化。

Abstract: Semantic IDs serve as a key component in generative recommendation systems. They not only incorporate open-world knowledge from large language models (LLMs) but also compress the semantic space to reduce generation difficulty. However, existing methods suffer from two major limitations: (1) the lack of contextual awareness in generation tasks leads to a gap between the Semantic ID codebook space and the generation space, resulting in suboptimal recommendations; and (2) suboptimal quantization methods exacerbate semantic loss in LLMs. To address these issues, we propose Dual-Flow Orthogonal Semantic IDs (DOS) method. Specifically, DOS employs a user-item dual flow-framework that leverages collaborative signals to align the Semantic ID codebook space with the generation space. Furthermore, we introduce an orthogonal residual quantization scheme that rotates the semantic space to an appropriate orientation, thereby maximizing semantic preservation. Extensive offline experiments and online A/B testing demonstrate the effectiveness of DOS. The proposed method has been successfully deployed in Meituan's mobile application, serving hundreds of millions of users.

</details>


### [7] [VK-LSVD: A Large-Scale Industrial Dataset for Short-Video Recommendation](https://arxiv.org/abs/2602.04567)
*Aleksandr Poslavsky,Alexander D'yakonov,Yuriy Dorn,Andrey Zimovnov*

Main category: cs.IR

TL;DR: 该论文介绍了VK-LSVD，这是目前最大的公开短视频推荐工业数据集，包含400亿次交互、1000万用户和2000万视频，旨在解决该领域缺乏大规模真实数据集的问题。


<details>
  <summary>Details</summary>
Motivation: 短视频推荐面临独特挑战，如从隐式反馈中建模快速变化的用户兴趣，但该领域进展受到缺乏反映真实平台动态的大规模开放数据集的限制。

Method: 通过收集VK平台的实际数据构建VK-LSVD数据集，包含超过400亿次交互、1000万用户和近2000万视频的6个月数据，并提供丰富特征包括内容嵌入、多样化反馈信号和上下文元数据。

Result: 数据集分析证实了其质量和多样性，并已立即应用于VK RecSys Challenge 2025竞赛中，成为该领域的核心基准数据集。

Conclusion: VK-LSVD为构建真实基准提供了重要的开放数据集，将加速序列推荐、冷启动场景和下一代推荐系统的研究进展。

Abstract: Short-video recommendation presents unique challenges, such as modeling rapid user interest shifts from implicit feedback, but progress is constrained by a lack of large-scale open datasets that reflect real-world platform dynamics. To bridge this gap, we introduce the VK Large Short-Video Dataset (VK-LSVD), the largest publicly available industrial dataset of its kind. VK-LSVD offers an unprecedented scale of over 40 billion interactions from 10 million users and almost 20 million videos over six months, alongside rich features including content embeddings, diverse feedback signals, and contextual metadata. Our analysis supports the dataset's quality and diversity. The dataset's immediate impact is confirmed by its central role in the live VK RecSys Challenge 2025. VK-LSVD provides a vital, open dataset to use in building realistic benchmarks to accelerate research in sequential recommendation, cold-start scenarios, and next-generation recommender systems.

</details>


### [8] [AIANO: Enhancing Information Retrieval with AI-Augmented Annotation](https://arxiv.org/abs/2602.04579)
*Sameh Khattab,Marie Bauer,Lukas Heine,Till Rostalski,Jens Kleesiek,Julian Friedrich*

Main category: cs.IR

TL;DR: AIANO是一个专门用于信息检索数据集标注的工具，采用AI增强的工作流程，将人类专业知识与LLM辅助紧密结合，相比基线工具将标注速度提高近一倍。


<details>
  <summary>Details</summary>
Motivation: 随着LLM和RAG的兴起，对高质量、精心策划的信息检索数据集的需求迅速增长。然而，目前这些数据集使用现成的标注工具创建，使得标注过程复杂且低效。

Method: 开发了专门的标注工具AIANO，采用AI增强的标注工作流程，紧密集成人类专业知识与LLM辅助，使标注者能够利用AI建议同时保持对标注决策的完全控制。

Result: 在15名参与者的用户研究中，AIANO相比基线工具将标注速度提高近一倍，同时更易于使用并提高了检索准确性。

Conclusion: AIANO的AI增强方法加速并增强了信息检索任务的数据集创建，推进了检索密集型领域的标注能力。

Abstract: The rise of Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) has rapidly increased the need for high-quality, curated information retrieval datasets. These datasets, however, are currently created with off-the-shelf annotation tools that make the annotation process complex and inefficient. To streamline this process, we developed a specialized annotation tool - AIANO. By adopting an AI-augmented annotation workflow that tightly integrates human expertise with LLM assistance, AIANO enables annotators to leverage AI suggestions while retaining full control over annotation decisions. In a within-subject user study ($n = 15$), participants created question-answering datasets using both a baseline tool and AIANO. AIANO nearly doubled annotation speed compared to the baseline while being easier to use and improving retrieval accuracy. These results demonstrate that AIANO's AI-augmented approach accelerates and enhances dataset creation for information retrieval tasks, advancing annotation capabilities in retrieval-intensive domains.

</details>


### [9] [Multi-Source Retrieval and Reasoning for Legal Sentencing Prediction](https://arxiv.org/abs/2602.04690)
*Junjie Chen,Haitao Li,Qilei Zhang,Zhenghua Li,Ya Zhang,Quan Zhou,Cheng Luo,Yiqun Liu,Dongsheng Guo,Qingyao Ai*

Main category: cs.IR

TL;DR: MSR²框架通过多源检索与强化学习增强LLMs在法律量刑预测中的表现，提升准确性和可解释性


<details>
  <summary>Details</summary>
Motivation: 法律量刑预测（LSP）相比法律条文和罪名预测更为困难，需要细粒度客观知识和灵活的主观推理，现有方法在这方面表现不佳

Method: 提出MSR²框架，结合多源检索与强化学习，让LLMs根据推理需求进行多源检索，并应用过程级奖励来指导中间主观推理步骤

Result: 在两个真实世界数据集上的实验表明，MSR²在法律量刑预测中同时提高了准确性和可解释性

Conclusion: MSR²为实用法律AI提供了有前景的一步，通过整合检索、推理和强化学习来应对法律量刑预测的挑战

Abstract: Legal judgment prediction (LJP) aims to predict judicial outcomes from case facts and typically includes law article, charge, and sentencing prediction. While recent methods perform well on the first two subtasks, legal sentencing prediction (LSP) remains difficult due to its need for fine-grained objective knowledge and flexible subjective reasoning. To address these limitations, we propose $MSR^2$, a framework that integrates multi-source retrieval and reasoning in LLMs with reinforcement learning. $MSR^2$ enables LLMs to perform multi-source retrieval based on reasoning needs and applies a process-level reward to guide intermediate subjective reasoning steps. Experiments on two real-world datasets show that $MSR^2$ improves both accuracy and interpretability in LSP, providing a promising step toward practical legal AI. Our code is available at https://anonymous.4open.science/r/MSR2-FC3B.

</details>


### [10] [Addressing Corpus Knowledge Poisoning Attacks on RAG Using Sparse Attention](https://arxiv.org/abs/2602.04711)
*Sagie Dekel,Moshe Tennenholtz,Oren Kurland*

Main category: cs.IR

TL;DR: SDAG提出一种稀疏文档注意力机制，通过阻止检索文档间的交叉注意力来防御RAG中的知识库中毒攻击，显著降低攻击成功率且无需微调。


<details>
  <summary>Details</summary>
Motivation: RAG虽然能保持LLM响应时效性并减少幻觉，但易受知识库中毒攻击（攻击者注入误导文档操控LLM输出）。标准因果注意力机制在攻击场景下会导致有害的跨文档交互。

Method: 提出SDAG（稀疏文档注意力RAG），采用块稀疏注意力机制，禁止检索文档间的交叉注意力。仅需在推理时修改注意力掩码，无需微调或架构改动。

Result: 在多种攻击策略下的LLM问答评估中，SDAG在攻击成功率方面显著优于标准因果注意力机制。与现有最佳RAG防御方法结合后，性能在统计上显著更优。

Conclusion: SDAG通过简单的注意力掩码修改有效防御RAG知识库中毒攻击，无需额外训练成本，且与现有防御方法兼容，能显著提升RAG系统的安全性。

Abstract: Retrieval Augmented Generation (RAG) is a highly effective paradigm for keeping LLM-based responses up-to-date and reducing the likelihood of hallucinations. Yet, RAG was recently shown to be quite vulnerable to corpus knowledge poisoning: an attacker injects misleading documents to the corpus to steer an LLMs' output to an undesired response. We argue that the standard causal attention mechanism in LLMs enables harmful cross-document interactions, specifically in cases of attacks. Accordingly, we introduce a novel defense approach for RAG: Sparse Document Attention RAG (SDAG). This is a block-sparse attention mechanism that disallows cross-attention between retrieved documents. SDAG requires a minimal inference-time change to the attention mask; furthermore, no fine-tuning or additional architectural changes are needed. We present an empirical evaluation of LLM-based question answering (QA) with a variety of attack strategies on RAG. We show that our SDAG method substantially outperforms the standard causal attention mechanism in terms of attack success rate. We further demonstrate the clear merits of integrating SDAG with state-of-the-art RAG defense methods. Specifically, the integration results in performance that is statistically significantly better than the state-of-the-art.

</details>
