<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 18]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [MTFM: A Scalable and Alignment-free Foundation Model for Industrial Recommendation in Meituan](https://arxiv.org/abs/2602.11235)
*Xin Song,Zhilin Guan,Ruidong Han,Binghao Tang,Tianwen Chen,Bing Li,Zihao Li,Han Zhang,Fei Jiang,Chaolin Xie,Chi Ma,Chunyang Jiang,Chunzhen Jing,Dengxuan Li,Fengyi Li,Lei Yu,Mengyao Sun,Pu Wang,Qing Wang,Rui Fan,Shangyu Chen,Shifeng Du,Siyuan Bai,Wei Lin,Wentao Zhu,Zhou Han,Zhuo Chen,Zikang Xu*

Main category: cs.IR

TL;DR: MTFM是一个基于Transformer的美团推荐基础模型，通过异构令牌转换、多场景用户级样本聚合、分组查询注意力等技术，解决了跨域多场景推荐中的资源消耗和输入对齐问题。


<details>
  <summary>Details</summary>
Motivation: 工业推荐系统通常涉及多个场景，但现有的跨域和多场景方法需要大量资源且要求严格的输入对齐，限制了其可扩展性。需要一种更高效、对齐自由的方法来捕获多场景知识。

Method: 1. 将跨域数据转换为异构令牌，以对齐自由的方式捕获多场景知识；2. 引入多场景用户级样本聚合，减少实例总数提升训练吞吐量；3. 集成分组查询注意力和定制化混合目标注意力，降低内存使用和计算复杂度；4. 系统级优化如内核融合和消除CPU-GPU阻塞。

Result: 离线和在线实验验证了MTFM的有效性，通过扩展模型容量和多场景训练数据实现了显著的性能提升。

Conclusion: MTFM提供了一个高效的跨域多场景推荐框架，通过技术创新解决了资源消耗和输入对齐的限制，为工业推荐系统提供了可扩展的解决方案。

Abstract: Industrial recommendation systems typically involve multiple scenarios, yet existing cross-domain (CDR) and multi-scenario (MSR) methods often require prohibitive resources and strict input alignment, limiting their extensibility. We propose MTFM (Meituan Foundation Model for Recommendation), a transformer-based framework that addresses these challenges. Instead of pre-aligning inputs, MTFM transforms cross-domain data into heterogeneous tokens, capturing multi-scenario knowledge in an alignment-free manner. To enhance efficiency, we first introduce a multi-scenario user-level sample aggregation that significantly enhances training throughput by reducing the total number of instances. We further integrate Grouped-Query Attention and a customized Hybrid Target Attention to minimize memory usage and computational complexity. Furthermore, we implement various system-level optimizations, such as kernel fusion and the elimination of CPU-GPU blocking, to further enhance both training and inference throughput. Offline and online experiments validate the effectiveness of MTFM, demonstrating that significant performance gains are achieved by scaling both model capacity and multi-scenario training data.

</details>


### [2] [From Noise to Order: Learning to Rank via Denoising Diffusion](https://arxiv.org/abs/2602.11453)
*Sajad Ebrahimi,Bhaskar Mitra,Negar Arabzadeh,Ye Yuan,Haolun Wu,Fattane Zarrinkalam,Ebrahim Bagheri*

Main category: cs.IR

TL;DR: 本文提出DiffusionRank，一种基于去噪扩散的深度生成式学习排序方法，替代传统的判别式方法，通过建模特征向量和相关性标签的联合分布来提升排序模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统学习排序方法局限于判别式机器学习，只建模文档相关性概率。作者认为生成式方法能建模完整数据分布，可能产生更鲁棒的排序模型，因为过度参数化的判别模型可能以不同方式拟合训练数据，而生成式方法需要解释完整数据分布。

Method: 提出DiffusionRank，扩展TabDiff（基于去噪扩散的表格数据生成模型），创建生成式等价于经典判别式点对和成对学习排序目标。该方法建模特征向量和相关性标签的联合分布。

Result: 实验结果显示DiffusionRank模型相比其判别式对应方法有显著改进，证明了生成式方法在学习排序任务中的有效性。

Conclusion: 这项工作为未来研究开辟了丰富空间，展示了如何利用深度生成建模方法（如扩散模型）来改进信息检索中的学习排序任务。

Abstract: In information retrieval (IR), learning-to-rank (LTR) methods have traditionally limited themselves to discriminative machine learning approaches that model the probability of the document being relevant to the query given some feature representation of the query-document pair. In this work, we propose an alternative denoising diffusion-based deep generative approach to LTR that instead models the full joint distribution over feature vectors and relevance labels. While in the discriminative setting, an over-parameterized ranking model may find different ways to fit the training data, we hypothesize that candidate solutions that can explain the full data distribution under the generative setting produce more robust ranking models. With this motivation, we propose DiffusionRank that extends TabDiff, an existing denoising diffusion-based generative model for tabular datasets, to create generative equivalents of classical discriminative pointwise and pairwise LTR objectives. Our empirical results demonstrate significant improvements from DiffusionRank models over their discriminative counterparts. Our work points to a rich space for future research exploration on how we can leverage ongoing advancements in deep generative modeling approaches, such as diffusion, for learning-to-rank in IR.

</details>


### [3] [KuaiSearch: A Large-Scale E-Commerce Search Dataset for Recall, Ranking, and Relevance](https://arxiv.org/abs/2602.11518)
*Yupeng Li,Ben Chen,Mingyue Cheng,Zhiding Liu,Xuxin Zhang,Chenyi Lei,Wenwu Ou*

Main category: cs.IR

TL;DR: KuaiSearch是当前最大的电商搜索数据集，基于快手平台真实用户搜索交互构建，覆盖冷启动用户和长尾商品，涵盖召回、排序、相关性判断三个搜索阶段。


<details>
  <summary>Details</summary>
Motivation: 现有电商搜索数据集存在多个局限：查询通常是启发式构建的、过滤了冷启动用户和长尾商品、查询和商品文本被匿名化、大多只覆盖单一搜索阶段，这些限制了基于LLM的电商搜索研究。

Method: 基于快手平台真实用户搜索交互构建数据集，保留真实用户查询和自然语言商品文本，覆盖冷启动用户和长尾商品，系统性地涵盖召回、排序、相关性判断三个搜索阶段。

Result: 构建了当前最大的电商搜索数据集KuaiSearch，从商品、用户、查询等多个角度进行全面分析，并在多个代表性搜索任务上建立了基准实验。

Conclusion: KuaiSearch为现实世界电商搜索研究提供了宝贵基础，实验结果表明该数据集具有重要价值。

Abstract: E-commerce search serves as a central interface, connecting user demands with massive product inventories and plays a vital role in our daily lives. However, in real-world applications, it faces challenges, including highly ambiguous queries, noisy product texts with weak semantic order, and diverse user preferences, all of which make it difficult to accurately capture user intent and fine-grained product semantics. In recent years, significant advances in large language models (LLMs) for semantic representation and contextual reasoning have created new opportunities to address these challenges. Nevertheless, existing e-commerce search datasets still suffer from notable limitations: queries are often heuristically constructed, cold-start users and long-tail products are filtered out, query and product texts are anonymized, and most datasets cover only a single stage of the search pipeline. Collectively, these issues constrain research on LLM-based e-commerce search. To address these challenges, we construct and release KuaiSearch. To the best of our knowledge, it is the largest e-commerce search dataset currently available. KuaiSearch is built upon real user search interactions from the Kuaishou platform, preserving authentic user queries and natural-language product texts, covering cold-start users and long-tail products, and systematically spanning three key stages of the search pipeline: recall, ranking, and relevance judgment. We conduct a comprehensive analysis of KuaiSearch from multiple perspectives, including products, users, and queries, and establish benchmark experiments across several representative search tasks. Experimental results demonstrate that KuaiSearch provides a valuable foundation for research on real-world e-commerce search.

</details>


### [4] [LASER: An Efficient Target-Aware Segmented Attention Framework for End-to-End Long Sequence Modeling](https://arxiv.org/abs/2602.11562)
*Tianhe Lin,Ziwei Xiong,Baoyuan Ou,Yingjie Qin,Lai Xu,Xiaocheng Zhong,Yao Hu,Zhiyong Wang,Tao Zhou,Yubin Xu,Di Wu*

Main category: cs.IR

TL;DR: LASER是一个全栈优化框架，通过系统效率（SeqVault混合存储）和算法效率（STA注意力机制）解决超长用户行为序列建模中的延迟瓶颈问题，在工业推荐系统中实现毫秒级访问和显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 工业推荐系统中建模超长用户行为序列面临严格的"延迟墙"挑战，包括检索海量用户历史的高I/O延迟和标准注意力机制的二次计算复杂度，这限制了实时部署能力。

Method: 1. 系统效率：SeqVault统一模式感知服务基础设施，采用DRAM-SSD混合索引策略，减少检索延迟和CPU使用率；2. 算法效率：Segmented Target Attention（STA）机制，通过sigmoid门控策略过滤噪声项，结合轻量级Global Stacked Target Attention（GSTA）模块捕获跨段依赖。

Result: SeqVault将检索延迟降低50%，CPU使用率降低75%；在线A/B测试中，LASER在服务超过1亿日活用户时，ADVV提升2.36%，收入提升2.08%，显示出显著的可扩展性和商业影响。

Conclusion: LASER通过系统与算法的协同优化，有效突破了超长用户行为序列建模的延迟瓶颈，实现了工业级实时部署，为推荐系统提供了可扩展的高效解决方案。

Abstract: Modeling ultra-long user behavior sequences is pivotal for capturing evolving and lifelong interests in modern recommendation systems. However, deploying such models in real-time industrial environments faces a strict "Latency Wall", constrained by two distinct bottlenecks: the high I/O latency of retrieving massive user histories and the quadratic computational complexity of standard attention mechanisms. To break these bottlenecks, we present LASER, a full-stack optimization framework developed and deployed at Xiaohongshu (RedNote). Our approach tackles the challenges through two complementary innovations: (1) System efficiency: We introduce SeqVault, a unified schema-aware serving infrastructure for long user histories. By implementing a hybrid DRAM-SSD indexing strategy, SeqVault reduces retrieval latency by 50% and CPU usage by 75%, ensuring millisecond-level access to full real-time and life-cycle user histories. (2) Algorithmic efficiency: We propose a Segmented Target Attention (STA) mechanism to address the computational overhead. Motivated by the inherent sparsity of user interests, STA employs a sigmoid-based gating strategy that acts as a silence mechanism to filter out noisy items. Subsequently, a lightweight Global Stacked Target Attention (GSTA) module refines these compressed segments to capture cross-segment dependencies without incurring high computational costs. This design performs effective sequence compression, reducing the complexity of long-sequence modeling while preserving critical signals. Extensive offline evaluations demonstrate that LASER consistently outperforms state-of-the-art baselines. In large-scale online A/B testing serving over 100 million daily active users, LASER achieved a 2.36% lift in ADVV and a 2.08% lift in revenue, demonstrating its scalability and significant commercial impact.

</details>


### [5] [Analytical Search](https://arxiv.org/abs/2602.11581)
*Yiteng Tu,Shuo Miao,Weihang Su,Yiqun Liu,Qingyao Ai*

Main category: cs.IR

TL;DR: 该论文提出"分析式搜索"作为新兴搜索范式，旨在满足跨领域的分析性信息需求，强调证据驱动、过程导向的分析工作流，以解决现有搜索系统在支持趋势分析、因果影响评估等复杂分析任务时的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有信息检索范式（基于相关性文档排序或RAG增强生成）难以满足分析性信息需求的端到端要求。这些系统要么侧重信息查找而非问题解决，要么简单视为问答任务，缺乏对推理过程、证据使用和可验证性的控制，无法支持具有多样化效用概念和高问责要求的分析查询。

Method: 提出分析式搜索作为新兴搜索范式，将其重新定义为证据治理、过程导向的分析工作流。该框架明确建模分析意图，检索证据进行融合，并通过结构化、多步推理产生可验证结论。系统框架整合了查询理解、面向召回率的检索、推理感知融合和自适应验证。

Result: 论文提出了分析式搜索的统一系统框架，并讨论了构建分析式搜索引擎的潜在研究方向。通过对比现有搜索范式，突出了分析式搜索的概念意义和实践重要性。

Conclusion: 分析式搜索代表了满足分析性信息需求的下一代搜索引擎发展方向，呼吁学术界和工业界共同努力构建支持复杂分析任务的搜索系统。

Abstract: Analytical information needs, such as trend analysis and causal impact assessment, are prevalent across various domains including law, finance, science, and much more. However, existing information retrieval paradigms, whether based on relevance-oriented document ranking or retrieval-augmented generation (RAG) with large language models (LLMs), often struggle to meet the end-to-end requirements of such tasks at the corpus scale. They either emphasize information finding rather than end-to-end problem solving, or simply treat everything as naive question answering, offering limited control over reasoning, evidence usage, and verifiability. As a result, they struggle to support analytical queries that have diverse utility concepts and high accountability requirements.
  In this paper, we propose analytical search as a distinct and emerging search paradigm designed to fulfill these analytical information needs. Analytical search reframes search as an evidence-governed, process-oriented analytical workflow that explicitly models analytical intent, retrieves evidence for fusion, and produces verifiable conclusions through structured, multi-step inference. We position analytical search in contrast to existing paradigms, and present a unified system framework that integrates query understanding, recall-oriented retrieval, reasoning-aware fusion, and adaptive verification. We also discuss potential research directions for the construction of analytical search engines. In this way, we highlight the conceptual significance and practical importance of analytical search and call on efforts toward the next generation of search engines that support analytical information needs.

</details>


### [6] [Recurrent Preference Memory for Efficient Long-Sequence Generative Recommendation](https://arxiv.org/abs/2602.11605)
*Yixiao Chen,Yuan Wang,Yue Liu,Qiyao Wang,Ke Cheng,Xin Xu,Juntong Yan,Shuojin Yang,Menghao Guo,Jun Zhang,Huan Yu,Jie Jiang*

Main category: cs.IR

TL;DR: Rec2PM框架通过将长用户交互历史压缩为紧凑的偏好记忆token，解决了生成式推荐模型在终身序列上的计算成本和噪声积累问题，实现了高效并行训练和推理。


<details>
  <summary>Details</summary>
Motivation: 生成式推荐模型通常使用完整注意力建模用户行为，但在处理终身序列时面临计算成本过高和随机交互噪声积累的挑战，需要更高效的序列压缩方法。

Method: 提出Rec2PM框架，将长用户交互历史压缩为紧凑的偏好记忆token；采用自参照教师强制策略，利用历史全局视图生成参考记忆作为监督目标，实现并行化循环更新；将记忆表示为token嵌入而非KV缓存，提高存储效率。

Result: 在大规模基准测试中，Rec2PM显著降低了推理延迟和内存占用，同时比完整序列模型获得了更高的准确性；分析表明偏好记忆起到了去噪信息瓶颈的作用，有效过滤交互噪声并捕捉稳健的长期兴趣。

Conclusion: Rec2PM通过创新的记忆压缩和并行训练策略，成功解决了生成式推荐模型在长序列处理中的效率和噪声问题，为大规模推荐系统提供了实用的解决方案。

Abstract: Generative recommendation (GenRec) models typically model user behavior via full attention, but scaling to lifelong sequences is hindered by prohibitive computational costs and noise accumulation from stochastic interactions. To address these challenges, we introduce Rec2PM, a framework that compresses long user interaction histories into compact Preference Memory tokens. Unlike traditional recurrent methods that suffer from serial training, Rec2PM employs a novel self-referential teacher-forcing strategy: it leverages a global view of the history to generate reference memories, which serve as supervision targets for parallelized recurrent updates. This allows for fully parallel training while maintaining the capability for iterative updates during inference. Additionally, by representing memory as token embeddings rather than extensive KV caches, Rec2PM achieves extreme storage efficiency. Experiments on large-scale benchmarks show that Rec2PM significantly reduces inference latency and memory footprint while achieving superior accuracy compared to full-sequence models. Analysis reveals that the Preference Memory functions as a denoising Information Bottleneck, effectively filtering interaction noise to capture robust long-term interests.

</details>


### [7] [Evolutionary Router Feature Generation for Zero-Shot Graph Anomaly Detection with Mixture-of-Experts](https://arxiv.org/abs/2602.11622)
*Haiyang Jiang,Tong Chen,Xinyi Gao,Guansong Pang,Quoc Viet Hung Nguyen,Hongzhi Yin*

Main category: cs.IR

TL;DR: 提出EvoFG框架，通过进化特征生成和记忆增强路由器解决零样本图异常检测中的分布偏移问题


<details>
  <summary>Details</summary>
Motivation: 现有单GNN方法难以建模跨图的异构结构和异常模式，而混合专家架构在零样本图异常检测中受分布偏移限制，面临路由特征语义差异和领域不变性不足的挑战

Method: 提出进化特征生成方案，通过LLM生成器和Shapley引导评估迭代构建结构特征；设计记忆增强路由器，采用不变学习目标捕捉可迁移的路由模式

Result: 在六个基准测试中，EvoFG持续优于最先进基线，实现了强大且稳定的零样本图异常检测性能

Conclusion: EvoFG通过进化特征生成和不变学习有效解决了零样本图异常检测中的分布偏移问题，为混合专家架构在跨图异常检测中的应用提供了新思路

Abstract: Zero-shot graph anomaly detection (GAD) has attracted increasing attention recent years, yet the heterogeneity of graph structures, features, and anomaly patterns across graphs make existing single GNN methods insufficiently expressive to model diverse anomaly mechanisms. In this regard, Mixture-of-experts (MoE) architectures provide a promising paradigm by integrating diverse GNN experts with complementary inductive biases, yet their effectiveness in zero-shot GAD is severely constrained by distribution shifts, leading to two key routing challenges. First, nodes often carry vastly different semantics across graphs, and straightforwardly performing routing based on their features is prone to generating biased or suboptimal expert assignments. Second, as anomalous graphs often exhibit pronounced distributional discrepancies, existing router designs fall short in capturing domain-invariant routing principles that generalize beyond the training graphs. To address these challenges, we propose a novel MoE framework with evolutionary router feature generation (EvoFG) for zero-shot GAD. To enhance MoE routing, we propose an evolutionary feature generation scheme that iteratively constructs and selects informative structural features via an LLM-based generator and Shapley-guided evaluation. Moreover, a memory-enhanced router with an invariant learning objective is designed to capture transferable routing patterns under distribution shifts. Extensive experiments on six benchmarks show that EvoFG consistently outperforms state-of-the-art baselines, achieving strong and stable zero-shot GAD performance.

</details>


### [8] [IntTravel: A Real-World Dataset and Generative Framework for Integrated Multi-Task Travel Recommendation](https://arxiv.org/abs/2602.11664)
*Huimin Yan,Longfei Xu,Junjie Sun,Zheng Liu,Wei Luo,Kaikui Liu,Xiangxiang Chu*

Main category: cs.IR

TL;DR: IntTravel是一个大规模集成旅行推荐数据集和生成式多任务推荐框架，解决了现有POI推荐研究中数据集碎片化、任务单一的问题，在真实部署中提升了点击率。


<details>
  <summary>Details</summary>
Motivation: 当前POI推荐研究存在数据集碎片化、任务单一的问题，仅关注"去哪里"而忽略了出发时间、出行方式和途中需求等完整旅程要素，且数据集规模有限影响性能评估。

Method: 提出了IntTravel数据集（41亿次交互、1.63亿用户、730万POI）和基于此的端到端解码器生成式多任务推荐框架，采用信息保留、选择和分解技术平衡任务协作与专业化区分。

Result: 在IntTravel数据集和非旅行基准测试中都取得了最先进的性能，在Amap平台部署后为数亿用户服务，点击率提升了1.09%。

Conclusion: IntTravel填补了集成旅行推荐领域的数据集空白，其生成式多任务框架能有效处理旅程的多个方面，具有很好的泛化能力和实际应用价值。

Abstract: Next Point of Interest (POI) recommendation is essential for modern mobility and location-based services. To provide a smooth user experience, models must understand several components of a journey holistically: "when to depart", "how to travel", "where to go", and "what needs arise via the route". However, current research is limited by fragmented datasets that focus merely on next POI recommendation ("where to go"), neglecting the departure time, travel mode, and situational requirements along the journey. Furthermore, the limited scale of these datasets impedes accurate evaluation of performance. To bridge this gap, we introduce IntTravel, the first large-scale public dataset for integrated travel recommendation, including 4.1 billion interactions from 163 million users with 7.3 million POIs. Built upon this dataset, we introduce an end-to-end, decoder-only generative framework for multi-task recommendation. It incorporates information preservation, selection, and factorization to balance task collaboration with specialized differentiation, yielding substantial performance gains. The framework's generalizability is highlighted by its state-of-the-art performance across both IntTravel dataset and an additional non-travel benchmark. IntTravel has been successfully deployed on Amap serving hundreds of millions of users, leading to a 1.09% increase in CTR. IntTravel is available at https://github.com/AMAP-ML/IntTravel.

</details>


### [9] [EpicCBR: Item-Relation-Enhanced Dual-Scenario Contrastive Learning for Cold-Start Bundle Recommendation](https://arxiv.org/abs/2602.11680)
*Yihang Li,Zhuo Liu,Wei Wei*

Main category: cs.IR

TL;DR: EpicCBR是一个用于冷启动捆绑推荐的多视图对比学习框架，通过挖掘物品关系构建用户画像，利用流行度方法表征新捆绑特征，在冷启动场景下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有捆绑推荐模型主要依赖已观察到的用户-捆绑交互，难以处理不断涌现的新捆绑（冷启动问题）。这些方法通常将每个捆绑视为独立实例，未能充分利用用户-物品和捆绑-物品关系中的流行物品信息。

Method: 提出EpicCBR框架：1）通过挖掘物品关系构建用户画像，识别可能对捆绑感兴趣的用户；2）提出基于流行度的方法，通过历史捆绑信息和用户偏好表征新捆绑特征；3）引入多视图图对比学习框架，整合冷启动和热启动场景，确保模型泛化能力。

Result: 在三个流行基准测试上的广泛实验表明，EpicCBR显著优于现有最先进方法，在冷启动场景下性能提升高达387%，充分证明了该方法在冷启动场景下的优越性。

Conclusion: EpicCBR通过多视图对比学习有效解决了捆绑推荐中的冷启动问题，充分利用物品关系和流行度信息，在冷启动和热启动场景下都表现出强大的泛化能力。

Abstract: Bundle recommendation aims to recommend a set of items to users for overall consumption. Existing bundle recommendation models primarily depend on observed user-bundle interactions, limiting exploration of newly-emerged bundles that are constantly created. It pose a critical representation challenge for current bundle methods, as they usually treat each bundle as an independent instance, while neglecting to fully leverage the user-item (UI) and bundle-item (BI) relations over popular items. To alleviate it, in this paper we propose a multi-view contrastive learning framework for cold-start bundle recommendation, named EpicCBR. Specifically, it precisely mine and utilize the item relations to construct user profiles, identifying users likely to engage with bundles. Additionally, a popularity-based method that characterizes the features of new bundles through historical bundle information and user preferences is proposed. To build a framework that demonstrates robustness in both cold-start and warm-start scenarios, a multi-view graph contrastive learning framework capable of integrating these diverse scenarios is introduced to ensure the model's generalization capability. Extensive experiments conducted on three popular benchmarks showed that EpicCBR outperforms state-of-the-art by a large margin (up to 387%), sufficiently demonstrating the superiority of the proposed method in cold-start scenario. The code and dataset can be found in the GitHub repository: https://github.com/alexlovecoding/EpicCBR.

</details>


### [10] [Uncertainty-aware Generative Recommendation](https://arxiv.org/abs/2602.11719)
*Chenxiao Fan,Chongming Gao,Yaxin Gong,Haoyan Liu,Fuli Feng,Xiangnan He*

Main category: cs.IR

TL;DR: UGR提出不确定性感知生成推荐框架，通过不确定性加权奖励、难度感知优化和显式置信度对齐三个机制，解决现有生成推荐方法中的不确定性盲视问题，提升推荐性能和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有生成推荐方法依赖二元结果正确性，存在"不确定性盲视"问题：忽视模型内在生成置信度、忽略样本学习难度差异、缺乏显式置信度表达，导致训练不稳定和决策风险不可量化。

Method: 提出UGR统一框架，包含三个协同机制：1) 不确定性加权奖励机制，惩罚置信度高的错误；2) 难度感知优化动态，防止过早收敛；3) 显式置信度对齐，赋予模型置信度表达能力。

Result: 实验表明UGR不仅获得更优的推荐性能，而且从根本上稳定了训练过程，避免了标准方法中常见的性能下降。学习到的置信度还支持可靠的下游风险感知应用。

Conclusion: UGR通过将不确定性作为关键信号进行自适应优化，解决了生成推荐中的不确定性盲视问题，实现了更稳定、更可靠的推荐系统，为风险感知应用奠定了基础。

Abstract: Generative Recommendation has emerged as a transformative paradigm, reformulating recommendation as an end-to-end autoregressive sequence generation task. Despite its promise, existing preference optimization methods typically rely on binary outcome correctness, suffering from a systemic limitation we term uncertainty blindness. This issue manifests in the neglect of the model's intrinsic generation confidence, the variation in sample learning difficulty, and the lack of explicit confidence expression, directly leading to unstable training dynamics and unquantifiable decision risks. In this paper, we propose Uncertainty-aware Generative Recommendation (UGR), a unified framework that leverages uncertainty as a critical signal for adaptive optimization. UGR synergizes three mechanisms: (1) an uncertainty-weighted reward to penalize confident errors; (2) difficulty-aware optimization dynamics to prevent premature convergence; and (3) explicit confidence alignment to empower the model with confidence expression capabilities. Extensive experiments demonstrate that UGR not only yields superior recommendation performance but also fundamentally stabilizes training, preventing the performance degradation often observed in standard methods. Furthermore, the learned confidence enables reliable downstream risk-aware applications.

</details>


### [11] [ULTRA:Urdu Language Transformer-based Recommendation Architecture](https://arxiv.org/abs/2602.11836)
*Alishbah Bashir,Fatima Qaiser,Ijaz Hussain*

Main category: cs.IR

TL;DR: ULTRA是一个针对乌尔都语的语义内容推荐框架，采用双嵌入架构和查询长度感知路由机制，动态区分短查询和长查询，通过专门的语义管道优化推荐效果。


<details>
  <summary>Details</summary>
Motivation: 乌尔都语作为低资源语言，缺乏有效的语义内容推荐系统。现有方法主要依赖词汇匹配或语言无关技术，难以捕捉语义意图，在不同查询长度和信息需求下表现不佳，导致推荐相关性和适应性降低。

Method: 提出ULTRA框架，采用双嵌入架构和查询长度感知路由机制。基于阈值驱动的决策过程，用户查询被路由到专门优化的语义管道：针对标题/标题级别或完整内容/文档级别的表示。利用基于Transformer的嵌入和优化的池化策略，实现超越表面关键词匹配的上下文感知相似性搜索。

Result: 在大规模乌尔都语新闻语料库上的实验表明，该架构在不同查询类型上持续提高推荐相关性。与单管道基线相比，精确度提升超过90%，证明了查询自适应语义对齐对低资源语言的有效性。

Conclusion: ULTRA是一个稳健且可推广的内容推荐架构，为低资源语言环境下的语义检索系统提供了实用的设计见解。

Abstract: Urdu, as a low-resource language, lacks effective semantic content recommendation systems, particularly in the domain of personalized news retrieval. Existing approaches largely rely on lexical matching or language-agnostic techniques, which struggle to capture semantic intent and perform poorly under varying query lengths and information needs. This limitation results in reduced relevance and adaptability in Urdu content recommendation. We propose ULTRA (Urdu Language Transformer-based Recommendation Architecture),an adaptive semantic recommendation framework designed to address these challenges. ULTRA introduces a dual-embedding architecture with a query-length aware routing mechanism that dynamically distinguishes between short, intent-focused queries and longer, context-rich queries. Based on a threshold-driven decision process, user queries are routed to specialized semantic pipelines optimized for either title/headline-level or full-content/document level representations, ensuring appropriate semantic granularity during retrieval. The proposed system leverages transformer-based embeddings and optimized pooling strategies to move beyond surface-level keyword matching and enable context-aware similarity search. Extensive experiments conducted on a large-scale Urdu news corpus demonstrate that the proposed architecture consistently improves recommendation relevance across diverse query types. Results show gains in precision above 90% compared to single-pipeline baselines, highlighting the effectiveness of query-adaptive semantic alignment for low-resource languages. The findings establish ULTRA as a robust and generalizable content recommendation architecture, offering practical design insights for semantic retrieval systems in low-resource language settings.

</details>


### [12] [Improving Neural Retrieval with Attribution-Guided Query Rewriting](https://arxiv.org/abs/2602.11841)
*Moncef Garouani,Josiane Mothe*

Main category: cs.IR

TL;DR: 提出基于归因引导的查询重写方法，利用检索器的梯度归因分数指导LLM重写查询，解决神经检索器对模糊查询的脆弱性问题


<details>
  <summary>Details</summary>
Motivation: 神经检索器虽然有效但脆弱：当查询表述不明确或模糊时，即使存在相关文档也可能导致检索失败。现有方法仅部分解决此问题：LLM重写查询时缺乏检索器反馈，可解释性方法仅用于事后分析

Method: 提出归因引导的查询重写方法：1) 为每个查询计算检索器的梯度归因分数（token-level attributions）；2) 将这些分数作为软指导构建结构化提示；3) 使用LLM基于此提示重写查询，澄清弱或误导性查询成分同时保持原始意图

Result: 在BEIR数据集上评估，该方法生成的查询重写持续提升检索效果，优于现有基线方法，对于隐含或模糊信息需求的查询提升效果更显著

Conclusion: 通过将检索器的梯度归因反馈整合到查询重写过程中，有效解决了神经检索器对模糊查询的脆弱性问题，实现了可解释性方法与查询重写的闭环整合

Abstract: Neural retrievers are effective but brittle: underspecified or ambiguous queries can misdirect ranking even when relevant documents exist. Existing approaches address this brittleness only partially: LLMs rewrite queries without retriever feedback, and explainability methods identify misleading tokens but are used for post-hoc analysis. We close this loop and propose an attribution-guided query rewriting method that uses token-level explanations to guide query rewriting. For each query, we compute gradient-based token attributions from the retriever and then use these scores as soft guidance in a structured prompt to an LLM that clarifies weak or misleading query components while preserving intent. Evaluated on BEIR collections, the resulting rewrites consistently improve retrieval effectiveness over strong baselines, with larger gains for implicit or ambiguous information needs.

</details>


### [13] [Efficient Crawling for Scalable Web Data Acquisition (Extended Version)](https://arxiv.org/abs/2602.11874)
*Antoine Gauquier,Ioana Manolescu,Pierre Senellart*

Main category: cs.IR

TL;DR: 提出基于强化学习的SB-CLASSIFIER爬虫算法，高效获取网站中的统计数据资源，仅爬取少量网页即可获取大部分目标资源


<details>
  <summary>Details</summary>
Motivation: 新闻报道事实核查和社会经济研究需要高质量的统计数据，但大规模获取统计数据资源通常困难、低效或不可能，因为数据发布方式多样。需要改进开放统计数据可访问性。

Method: 提出基于强化学习的专注网络爬虫算法，使用sleeping bandits方法。SB-CLASSIFIER通过学习哪些超链接能导向包含大量目标资源的页面，基于链接所在网页的路径信息进行决策。

Result: 在包含数百万网页的网站上实验表明，该爬虫高度高效，仅爬取网站的一小部分就能获取大部分目标资源。

Conclusion: 该研究提出的强化学习方法有效解决了统计数据资源获取的效率问题，通过智能选择爬取路径，显著提高了开放统计数据可访问性。

Abstract: Journalistic fact-checking, as well as social or economic research, require analyzing high-quality statistics datasets (SDs, in short). However, retrieving SD corpora at scale may be hard, inefficient, or impossible, depending on how they are published online. To improve open statistics data accessibility, we present a focused Web crawling algorithm that retrieves as many targets, i.e., resources of certain types, as possible, from a given website, in an efficient and scalable way, by crawling (much) less than the full website. We show that optimally solving this problem is intractable, and propose an approach based on reinforcement learning, namely using sleeping bandits. We propose SB-CLASSIFIER, a crawler that efficiently learns which hyperlinks lead to pages that link to many targets, based on the paths leading to the links in their enclosing webpages. Our experiments on websites with millions of webpages show that our crawler is highly efficient, delivering high fractions of a site's targets while crawling only a small part.

</details>


### [14] [IncompeBench: A Permissively Licensed, Fine-Grained Benchmark for Music Information Retrieval](https://arxiv.org/abs/2602.11941)
*Benjamin Clavié,Atoof Shakir,Jonah Turner,Sean Lee,Aamir Shakir,Makoto P. Kato*

Main category: cs.IR

TL;DR: IncompeBench是一个高质量的音乐信息检索基准数据集，包含1,574个音乐片段、500个多样化查询和超过125,000个相关性标注。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态信息检索和音乐信息检索取得了显著进展，但缺乏高质量的音乐检索评估基准。现有基准在质量、多样性和标注一致性方面存在不足。

Method: 通过多阶段标注流程创建基准，包括1,574个许可开放的高质量音乐片段、500个多样化查询，并生成超过125,000个人工相关性标注，确保标注者间高度一致。

Result: 创建了IncompeBench基准数据集，提供严格和宽松两个版本，公开在Hugging Face和GitHub上，为音乐信息检索提供可靠的评估工具。

Conclusion: IncompeBench填补了音乐信息检索领域高质量基准的空白，为未来研究提供了标准化评估框架，促进音乐检索技术的发展。

Abstract: Multimodal Information Retrieval has made significant progress in recent years, leveraging the increasingly strong multimodal abilities of deep pre-trained models to represent information across modalities. Music Information Retrieval (MIR), in particular, has considerably increased in quality, with neural representations of music even making its way into everyday life products. However, there is a lack of high-quality benchmarks for evaluating music retrieval performance. To address this issue, we introduce \textbf{IncompeBench}, a carefully annotated benchmark comprising $1,574$ permissively licensed, high-quality music snippets, $500$ diverse queries, and over $125,000$ individual relevance judgements. These annotations were created through the use of a multi-stage pipeline, resulting in high agreement between human annotators and the generated data. The resulting datasets are publicly available at https://huggingface.co/datasets/mixedbread-ai/incompebench-strict and https://huggingface.co/datasets/mixedbread-ai/incompebench-lenient with the prompts available at https://github.com/mixedbread-ai/incompebench-programs.

</details>


### [15] [Compress, Cross and Scale: Multi-Level Compression Cross Networks for Efficient Scaling in Recommender Systems](https://arxiv.org/abs/2602.12041)
*Heng Yu,Xiangjun Zhou,Jie Xia,Heng Zhao,Anxin Wu,Yu Zhao,Dongying Kong*

Main category: cs.IR

TL;DR: MLCC是一种结构化特征交互架构，通过分层压缩和动态组合高效捕获高阶特征依赖，其多通道扩展MC-MLCC通过并行子空间分解实现高效水平扩展，在保持高性能的同时大幅减少参数和计算量。


<details>
  <summary>Details</summary>
Motivation: 现代推荐系统中，现有交互模块难以同时实现强交互能力、高计算效率和良好可扩展性，导致在严格生产约束下模型扩展的投资回报率有限。

Method: 提出MLCC架构，通过分层压缩和动态组合组织特征交叉；进一步提出MC-MLCC多通道扩展，将特征交互分解到并行子空间，实现高效水平扩展。

Result: 在三个公开基准和工业数据集上，模型比DLRM基线提升最多0.52 AUC，同时减少最多26倍参数和FLOPs；通道扩展比传统嵌入膨胀效率更高；在线A/B测试验证了实际有效性。

Conclusion: MLCC和MC-MLCC能够高效捕获高阶特征交互，在严格延迟和资源约束下实现更好的性能-效率权衡，已在B站广告系统中广泛应用。

Abstract: Modeling high-order feature interactions efficiently is a central challenge in click-through rate and conversion rate prediction. Modern industrial recommender systems are predominantly built upon deep learning recommendation models, where the interaction backbone plays a critical role in determining both predictive performance and system efficiency. However, existing interaction modules often struggle to simultaneously achieve strong interaction capacity, high computational efficiency, and good scalability, resulting in limited ROI when models are scaled under strict production constraints. In this work, we propose MLCC, a structured feature interaction architecture that organizes feature crosses through hierarchical compression and dynamic composition, which can efficiently capture high-order feature dependencies while maintaining favorable computational complexity. We further introduce MC-MLCC, a Multi-Channel extension that decomposes feature interactions into parallel subspaces, enabling efficient horizontal scaling with improved representation capacity and significantly reduced parameter growth. Extensive experiments on three public benchmarks and a large-scale industrial dataset show that our proposed models consistently outperform strong DLRM-style baselines by up to 0.52 AUC, while reducing model parameters and FLOPs by up to 26$\times$ under comparable performance. Comprehensive scaling analyses demonstrate stable and predictable scaling behavior across embedding dimension, head number, and channel count, with channel-based scaling achieving substantially better efficiency than conventional embedding inflation. Finally, online A/B testing on a real-world advertising platform validates the practical effectiveness of our approach, which has been widely adopted in Bilibili advertising system under strict latency and resource constraints.

</details>


### [16] [Towards Personalized Bangla Book Recommendation: A Large-Scale Multi-Entity Book Graph Dataset](https://arxiv.org/abs/2602.12129)
*Rahin Arefin Ahmed,Md. Anik Chowdhury,Sakil Ahmed Sheikh Reza,Devnil Bhattacharjee,Muhammad Abdullah Adnan,Nafis Sadeq*

Main category: cs.IR

TL;DR: 提出了RokomariBG，一个大规模孟加拉语图书推荐数据集，包含12.7万本书、6.3万用户等实体，并进行了系统基准测试，神经检索模型表现最佳


<details>
  <summary>Details</summary>
Motivation: 孟加拉语文学领域的个性化图书推荐研究受到缺乏结构化、大规模公开数据集的限制，需要为低资源语言环境提供基础数据集

Method: 构建了RokomariBG数据集，包含书籍、用户、作者、类别、出版商、评论等多实体异构图，包含8种关系类型。使用多种推荐模型进行基准测试，包括协同过滤、矩阵分解、基于内容的方法、图神经网络、混合模型和神经双塔检索架构

Result: 神经检索模型在Top-N推荐任务中表现最佳（NDCG@10 = 0.204），利用多关系结构和文本侧信息对提升推荐性能很重要。建立了孟加拉语图书推荐研究的基础基准

Conclusion: 该工作为孟加拉语图书推荐研究提供了公开可用的基础资源，支持可重复评估和未来在低资源文化领域的推荐研究，数据集和代码已公开

Abstract: Personalized book recommendation in Bangla literature has been constrained by the lack of structured, large-scale, and publicly available datasets. This work introduces RokomariBG, a large-scale, multi-entity heterogeneous book graph dataset designed to support research on personalized recommendation in a low-resource language setting. The dataset comprises 127,302 books, 63,723 users, 16,601 authors, 1,515 categories, 2,757 publishers, and 209,602 reviews, connected through eight relation types and organized as a comprehensive knowledge graph.
  To demonstrate the utility of the dataset, we provide a systematic benchmarking study on the Top-N recommendation task, evaluating a diverse set of representative recommendation models, including classical collaborative filtering methods, matrix factorization models, content-based approaches, graph neural networks, a hybrid matrix factorization model with side information, and a neural two-tower retrieval architecture. The benchmarking results highlight the importance of leveraging multi-relational structure and textual side information, with neural retrieval models achieving the strongest performance (NDCG@10 = 0.204). Overall, this work establishes a foundational benchmark and a publicly available resource for Bangla book recommendation research, enabling reproducible evaluation and future studies on recommendation in low-resource cultural domains. The dataset and code are publicly available at https://github.com/backlashblitz/Bangla-Book-Recommendation-Dataset

</details>


### [17] [SAGEO Arena: A Realistic Environment for Evaluating Search-Augmented Generative Engine Optimization](https://arxiv.org/abs/2602.12187)
*Sunghwan Kim,Wooseok Jeong,Serin Kim,Sangam Lee,Dongha Lee*

Main category: cs.IR

TL;DR: SAGEO Arena：首个用于搜索增强生成引擎优化（SAGEO）的端到端评估环境，整合检索、重排序和生成全流程，支持包含结构化信息的真实网页文档优化评估。


<details>
  <summary>Details</summary>
Motivation: 现有SAGEO评估环境存在三大缺陷：1）缺乏端到端可见性评估，仅基于预选文档；2）忽略检索和重排序环节；3）丢弃网页文档的结构化信息（如schema标记）。这些限制使得现有方法在真实条件下不实用。

Method: 提出SAGEO Arena评估环境，整合完整的生成式搜索流水线，基于包含丰富结构化信息的大规模网页文档语料库，支持分阶段的SAGEO分析，同时针对搜索优化（SEO）和生成优化（GEO）。

Result: 研究发现：1）现有方法在真实条件下大多不实用，常损害检索和重排序性能；2）结构化信息有助于缓解这些限制；3）有效的SAGEO需要针对流水线每个阶段进行定制化优化。

Conclusion: SAGEO Arena为超越简化设置的现实SAGEO评估和优化铺平道路，揭示了结构化信息的重要性以及分阶段优化策略的必要性。

Abstract: Search-Augmented Generative Engines (SAGE) have emerged as a new paradigm for information access, bridging web-scale retrieval with generative capabilities to deliver synthesized answers. This shift has fundamentally reshaped how web content gains exposure online, giving rise to Search-Augmented Generative Engine Optimization (SAGEO), the practice of optimizing web documents to improve their visibility in AI-generated responses. Despite growing interest, no evaluation environment currently supports comprehensive investigation of SAGEO. Specifically, existing benchmarks lack end-to-end visibility evaluation of optimization strategies, operating on pre-determined candidate documents that abstract away retrieval and reranking preceding generation. Moreover, existing benchmarks discard structural information (e.g., schema markup) present in real web documents, overlooking the rich signals that search systems actively leverage in practice. Motivated by these gaps, we introduce SAGEO Arena, a realistic and reproducible environment for stage-level SAGEO analysis. Our objective is to jointly target search-oriented optimization (SEO) and generation-centric optimization (GEO). To achieve this, we integrate a full generative search pipeline over a large-scale corpus of web documents with rich structural information. Our findings reveal that existing approaches remain largely impractical under realistic conditions and often degrade performance in retrieval and reranking. We also find that structural information helps mitigate these limitations, and that effective SAGEO requires tailoring optimization to each pipeline stage. Overall, our benchmark paves the way for realistic SAGEO evaluation and optimization beyond simplified settings.

</details>


### [18] [AttentionRetriever: Attention Layers are Secretly Long Document Retrievers](https://arxiv.org/abs/2602.12278)
*David Jiahao Fu,Lam Thanh Do,Jiayu Li,Kevin Chen-Chuan Chang*

Main category: cs.IR

TL;DR: AttentionRetriever：利用注意力机制和基于实体的检索，为长文档构建上下文感知嵌入并确定检索范围的新型长文档检索模型


<details>
  <summary>Details</summary>
Motivation: 现有检索模型并非为长文档检索设计，无法解决长文档检索的关键挑战，包括上下文感知、因果依赖和检索范围确定等问题

Method: 提出AttentionRetriever模型，结合注意力机制和基于实体的检索，为长文档构建上下文感知嵌入，并确定适当的检索范围

Result: 在长文档检索数据集上大幅优于现有检索模型，同时保持与密集检索模型相当的效率

Conclusion: AttentionRetriever有效解决了长文档检索的关键挑战，在性能和效率方面都表现出色，为RAG系统中的长文档处理提供了更好的解决方案

Abstract: Retrieval augmented generation (RAG) has been widely adopted to help Large Language Models (LLMs) to process tasks involving long documents. However, existing retrieval models are not designed for long document retrieval and fail to address several key challenges of long document retrieval, including context-awareness, causal dependence, and scope of retrieval. In this paper, we proposed AttentionRetriever, a novel long document retrieval model that leverages attention mechanism and entity-based retrieval to build context-aware embeddings for long document and determine the scope of retrieval. With extensive experiments, we found AttentionRetriever is able to outperform existing retrieval models on long document retrieval datasets by a large margin while remaining as efficient as dense retrieval models.

</details>
