{"id": "2602.11235", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.11235", "abs": "https://arxiv.org/abs/2602.11235", "authors": ["Xin Song", "Zhilin Guan", "Ruidong Han", "Binghao Tang", "Tianwen Chen", "Bing Li", "Zihao Li", "Han Zhang", "Fei Jiang", "Chaolin Xie", "Chi Ma", "Chunyang Jiang", "Chunzhen Jing", "Dengxuan Li", "Fengyi Li", "Lei Yu", "Mengyao Sun", "Pu Wang", "Qing Wang", "Rui Fan", "Shangyu Chen", "Shifeng Du", "Siyuan Bai", "Wei Lin", "Wentao Zhu", "Zhou Han", "Zhuo Chen", "Zikang Xu"], "title": "MTFM: A Scalable and Alignment-free Foundation Model for Industrial Recommendation in Meituan", "comment": null, "summary": "Industrial recommendation systems typically involve multiple scenarios, yet existing cross-domain (CDR) and multi-scenario (MSR) methods often require prohibitive resources and strict input alignment, limiting their extensibility. We propose MTFM (Meituan Foundation Model for Recommendation), a transformer-based framework that addresses these challenges. Instead of pre-aligning inputs, MTFM transforms cross-domain data into heterogeneous tokens, capturing multi-scenario knowledge in an alignment-free manner. To enhance efficiency, we first introduce a multi-scenario user-level sample aggregation that significantly enhances training throughput by reducing the total number of instances. We further integrate Grouped-Query Attention and a customized Hybrid Target Attention to minimize memory usage and computational complexity. Furthermore, we implement various system-level optimizations, such as kernel fusion and the elimination of CPU-GPU blocking, to further enhance both training and inference throughput. Offline and online experiments validate the effectiveness of MTFM, demonstrating that significant performance gains are achieved by scaling both model capacity and multi-scenario training data.", "AI": {"tldr": "MTFM\u662f\u4e00\u4e2a\u57fa\u4e8eTransformer\u7684\u7f8e\u56e2\u63a8\u8350\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u5f02\u6784\u4ee4\u724c\u8f6c\u6362\u3001\u591a\u573a\u666f\u7528\u6237\u7ea7\u6837\u672c\u805a\u5408\u3001\u5206\u7ec4\u67e5\u8be2\u6ce8\u610f\u529b\u7b49\u6280\u672f\uff0c\u89e3\u51b3\u4e86\u8de8\u57df\u591a\u573a\u666f\u63a8\u8350\u4e2d\u7684\u8d44\u6e90\u6d88\u8017\u548c\u8f93\u5165\u5bf9\u9f50\u95ee\u9898\u3002", "motivation": "\u5de5\u4e1a\u63a8\u8350\u7cfb\u7edf\u901a\u5e38\u6d89\u53ca\u591a\u4e2a\u573a\u666f\uff0c\u4f46\u73b0\u6709\u7684\u8de8\u57df\u548c\u591a\u573a\u666f\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u8d44\u6e90\u4e14\u8981\u6c42\u4e25\u683c\u7684\u8f93\u5165\u5bf9\u9f50\uff0c\u9650\u5236\u4e86\u5176\u53ef\u6269\u5c55\u6027\u3002\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u5bf9\u9f50\u81ea\u7531\u7684\u65b9\u6cd5\u6765\u6355\u83b7\u591a\u573a\u666f\u77e5\u8bc6\u3002", "method": "1. \u5c06\u8de8\u57df\u6570\u636e\u8f6c\u6362\u4e3a\u5f02\u6784\u4ee4\u724c\uff0c\u4ee5\u5bf9\u9f50\u81ea\u7531\u7684\u65b9\u5f0f\u6355\u83b7\u591a\u573a\u666f\u77e5\u8bc6\uff1b2. \u5f15\u5165\u591a\u573a\u666f\u7528\u6237\u7ea7\u6837\u672c\u805a\u5408\uff0c\u51cf\u5c11\u5b9e\u4f8b\u603b\u6570\u63d0\u5347\u8bad\u7ec3\u541e\u5410\u91cf\uff1b3. \u96c6\u6210\u5206\u7ec4\u67e5\u8be2\u6ce8\u610f\u529b\u548c\u5b9a\u5236\u5316\u6df7\u5408\u76ee\u6807\u6ce8\u610f\u529b\uff0c\u964d\u4f4e\u5185\u5b58\u4f7f\u7528\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\uff1b4. \u7cfb\u7edf\u7ea7\u4f18\u5316\u5982\u5185\u6838\u878d\u5408\u548c\u6d88\u9664CPU-GPU\u963b\u585e\u3002", "result": "\u79bb\u7ebf\u548c\u5728\u7ebf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86MTFM\u7684\u6709\u6548\u6027\uff0c\u901a\u8fc7\u6269\u5c55\u6a21\u578b\u5bb9\u91cf\u548c\u591a\u573a\u666f\u8bad\u7ec3\u6570\u636e\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "MTFM\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u7684\u8de8\u57df\u591a\u573a\u666f\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u6280\u672f\u521b\u65b0\u89e3\u51b3\u4e86\u8d44\u6e90\u6d88\u8017\u548c\u8f93\u5165\u5bf9\u9f50\u7684\u9650\u5236\uff0c\u4e3a\u5de5\u4e1a\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.11453", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.11453", "abs": "https://arxiv.org/abs/2602.11453", "authors": ["Sajad Ebrahimi", "Bhaskar Mitra", "Negar Arabzadeh", "Ye Yuan", "Haolun Wu", "Fattane Zarrinkalam", "Ebrahim Bagheri"], "title": "From Noise to Order: Learning to Rank via Denoising Diffusion", "comment": null, "summary": "In information retrieval (IR), learning-to-rank (LTR) methods have traditionally limited themselves to discriminative machine learning approaches that model the probability of the document being relevant to the query given some feature representation of the query-document pair. In this work, we propose an alternative denoising diffusion-based deep generative approach to LTR that instead models the full joint distribution over feature vectors and relevance labels. While in the discriminative setting, an over-parameterized ranking model may find different ways to fit the training data, we hypothesize that candidate solutions that can explain the full data distribution under the generative setting produce more robust ranking models. With this motivation, we propose DiffusionRank that extends TabDiff, an existing denoising diffusion-based generative model for tabular datasets, to create generative equivalents of classical discriminative pointwise and pairwise LTR objectives. Our empirical results demonstrate significant improvements from DiffusionRank models over their discriminative counterparts. Our work points to a rich space for future research exploration on how we can leverage ongoing advancements in deep generative modeling approaches, such as diffusion, for learning-to-rank in IR.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDiffusionRank\uff0c\u4e00\u79cd\u57fa\u4e8e\u53bb\u566a\u6269\u6563\u7684\u6df1\u5ea6\u751f\u6210\u5f0f\u5b66\u4e60\u6392\u5e8f\u65b9\u6cd5\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684\u5224\u522b\u5f0f\u65b9\u6cd5\uff0c\u901a\u8fc7\u5efa\u6a21\u7279\u5f81\u5411\u91cf\u548c\u76f8\u5173\u6027\u6807\u7b7e\u7684\u8054\u5408\u5206\u5e03\u6765\u63d0\u5347\u6392\u5e8f\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edf\u5b66\u4e60\u6392\u5e8f\u65b9\u6cd5\u5c40\u9650\u4e8e\u5224\u522b\u5f0f\u673a\u5668\u5b66\u4e60\uff0c\u53ea\u5efa\u6a21\u6587\u6863\u76f8\u5173\u6027\u6982\u7387\u3002\u4f5c\u8005\u8ba4\u4e3a\u751f\u6210\u5f0f\u65b9\u6cd5\u80fd\u5efa\u6a21\u5b8c\u6574\u6570\u636e\u5206\u5e03\uff0c\u53ef\u80fd\u4ea7\u751f\u66f4\u9c81\u68d2\u7684\u6392\u5e8f\u6a21\u578b\uff0c\u56e0\u4e3a\u8fc7\u5ea6\u53c2\u6570\u5316\u7684\u5224\u522b\u6a21\u578b\u53ef\u80fd\u4ee5\u4e0d\u540c\u65b9\u5f0f\u62df\u5408\u8bad\u7ec3\u6570\u636e\uff0c\u800c\u751f\u6210\u5f0f\u65b9\u6cd5\u9700\u8981\u89e3\u91ca\u5b8c\u6574\u6570\u636e\u5206\u5e03\u3002", "method": "\u63d0\u51faDiffusionRank\uff0c\u6269\u5c55TabDiff\uff08\u57fa\u4e8e\u53bb\u566a\u6269\u6563\u7684\u8868\u683c\u6570\u636e\u751f\u6210\u6a21\u578b\uff09\uff0c\u521b\u5efa\u751f\u6210\u5f0f\u7b49\u4ef7\u4e8e\u7ecf\u5178\u5224\u522b\u5f0f\u70b9\u5bf9\u548c\u6210\u5bf9\u5b66\u4e60\u6392\u5e8f\u76ee\u6807\u3002\u8be5\u65b9\u6cd5\u5efa\u6a21\u7279\u5f81\u5411\u91cf\u548c\u76f8\u5173\u6027\u6807\u7b7e\u7684\u8054\u5408\u5206\u5e03\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aDiffusionRank\u6a21\u578b\u76f8\u6bd4\u5176\u5224\u522b\u5f0f\u5bf9\u5e94\u65b9\u6cd5\u6709\u663e\u8457\u6539\u8fdb\uff0c\u8bc1\u660e\u4e86\u751f\u6210\u5f0f\u65b9\u6cd5\u5728\u5b66\u4e60\u6392\u5e8f\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u672a\u6765\u7814\u7a76\u5f00\u8f9f\u4e86\u4e30\u5bcc\u7a7a\u95f4\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528\u6df1\u5ea6\u751f\u6210\u5efa\u6a21\u65b9\u6cd5\uff08\u5982\u6269\u6563\u6a21\u578b\uff09\u6765\u6539\u8fdb\u4fe1\u606f\u68c0\u7d22\u4e2d\u7684\u5b66\u4e60\u6392\u5e8f\u4efb\u52a1\u3002"}}
{"id": "2602.11518", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.11518", "abs": "https://arxiv.org/abs/2602.11518", "authors": ["Yupeng Li", "Ben Chen", "Mingyue Cheng", "Zhiding Liu", "Xuxin Zhang", "Chenyi Lei", "Wenwu Ou"], "title": "KuaiSearch: A Large-Scale E-Commerce Search Dataset for Recall, Ranking, and Relevance", "comment": null, "summary": "E-commerce search serves as a central interface, connecting user demands with massive product inventories and plays a vital role in our daily lives. However, in real-world applications, it faces challenges, including highly ambiguous queries, noisy product texts with weak semantic order, and diverse user preferences, all of which make it difficult to accurately capture user intent and fine-grained product semantics. In recent years, significant advances in large language models (LLMs) for semantic representation and contextual reasoning have created new opportunities to address these challenges. Nevertheless, existing e-commerce search datasets still suffer from notable limitations: queries are often heuristically constructed, cold-start users and long-tail products are filtered out, query and product texts are anonymized, and most datasets cover only a single stage of the search pipeline. Collectively, these issues constrain research on LLM-based e-commerce search. To address these challenges, we construct and release KuaiSearch. To the best of our knowledge, it is the largest e-commerce search dataset currently available. KuaiSearch is built upon real user search interactions from the Kuaishou platform, preserving authentic user queries and natural-language product texts, covering cold-start users and long-tail products, and systematically spanning three key stages of the search pipeline: recall, ranking, and relevance judgment. We conduct a comprehensive analysis of KuaiSearch from multiple perspectives, including products, users, and queries, and establish benchmark experiments across several representative search tasks. Experimental results demonstrate that KuaiSearch provides a valuable foundation for research on real-world e-commerce search.", "AI": {"tldr": "KuaiSearch\u662f\u5f53\u524d\u6700\u5927\u7684\u7535\u5546\u641c\u7d22\u6570\u636e\u96c6\uff0c\u57fa\u4e8e\u5feb\u624b\u5e73\u53f0\u771f\u5b9e\u7528\u6237\u641c\u7d22\u4ea4\u4e92\u6784\u5efa\uff0c\u8986\u76d6\u51b7\u542f\u52a8\u7528\u6237\u548c\u957f\u5c3e\u5546\u54c1\uff0c\u6db5\u76d6\u53ec\u56de\u3001\u6392\u5e8f\u3001\u76f8\u5173\u6027\u5224\u65ad\u4e09\u4e2a\u641c\u7d22\u9636\u6bb5\u3002", "motivation": "\u73b0\u6709\u7535\u5546\u641c\u7d22\u6570\u636e\u96c6\u5b58\u5728\u591a\u4e2a\u5c40\u9650\uff1a\u67e5\u8be2\u901a\u5e38\u662f\u542f\u53d1\u5f0f\u6784\u5efa\u7684\u3001\u8fc7\u6ee4\u4e86\u51b7\u542f\u52a8\u7528\u6237\u548c\u957f\u5c3e\u5546\u54c1\u3001\u67e5\u8be2\u548c\u5546\u54c1\u6587\u672c\u88ab\u533f\u540d\u5316\u3001\u5927\u591a\u53ea\u8986\u76d6\u5355\u4e00\u641c\u7d22\u9636\u6bb5\uff0c\u8fd9\u4e9b\u9650\u5236\u4e86\u57fa\u4e8eLLM\u7684\u7535\u5546\u641c\u7d22\u7814\u7a76\u3002", "method": "\u57fa\u4e8e\u5feb\u624b\u5e73\u53f0\u771f\u5b9e\u7528\u6237\u641c\u7d22\u4ea4\u4e92\u6784\u5efa\u6570\u636e\u96c6\uff0c\u4fdd\u7559\u771f\u5b9e\u7528\u6237\u67e5\u8be2\u548c\u81ea\u7136\u8bed\u8a00\u5546\u54c1\u6587\u672c\uff0c\u8986\u76d6\u51b7\u542f\u52a8\u7528\u6237\u548c\u957f\u5c3e\u5546\u54c1\uff0c\u7cfb\u7edf\u6027\u5730\u6db5\u76d6\u53ec\u56de\u3001\u6392\u5e8f\u3001\u76f8\u5173\u6027\u5224\u65ad\u4e09\u4e2a\u641c\u7d22\u9636\u6bb5\u3002", "result": "\u6784\u5efa\u4e86\u5f53\u524d\u6700\u5927\u7684\u7535\u5546\u641c\u7d22\u6570\u636e\u96c6KuaiSearch\uff0c\u4ece\u5546\u54c1\u3001\u7528\u6237\u3001\u67e5\u8be2\u7b49\u591a\u4e2a\u89d2\u5ea6\u8fdb\u884c\u5168\u9762\u5206\u6790\uff0c\u5e76\u5728\u591a\u4e2a\u4ee3\u8868\u6027\u641c\u7d22\u4efb\u52a1\u4e0a\u5efa\u7acb\u4e86\u57fa\u51c6\u5b9e\u9a8c\u3002", "conclusion": "KuaiSearch\u4e3a\u73b0\u5b9e\u4e16\u754c\u7535\u5546\u641c\u7d22\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9d\u8d35\u57fa\u7840\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u6570\u636e\u96c6\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2602.11562", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.11562", "abs": "https://arxiv.org/abs/2602.11562", "authors": ["Tianhe Lin", "Ziwei Xiong", "Baoyuan Ou", "Yingjie Qin", "Lai Xu", "Xiaocheng Zhong", "Yao Hu", "Zhiyong Wang", "Tao Zhou", "Yubin Xu", "Di Wu"], "title": "LASER: An Efficient Target-Aware Segmented Attention Framework for End-to-End Long Sequence Modeling", "comment": "9 pages", "summary": "Modeling ultra-long user behavior sequences is pivotal for capturing evolving and lifelong interests in modern recommendation systems. However, deploying such models in real-time industrial environments faces a strict \"Latency Wall\", constrained by two distinct bottlenecks: the high I/O latency of retrieving massive user histories and the quadratic computational complexity of standard attention mechanisms. To break these bottlenecks, we present LASER, a full-stack optimization framework developed and deployed at Xiaohongshu (RedNote). Our approach tackles the challenges through two complementary innovations: (1) System efficiency: We introduce SeqVault, a unified schema-aware serving infrastructure for long user histories. By implementing a hybrid DRAM-SSD indexing strategy, SeqVault reduces retrieval latency by 50% and CPU usage by 75%, ensuring millisecond-level access to full real-time and life-cycle user histories. (2) Algorithmic efficiency: We propose a Segmented Target Attention (STA) mechanism to address the computational overhead. Motivated by the inherent sparsity of user interests, STA employs a sigmoid-based gating strategy that acts as a silence mechanism to filter out noisy items. Subsequently, a lightweight Global Stacked Target Attention (GSTA) module refines these compressed segments to capture cross-segment dependencies without incurring high computational costs. This design performs effective sequence compression, reducing the complexity of long-sequence modeling while preserving critical signals. Extensive offline evaluations demonstrate that LASER consistently outperforms state-of-the-art baselines. In large-scale online A/B testing serving over 100 million daily active users, LASER achieved a 2.36% lift in ADVV and a 2.08% lift in revenue, demonstrating its scalability and significant commercial impact.", "AI": {"tldr": "LASER\u662f\u4e00\u4e2a\u5168\u6808\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u6548\u7387\uff08SeqVault\u6df7\u5408\u5b58\u50a8\uff09\u548c\u7b97\u6cd5\u6548\u7387\uff08STA\u6ce8\u610f\u529b\u673a\u5236\uff09\u89e3\u51b3\u8d85\u957f\u7528\u6237\u884c\u4e3a\u5e8f\u5217\u5efa\u6a21\u4e2d\u7684\u5ef6\u8fdf\u74f6\u9888\u95ee\u9898\uff0c\u5728\u5de5\u4e1a\u63a8\u8350\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u6beb\u79d2\u7ea7\u8bbf\u95ee\u548c\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5de5\u4e1a\u63a8\u8350\u7cfb\u7edf\u4e2d\u5efa\u6a21\u8d85\u957f\u7528\u6237\u884c\u4e3a\u5e8f\u5217\u9762\u4e34\u4e25\u683c\u7684\"\u5ef6\u8fdf\u5899\"\u6311\u6218\uff0c\u5305\u62ec\u68c0\u7d22\u6d77\u91cf\u7528\u6237\u5386\u53f2\u7684\u9ad8I/O\u5ef6\u8fdf\u548c\u6807\u51c6\u6ce8\u610f\u529b\u673a\u5236\u7684\u4e8c\u6b21\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u8fd9\u9650\u5236\u4e86\u5b9e\u65f6\u90e8\u7f72\u80fd\u529b\u3002", "method": "1. \u7cfb\u7edf\u6548\u7387\uff1aSeqVault\u7edf\u4e00\u6a21\u5f0f\u611f\u77e5\u670d\u52a1\u57fa\u7840\u8bbe\u65bd\uff0c\u91c7\u7528DRAM-SSD\u6df7\u5408\u7d22\u5f15\u7b56\u7565\uff0c\u51cf\u5c11\u68c0\u7d22\u5ef6\u8fdf\u548cCPU\u4f7f\u7528\u7387\uff1b2. \u7b97\u6cd5\u6548\u7387\uff1aSegmented Target Attention\uff08STA\uff09\u673a\u5236\uff0c\u901a\u8fc7sigmoid\u95e8\u63a7\u7b56\u7565\u8fc7\u6ee4\u566a\u58f0\u9879\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7Global Stacked Target Attention\uff08GSTA\uff09\u6a21\u5757\u6355\u83b7\u8de8\u6bb5\u4f9d\u8d56\u3002", "result": "SeqVault\u5c06\u68c0\u7d22\u5ef6\u8fdf\u964d\u4f4e50%\uff0cCPU\u4f7f\u7528\u7387\u964d\u4f4e75%\uff1b\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\uff0cLASER\u5728\u670d\u52a1\u8d85\u8fc71\u4ebf\u65e5\u6d3b\u7528\u6237\u65f6\uff0cADVV\u63d0\u53472.36%\uff0c\u6536\u5165\u63d0\u53472.08%\uff0c\u663e\u793a\u51fa\u663e\u8457\u7684\u53ef\u6269\u5c55\u6027\u548c\u5546\u4e1a\u5f71\u54cd\u3002", "conclusion": "LASER\u901a\u8fc7\u7cfb\u7edf\u4e0e\u7b97\u6cd5\u7684\u534f\u540c\u4f18\u5316\uff0c\u6709\u6548\u7a81\u7834\u4e86\u8d85\u957f\u7528\u6237\u884c\u4e3a\u5e8f\u5217\u5efa\u6a21\u7684\u5ef6\u8fdf\u74f6\u9888\uff0c\u5b9e\u73b0\u4e86\u5de5\u4e1a\u7ea7\u5b9e\u65f6\u90e8\u7f72\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.11581", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.11581", "abs": "https://arxiv.org/abs/2602.11581", "authors": ["Yiteng Tu", "Shuo Miao", "Weihang Su", "Yiqun Liu", "Qingyao Ai"], "title": "Analytical Search", "comment": null, "summary": "Analytical information needs, such as trend analysis and causal impact assessment, are prevalent across various domains including law, finance, science, and much more. However, existing information retrieval paradigms, whether based on relevance-oriented document ranking or retrieval-augmented generation (RAG) with large language models (LLMs), often struggle to meet the end-to-end requirements of such tasks at the corpus scale. They either emphasize information finding rather than end-to-end problem solving, or simply treat everything as naive question answering, offering limited control over reasoning, evidence usage, and verifiability. As a result, they struggle to support analytical queries that have diverse utility concepts and high accountability requirements.\n  In this paper, we propose analytical search as a distinct and emerging search paradigm designed to fulfill these analytical information needs. Analytical search reframes search as an evidence-governed, process-oriented analytical workflow that explicitly models analytical intent, retrieves evidence for fusion, and produces verifiable conclusions through structured, multi-step inference. We position analytical search in contrast to existing paradigms, and present a unified system framework that integrates query understanding, recall-oriented retrieval, reasoning-aware fusion, and adaptive verification. We also discuss potential research directions for the construction of analytical search engines. In this way, we highlight the conceptual significance and practical importance of analytical search and call on efforts toward the next generation of search engines that support analytical information needs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\"\u5206\u6790\u5f0f\u641c\u7d22\"\u4f5c\u4e3a\u65b0\u5174\u641c\u7d22\u8303\u5f0f\uff0c\u65e8\u5728\u6ee1\u8db3\u8de8\u9886\u57df\u7684\u5206\u6790\u6027\u4fe1\u606f\u9700\u6c42\uff0c\u5f3a\u8c03\u8bc1\u636e\u9a71\u52a8\u3001\u8fc7\u7a0b\u5bfc\u5411\u7684\u5206\u6790\u5de5\u4f5c\u6d41\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u641c\u7d22\u7cfb\u7edf\u5728\u652f\u6301\u8d8b\u52bf\u5206\u6790\u3001\u56e0\u679c\u5f71\u54cd\u8bc4\u4f30\u7b49\u590d\u6742\u5206\u6790\u4efb\u52a1\u65f6\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u4fe1\u606f\u68c0\u7d22\u8303\u5f0f\uff08\u57fa\u4e8e\u76f8\u5173\u6027\u6587\u6863\u6392\u5e8f\u6216RAG\u589e\u5f3a\u751f\u6210\uff09\u96be\u4ee5\u6ee1\u8db3\u5206\u6790\u6027\u4fe1\u606f\u9700\u6c42\u7684\u7aef\u5230\u7aef\u8981\u6c42\u3002\u8fd9\u4e9b\u7cfb\u7edf\u8981\u4e48\u4fa7\u91cd\u4fe1\u606f\u67e5\u627e\u800c\u975e\u95ee\u9898\u89e3\u51b3\uff0c\u8981\u4e48\u7b80\u5355\u89c6\u4e3a\u95ee\u7b54\u4efb\u52a1\uff0c\u7f3a\u4e4f\u5bf9\u63a8\u7406\u8fc7\u7a0b\u3001\u8bc1\u636e\u4f7f\u7528\u548c\u53ef\u9a8c\u8bc1\u6027\u7684\u63a7\u5236\uff0c\u65e0\u6cd5\u652f\u6301\u5177\u6709\u591a\u6837\u5316\u6548\u7528\u6982\u5ff5\u548c\u9ad8\u95ee\u8d23\u8981\u6c42\u7684\u5206\u6790\u67e5\u8be2\u3002", "method": "\u63d0\u51fa\u5206\u6790\u5f0f\u641c\u7d22\u4f5c\u4e3a\u65b0\u5174\u641c\u7d22\u8303\u5f0f\uff0c\u5c06\u5176\u91cd\u65b0\u5b9a\u4e49\u4e3a\u8bc1\u636e\u6cbb\u7406\u3001\u8fc7\u7a0b\u5bfc\u5411\u7684\u5206\u6790\u5de5\u4f5c\u6d41\u3002\u8be5\u6846\u67b6\u660e\u786e\u5efa\u6a21\u5206\u6790\u610f\u56fe\uff0c\u68c0\u7d22\u8bc1\u636e\u8fdb\u884c\u878d\u5408\uff0c\u5e76\u901a\u8fc7\u7ed3\u6784\u5316\u3001\u591a\u6b65\u63a8\u7406\u4ea7\u751f\u53ef\u9a8c\u8bc1\u7ed3\u8bba\u3002\u7cfb\u7edf\u6846\u67b6\u6574\u5408\u4e86\u67e5\u8be2\u7406\u89e3\u3001\u9762\u5411\u53ec\u56de\u7387\u7684\u68c0\u7d22\u3001\u63a8\u7406\u611f\u77e5\u878d\u5408\u548c\u81ea\u9002\u5e94\u9a8c\u8bc1\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u5206\u6790\u5f0f\u641c\u7d22\u7684\u7edf\u4e00\u7cfb\u7edf\u6846\u67b6\uff0c\u5e76\u8ba8\u8bba\u4e86\u6784\u5efa\u5206\u6790\u5f0f\u641c\u7d22\u5f15\u64ce\u7684\u6f5c\u5728\u7814\u7a76\u65b9\u5411\u3002\u901a\u8fc7\u5bf9\u6bd4\u73b0\u6709\u641c\u7d22\u8303\u5f0f\uff0c\u7a81\u51fa\u4e86\u5206\u6790\u5f0f\u641c\u7d22\u7684\u6982\u5ff5\u610f\u4e49\u548c\u5b9e\u8df5\u91cd\u8981\u6027\u3002", "conclusion": "\u5206\u6790\u5f0f\u641c\u7d22\u4ee3\u8868\u4e86\u6ee1\u8db3\u5206\u6790\u6027\u4fe1\u606f\u9700\u6c42\u7684\u4e0b\u4e00\u4ee3\u641c\u7d22\u5f15\u64ce\u53d1\u5c55\u65b9\u5411\uff0c\u547c\u5401\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u5171\u540c\u52aa\u529b\u6784\u5efa\u652f\u6301\u590d\u6742\u5206\u6790\u4efb\u52a1\u7684\u641c\u7d22\u7cfb\u7edf\u3002"}}
{"id": "2602.11605", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.11605", "abs": "https://arxiv.org/abs/2602.11605", "authors": ["Yixiao Chen", "Yuan Wang", "Yue Liu", "Qiyao Wang", "Ke Cheng", "Xin Xu", "Juntong Yan", "Shuojin Yang", "Menghao Guo", "Jun Zhang", "Huan Yu", "Jie Jiang"], "title": "Recurrent Preference Memory for Efficient Long-Sequence Generative Recommendation", "comment": "12 pages, 6figures", "summary": "Generative recommendation (GenRec) models typically model user behavior via full attention, but scaling to lifelong sequences is hindered by prohibitive computational costs and noise accumulation from stochastic interactions. To address these challenges, we introduce Rec2PM, a framework that compresses long user interaction histories into compact Preference Memory tokens. Unlike traditional recurrent methods that suffer from serial training, Rec2PM employs a novel self-referential teacher-forcing strategy: it leverages a global view of the history to generate reference memories, which serve as supervision targets for parallelized recurrent updates. This allows for fully parallel training while maintaining the capability for iterative updates during inference. Additionally, by representing memory as token embeddings rather than extensive KV caches, Rec2PM achieves extreme storage efficiency. Experiments on large-scale benchmarks show that Rec2PM significantly reduces inference latency and memory footprint while achieving superior accuracy compared to full-sequence models. Analysis reveals that the Preference Memory functions as a denoising Information Bottleneck, effectively filtering interaction noise to capture robust long-term interests.", "AI": {"tldr": "Rec2PM\u6846\u67b6\u901a\u8fc7\u5c06\u957f\u7528\u6237\u4ea4\u4e92\u5386\u53f2\u538b\u7f29\u4e3a\u7d27\u51d1\u7684\u504f\u597d\u8bb0\u5fc6token\uff0c\u89e3\u51b3\u4e86\u751f\u6210\u5f0f\u63a8\u8350\u6a21\u578b\u5728\u7ec8\u8eab\u5e8f\u5217\u4e0a\u7684\u8ba1\u7b97\u6210\u672c\u548c\u566a\u58f0\u79ef\u7d2f\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u5e76\u884c\u8bad\u7ec3\u548c\u63a8\u7406\u3002", "motivation": "\u751f\u6210\u5f0f\u63a8\u8350\u6a21\u578b\u901a\u5e38\u4f7f\u7528\u5b8c\u6574\u6ce8\u610f\u529b\u5efa\u6a21\u7528\u6237\u884c\u4e3a\uff0c\u4f46\u5728\u5904\u7406\u7ec8\u8eab\u5e8f\u5217\u65f6\u9762\u4e34\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u548c\u968f\u673a\u4ea4\u4e92\u566a\u58f0\u79ef\u7d2f\u7684\u6311\u6218\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u5e8f\u5217\u538b\u7f29\u65b9\u6cd5\u3002", "method": "\u63d0\u51faRec2PM\u6846\u67b6\uff0c\u5c06\u957f\u7528\u6237\u4ea4\u4e92\u5386\u53f2\u538b\u7f29\u4e3a\u7d27\u51d1\u7684\u504f\u597d\u8bb0\u5fc6token\uff1b\u91c7\u7528\u81ea\u53c2\u7167\u6559\u5e08\u5f3a\u5236\u7b56\u7565\uff0c\u5229\u7528\u5386\u53f2\u5168\u5c40\u89c6\u56fe\u751f\u6210\u53c2\u8003\u8bb0\u5fc6\u4f5c\u4e3a\u76d1\u7763\u76ee\u6807\uff0c\u5b9e\u73b0\u5e76\u884c\u5316\u5faa\u73af\u66f4\u65b0\uff1b\u5c06\u8bb0\u5fc6\u8868\u793a\u4e3atoken\u5d4c\u5165\u800c\u975eKV\u7f13\u5b58\uff0c\u63d0\u9ad8\u5b58\u50a8\u6548\u7387\u3002", "result": "\u5728\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRec2PM\u663e\u8457\u964d\u4f4e\u4e86\u63a8\u7406\u5ef6\u8fdf\u548c\u5185\u5b58\u5360\u7528\uff0c\u540c\u65f6\u6bd4\u5b8c\u6574\u5e8f\u5217\u6a21\u578b\u83b7\u5f97\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\uff1b\u5206\u6790\u8868\u660e\u504f\u597d\u8bb0\u5fc6\u8d77\u5230\u4e86\u53bb\u566a\u4fe1\u606f\u74f6\u9888\u7684\u4f5c\u7528\uff0c\u6709\u6548\u8fc7\u6ee4\u4ea4\u4e92\u566a\u58f0\u5e76\u6355\u6349\u7a33\u5065\u7684\u957f\u671f\u5174\u8da3\u3002", "conclusion": "Rec2PM\u901a\u8fc7\u521b\u65b0\u7684\u8bb0\u5fc6\u538b\u7f29\u548c\u5e76\u884c\u8bad\u7ec3\u7b56\u7565\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u751f\u6210\u5f0f\u63a8\u8350\u6a21\u578b\u5728\u957f\u5e8f\u5217\u5904\u7406\u4e2d\u7684\u6548\u7387\u548c\u566a\u58f0\u95ee\u9898\uff0c\u4e3a\u5927\u89c4\u6a21\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.11622", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.11622", "abs": "https://arxiv.org/abs/2602.11622", "authors": ["Haiyang Jiang", "Tong Chen", "Xinyi Gao", "Guansong Pang", "Quoc Viet Hung Nguyen", "Hongzhi Yin"], "title": "Evolutionary Router Feature Generation for Zero-Shot Graph Anomaly Detection with Mixture-of-Experts", "comment": null, "summary": "Zero-shot graph anomaly detection (GAD) has attracted increasing attention recent years, yet the heterogeneity of graph structures, features, and anomaly patterns across graphs make existing single GNN methods insufficiently expressive to model diverse anomaly mechanisms. In this regard, Mixture-of-experts (MoE) architectures provide a promising paradigm by integrating diverse GNN experts with complementary inductive biases, yet their effectiveness in zero-shot GAD is severely constrained by distribution shifts, leading to two key routing challenges. First, nodes often carry vastly different semantics across graphs, and straightforwardly performing routing based on their features is prone to generating biased or suboptimal expert assignments. Second, as anomalous graphs often exhibit pronounced distributional discrepancies, existing router designs fall short in capturing domain-invariant routing principles that generalize beyond the training graphs. To address these challenges, we propose a novel MoE framework with evolutionary router feature generation (EvoFG) for zero-shot GAD. To enhance MoE routing, we propose an evolutionary feature generation scheme that iteratively constructs and selects informative structural features via an LLM-based generator and Shapley-guided evaluation. Moreover, a memory-enhanced router with an invariant learning objective is designed to capture transferable routing patterns under distribution shifts. Extensive experiments on six benchmarks show that EvoFG consistently outperforms state-of-the-art baselines, achieving strong and stable zero-shot GAD performance.", "AI": {"tldr": "\u63d0\u51faEvoFG\u6846\u67b6\uff0c\u901a\u8fc7\u8fdb\u5316\u7279\u5f81\u751f\u6210\u548c\u8bb0\u5fc6\u589e\u5f3a\u8def\u7531\u5668\u89e3\u51b3\u96f6\u6837\u672c\u56fe\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898", "motivation": "\u73b0\u6709\u5355GNN\u65b9\u6cd5\u96be\u4ee5\u5efa\u6a21\u8de8\u56fe\u7684\u5f02\u6784\u7ed3\u6784\u548c\u5f02\u5e38\u6a21\u5f0f\uff0c\u800c\u6df7\u5408\u4e13\u5bb6\u67b6\u6784\u5728\u96f6\u6837\u672c\u56fe\u5f02\u5e38\u68c0\u6d4b\u4e2d\u53d7\u5206\u5e03\u504f\u79fb\u9650\u5236\uff0c\u9762\u4e34\u8def\u7531\u7279\u5f81\u8bed\u4e49\u5dee\u5f02\u548c\u9886\u57df\u4e0d\u53d8\u6027\u4e0d\u8db3\u7684\u6311\u6218", "method": "\u63d0\u51fa\u8fdb\u5316\u7279\u5f81\u751f\u6210\u65b9\u6848\uff0c\u901a\u8fc7LLM\u751f\u6210\u5668\u548cShapley\u5f15\u5bfc\u8bc4\u4f30\u8fed\u4ee3\u6784\u5efa\u7ed3\u6784\u7279\u5f81\uff1b\u8bbe\u8ba1\u8bb0\u5fc6\u589e\u5f3a\u8def\u7531\u5668\uff0c\u91c7\u7528\u4e0d\u53d8\u5b66\u4e60\u76ee\u6807\u6355\u6349\u53ef\u8fc1\u79fb\u7684\u8def\u7531\u6a21\u5f0f", "result": "\u5728\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEvoFG\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u57fa\u7ebf\uff0c\u5b9e\u73b0\u4e86\u5f3a\u5927\u4e14\u7a33\u5b9a\u7684\u96f6\u6837\u672c\u56fe\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd", "conclusion": "EvoFG\u901a\u8fc7\u8fdb\u5316\u7279\u5f81\u751f\u6210\u548c\u4e0d\u53d8\u5b66\u4e60\u6709\u6548\u89e3\u51b3\u4e86\u96f6\u6837\u672c\u56fe\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u4e3a\u6df7\u5408\u4e13\u5bb6\u67b6\u6784\u5728\u8de8\u56fe\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2602.11664", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.11664", "abs": "https://arxiv.org/abs/2602.11664", "authors": ["Huimin Yan", "Longfei Xu", "Junjie Sun", "Zheng Liu", "Wei Luo", "Kaikui Liu", "Xiangxiang Chu"], "title": "IntTravel: A Real-World Dataset and Generative Framework for Integrated Multi-Task Travel Recommendation", "comment": null, "summary": "Next Point of Interest (POI) recommendation is essential for modern mobility and location-based services. To provide a smooth user experience, models must understand several components of a journey holistically: \"when to depart\", \"how to travel\", \"where to go\", and \"what needs arise via the route\". However, current research is limited by fragmented datasets that focus merely on next POI recommendation (\"where to go\"), neglecting the departure time, travel mode, and situational requirements along the journey. Furthermore, the limited scale of these datasets impedes accurate evaluation of performance. To bridge this gap, we introduce IntTravel, the first large-scale public dataset for integrated travel recommendation, including 4.1 billion interactions from 163 million users with 7.3 million POIs. Built upon this dataset, we introduce an end-to-end, decoder-only generative framework for multi-task recommendation. It incorporates information preservation, selection, and factorization to balance task collaboration with specialized differentiation, yielding substantial performance gains. The framework's generalizability is highlighted by its state-of-the-art performance across both IntTravel dataset and an additional non-travel benchmark. IntTravel has been successfully deployed on Amap serving hundreds of millions of users, leading to a 1.09% increase in CTR. IntTravel is available at https://github.com/AMAP-ML/IntTravel.", "AI": {"tldr": "IntTravel\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u96c6\u6210\u65c5\u884c\u63a8\u8350\u6570\u636e\u96c6\u548c\u751f\u6210\u5f0f\u591a\u4efb\u52a1\u63a8\u8350\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709POI\u63a8\u8350\u7814\u7a76\u4e2d\u6570\u636e\u96c6\u788e\u7247\u5316\u3001\u4efb\u52a1\u5355\u4e00\u7684\u95ee\u9898\uff0c\u5728\u771f\u5b9e\u90e8\u7f72\u4e2d\u63d0\u5347\u4e86\u70b9\u51fb\u7387\u3002", "motivation": "\u5f53\u524dPOI\u63a8\u8350\u7814\u7a76\u5b58\u5728\u6570\u636e\u96c6\u788e\u7247\u5316\u3001\u4efb\u52a1\u5355\u4e00\u7684\u95ee\u9898\uff0c\u4ec5\u5173\u6ce8\"\u53bb\u54ea\u91cc\"\u800c\u5ffd\u7565\u4e86\u51fa\u53d1\u65f6\u95f4\u3001\u51fa\u884c\u65b9\u5f0f\u548c\u9014\u4e2d\u9700\u6c42\u7b49\u5b8c\u6574\u65c5\u7a0b\u8981\u7d20\uff0c\u4e14\u6570\u636e\u96c6\u89c4\u6a21\u6709\u9650\u5f71\u54cd\u6027\u80fd\u8bc4\u4f30\u3002", "method": "\u63d0\u51fa\u4e86IntTravel\u6570\u636e\u96c6\uff0841\u4ebf\u6b21\u4ea4\u4e92\u30011.63\u4ebf\u7528\u6237\u3001730\u4e07POI\uff09\u548c\u57fa\u4e8e\u6b64\u7684\u7aef\u5230\u7aef\u89e3\u7801\u5668\u751f\u6210\u5f0f\u591a\u4efb\u52a1\u63a8\u8350\u6846\u67b6\uff0c\u91c7\u7528\u4fe1\u606f\u4fdd\u7559\u3001\u9009\u62e9\u548c\u5206\u89e3\u6280\u672f\u5e73\u8861\u4efb\u52a1\u534f\u4f5c\u4e0e\u4e13\u4e1a\u5316\u533a\u5206\u3002", "result": "\u5728IntTravel\u6570\u636e\u96c6\u548c\u975e\u65c5\u884c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u90fd\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5728Amap\u5e73\u53f0\u90e8\u7f72\u540e\u4e3a\u6570\u4ebf\u7528\u6237\u670d\u52a1\uff0c\u70b9\u51fb\u7387\u63d0\u5347\u4e861.09%\u3002", "conclusion": "IntTravel\u586b\u8865\u4e86\u96c6\u6210\u65c5\u884c\u63a8\u8350\u9886\u57df\u7684\u6570\u636e\u96c6\u7a7a\u767d\uff0c\u5176\u751f\u6210\u5f0f\u591a\u4efb\u52a1\u6846\u67b6\u80fd\u6709\u6548\u5904\u7406\u65c5\u7a0b\u7684\u591a\u4e2a\u65b9\u9762\uff0c\u5177\u6709\u5f88\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.11680", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.11680", "abs": "https://arxiv.org/abs/2602.11680", "authors": ["Yihang Li", "Zhuo Liu", "Wei Wei"], "title": "EpicCBR: Item-Relation-Enhanced Dual-Scenario Contrastive Learning for Cold-Start Bundle Recommendation", "comment": "10 pages, 3 figures, 5 tables, accepted by WSDM 2026", "summary": "Bundle recommendation aims to recommend a set of items to users for overall consumption. Existing bundle recommendation models primarily depend on observed user-bundle interactions, limiting exploration of newly-emerged bundles that are constantly created. It pose a critical representation challenge for current bundle methods, as they usually treat each bundle as an independent instance, while neglecting to fully leverage the user-item (UI) and bundle-item (BI) relations over popular items. To alleviate it, in this paper we propose a multi-view contrastive learning framework for cold-start bundle recommendation, named EpicCBR. Specifically, it precisely mine and utilize the item relations to construct user profiles, identifying users likely to engage with bundles. Additionally, a popularity-based method that characterizes the features of new bundles through historical bundle information and user preferences is proposed. To build a framework that demonstrates robustness in both cold-start and warm-start scenarios, a multi-view graph contrastive learning framework capable of integrating these diverse scenarios is introduced to ensure the model's generalization capability. Extensive experiments conducted on three popular benchmarks showed that EpicCBR outperforms state-of-the-art by a large margin (up to 387%), sufficiently demonstrating the superiority of the proposed method in cold-start scenario. The code and dataset can be found in the GitHub repository: https://github.com/alexlovecoding/EpicCBR.", "AI": {"tldr": "EpicCBR\u662f\u4e00\u4e2a\u7528\u4e8e\u51b7\u542f\u52a8\u6346\u7ed1\u63a8\u8350\u7684\u591a\u89c6\u56fe\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6316\u6398\u7269\u54c1\u5173\u7cfb\u6784\u5efa\u7528\u6237\u753b\u50cf\uff0c\u5229\u7528\u6d41\u884c\u5ea6\u65b9\u6cd5\u8868\u5f81\u65b0\u6346\u7ed1\u7279\u5f81\uff0c\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e0b\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6346\u7ed1\u63a8\u8350\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u5df2\u89c2\u5bdf\u5230\u7684\u7528\u6237-\u6346\u7ed1\u4ea4\u4e92\uff0c\u96be\u4ee5\u5904\u7406\u4e0d\u65ad\u6d8c\u73b0\u7684\u65b0\u6346\u7ed1\uff08\u51b7\u542f\u52a8\u95ee\u9898\uff09\u3002\u8fd9\u4e9b\u65b9\u6cd5\u901a\u5e38\u5c06\u6bcf\u4e2a\u6346\u7ed1\u89c6\u4e3a\u72ec\u7acb\u5b9e\u4f8b\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u7528\u6237-\u7269\u54c1\u548c\u6346\u7ed1-\u7269\u54c1\u5173\u7cfb\u4e2d\u7684\u6d41\u884c\u7269\u54c1\u4fe1\u606f\u3002", "method": "\u63d0\u51faEpicCBR\u6846\u67b6\uff1a1\uff09\u901a\u8fc7\u6316\u6398\u7269\u54c1\u5173\u7cfb\u6784\u5efa\u7528\u6237\u753b\u50cf\uff0c\u8bc6\u522b\u53ef\u80fd\u5bf9\u6346\u7ed1\u611f\u5174\u8da3\u7684\u7528\u6237\uff1b2\uff09\u63d0\u51fa\u57fa\u4e8e\u6d41\u884c\u5ea6\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5386\u53f2\u6346\u7ed1\u4fe1\u606f\u548c\u7528\u6237\u504f\u597d\u8868\u5f81\u65b0\u6346\u7ed1\u7279\u5f81\uff1b3\uff09\u5f15\u5165\u591a\u89c6\u56fe\u56fe\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u6574\u5408\u51b7\u542f\u52a8\u548c\u70ed\u542f\u52a8\u573a\u666f\uff0c\u786e\u4fdd\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5728\u4e09\u4e2a\u6d41\u884c\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cEpicCBR\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e0b\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe387%\uff0c\u5145\u5206\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e0b\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "EpicCBR\u901a\u8fc7\u591a\u89c6\u56fe\u5bf9\u6bd4\u5b66\u4e60\u6709\u6548\u89e3\u51b3\u4e86\u6346\u7ed1\u63a8\u8350\u4e2d\u7684\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u5145\u5206\u5229\u7528\u7269\u54c1\u5173\u7cfb\u548c\u6d41\u884c\u5ea6\u4fe1\u606f\uff0c\u5728\u51b7\u542f\u52a8\u548c\u70ed\u542f\u52a8\u573a\u666f\u4e0b\u90fd\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2602.11719", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.11719", "abs": "https://arxiv.org/abs/2602.11719", "authors": ["Chenxiao Fan", "Chongming Gao", "Yaxin Gong", "Haoyan Liu", "Fuli Feng", "Xiangnan He"], "title": "Uncertainty-aware Generative Recommendation", "comment": null, "summary": "Generative Recommendation has emerged as a transformative paradigm, reformulating recommendation as an end-to-end autoregressive sequence generation task. Despite its promise, existing preference optimization methods typically rely on binary outcome correctness, suffering from a systemic limitation we term uncertainty blindness. This issue manifests in the neglect of the model's intrinsic generation confidence, the variation in sample learning difficulty, and the lack of explicit confidence expression, directly leading to unstable training dynamics and unquantifiable decision risks. In this paper, we propose Uncertainty-aware Generative Recommendation (UGR), a unified framework that leverages uncertainty as a critical signal for adaptive optimization. UGR synergizes three mechanisms: (1) an uncertainty-weighted reward to penalize confident errors; (2) difficulty-aware optimization dynamics to prevent premature convergence; and (3) explicit confidence alignment to empower the model with confidence expression capabilities. Extensive experiments demonstrate that UGR not only yields superior recommendation performance but also fundamentally stabilizes training, preventing the performance degradation often observed in standard methods. Furthermore, the learned confidence enables reliable downstream risk-aware applications.", "AI": {"tldr": "UGR\u63d0\u51fa\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u751f\u6210\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u52a0\u6743\u5956\u52b1\u3001\u96be\u5ea6\u611f\u77e5\u4f18\u5316\u548c\u663e\u5f0f\u7f6e\u4fe1\u5ea6\u5bf9\u9f50\u4e09\u4e2a\u673a\u5236\uff0c\u89e3\u51b3\u73b0\u6709\u751f\u6210\u63a8\u8350\u65b9\u6cd5\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u76f2\u89c6\u95ee\u9898\uff0c\u63d0\u5347\u63a8\u8350\u6027\u80fd\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u63a8\u8350\u65b9\u6cd5\u4f9d\u8d56\u4e8c\u5143\u7ed3\u679c\u6b63\u786e\u6027\uff0c\u5b58\u5728\"\u4e0d\u786e\u5b9a\u6027\u76f2\u89c6\"\u95ee\u9898\uff1a\u5ffd\u89c6\u6a21\u578b\u5185\u5728\u751f\u6210\u7f6e\u4fe1\u5ea6\u3001\u5ffd\u7565\u6837\u672c\u5b66\u4e60\u96be\u5ea6\u5dee\u5f02\u3001\u7f3a\u4e4f\u663e\u5f0f\u7f6e\u4fe1\u5ea6\u8868\u8fbe\uff0c\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u51b3\u7b56\u98ce\u9669\u4e0d\u53ef\u91cf\u5316\u3002", "method": "\u63d0\u51faUGR\u7edf\u4e00\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u534f\u540c\u673a\u5236\uff1a1) \u4e0d\u786e\u5b9a\u6027\u52a0\u6743\u5956\u52b1\u673a\u5236\uff0c\u60e9\u7f5a\u7f6e\u4fe1\u5ea6\u9ad8\u7684\u9519\u8bef\uff1b2) \u96be\u5ea6\u611f\u77e5\u4f18\u5316\u52a8\u6001\uff0c\u9632\u6b62\u8fc7\u65e9\u6536\u655b\uff1b3) \u663e\u5f0f\u7f6e\u4fe1\u5ea6\u5bf9\u9f50\uff0c\u8d4b\u4e88\u6a21\u578b\u7f6e\u4fe1\u5ea6\u8868\u8fbe\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660eUGR\u4e0d\u4ec5\u83b7\u5f97\u66f4\u4f18\u7684\u63a8\u8350\u6027\u80fd\uff0c\u800c\u4e14\u4ece\u6839\u672c\u4e0a\u7a33\u5b9a\u4e86\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u907f\u514d\u4e86\u6807\u51c6\u65b9\u6cd5\u4e2d\u5e38\u89c1\u7684\u6027\u80fd\u4e0b\u964d\u3002\u5b66\u4e60\u5230\u7684\u7f6e\u4fe1\u5ea6\u8fd8\u652f\u6301\u53ef\u9760\u7684\u4e0b\u6e38\u98ce\u9669\u611f\u77e5\u5e94\u7528\u3002", "conclusion": "UGR\u901a\u8fc7\u5c06\u4e0d\u786e\u5b9a\u6027\u4f5c\u4e3a\u5173\u952e\u4fe1\u53f7\u8fdb\u884c\u81ea\u9002\u5e94\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u751f\u6210\u63a8\u8350\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u76f2\u89c6\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u7a33\u5b9a\u3001\u66f4\u53ef\u9760\u7684\u63a8\u8350\u7cfb\u7edf\uff0c\u4e3a\u98ce\u9669\u611f\u77e5\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2602.11836", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.11836", "abs": "https://arxiv.org/abs/2602.11836", "authors": ["Alishbah Bashir", "Fatima Qaiser", "Ijaz Hussain"], "title": "ULTRA:Urdu Language Transformer-based Recommendation Architecture", "comment": null, "summary": "Urdu, as a low-resource language, lacks effective semantic content recommendation systems, particularly in the domain of personalized news retrieval. Existing approaches largely rely on lexical matching or language-agnostic techniques, which struggle to capture semantic intent and perform poorly under varying query lengths and information needs. This limitation results in reduced relevance and adaptability in Urdu content recommendation. We propose ULTRA (Urdu Language Transformer-based Recommendation Architecture),an adaptive semantic recommendation framework designed to address these challenges. ULTRA introduces a dual-embedding architecture with a query-length aware routing mechanism that dynamically distinguishes between short, intent-focused queries and longer, context-rich queries. Based on a threshold-driven decision process, user queries are routed to specialized semantic pipelines optimized for either title/headline-level or full-content/document level representations, ensuring appropriate semantic granularity during retrieval. The proposed system leverages transformer-based embeddings and optimized pooling strategies to move beyond surface-level keyword matching and enable context-aware similarity search. Extensive experiments conducted on a large-scale Urdu news corpus demonstrate that the proposed architecture consistently improves recommendation relevance across diverse query types. Results show gains in precision above 90% compared to single-pipeline baselines, highlighting the effectiveness of query-adaptive semantic alignment for low-resource languages. The findings establish ULTRA as a robust and generalizable content recommendation architecture, offering practical design insights for semantic retrieval systems in low-resource language settings.", "AI": {"tldr": "ULTRA\u662f\u4e00\u4e2a\u9488\u5bf9\u4e4c\u5c14\u90fd\u8bed\u7684\u8bed\u4e49\u5185\u5bb9\u63a8\u8350\u6846\u67b6\uff0c\u91c7\u7528\u53cc\u5d4c\u5165\u67b6\u6784\u548c\u67e5\u8be2\u957f\u5ea6\u611f\u77e5\u8def\u7531\u673a\u5236\uff0c\u52a8\u6001\u533a\u5206\u77ed\u67e5\u8be2\u548c\u957f\u67e5\u8be2\uff0c\u901a\u8fc7\u4e13\u95e8\u7684\u8bed\u4e49\u7ba1\u9053\u4f18\u5316\u63a8\u8350\u6548\u679c\u3002", "motivation": "\u4e4c\u5c14\u90fd\u8bed\u4f5c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\uff0c\u7f3a\u4e4f\u6709\u6548\u7684\u8bed\u4e49\u5185\u5bb9\u63a8\u8350\u7cfb\u7edf\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u8bcd\u6c47\u5339\u914d\u6216\u8bed\u8a00\u65e0\u5173\u6280\u672f\uff0c\u96be\u4ee5\u6355\u6349\u8bed\u4e49\u610f\u56fe\uff0c\u5728\u4e0d\u540c\u67e5\u8be2\u957f\u5ea6\u548c\u4fe1\u606f\u9700\u6c42\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u5bfc\u81f4\u63a8\u8350\u76f8\u5173\u6027\u548c\u9002\u5e94\u6027\u964d\u4f4e\u3002", "method": "\u63d0\u51faULTRA\u6846\u67b6\uff0c\u91c7\u7528\u53cc\u5d4c\u5165\u67b6\u6784\u548c\u67e5\u8be2\u957f\u5ea6\u611f\u77e5\u8def\u7531\u673a\u5236\u3002\u57fa\u4e8e\u9608\u503c\u9a71\u52a8\u7684\u51b3\u7b56\u8fc7\u7a0b\uff0c\u7528\u6237\u67e5\u8be2\u88ab\u8def\u7531\u5230\u4e13\u95e8\u4f18\u5316\u7684\u8bed\u4e49\u7ba1\u9053\uff1a\u9488\u5bf9\u6807\u9898/\u6807\u9898\u7ea7\u522b\u6216\u5b8c\u6574\u5185\u5bb9/\u6587\u6863\u7ea7\u522b\u7684\u8868\u793a\u3002\u5229\u7528\u57fa\u4e8eTransformer\u7684\u5d4c\u5165\u548c\u4f18\u5316\u7684\u6c60\u5316\u7b56\u7565\uff0c\u5b9e\u73b0\u8d85\u8d8a\u8868\u9762\u5173\u952e\u8bcd\u5339\u914d\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u76f8\u4f3c\u6027\u641c\u7d22\u3002", "result": "\u5728\u5927\u89c4\u6a21\u4e4c\u5c14\u90fd\u8bed\u65b0\u95fb\u8bed\u6599\u5e93\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u67b6\u6784\u5728\u4e0d\u540c\u67e5\u8be2\u7c7b\u578b\u4e0a\u6301\u7eed\u63d0\u9ad8\u63a8\u8350\u76f8\u5173\u6027\u3002\u4e0e\u5355\u7ba1\u9053\u57fa\u7ebf\u76f8\u6bd4\uff0c\u7cbe\u786e\u5ea6\u63d0\u5347\u8d85\u8fc790%\uff0c\u8bc1\u660e\u4e86\u67e5\u8be2\u81ea\u9002\u5e94\u8bed\u4e49\u5bf9\u9f50\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u6709\u6548\u6027\u3002", "conclusion": "ULTRA\u662f\u4e00\u4e2a\u7a33\u5065\u4e14\u53ef\u63a8\u5e7f\u7684\u5185\u5bb9\u63a8\u8350\u67b6\u6784\uff0c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u73af\u5883\u4e0b\u7684\u8bed\u4e49\u68c0\u7d22\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8bbe\u8ba1\u89c1\u89e3\u3002"}}
{"id": "2602.11841", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.11841", "abs": "https://arxiv.org/abs/2602.11841", "authors": ["Moncef Garouani", "Josiane Mothe"], "title": "Improving Neural Retrieval with Attribution-Guided Query Rewriting", "comment": null, "summary": "Neural retrievers are effective but brittle: underspecified or ambiguous queries can misdirect ranking even when relevant documents exist. Existing approaches address this brittleness only partially: LLMs rewrite queries without retriever feedback, and explainability methods identify misleading tokens but are used for post-hoc analysis. We close this loop and propose an attribution-guided query rewriting method that uses token-level explanations to guide query rewriting. For each query, we compute gradient-based token attributions from the retriever and then use these scores as soft guidance in a structured prompt to an LLM that clarifies weak or misleading query components while preserving intent. Evaluated on BEIR collections, the resulting rewrites consistently improve retrieval effectiveness over strong baselines, with larger gains for implicit or ambiguous information needs.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5f52\u56e0\u5f15\u5bfc\u7684\u67e5\u8be2\u91cd\u5199\u65b9\u6cd5\uff0c\u5229\u7528\u68c0\u7d22\u5668\u7684\u68af\u5ea6\u5f52\u56e0\u5206\u6570\u6307\u5bfcLLM\u91cd\u5199\u67e5\u8be2\uff0c\u89e3\u51b3\u795e\u7ecf\u68c0\u7d22\u5668\u5bf9\u6a21\u7cca\u67e5\u8be2\u7684\u8106\u5f31\u6027\u95ee\u9898", "motivation": "\u795e\u7ecf\u68c0\u7d22\u5668\u867d\u7136\u6709\u6548\u4f46\u8106\u5f31\uff1a\u5f53\u67e5\u8be2\u8868\u8ff0\u4e0d\u660e\u786e\u6216\u6a21\u7cca\u65f6\uff0c\u5373\u4f7f\u5b58\u5728\u76f8\u5173\u6587\u6863\u4e5f\u53ef\u80fd\u5bfc\u81f4\u68c0\u7d22\u5931\u8d25\u3002\u73b0\u6709\u65b9\u6cd5\u4ec5\u90e8\u5206\u89e3\u51b3\u6b64\u95ee\u9898\uff1aLLM\u91cd\u5199\u67e5\u8be2\u65f6\u7f3a\u4e4f\u68c0\u7d22\u5668\u53cd\u9988\uff0c\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u4ec5\u7528\u4e8e\u4e8b\u540e\u5206\u6790", "method": "\u63d0\u51fa\u5f52\u56e0\u5f15\u5bfc\u7684\u67e5\u8be2\u91cd\u5199\u65b9\u6cd5\uff1a1) \u4e3a\u6bcf\u4e2a\u67e5\u8be2\u8ba1\u7b97\u68c0\u7d22\u5668\u7684\u68af\u5ea6\u5f52\u56e0\u5206\u6570\uff08token-level attributions\uff09\uff1b2) \u5c06\u8fd9\u4e9b\u5206\u6570\u4f5c\u4e3a\u8f6f\u6307\u5bfc\u6784\u5efa\u7ed3\u6784\u5316\u63d0\u793a\uff1b3) \u4f7f\u7528LLM\u57fa\u4e8e\u6b64\u63d0\u793a\u91cd\u5199\u67e5\u8be2\uff0c\u6f84\u6e05\u5f31\u6216\u8bef\u5bfc\u6027\u67e5\u8be2\u6210\u5206\u540c\u65f6\u4fdd\u6301\u539f\u59cb\u610f\u56fe", "result": "\u5728BEIR\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u8be5\u65b9\u6cd5\u751f\u6210\u7684\u67e5\u8be2\u91cd\u5199\u6301\u7eed\u63d0\u5347\u68c0\u7d22\u6548\u679c\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5bf9\u4e8e\u9690\u542b\u6216\u6a21\u7cca\u4fe1\u606f\u9700\u6c42\u7684\u67e5\u8be2\u63d0\u5347\u6548\u679c\u66f4\u663e\u8457", "conclusion": "\u901a\u8fc7\u5c06\u68c0\u7d22\u5668\u7684\u68af\u5ea6\u5f52\u56e0\u53cd\u9988\u6574\u5408\u5230\u67e5\u8be2\u91cd\u5199\u8fc7\u7a0b\u4e2d\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u795e\u7ecf\u68c0\u7d22\u5668\u5bf9\u6a21\u7cca\u67e5\u8be2\u7684\u8106\u5f31\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u4e0e\u67e5\u8be2\u91cd\u5199\u7684\u95ed\u73af\u6574\u5408"}}
{"id": "2602.11874", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.11874", "abs": "https://arxiv.org/abs/2602.11874", "authors": ["Antoine Gauquier", "Ioana Manolescu", "Pierre Senellart"], "title": "Efficient Crawling for Scalable Web Data Acquisition (Extended Version)", "comment": "Extended version of a paper published at the EDBT 2026 conference", "summary": "Journalistic fact-checking, as well as social or economic research, require analyzing high-quality statistics datasets (SDs, in short). However, retrieving SD corpora at scale may be hard, inefficient, or impossible, depending on how they are published online. To improve open statistics data accessibility, we present a focused Web crawling algorithm that retrieves as many targets, i.e., resources of certain types, as possible, from a given website, in an efficient and scalable way, by crawling (much) less than the full website. We show that optimally solving this problem is intractable, and propose an approach based on reinforcement learning, namely using sleeping bandits. We propose SB-CLASSIFIER, a crawler that efficiently learns which hyperlinks lead to pages that link to many targets, based on the paths leading to the links in their enclosing webpages. Our experiments on websites with millions of webpages show that our crawler is highly efficient, delivering high fractions of a site's targets while crawling only a small part.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684SB-CLASSIFIER\u722c\u866b\u7b97\u6cd5\uff0c\u9ad8\u6548\u83b7\u53d6\u7f51\u7ad9\u4e2d\u7684\u7edf\u8ba1\u6570\u636e\u8d44\u6e90\uff0c\u4ec5\u722c\u53d6\u5c11\u91cf\u7f51\u9875\u5373\u53ef\u83b7\u53d6\u5927\u90e8\u5206\u76ee\u6807\u8d44\u6e90", "motivation": "\u65b0\u95fb\u62a5\u9053\u4e8b\u5b9e\u6838\u67e5\u548c\u793e\u4f1a\u7ecf\u6d4e\u7814\u7a76\u9700\u8981\u9ad8\u8d28\u91cf\u7684\u7edf\u8ba1\u6570\u636e\uff0c\u4f46\u5927\u89c4\u6a21\u83b7\u53d6\u7edf\u8ba1\u6570\u636e\u8d44\u6e90\u901a\u5e38\u56f0\u96be\u3001\u4f4e\u6548\u6216\u4e0d\u53ef\u80fd\uff0c\u56e0\u4e3a\u6570\u636e\u53d1\u5e03\u65b9\u5f0f\u591a\u6837\u3002\u9700\u8981\u6539\u8fdb\u5f00\u653e\u7edf\u8ba1\u6570\u636e\u53ef\u8bbf\u95ee\u6027\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4e13\u6ce8\u7f51\u7edc\u722c\u866b\u7b97\u6cd5\uff0c\u4f7f\u7528sleeping bandits\u65b9\u6cd5\u3002SB-CLASSIFIER\u901a\u8fc7\u5b66\u4e60\u54ea\u4e9b\u8d85\u94fe\u63a5\u80fd\u5bfc\u5411\u5305\u542b\u5927\u91cf\u76ee\u6807\u8d44\u6e90\u7684\u9875\u9762\uff0c\u57fa\u4e8e\u94fe\u63a5\u6240\u5728\u7f51\u9875\u7684\u8def\u5f84\u4fe1\u606f\u8fdb\u884c\u51b3\u7b56\u3002", "result": "\u5728\u5305\u542b\u6570\u767e\u4e07\u7f51\u9875\u7684\u7f51\u7ad9\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u722c\u866b\u9ad8\u5ea6\u9ad8\u6548\uff0c\u4ec5\u722c\u53d6\u7f51\u7ad9\u7684\u4e00\u5c0f\u90e8\u5206\u5c31\u80fd\u83b7\u53d6\u5927\u90e8\u5206\u76ee\u6807\u8d44\u6e90\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u7edf\u8ba1\u6570\u636e\u8d44\u6e90\u83b7\u53d6\u7684\u6548\u7387\u95ee\u9898\uff0c\u901a\u8fc7\u667a\u80fd\u9009\u62e9\u722c\u53d6\u8def\u5f84\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5f00\u653e\u7edf\u8ba1\u6570\u636e\u53ef\u8bbf\u95ee\u6027\u3002"}}
{"id": "2602.11941", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.11941", "abs": "https://arxiv.org/abs/2602.11941", "authors": ["Benjamin Clavi\u00e9", "Atoof Shakir", "Jonah Turner", "Sean Lee", "Aamir Shakir", "Makoto P. Kato"], "title": "IncompeBench: A Permissively Licensed, Fine-Grained Benchmark for Music Information Retrieval", "comment": null, "summary": "Multimodal Information Retrieval has made significant progress in recent years, leveraging the increasingly strong multimodal abilities of deep pre-trained models to represent information across modalities. Music Information Retrieval (MIR), in particular, has considerably increased in quality, with neural representations of music even making its way into everyday life products. However, there is a lack of high-quality benchmarks for evaluating music retrieval performance. To address this issue, we introduce \\textbf{IncompeBench}, a carefully annotated benchmark comprising $1,574$ permissively licensed, high-quality music snippets, $500$ diverse queries, and over $125,000$ individual relevance judgements. These annotations were created through the use of a multi-stage pipeline, resulting in high agreement between human annotators and the generated data. The resulting datasets are publicly available at https://huggingface.co/datasets/mixedbread-ai/incompebench-strict and https://huggingface.co/datasets/mixedbread-ai/incompebench-lenient with the prompts available at https://github.com/mixedbread-ai/incompebench-programs.", "AI": {"tldr": "IncompeBench\u662f\u4e00\u4e2a\u9ad8\u8d28\u91cf\u7684\u97f3\u4e50\u4fe1\u606f\u68c0\u7d22\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b1,574\u4e2a\u97f3\u4e50\u7247\u6bb5\u3001500\u4e2a\u591a\u6837\u5316\u67e5\u8be2\u548c\u8d85\u8fc7125,000\u4e2a\u76f8\u5173\u6027\u6807\u6ce8\u3002", "motivation": "\u5c3d\u7ba1\u591a\u6a21\u6001\u4fe1\u606f\u68c0\u7d22\u548c\u97f3\u4e50\u4fe1\u606f\u68c0\u7d22\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u7684\u97f3\u4e50\u68c0\u7d22\u8bc4\u4f30\u57fa\u51c6\u3002\u73b0\u6709\u57fa\u51c6\u5728\u8d28\u91cf\u3001\u591a\u6837\u6027\u548c\u6807\u6ce8\u4e00\u81f4\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u591a\u9636\u6bb5\u6807\u6ce8\u6d41\u7a0b\u521b\u5efa\u57fa\u51c6\uff0c\u5305\u62ec1,574\u4e2a\u8bb8\u53ef\u5f00\u653e\u7684\u9ad8\u8d28\u91cf\u97f3\u4e50\u7247\u6bb5\u3001500\u4e2a\u591a\u6837\u5316\u67e5\u8be2\uff0c\u5e76\u751f\u6210\u8d85\u8fc7125,000\u4e2a\u4eba\u5de5\u76f8\u5173\u6027\u6807\u6ce8\uff0c\u786e\u4fdd\u6807\u6ce8\u8005\u95f4\u9ad8\u5ea6\u4e00\u81f4\u3002", "result": "\u521b\u5efa\u4e86IncompeBench\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u63d0\u4f9b\u4e25\u683c\u548c\u5bbd\u677e\u4e24\u4e2a\u7248\u672c\uff0c\u516c\u5f00\u5728Hugging Face\u548cGitHub\u4e0a\uff0c\u4e3a\u97f3\u4e50\u4fe1\u606f\u68c0\u7d22\u63d0\u4f9b\u53ef\u9760\u7684\u8bc4\u4f30\u5de5\u5177\u3002", "conclusion": "IncompeBench\u586b\u8865\u4e86\u97f3\u4e50\u4fe1\u606f\u68c0\u7d22\u9886\u57df\u9ad8\u8d28\u91cf\u57fa\u51c6\u7684\u7a7a\u767d\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u4fc3\u8fdb\u97f3\u4e50\u68c0\u7d22\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.12041", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.12041", "abs": "https://arxiv.org/abs/2602.12041", "authors": ["Heng Yu", "Xiangjun Zhou", "Jie Xia", "Heng Zhao", "Anxin Wu", "Yu Zhao", "Dongying Kong"], "title": "Compress, Cross and Scale: Multi-Level Compression Cross Networks for Efficient Scaling in Recommender Systems", "comment": "11 pages, 3 figures", "summary": "Modeling high-order feature interactions efficiently is a central challenge in click-through rate and conversion rate prediction. Modern industrial recommender systems are predominantly built upon deep learning recommendation models, where the interaction backbone plays a critical role in determining both predictive performance and system efficiency. However, existing interaction modules often struggle to simultaneously achieve strong interaction capacity, high computational efficiency, and good scalability, resulting in limited ROI when models are scaled under strict production constraints. In this work, we propose MLCC, a structured feature interaction architecture that organizes feature crosses through hierarchical compression and dynamic composition, which can efficiently capture high-order feature dependencies while maintaining favorable computational complexity. We further introduce MC-MLCC, a Multi-Channel extension that decomposes feature interactions into parallel subspaces, enabling efficient horizontal scaling with improved representation capacity and significantly reduced parameter growth. Extensive experiments on three public benchmarks and a large-scale industrial dataset show that our proposed models consistently outperform strong DLRM-style baselines by up to 0.52 AUC, while reducing model parameters and FLOPs by up to 26$\\times$ under comparable performance. Comprehensive scaling analyses demonstrate stable and predictable scaling behavior across embedding dimension, head number, and channel count, with channel-based scaling achieving substantially better efficiency than conventional embedding inflation. Finally, online A/B testing on a real-world advertising platform validates the practical effectiveness of our approach, which has been widely adopted in Bilibili advertising system under strict latency and resource constraints.", "AI": {"tldr": "MLCC\u662f\u4e00\u79cd\u7ed3\u6784\u5316\u7279\u5f81\u4ea4\u4e92\u67b6\u6784\uff0c\u901a\u8fc7\u5206\u5c42\u538b\u7f29\u548c\u52a8\u6001\u7ec4\u5408\u9ad8\u6548\u6355\u83b7\u9ad8\u9636\u7279\u5f81\u4f9d\u8d56\uff0c\u5176\u591a\u901a\u9053\u6269\u5c55MC-MLCC\u901a\u8fc7\u5e76\u884c\u5b50\u7a7a\u95f4\u5206\u89e3\u5b9e\u73b0\u9ad8\u6548\u6c34\u5e73\u6269\u5c55\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u53c2\u6570\u548c\u8ba1\u7b97\u91cf\u3002", "motivation": "\u73b0\u4ee3\u63a8\u8350\u7cfb\u7edf\u4e2d\uff0c\u73b0\u6709\u4ea4\u4e92\u6a21\u5757\u96be\u4ee5\u540c\u65f6\u5b9e\u73b0\u5f3a\u4ea4\u4e92\u80fd\u529b\u3001\u9ad8\u8ba1\u7b97\u6548\u7387\u548c\u826f\u597d\u53ef\u6269\u5c55\u6027\uff0c\u5bfc\u81f4\u5728\u4e25\u683c\u751f\u4ea7\u7ea6\u675f\u4e0b\u6a21\u578b\u6269\u5c55\u7684\u6295\u8d44\u56de\u62a5\u7387\u6709\u9650\u3002", "method": "\u63d0\u51faMLCC\u67b6\u6784\uff0c\u901a\u8fc7\u5206\u5c42\u538b\u7f29\u548c\u52a8\u6001\u7ec4\u5408\u7ec4\u7ec7\u7279\u5f81\u4ea4\u53c9\uff1b\u8fdb\u4e00\u6b65\u63d0\u51faMC-MLCC\u591a\u901a\u9053\u6269\u5c55\uff0c\u5c06\u7279\u5f81\u4ea4\u4e92\u5206\u89e3\u5230\u5e76\u884c\u5b50\u7a7a\u95f4\uff0c\u5b9e\u73b0\u9ad8\u6548\u6c34\u5e73\u6269\u5c55\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u57fa\u51c6\u548c\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\uff0c\u6a21\u578b\u6bd4DLRM\u57fa\u7ebf\u63d0\u5347\u6700\u591a0.52 AUC\uff0c\u540c\u65f6\u51cf\u5c11\u6700\u591a26\u500d\u53c2\u6570\u548cFLOPs\uff1b\u901a\u9053\u6269\u5c55\u6bd4\u4f20\u7edf\u5d4c\u5165\u81a8\u80c0\u6548\u7387\u66f4\u9ad8\uff1b\u5728\u7ebfA/B\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u5b9e\u9645\u6709\u6548\u6027\u3002", "conclusion": "MLCC\u548cMC-MLCC\u80fd\u591f\u9ad8\u6548\u6355\u83b7\u9ad8\u9636\u7279\u5f81\u4ea4\u4e92\uff0c\u5728\u4e25\u683c\u5ef6\u8fdf\u548c\u8d44\u6e90\u7ea6\u675f\u4e0b\u5b9e\u73b0\u66f4\u597d\u7684\u6027\u80fd-\u6548\u7387\u6743\u8861\uff0c\u5df2\u5728B\u7ad9\u5e7f\u544a\u7cfb\u7edf\u4e2d\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2602.12129", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.12129", "abs": "https://arxiv.org/abs/2602.12129", "authors": ["Rahin Arefin Ahmed", "Md. Anik Chowdhury", "Sakil Ahmed Sheikh Reza", "Devnil Bhattacharjee", "Muhammad Abdullah Adnan", "Nafis Sadeq"], "title": "Towards Personalized Bangla Book Recommendation: A Large-Scale Multi-Entity Book Graph Dataset", "comment": null, "summary": "Personalized book recommendation in Bangla literature has been constrained by the lack of structured, large-scale, and publicly available datasets. This work introduces RokomariBG, a large-scale, multi-entity heterogeneous book graph dataset designed to support research on personalized recommendation in a low-resource language setting. The dataset comprises 127,302 books, 63,723 users, 16,601 authors, 1,515 categories, 2,757 publishers, and 209,602 reviews, connected through eight relation types and organized as a comprehensive knowledge graph.\n  To demonstrate the utility of the dataset, we provide a systematic benchmarking study on the Top-N recommendation task, evaluating a diverse set of representative recommendation models, including classical collaborative filtering methods, matrix factorization models, content-based approaches, graph neural networks, a hybrid matrix factorization model with side information, and a neural two-tower retrieval architecture. The benchmarking results highlight the importance of leveraging multi-relational structure and textual side information, with neural retrieval models achieving the strongest performance (NDCG@10 = 0.204). Overall, this work establishes a foundational benchmark and a publicly available resource for Bangla book recommendation research, enabling reproducible evaluation and future studies on recommendation in low-resource cultural domains. The dataset and code are publicly available at https://github.com/backlashblitz/Bangla-Book-Recommendation-Dataset", "AI": {"tldr": "\u63d0\u51fa\u4e86RokomariBG\uff0c\u4e00\u4e2a\u5927\u89c4\u6a21\u5b5f\u52a0\u62c9\u8bed\u56fe\u4e66\u63a8\u8350\u6570\u636e\u96c6\uff0c\u5305\u542b12.7\u4e07\u672c\u4e66\u30016.3\u4e07\u7528\u6237\u7b49\u5b9e\u4f53\uff0c\u5e76\u8fdb\u884c\u4e86\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\uff0c\u795e\u7ecf\u68c0\u7d22\u6a21\u578b\u8868\u73b0\u6700\u4f73", "motivation": "\u5b5f\u52a0\u62c9\u8bed\u6587\u5b66\u9886\u57df\u7684\u4e2a\u6027\u5316\u56fe\u4e66\u63a8\u8350\u7814\u7a76\u53d7\u5230\u7f3a\u4e4f\u7ed3\u6784\u5316\u3001\u5927\u89c4\u6a21\u516c\u5f00\u6570\u636e\u96c6\u7684\u9650\u5236\uff0c\u9700\u8981\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u73af\u5883\u63d0\u4f9b\u57fa\u7840\u6570\u636e\u96c6", "method": "\u6784\u5efa\u4e86RokomariBG\u6570\u636e\u96c6\uff0c\u5305\u542b\u4e66\u7c4d\u3001\u7528\u6237\u3001\u4f5c\u8005\u3001\u7c7b\u522b\u3001\u51fa\u7248\u5546\u3001\u8bc4\u8bba\u7b49\u591a\u5b9e\u4f53\u5f02\u6784\u56fe\uff0c\u5305\u542b8\u79cd\u5173\u7cfb\u7c7b\u578b\u3002\u4f7f\u7528\u591a\u79cd\u63a8\u8350\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u62ec\u534f\u540c\u8fc7\u6ee4\u3001\u77e9\u9635\u5206\u89e3\u3001\u57fa\u4e8e\u5185\u5bb9\u7684\u65b9\u6cd5\u3001\u56fe\u795e\u7ecf\u7f51\u7edc\u3001\u6df7\u5408\u6a21\u578b\u548c\u795e\u7ecf\u53cc\u5854\u68c0\u7d22\u67b6\u6784", "result": "\u795e\u7ecf\u68c0\u7d22\u6a21\u578b\u5728Top-N\u63a8\u8350\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f73\uff08NDCG@10 = 0.204\uff09\uff0c\u5229\u7528\u591a\u5173\u7cfb\u7ed3\u6784\u548c\u6587\u672c\u4fa7\u4fe1\u606f\u5bf9\u63d0\u5347\u63a8\u8350\u6027\u80fd\u5f88\u91cd\u8981\u3002\u5efa\u7acb\u4e86\u5b5f\u52a0\u62c9\u8bed\u56fe\u4e66\u63a8\u8350\u7814\u7a76\u7684\u57fa\u7840\u57fa\u51c6", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5b5f\u52a0\u62c9\u8bed\u56fe\u4e66\u63a8\u8350\u7814\u7a76\u63d0\u4f9b\u4e86\u516c\u5f00\u53ef\u7528\u7684\u57fa\u7840\u8d44\u6e90\uff0c\u652f\u6301\u53ef\u91cd\u590d\u8bc4\u4f30\u548c\u672a\u6765\u5728\u4f4e\u8d44\u6e90\u6587\u5316\u9886\u57df\u7684\u63a8\u8350\u7814\u7a76\uff0c\u6570\u636e\u96c6\u548c\u4ee3\u7801\u5df2\u516c\u5f00"}}
{"id": "2602.12187", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.12187", "abs": "https://arxiv.org/abs/2602.12187", "authors": ["Sunghwan Kim", "Wooseok Jeong", "Serin Kim", "Sangam Lee", "Dongha Lee"], "title": "SAGEO Arena: A Realistic Environment for Evaluating Search-Augmented Generative Engine Optimization", "comment": "Work in Progress", "summary": "Search-Augmented Generative Engines (SAGE) have emerged as a new paradigm for information access, bridging web-scale retrieval with generative capabilities to deliver synthesized answers. This shift has fundamentally reshaped how web content gains exposure online, giving rise to Search-Augmented Generative Engine Optimization (SAGEO), the practice of optimizing web documents to improve their visibility in AI-generated responses. Despite growing interest, no evaluation environment currently supports comprehensive investigation of SAGEO. Specifically, existing benchmarks lack end-to-end visibility evaluation of optimization strategies, operating on pre-determined candidate documents that abstract away retrieval and reranking preceding generation. Moreover, existing benchmarks discard structural information (e.g., schema markup) present in real web documents, overlooking the rich signals that search systems actively leverage in practice. Motivated by these gaps, we introduce SAGEO Arena, a realistic and reproducible environment for stage-level SAGEO analysis. Our objective is to jointly target search-oriented optimization (SEO) and generation-centric optimization (GEO). To achieve this, we integrate a full generative search pipeline over a large-scale corpus of web documents with rich structural information. Our findings reveal that existing approaches remain largely impractical under realistic conditions and often degrade performance in retrieval and reranking. We also find that structural information helps mitigate these limitations, and that effective SAGEO requires tailoring optimization to each pipeline stage. Overall, our benchmark paves the way for realistic SAGEO evaluation and optimization beyond simplified settings.", "AI": {"tldr": "SAGEO Arena\uff1a\u9996\u4e2a\u7528\u4e8e\u641c\u7d22\u589e\u5f3a\u751f\u6210\u5f15\u64ce\u4f18\u5316\uff08SAGEO\uff09\u7684\u7aef\u5230\u7aef\u8bc4\u4f30\u73af\u5883\uff0c\u6574\u5408\u68c0\u7d22\u3001\u91cd\u6392\u5e8f\u548c\u751f\u6210\u5168\u6d41\u7a0b\uff0c\u652f\u6301\u5305\u542b\u7ed3\u6784\u5316\u4fe1\u606f\u7684\u771f\u5b9e\u7f51\u9875\u6587\u6863\u4f18\u5316\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709SAGEO\u8bc4\u4f30\u73af\u5883\u5b58\u5728\u4e09\u5927\u7f3a\u9677\uff1a1\uff09\u7f3a\u4e4f\u7aef\u5230\u7aef\u53ef\u89c1\u6027\u8bc4\u4f30\uff0c\u4ec5\u57fa\u4e8e\u9884\u9009\u6587\u6863\uff1b2\uff09\u5ffd\u7565\u68c0\u7d22\u548c\u91cd\u6392\u5e8f\u73af\u8282\uff1b3\uff09\u4e22\u5f03\u7f51\u9875\u6587\u6863\u7684\u7ed3\u6784\u5316\u4fe1\u606f\uff08\u5982schema\u6807\u8bb0\uff09\u3002\u8fd9\u4e9b\u9650\u5236\u4f7f\u5f97\u73b0\u6709\u65b9\u6cd5\u5728\u771f\u5b9e\u6761\u4ef6\u4e0b\u4e0d\u5b9e\u7528\u3002", "method": "\u63d0\u51faSAGEO Arena\u8bc4\u4f30\u73af\u5883\uff0c\u6574\u5408\u5b8c\u6574\u7684\u751f\u6210\u5f0f\u641c\u7d22\u6d41\u6c34\u7ebf\uff0c\u57fa\u4e8e\u5305\u542b\u4e30\u5bcc\u7ed3\u6784\u5316\u4fe1\u606f\u7684\u5927\u89c4\u6a21\u7f51\u9875\u6587\u6863\u8bed\u6599\u5e93\uff0c\u652f\u6301\u5206\u9636\u6bb5\u7684SAGEO\u5206\u6790\uff0c\u540c\u65f6\u9488\u5bf9\u641c\u7d22\u4f18\u5316\uff08SEO\uff09\u548c\u751f\u6210\u4f18\u5316\uff08GEO\uff09\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u73b0\u6709\u65b9\u6cd5\u5728\u771f\u5b9e\u6761\u4ef6\u4e0b\u5927\u591a\u4e0d\u5b9e\u7528\uff0c\u5e38\u635f\u5bb3\u68c0\u7d22\u548c\u91cd\u6392\u5e8f\u6027\u80fd\uff1b2\uff09\u7ed3\u6784\u5316\u4fe1\u606f\u6709\u52a9\u4e8e\u7f13\u89e3\u8fd9\u4e9b\u9650\u5236\uff1b3\uff09\u6709\u6548\u7684SAGEO\u9700\u8981\u9488\u5bf9\u6d41\u6c34\u7ebf\u6bcf\u4e2a\u9636\u6bb5\u8fdb\u884c\u5b9a\u5236\u5316\u4f18\u5316\u3002", "conclusion": "SAGEO Arena\u4e3a\u8d85\u8d8a\u7b80\u5316\u8bbe\u7f6e\u7684\u73b0\u5b9eSAGEO\u8bc4\u4f30\u548c\u4f18\u5316\u94fa\u5e73\u9053\u8def\uff0c\u63ed\u793a\u4e86\u7ed3\u6784\u5316\u4fe1\u606f\u7684\u91cd\u8981\u6027\u4ee5\u53ca\u5206\u9636\u6bb5\u4f18\u5316\u7b56\u7565\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2602.12278", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.12278", "abs": "https://arxiv.org/abs/2602.12278", "authors": ["David Jiahao Fu", "Lam Thanh Do", "Jiayu Li", "Kevin Chen-Chuan Chang"], "title": "AttentionRetriever: Attention Layers are Secretly Long Document Retrievers", "comment": null, "summary": "Retrieval augmented generation (RAG) has been widely adopted to help Large Language Models (LLMs) to process tasks involving long documents. However, existing retrieval models are not designed for long document retrieval and fail to address several key challenges of long document retrieval, including context-awareness, causal dependence, and scope of retrieval. In this paper, we proposed AttentionRetriever, a novel long document retrieval model that leverages attention mechanism and entity-based retrieval to build context-aware embeddings for long document and determine the scope of retrieval. With extensive experiments, we found AttentionRetriever is able to outperform existing retrieval models on long document retrieval datasets by a large margin while remaining as efficient as dense retrieval models.", "AI": {"tldr": "AttentionRetriever\uff1a\u5229\u7528\u6ce8\u610f\u529b\u673a\u5236\u548c\u57fa\u4e8e\u5b9e\u4f53\u7684\u68c0\u7d22\uff0c\u4e3a\u957f\u6587\u6863\u6784\u5efa\u4e0a\u4e0b\u6587\u611f\u77e5\u5d4c\u5165\u5e76\u786e\u5b9a\u68c0\u7d22\u8303\u56f4\u7684\u65b0\u578b\u957f\u6587\u6863\u68c0\u7d22\u6a21\u578b", "motivation": "\u73b0\u6709\u68c0\u7d22\u6a21\u578b\u5e76\u975e\u4e3a\u957f\u6587\u6863\u68c0\u7d22\u8bbe\u8ba1\uff0c\u65e0\u6cd5\u89e3\u51b3\u957f\u6587\u6863\u68c0\u7d22\u7684\u5173\u952e\u6311\u6218\uff0c\u5305\u62ec\u4e0a\u4e0b\u6587\u611f\u77e5\u3001\u56e0\u679c\u4f9d\u8d56\u548c\u68c0\u7d22\u8303\u56f4\u786e\u5b9a\u7b49\u95ee\u9898", "method": "\u63d0\u51faAttentionRetriever\u6a21\u578b\uff0c\u7ed3\u5408\u6ce8\u610f\u529b\u673a\u5236\u548c\u57fa\u4e8e\u5b9e\u4f53\u7684\u68c0\u7d22\uff0c\u4e3a\u957f\u6587\u6863\u6784\u5efa\u4e0a\u4e0b\u6587\u611f\u77e5\u5d4c\u5165\uff0c\u5e76\u786e\u5b9a\u9002\u5f53\u7684\u68c0\u7d22\u8303\u56f4", "result": "\u5728\u957f\u6587\u6863\u68c0\u7d22\u6570\u636e\u96c6\u4e0a\u5927\u5e45\u4f18\u4e8e\u73b0\u6709\u68c0\u7d22\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u5bc6\u96c6\u68c0\u7d22\u6a21\u578b\u76f8\u5f53\u7684\u6548\u7387", "conclusion": "AttentionRetriever\u6709\u6548\u89e3\u51b3\u4e86\u957f\u6587\u6863\u68c0\u7d22\u7684\u5173\u952e\u6311\u6218\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u65b9\u9762\u90fd\u8868\u73b0\u51fa\u8272\uff0c\u4e3aRAG\u7cfb\u7edf\u4e2d\u7684\u957f\u6587\u6863\u5904\u7406\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848"}}
