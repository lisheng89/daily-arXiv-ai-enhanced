<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 4]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [The Personalization Paradox: Semantic Loss vs. Reasoning Gains in Agentic AI Q&A](https://arxiv.org/abs/2512.04343)
*Satyajit Movidi,Stephen Russell*

Main category: cs.IR

TL;DR: 研究比较了个性化与非个性化AI顾问系统配置，发现个性化在推理质量和事实基础方面有提升，但会降低语义相似度得分，揭示了当前LLM评估方法的结构性缺陷。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索个性化如何影响AI学生顾问系统的性能，特别是在不同评估维度上的表现，以了解个性化对系统效果的实际影响。

Method: 使用AIVisor代理检索增强LLM，设计了12个真实咨询问题，比较10种个性化与非个性化配置，采用线性混合效应模型分析词汇、语义和事实基础三个维度的评估指标。

Result: 结果显示个性化在推理质量和事实基础方面有可靠提升，但在语义相似度上产生显著负面交互效应，这主要是由于当前评估指标会惩罚与通用参考文本有意义的个性化偏差。

Conclusion: 个性化产生的是指标依赖的转变而非统一改进，揭示了当前LLM评估方法不适用于评估用户特定响应的结构性缺陷，为更透明稳健的个性化AI提供了方法论基础。

Abstract: AIVisor, an agentic retrieval-augmented LLM for student advising, was used to examine how personalization affects system performance across multiple evaluation dimensions. Using twelve authentic advising questions intentionally designed to stress lexical precision, we compared ten personalized and non-personalized system configurations and analyzed outcomes with a Linear Mixed-Effects Model across lexical (BLEU, ROUGE-L), semantic (METEOR, BERTScore), and grounding (RAGAS) metrics. Results showed a consistent trade-off: personalization reliably improved reasoning quality and grounding, yet introduced a significant negative interaction on semantic similarity, driven not by poorer answers but by the limits of current metrics, which penalize meaningful personalized deviations from generic reference texts. This reveals a structural flaw in prevailing LLM evaluation methods, which are ill-suited for assessing user-specific responses. The fully integrated personalized configuration produced the highest overall gains, suggesting that personalization can enhance system effectiveness when evaluated with appropriate multidimensional metrics. Overall, the study demonstrates that personalization produces metric-dependent shifts rather than uniform improvements and provides a methodological foundation for more transparent and robust personalization in agentic AI.

</details>


### [2] [UserSimCRS v2: Simulation-Based Evaluation for Conversational Recommender Systems](https://arxiv.org/abs/2512.04588)
*Nolwenn Bernard,Krisztian Balog*

Main category: cs.IR

TL;DR: UserSimCRS v2是对话推荐系统评估工具包的重大升级，包含增强的用户模拟器、LLM模拟器、更广泛的系统集成和新的评估工具


<details>
  <summary>Details</summary>
Motivation: 对话推荐系统的仿真评估资源稀缺，需要更新工具包以跟上最新研究进展

Method: 开发UserSimCRS v2，包含：增强的议程式用户模拟器、引入基于大语言模型的模拟器、扩展CRS和数据集集成、新增LLM-as-a-judge评估工具

Result: 通过案例研究展示了这些扩展功能的有效性

Conclusion: UserSimCRS v2显著提升了对话推荐系统仿真评估的能力，与最新研究保持同步

Abstract: Resources for simulation-based evaluation of conversational recommender systems (CRSs) are scarce. The UserSimCRS toolkit was introduced to address this gap. In this work, we present UserSimCRS v2, a significant upgrade aligning the toolkit with state-of-the-art research. Key extensions include an enhanced agenda-based user simulator, introduction of large language model-based simulators, integration for a wider range of CRSs and datasets, and new LLM-as-a-judge evaluation utilities. We demonstrate these extensions in a case study.

</details>


### [3] [Spatially-Enhanced Retrieval-Augmented Generation for Walkability and Urban Discovery](https://arxiv.org/abs/2512.04790)
*Maddalena Amendola,Chiara Pugliese,Raffaele Perego,Chiara Renso*

Main category: cs.IR

TL;DR: WalkRAG是一个基于空间检索增强生成（RAG）的对话式框架，用于推荐可步行的城市行程路线，结合信息检索、空间推理和LLM来支持城市探索。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）在人工智能中已成为基础工具，广泛应用于城市系统和旅游推荐等领域，但它们存在幻觉问题以及在空间检索和推理方面的局限性，需要新的解决方案来克服这些缺陷。

Method: 提出WalkRAG框架，这是一种基于空间检索增强生成（RAG）的方法，具有对话式界面。该框架扩展了RAG方法以处理涉及地理理解的任务，允许用户根据特定的空间约束和偏好请求路线，并交互式检索沿途路径和兴趣点（POI）的信息。

Result: 初步结果表明，结合信息检索、空间推理和LLM的方法在支持城市探索方面是有效的，能够为用户提供满足特定需求的步行路线推荐。

Conclusion: WalkRAG展示了空间RAG框架在推荐可步行城市行程方面的潜力，通过整合信息检索、空间推理和LLM能力，为解决LLM在空间任务中的局限性提供了有前景的解决方案。

Abstract: Large Language Models (LLMs) have become foundational tools in artificial intelligence, supporting a wide range of applications beyond traditional natural language processing, including urban systems and tourist recommendations. However, their tendency to hallucinate and their limitations in spatial retrieval and reasoning are well known, pointing to the need for novel solutions. Retrieval-augmented generation (RAG) has recently emerged as a promising way to enhance LLMs with accurate, domain-specific, and timely information. Spatial RAG extends this approach to tasks involving geographic understanding. In this work, we introduce WalkRAG, a spatial RAG-based framework with a conversational interface for recommending walkable urban itineraries. Users can request routes that meet specific spatial constraints and preferences while interactively retrieving information about the path and points of interest (POIs) along the way. Preliminary results show the effectiveness of combining information retrieval, spatial reasoning, and LLMs to support urban discovery.

</details>


### [4] [Ask Safely: Privacy-Aware LLM Query Generation for Knowledge Graphs](https://arxiv.org/abs/2512.04852)
*Mauro Dalle Lucca Tosi,Jordi Cabot*

Main category: cs.IR

TL;DR: 提出一种保护隐私的知识图谱查询生成方法，通过识别并省略图谱中的敏感信息，再使用LLM将自然语言问题转换为Cypher查询


<details>
  <summary>Details</summary>
Motivation: 当知识图谱包含敏感数据且用户无法部署本地生成式LLM时，现有LLM查询方法存在隐私泄露风险，需要保护敏感信息不被传输到第三方服务

Method: 基于图谱结构识别敏感信息，在请求LLM将自然语言问题转换为Cypher查询前，省略这些敏感值，从而保护隐私

Result: 实验结果表明，该方法在保持生成查询质量的同时，有效防止敏感数据传输到第三方服务

Conclusion: 提出的隐私感知查询生成方法解决了敏感知识图谱查询中的隐私保护问题，平衡了查询质量与数据安全

Abstract: Large Language Models (LLMs) are increasingly used to query knowledge graphs (KGs) due to their strong semantic understanding and extrapolation capabilities compared to traditional approaches. However, these methods cannot be applied when the KG contains sensitive data and the user lacks the resources to deploy a local generative LLM. To address this issue, we propose a privacy-aware query generation approach for KGs. Our method identifies sensitive information in the graph based on its structure and omits such values before requesting the LLM to translate natural language questions into Cypher queries. Experimental results show that our approach preserves the quality of the generated queries while preventing sensitive data from being transmitted to third-party services.

</details>
