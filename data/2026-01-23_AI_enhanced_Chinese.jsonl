{"id": "2601.15484", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.15484", "abs": "https://arxiv.org/abs/2601.15484", "authors": ["Philipp Eibl", "Erica Coppolillo", "Simone Mungari", "Luca Luceri"], "title": "Is Grokipedia Right-Leaning? Comparing Political Framing in Wikipedia and Grokipedia on Controversial Topics", "comment": null, "summary": "Online encyclopedias are central to contemporary information infrastructures and have become focal points of debates over ideological bias. Wikipedia, in particular, has long been accused of left-leaning bias, while Grokipedia, an AI-generated encyclopedia launched by xAI, has been framed as a right-leaning alternative. This paper presents a comparative analysis of Wikipedia and Grokipedia on well-established politically contested topics. Specifically, we examine differences in semantic framing, political orientation, and content prioritization. We find that semantic similarity between the two platforms decays across article sections and diverges more strongly on controversial topics than on randomly sampled ones. Additionally, we show that both encyclopedias predominantly exhibit left-leaning framings, although Grokipedia exhibits a more bimodal distribution with increased prominence of right-leaning content. The experimental code is publicly available.", "AI": {"tldr": "\u6bd4\u8f83\u5206\u6790\u7ef4\u57fa\u767e\u79d1\u548cGrokipedia\u5728\u653f\u6cbb\u4e89\u8bae\u8bdd\u9898\u4e0a\u7684\u5dee\u5f02\uff0c\u53d1\u73b0\u4e24\u8005\u8bed\u4e49\u76f8\u4f3c\u5ea6\u968f\u6587\u7ae0\u7ae0\u8282\u9012\u51cf\uff0c\u5728\u4e89\u8bae\u8bdd\u9898\u4e0a\u5206\u6b67\u66f4\u5927\uff0c\u4e14\u4e24\u8005\u90fd\u4e3b\u8981\u5448\u73b0\u5de6\u503e\u6846\u67b6\uff0c\u4f46Grokipedia\u5448\u73b0\u66f4\u660e\u663e\u7684\u53cc\u5cf0\u5206\u5e03\u5e76\u5305\u542b\u66f4\u591a\u53f3\u503e\u5185\u5bb9\u3002", "motivation": "\u5728\u7ebf\u767e\u79d1\u5168\u4e66\u662f\u73b0\u4ee3\u4fe1\u606f\u57fa\u7840\u8bbe\u65bd\u7684\u6838\u5fc3\uff0c\u5e38\u6d89\u53ca\u610f\u8bc6\u5f62\u6001\u504f\u89c1\u4e89\u8bae\u3002\u7ef4\u57fa\u767e\u79d1\u957f\u671f\u88ab\u6307\u8d23\u6709\u5de6\u503e\u504f\u89c1\uff0c\u800cxAI\u63a8\u51fa\u7684AI\u751f\u6210\u767e\u79d1\u5168\u4e66Grokipedia\u5219\u88ab\u89c6\u4e3a\u53f3\u503e\u66ff\u4ee3\u54c1\u3002\u672c\u7814\u7a76\u65e8\u5728\u6bd4\u8f83\u5206\u6790\u8fd9\u4e24\u4e2a\u5e73\u53f0\u5728\u653f\u6cbb\u4e89\u8bae\u8bdd\u9898\u4e0a\u7684\u5dee\u5f02\u3002", "method": "\u5bf9\u7ef4\u57fa\u767e\u79d1\u548cGrokipedia\u5728\u5df2\u786e\u7acb\u7684\u653f\u6cbb\u4e89\u8bae\u8bdd\u9898\u4e0a\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\uff0c\u5177\u4f53\u8003\u5bdf\u8bed\u4e49\u6846\u67b6\u3001\u653f\u6cbb\u503e\u5411\u548c\u5185\u5bb9\u4f18\u5148\u7ea7\u7684\u5dee\u5f02\u3002\u4f7f\u7528\u8bed\u4e49\u76f8\u4f3c\u5ea6\u5206\u6790\u3001\u653f\u6cbb\u503e\u5411\u68c0\u6d4b\u7b49\u65b9\u6cd5\u3002", "result": "1. \u4e24\u4e2a\u5e73\u53f0\u7684\u8bed\u4e49\u76f8\u4f3c\u5ea6\u968f\u6587\u7ae0\u7ae0\u8282\u9012\u51cf\uff1b2. \u5728\u4e89\u8bae\u8bdd\u9898\u4e0a\u7684\u5206\u6b67\u6bd4\u968f\u673a\u62bd\u6837\u8bdd\u9898\u66f4\u5927\uff1b3. \u4e24\u4e2a\u767e\u79d1\u5168\u4e66\u90fd\u4e3b\u8981\u5448\u73b0\u5de6\u503e\u6846\u67b6\uff1b4. Grokipedia\u5448\u73b0\u66f4\u660e\u663e\u7684\u53cc\u5cf0\u5206\u5e03\uff0c\u53f3\u503e\u5185\u5bb9\u66f4\u7a81\u51fa\u3002", "conclusion": "\u7ef4\u57fa\u767e\u79d1\u548cGrokipedia\u5728\u653f\u6cbb\u4e89\u8bae\u8bdd\u9898\u4e0a\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u867d\u7136\u4e24\u8005\u90fd\u4e3b\u8981\u5448\u73b0\u5de6\u503e\u6846\u67b6\uff0c\u4f46Grokipedia\u5305\u542b\u66f4\u591a\u53f3\u503e\u5185\u5bb9\uff0c\u5448\u73b0\u66f4\u660e\u663e\u7684\u610f\u8bc6\u5f62\u6001\u53cc\u5cf0\u5206\u5e03\u3002\u5b9e\u9a8c\u4ee3\u7801\u5df2\u516c\u5f00\u3002"}}
{"id": "2601.15518", "categories": ["cs.IR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.15518", "abs": "https://arxiv.org/abs/2601.15518", "authors": ["Wenxin Zhou", "Ritesh Mehta", "Anthony Miyaguchi"], "title": "DS@GT at TREC TOT 2025: Bridging Vague Recollection with Fusion Retrieval and Learned Reranking", "comment": "Paper submitted to TREC 2025 (34th Text REtrieval Conference)", "summary": "We develop a two-stage retrieval system that combines multiple complementary retrieval methods with a learned reranker and LLM-based reranking, to address the TREC Tip-of-the-Tongue (ToT) task. In the first stage, we employ hybrid retrieval that merges LLM-based retrieval, sparse (BM25), and dense (BGE-M3) retrieval methods. We also introduce topic-aware multi-index dense retrieval that partitions the Wikipedia corpus into 24 topical domains. In the second stage, we evaluate both a trained LambdaMART reranker and LLM-based reranking. To support model training, we generate 5000 synthetic ToT queries using LLMs. Our best system achieves recall of 0.66 and NDCG@1000 of 0.41 on the test set by combining hybrid retrieval with Gemini-2.5-flash reranking, demonstrating the effectiveness of fusion retrieval.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5\u68c0\u7d22\u7cfb\u7edf\uff0c\u7ed3\u5408\u591a\u79cd\u68c0\u7d22\u65b9\u6cd5\u4e0e\u5b66\u4e60\u578b\u91cd\u6392\u5e8f\u5668\u53caLLM\u91cd\u6392\u5e8f\uff0c\u7528\u4e8eTREC Tip-of-the-Tongue\u4efb\u52a1\uff0c\u901a\u8fc7\u6df7\u5408\u68c0\u7d22\u548cGemini-2.5-flash\u91cd\u6392\u5e8f\u8fbe\u5230\u6700\u4f73\u6548\u679c", "motivation": "\u89e3\u51b3TREC Tip-of-the-Tongue\uff08\u8bdd\u5230\u5634\u8fb9\uff09\u4efb\u52a1\u7684\u68c0\u7d22\u6311\u6218\uff0c\u8be5\u4efb\u52a1\u9700\u8981\u4ece\u6a21\u7cca\u8bb0\u5fc6\u4e2d\u68c0\u7d22\u5177\u4f53\u4fe1\u606f\uff0c\u4f20\u7edf\u5355\u4e00\u68c0\u7d22\u65b9\u6cd5\u6548\u679c\u6709\u9650", "method": "\u4e24\u9636\u6bb5\u68c0\u7d22\u7cfb\u7edf\uff1a\u7b2c\u4e00\u9636\u6bb5\u91c7\u7528\u6df7\u5408\u68c0\u7d22\uff0c\u7ed3\u5408LLM\u68c0\u7d22\u3001\u7a00\u758f\u68c0\u7d22\uff08BM25\uff09\u548c\u7a20\u5bc6\u68c0\u7d22\uff08BGE-M3\uff09\uff0c\u5e76\u5f15\u5165\u4e3b\u9898\u611f\u77e5\u591a\u7d22\u5f15\u7a20\u5bc6\u68c0\u7d22\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u8bad\u7ec3\u597d\u7684LambdaMART\u91cd\u6392\u5e8f\u5668\u548cLLM\u91cd\u6392\u5e8f\uff1b\u4e3a\u8bad\u7ec3\u751f\u62105000\u4e2a\u5408\u6210ToT\u67e5\u8be2", "result": "\u6700\u4f73\u7cfb\u7edf\uff08\u6df7\u5408\u68c0\u7d22+Gemini-2.5-flash\u91cd\u6392\u5e8f\uff09\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u5230\u53ec\u56de\u73870.66\u548cNDCG@1000\u4e3a0.41\uff0c\u8bc1\u660e\u4e86\u878d\u5408\u68c0\u7d22\u7684\u6709\u6548\u6027", "conclusion": "\u878d\u5408\u591a\u79cd\u4e92\u8865\u68c0\u7d22\u65b9\u6cd5\u4e0eLLM\u91cd\u6392\u5e8f\u80fd\u6709\u6548\u89e3\u51b3Tip-of-the-Tongue\u4efb\u52a1\uff0c\u6df7\u5408\u68c0\u7d22\u7b56\u7565\u663e\u8457\u63d0\u5347\u68c0\u7d22\u6027\u80fd"}}
{"id": "2601.15594", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.15594", "abs": "https://arxiv.org/abs/2601.15594", "authors": ["Zhixian Zhou", "Bin Chen", "Zhe Peng", "Zhiming Liang", "Ruijun Wu", "Chen Sun", "Shuo Wang"], "title": "Blockchain-Based Spectrum Resource Securitization via Semi-Fungible Token-Lock", "comment": null, "summary": "As 6G networks evolve, spectrum assets require flexible, dynamic, and efficient utilization, motivating blockchain based spectrum securitization. Existing approaches based on ERC404 style hybrid token models rely on frequent minting and burning during asset transfers, which disrupt token identity continuity and increase on chain overhead. This paper proposes the Semi Fungible Token Lock (SFT Lock) method, a lock/unlock based mechanism that preserves NFT identity and historical traceability while enabling fractional ownership and transferability. By replacing mint/burn operations with deterministic state transitions, SFT Lock ensures consistent lifecycle representation of spectrum assets and significantly reduces on chain operations. Based on this mechanism, a modular smart contract architecture is designed to support spectrum authorization, securitization, and sharing, and a staking mechanism is introduced to enhance asset liquidity. Experimental results on a private Ethereum network demonstrate that, compared with ERC404 style hybrid token models, the proposed method achieves substantial gas savings while maintaining functional correctness and traceability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSFT Lock\u65b9\u6cd5\uff0c\u901a\u8fc7\u9501/\u89e3\u9501\u673a\u5236\u66ff\u4ee3\u94f8\u9020/\u9500\u6bc1\u64cd\u4f5c\uff0c\u5728\u4fdd\u6301NFT\u8eab\u4efd\u548c\u5386\u53f2\u53ef\u8ffd\u6eaf\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u9891\u8c31\u8d44\u4ea7\u7684\u5206\u5272\u6240\u6709\u6743\u548c\u53ef\u8f6c\u79fb\u6027\uff0c\u663e\u8457\u964d\u4f4e\u94fe\u4e0a\u5f00\u9500\u3002", "motivation": "\u968f\u77406G\u7f51\u7edc\u53d1\u5c55\uff0c\u9891\u8c31\u8d44\u4ea7\u9700\u8981\u7075\u6d3b\u3001\u52a8\u6001\u548c\u9ad8\u6548\u7684\u5229\u7528\uff0c\u8fd9\u63a8\u52a8\u4e86\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u9891\u8c31\u8bc1\u5238\u5316\u3002\u73b0\u6709\u57fa\u4e8eERC404\u6df7\u5408\u4ee3\u5e01\u6a21\u578b\u7684\u65b9\u6cd5\u5728\u8d44\u4ea7\u8f6c\u79fb\u65f6\u9891\u7e41\u8fdb\u884c\u94f8\u9020\u548c\u9500\u6bc1\u64cd\u4f5c\uff0c\u8fd9\u4f1a\u7834\u574f\u4ee3\u5e01\u8eab\u4efd\u8fde\u7eed\u6027\u5e76\u589e\u52a0\u94fe\u4e0a\u5f00\u9500\u3002", "method": "\u63d0\u51fa\u534a\u540c\u8d28\u5316\u4ee3\u5e01\u9501\u5b9a(SFT Lock)\u65b9\u6cd5\uff0c\u91c7\u7528\u9501/\u89e3\u9501\u673a\u5236\u66ff\u4ee3\u94f8\u9020/\u9500\u6bc1\u64cd\u4f5c\uff0c\u901a\u8fc7\u786e\u5b9a\u6027\u72b6\u6001\u8f6c\u6362\u4fdd\u6301NFT\u8eab\u4efd\u548c\u5386\u53f2\u53ef\u8ffd\u6eaf\u6027\u3002\u8bbe\u8ba1\u4e86\u6a21\u5757\u5316\u667a\u80fd\u5408\u7ea6\u67b6\u6784\u652f\u6301\u9891\u8c31\u6388\u6743\u3001\u8bc1\u5238\u5316\u548c\u5171\u4eab\uff0c\u5e76\u5f15\u5165\u8d28\u62bc\u673a\u5236\u589e\u5f3a\u8d44\u4ea7\u6d41\u52a8\u6027\u3002", "result": "\u5728\u79c1\u6709\u4ee5\u592a\u574a\u7f51\u7edc\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0eERC404\u6df7\u5408\u4ee3\u5e01\u6a21\u578b\u76f8\u6bd4\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u4fdd\u6301\u529f\u80fd\u6b63\u786e\u6027\u548c\u53ef\u8ffd\u6eaf\u6027\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684gas\u8282\u7701\u3002", "conclusion": "SFT Lock\u65b9\u6cd5\u4e3a6G\u7f51\u7edc\u4e2d\u7684\u9891\u8c31\u8bc1\u5238\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u66f4\u53ef\u6301\u7eed\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u51cf\u5c11\u94fe\u4e0a\u64cd\u4f5c\u540c\u65f6\u4fdd\u6301\u8d44\u4ea7\u8eab\u4efd\u8fde\u7eed\u6027\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.15673", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.15673", "abs": "https://arxiv.org/abs/2601.15673", "authors": ["Qilong Yan", "Yifei Xing", "Dugang Liu", "Jingpu Duan", "Jian Yin"], "title": "Enhancing guidance for missing data in diffusion-based sequential recommendation", "comment": "ICASSP 2026 accecpted", "summary": "Contemporary sequential recommendation methods are becoming more complex, shifting from classification to a diffusion-guided generative paradigm. However, the quality of guidance in the form of user information is often compromised by missing data in the observed sequences, leading to suboptimal generation quality. Existing methods address this by removing locally similar items, but overlook ``critical turning points'' in user interest, which are crucial for accurately predicting subsequent user intent. To address this, we propose a novel Counterfactual Attention Regulation Diffusion model (CARD), which focuses on amplifying the signal from key interest-turning-point items while concurrently identifying and suppressing noise within the user sequence. CARD consists of (1) a Dual-side Thompson Sampling method to identify sequences undergoing significant interest shift, and (2) a counterfactual attention mechanism for these sequences to quantify the importance of each item. In this manner, CARD provides the diffusion model with a high-quality guidance signal composed of dynamically re-weighted interaction vectors to enable effective generation. Experiments show our method works well on real-world data without being computationally expensive. Our code is available at https://github.com/yanqilong3321/CARD.", "AI": {"tldr": "\u63d0\u51faCARD\u6a21\u578b\uff0c\u901a\u8fc7\u53cd\u4e8b\u5b9e\u6ce8\u610f\u529b\u673a\u5236\u589e\u5f3a\u7528\u6237\u5174\u8da3\u8f6c\u6298\u70b9\u4fe1\u53f7\uff0c\u6291\u5236\u5e8f\u5217\u566a\u58f0\uff0c\u63d0\u5347\u6269\u6563\u6a21\u578b\u5728\u5e8f\u5217\u63a8\u8350\u4e2d\u7684\u751f\u6210\u8d28\u91cf", "motivation": "\u73b0\u6709\u5e8f\u5217\u63a8\u8350\u65b9\u6cd5\u4ece\u5206\u7c7b\u8f6c\u5411\u6269\u6563\u751f\u6210\u8303\u5f0f\uff0c\u4f46\u7528\u6237\u5e8f\u5217\u4e2d\u7684\u7f3a\u5931\u6570\u636e\u5bfc\u81f4\u5f15\u5bfc\u4fe1\u53f7\u8d28\u91cf\u4e0b\u964d\u3002\u73b0\u6709\u65b9\u6cd5\u4ec5\u53bb\u9664\u5c40\u90e8\u76f8\u4f3c\u9879\uff0c\u5ffd\u7565\u4e86\u7528\u6237\u5174\u8da3\u7684\"\u5173\u952e\u8f6c\u6298\u70b9\"\uff0c\u8fd9\u4e9b\u8f6c\u6298\u70b9\u5bf9\u51c6\u786e\u9884\u6d4b\u540e\u7eed\u7528\u6237\u610f\u56fe\u81f3\u5173\u91cd\u8981", "method": "\u63d0\u51faCARD\u6a21\u578b\uff1a1) \u53cc\u9762\u6c64\u666e\u68ee\u91c7\u6837\u65b9\u6cd5\u8bc6\u522b\u53d1\u751f\u663e\u8457\u5174\u8da3\u8f6c\u79fb\u7684\u5e8f\u5217\uff1b2) \u5bf9\u8fd9\u4e9b\u5e8f\u5217\u4f7f\u7528\u53cd\u4e8b\u5b9e\u6ce8\u610f\u529b\u673a\u5236\u91cf\u5316\u6bcf\u4e2a\u9879\u76ee\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u6269\u6563\u6a21\u578b\u63d0\u4f9b\u52a8\u6001\u91cd\u65b0\u52a0\u6743\u7684\u4ea4\u4e92\u5411\u91cf\u4f5c\u4e3a\u9ad8\u8d28\u91cf\u5f15\u5bfc\u4fe1\u53f7", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4e14\u8ba1\u7b97\u5f00\u9500\u4e0d\u5927", "conclusion": "CARD\u6a21\u578b\u901a\u8fc7\u5173\u6ce8\u7528\u6237\u5174\u8da3\u8f6c\u6298\u70b9\u5e76\u6291\u5236\u5e8f\u5217\u566a\u58f0\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6269\u6563\u6a21\u578b\u5728\u5e8f\u5217\u63a8\u8350\u4e2d\u7684\u751f\u6210\u8d28\u91cf\uff0c\u4e3a\u89e3\u51b3\u5e8f\u5217\u6570\u636e\u7f3a\u5931\u5bfc\u81f4\u7684\u5f15\u5bfc\u4fe1\u53f7\u8d28\u91cf\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2601.15721", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.15721", "abs": "https://arxiv.org/abs/2601.15721", "authors": ["Xinda Chen", "Jiawei Wu", "Yishuang Liu", "Jialin Zhu", "Shuwen Xiao", "Junjun Zheng", "Xiangheng Kong", "Yuning Jiang"], "title": "CoNRec: Context-Discerning Negative Recommendation with LLMs", "comment": null, "summary": "Understanding what users like is relatively straightforward; understanding what users dislike, however, remains a challenging and underexplored problem. Research into users' negative preferences has gained increasing importance in modern recommendation systems. Numerous platforms have introduced explicit negative feedback mechanisms and leverage such signals to refine their recommendation models. Beyond traditional business metrics, user experience-driven metrics, such as negative feedback rates, have become critical indicators for evaluating system performance. However, most existing approaches primarily use negative feedback as an auxiliary signal to enhance positive recommendations, paying little attention to directly modeling negative interests, which can be highly valuable in offline applications. Moreover, due to the inherent sparsity of negative feedback data, models often suffer from context understanding biases induced by positive feedback dominance. To address these challenges, we propose the first large language model framework for negative feedback modeling with special designed context-discerning modules. We use semantic ID Representation to replace text-based item descriptions and introduce an item-level alignment task that enhances the LLM's understanding of the semantic context behind negative feedback. Furthermore, we design a Progressive GRPO training paradigm that enables the model to dynamically balance the positive and negative behavioral context utilization. Besides, our investigation further reveals a fundamental misalignment between the conventional next-negative-item prediction objective and users' true negative preferences, which is heavily influenced by the system's recommendation order. To mitigate this, we propose a novel reward function and evaluation metric grounded in multi-day future negative feedback and their collaborative signals.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8d1f\u53cd\u9988\u5efa\u6a21\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49ID\u8868\u793a\u548c\u6e10\u8fdb\u5f0fGRPO\u8bad\u7ec3\u89e3\u51b3\u8d1f\u53cd\u9988\u7a00\u758f\u6027\u95ee\u9898\uff0c\u5e76\u8bbe\u8ba1\u65b0\u7684\u5956\u52b1\u51fd\u6570\u548c\u8bc4\u4f30\u6307\u6807\u6765\u7ea0\u6b63\u4f20\u7edf\u8d1f\u9879\u9884\u6d4b\u76ee\u6807\u4e0e\u7528\u6237\u771f\u5b9e\u8d1f\u504f\u597d\u7684\u504f\u5dee\u3002", "motivation": "\u73b0\u6709\u63a8\u8350\u7cfb\u7edf\u4e3b\u8981\u5c06\u8d1f\u53cd\u9988\u4f5c\u4e3a\u8f85\u52a9\u4fe1\u53f7\u6765\u589e\u5f3a\u6b63\u63a8\u8350\uff0c\u5f88\u5c11\u76f4\u63a5\u5efa\u6a21\u8d1f\u5174\u8da3\uff0c\u4e14\u7531\u4e8e\u8d1f\u53cd\u9988\u6570\u636e\u7a00\u758f\uff0c\u6a21\u578b\u6613\u53d7\u6b63\u53cd\u9988\u4e3b\u5bfc\u7684\u4e0a\u4e0b\u6587\u7406\u89e3\u504f\u5dee\u5f71\u54cd\u3002\u4f20\u7edf\u8d1f\u9879\u9884\u6d4b\u76ee\u6807\u4e0e\u7528\u6237\u771f\u5b9e\u8d1f\u504f\u597d\u5b58\u5728\u6839\u672c\u6027\u9519\u4f4d\u3002", "method": "1) \u4f7f\u7528\u8bed\u4e49ID\u8868\u793a\u66ff\u4ee3\u57fa\u4e8e\u6587\u672c\u7684\u9879\u76ee\u63cf\u8ff0\uff1b2) \u5f15\u5165\u9879\u76ee\u7ea7\u5bf9\u9f50\u4efb\u52a1\u589e\u5f3aLLM\u5bf9\u8d1f\u53cd\u9988\u8bed\u4e49\u4e0a\u4e0b\u6587\u7684\u7406\u89e3\uff1b3) \u8bbe\u8ba1\u6e10\u8fdb\u5f0fGRPO\u8bad\u7ec3\u8303\u5f0f\uff0c\u52a8\u6001\u5e73\u8861\u6b63\u8d1f\u884c\u4e3a\u4e0a\u4e0b\u6587\u7684\u5229\u7528\uff1b4) \u63d0\u51fa\u57fa\u4e8e\u591a\u65e5\u672a\u6765\u8d1f\u53cd\u9988\u53ca\u5176\u534f\u540c\u4fe1\u53f7\u7684\u65b0\u5956\u52b1\u51fd\u6570\u548c\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2aLLM\u8d1f\u53cd\u9988\u5efa\u6a21\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49ID\u8868\u793a\u548c\u6e10\u8fdb\u5f0f\u8bad\u7ec3\u89e3\u51b3\u4e86\u8d1f\u53cd\u9988\u7a00\u758f\u6027\u95ee\u9898\uff0c\u65b0\u8bbe\u8ba1\u7684\u5956\u52b1\u51fd\u6570\u548c\u8bc4\u4f30\u6307\u6807\u80fd\u66f4\u51c6\u786e\u5730\u53cd\u6620\u7528\u6237\u771f\u5b9e\u8d1f\u504f\u597d\uff0c\u51cf\u5c11\u63a8\u8350\u987a\u5e8f\u5e26\u6765\u7684\u504f\u5dee\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u8d1f\u53cd\u9988\u5efa\u6a21\u7684\u7a7a\u767d\uff0c\u63d0\u51fa\u7684LLM\u6846\u67b6\u80fd\u66f4\u597d\u5730\u7406\u89e3\u548c\u5229\u7528\u7528\u6237\u8d1f\u504f\u597d\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u7528\u6237\u5174\u8da3\u7406\u89e3\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u548c\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2601.15849", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.15849", "abs": "https://arxiv.org/abs/2601.15849", "authors": ["Tsung-Hsiang Chou", "Chen-Jui Yu", "Shui-Hsiang Hsu", "Yao-Chung Fan"], "title": "CGPT: Cluster-Guided Partial Tables with LLM-Generated Supervision for Table Retrieval", "comment": "Accepted at The Web Conference 2026 (WWW 2026)", "summary": "General-purpose embedding models have demonstrated strong performance in text retrieval but remain suboptimal for table retrieval, where highly structured content leads to semantic compression and query-table mismatch. Recent LLM-based retrieval augmentation methods mitigate this issue by generating synthetic queries, yet they often rely on heuristic partial-table selection and seldom leverage these synthetic queries as supervision to improve the embedding model. We introduce CGPT, a training framework that enhances table retrieval through LLM-generated supervision. CGPT constructs semantically diverse partial tables by clustering table instances using K-means and sampling across clusters to broaden semantic coverage. An LLM then generates synthetic queries for these partial tables, which are used in hard-negative contrastive fine-tuning to refine the embedding model. Experiments across four public benchmarks (MimoTable, OTTQA, FetaQA, and E2E-WTQ) show that CGPT consistently outperforms retrieval baselines, including QGpT, with an average R@1 improvement of 16.54 percent. In a unified multi-domain corpus setting, CGPT further demonstrates strong cross-domain generalization and remains effective even when using smaller LLMs for synthetic query generation. These results indicate that semantically guided partial-table construction, combined with contrastive training from LLM-generated supervision, provides an effective and scalable paradigm for large-scale table retrieval. Our code is available at https://github.com/yumeow0122/CGPT.", "AI": {"tldr": "CGPT\u901a\u8fc7LLM\u751f\u6210\u76d1\u7763\u4fe1\u53f7\u589e\u5f3a\u8868\u683c\u68c0\u7d22\uff0c\u4f7f\u7528\u805a\u7c7b\u6784\u5efa\u8bed\u4e49\u591a\u6837\u7684\u90e8\u5206\u8868\u683c\uff0c\u751f\u6210\u5408\u6210\u67e5\u8be2\u8fdb\u884c\u5bf9\u6bd4\u5b66\u4e60\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u901a\u7528\u5d4c\u5165\u6a21\u578b\u5728\u6587\u672c\u68c0\u7d22\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u8868\u683c\u68c0\u7d22\u4e2d\u5b58\u5728\u8bed\u4e49\u538b\u7f29\u548c\u67e5\u8be2-\u8868\u683c\u4e0d\u5339\u914d\u95ee\u9898\u3002\u73b0\u6709LLM\u68c0\u7d22\u589e\u5f3a\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u90e8\u5206\u8868\u683c\u9009\u62e9\uff0c\u4e14\u5f88\u5c11\u5229\u7528\u5408\u6210\u67e5\u8be2\u4f5c\u4e3a\u76d1\u7763\u4fe1\u53f7\u6765\u6539\u8fdb\u5d4c\u5165\u6a21\u578b\u3002", "method": "CGPT\u8bad\u7ec3\u6846\u67b6\uff1a1) \u4f7f\u7528K-means\u805a\u7c7b\u8868\u683c\u5b9e\u4f8b\uff0c\u8de8\u805a\u7c7b\u91c7\u6837\u6784\u5efa\u8bed\u4e49\u591a\u6837\u7684\u90e8\u5206\u8868\u683c\uff1b2) \u7528LLM\u4e3a\u8fd9\u4e9b\u90e8\u5206\u8868\u683c\u751f\u6210\u5408\u6210\u67e5\u8be2\uff1b3) \u901a\u8fc7\u786c\u8d1f\u4f8b\u5bf9\u6bd4\u5fae\u8c03\u6765\u4f18\u5316\u5d4c\u5165\u6a21\u578b\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\uff08MimoTable\u3001OTTQA\u3001FetaQA\u3001E2E-WTQ\uff09\u4e2d\uff0cCGPT\u5e73\u5747R@1\u63d0\u534716.54%\uff0c\u4f18\u4e8e\u5305\u62ecQGpT\u5728\u5185\u7684\u68c0\u7d22\u57fa\u7ebf\u3002\u5728\u7edf\u4e00\u591a\u9886\u57df\u8bed\u6599\u8bbe\u7f6e\u4e2d\uff0cCGPT\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\uff0c\u5373\u4f7f\u4f7f\u7528\u8f83\u5c0fLLM\u751f\u6210\u67e5\u8be2\u4e5f\u6709\u6548\u3002", "conclusion": "\u8bed\u4e49\u5f15\u5bfc\u7684\u90e8\u5206\u8868\u683c\u6784\u5efa\u7ed3\u5408LLM\u751f\u6210\u76d1\u7763\u7684\u5bf9\u6bd4\u8bad\u7ec3\uff0c\u4e3a\u5927\u89c4\u6a21\u8868\u683c\u68c0\u7d22\u63d0\u4f9b\u4e86\u6709\u6548\u4e14\u53ef\u6269\u5c55\u7684\u8303\u5f0f\u3002\u8be5\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u8868\u683c\u68c0\u7d22\u6027\u80fd\u5e76\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2601.15860", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.15860", "abs": "https://arxiv.org/abs/2601.15860", "authors": ["Shui-Hsiang Hsu", "Tsung-Hsiang Chou", "Chen-Jui Yu", "Yao-Chung Fan"], "title": "STAR: Semantic Table Representation with Header-Aware Clustering and Adaptive Weighted Fusion", "comment": "Accepted at The Web Conference 2026 (WWW 2026)", "summary": "Table retrieval is the task of retrieving the most relevant tables from large-scale corpora given natural language queries. However, structural and semantic discrepancies between unstructured text and structured tables make embedding alignment particularly challenging. Recent methods such as QGpT attempt to enrich table semantics by generating synthetic queries, yet they still rely on coarse partial-table sampling and simple fusion strategies, which limit semantic diversity and hinder effective query-table alignment. We propose STAR (Semantic Table Representation), a lightweight framework that improves semantic table representation through semantic clustering and weighted fusion. STAR first applies header-aware K-means clustering to group semantically similar rows and selects representative centroid instances to construct a diverse partial table. It then generates cluster-specific synthetic queries to comprehensively cover the table's semantic space. Finally, STAR employs weighted fusion strategies to integrate table and query embeddings, enabling fine-grained semantic alignment. This design enables STAR to capture complementary information from structured and textual sources, improving the expressiveness of table representations. Experiments on five benchmarks show that STAR achieves consistently higher Recall than QGpT on all datasets, demonstrating the effectiveness of semantic clustering and adaptive weighted fusion for robust table representation. Our code is available at https://github.com/adsl135789/STAR.", "AI": {"tldr": "STAR\u6846\u67b6\u901a\u8fc7\u8bed\u4e49\u805a\u7c7b\u548c\u52a0\u6743\u878d\u5408\u6539\u8fdb\u8868\u683c\u8bed\u4e49\u8868\u793a\uff0c\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u4f18\u4e8eQGpT\u65b9\u6cd5", "motivation": "\u8868\u683c\u68c0\u7d22\u9762\u4e34\u975e\u7ed3\u6784\u5316\u6587\u672c\u4e0e\u7ed3\u6784\u5316\u8868\u683c\u4e4b\u95f4\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u5dee\u5f02\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u5982QGpT\u901a\u8fc7\u751f\u6210\u5408\u6210\u67e5\u8be2\u6765\u4e30\u5bcc\u8868\u683c\u8bed\u4e49\uff0c\u4f46\u4f9d\u8d56\u7c97\u7cd9\u7684\u90e8\u5206\u8868\u683c\u91c7\u6837\u548c\u7b80\u5355\u878d\u5408\u7b56\u7565\uff0c\u9650\u5236\u4e86\u8bed\u4e49\u591a\u6837\u6027\u5e76\u963b\u788d\u6709\u6548\u7684\u67e5\u8be2-\u8868\u683c\u5bf9\u9f50\u3002", "method": "STAR\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u6b65\u9aa4\uff1a1) \u4f7f\u7528\u57fa\u4e8e\u8868\u5934\u7684K-means\u805a\u7c7b\u5bf9\u8bed\u4e49\u76f8\u4f3c\u884c\u5206\u7ec4\uff0c\u9009\u62e9\u4ee3\u8868\u6027\u4e2d\u5fc3\u5b9e\u4f8b\u6784\u5efa\u591a\u6837\u5316\u90e8\u5206\u8868\u683c\uff1b2) \u751f\u6210\u805a\u7c7b\u7279\u5b9a\u7684\u5408\u6210\u67e5\u8be2\u4ee5\u5168\u9762\u8986\u76d6\u8868\u683c\u8bed\u4e49\u7a7a\u95f4\uff1b3) \u91c7\u7528\u52a0\u6743\u878d\u5408\u7b56\u7565\u6574\u5408\u8868\u683c\u548c\u67e5\u8be2\u5d4c\u5165\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u8bed\u4e49\u5bf9\u9f50\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSTAR\u5728\u6240\u6709\u6570\u636e\u96c6\u4e0a\u7684Recall\u6307\u6807\u5747\u4e00\u81f4\u9ad8\u4e8eQGpT\uff0c\u8bc1\u660e\u4e86\u8bed\u4e49\u805a\u7c7b\u548c\u81ea\u9002\u5e94\u52a0\u6743\u878d\u5408\u5bf9\u9c81\u68d2\u8868\u683c\u8868\u793a\u7684\u6709\u6548\u6027\u3002", "conclusion": "STAR\u901a\u8fc7\u8bed\u4e49\u805a\u7c7b\u548c\u52a0\u6743\u878d\u5408\u80fd\u591f\u4ece\u7ed3\u6784\u5316\u548c\u6587\u672c\u6e90\u4e2d\u6355\u83b7\u4e92\u8865\u4fe1\u606f\uff0c\u63d0\u9ad8\u8868\u683c\u8868\u793a\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u4e3a\u8868\u683c\u68c0\u7d22\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.15930", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.15930", "abs": "https://arxiv.org/abs/2601.15930", "authors": ["Tianjun Wei", "Enneng Yang", "Yingpeng Du", "Huizhong Guo", "Jie Zhang", "Zhu Sun"], "title": "MMGRid: Navigating Temporal-aware and Cross-domain Generative Recommendation via Model Merging", "comment": "https://github.com/Joinn99/MMGRid", "summary": "Model merging (MM) offers an efficient mechanism for integrating multiple specialized models without access to original training data or costly retraining. While MM has demonstrated success in domains like computer vision, its role in recommender systems (RSs) remains largely unexplored. Recently, Generative Recommendation (GR) has emerged as a new paradigm in RSs, characterized by rapidly growing model scales and substantial computational costs, making MM particularly appealing for cost-sensitive deployment scenarios. In this work, we present the first systematic study of MM in GR through a contextual lens. We focus on a fundamental yet underexplored challenge in real-world: how to merge generative recommenders specialized to different real-world contexts, arising from temporal evolving user behaviors and heterogeneous application domains. To this end, we propose a unified framework MMGRid, a structured contextual grid of GR checkpoints that organizes models trained under diverse contexts induced by temporal evolution and domain diversity. All checkpoints are derived from a shared base LLM but fine-tuned on context-specific data, forming a realistic and controlled model space for systematically analyzing MM across GR paradigms and merging algorithms. Our investigation reveals several key insights. First, training GR models from LLMs can introduce parameter conflicts during merging due to token distribution shifts and objective disparities; such conflicts can be alleviated by disentangling task-aware and context-specific parameter changes via base model replacement. Second, incremental training across contexts induces recency bias, which can be effectively balanced through weighted contextual merging. Notably, we observe that optimal merging weights correlate with context-dependent interaction characteristics, offering practical guidance for weight selection in real-world deployments.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u6a21\u578b\u5408\u5e76\u95ee\u9898\uff0c\u63d0\u51fa\u4e86MMGRid\u6846\u67b6\u6765\u7ec4\u7ec7\u4e0d\u540c\u4e0a\u4e0b\u6587\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u53c2\u6570\u51b2\u7a81\u548c\u65f6\u6548\u6027\u504f\u5dee\u7b49\u5173\u952e\u6311\u6218\uff0c\u5e76\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u6a21\u578b\u5408\u5e76\u4e3a\u96c6\u6210\u591a\u4e2a\u4e13\u4e1a\u6a21\u578b\u63d0\u4f9b\u4e86\u9ad8\u6548\u673a\u5236\uff0c\u4f46\u5728\u63a8\u8350\u7cfb\u7edf\u9886\u57df\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u751f\u6210\u5f0f\u63a8\u8350\u6a21\u578b\u89c4\u6a21\u5feb\u901f\u589e\u957f\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u4f7f\u5f97\u6a21\u578b\u5408\u5e76\u5728\u6210\u672c\u654f\u611f\u90e8\u7f72\u573a\u666f\u4e2d\u7279\u522b\u6709\u5438\u5f15\u529b\u3002\u9700\u8981\u7814\u7a76\u5982\u4f55\u5408\u5e76\u9488\u5bf9\u4e0d\u540c\u73b0\u5b9e\u4e16\u754c\u4e0a\u4e0b\u6587\uff08\u5982\u65f6\u95f4\u6f14\u5316\u548c\u9886\u57df\u5f02\u6784\uff09\u8bad\u7ec3\u7684\u751f\u6210\u5f0f\u63a8\u8350\u5668\u3002", "method": "\u63d0\u51fa\u4e86\u7edf\u4e00\u7684MMGRid\u6846\u67b6\uff0c\u6784\u5efa\u7ed3\u6784\u5316\u7684\u4e0a\u4e0b\u6587\u7f51\u683c\u6765\u7ec4\u7ec7\u7531\u65f6\u95f4\u6f14\u5316\u548c\u9886\u57df\u591a\u6837\u6027\u8bf1\u5bfc\u7684\u4e0d\u540c\u4e0a\u4e0b\u6587\u8bad\u7ec3\u7684GR\u68c0\u67e5\u70b9\u3002\u6240\u6709\u68c0\u67e5\u70b9\u90fd\u6765\u81ea\u5171\u4eab\u7684\u57fa\u7840LLM\uff0c\u4f46\u5728\u7279\u5b9a\u4e0a\u4e0b\u6587\u6570\u636e\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u5f62\u6210\u7528\u4e8e\u7cfb\u7edf\u5206\u6790\u6a21\u578b\u5408\u5e76\u7684\u73b0\u5b9e\u53ef\u63a7\u6a21\u578b\u7a7a\u95f4\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u4eceLLM\u8bad\u7ec3GR\u6a21\u578b\u4f1a\u56e0token\u5206\u5e03\u504f\u79fb\u548c\u76ee\u6807\u5dee\u5f02\u5f15\u5165\u53c2\u6570\u51b2\u7a81\uff0c\u53ef\u901a\u8fc7\u57fa\u7840\u6a21\u578b\u66ff\u6362\u6765\u5206\u79bb\u4efb\u52a1\u611f\u77e5\u548c\u4e0a\u4e0b\u6587\u7279\u5b9a\u53c2\u6570\u53d8\u5316\u4ee5\u7f13\u89e3\u51b2\u7a81\uff1b2\uff09\u8de8\u4e0a\u4e0b\u6587\u589e\u91cf\u8bad\u7ec3\u4f1a\u5f15\u5165\u65f6\u6548\u6027\u504f\u5dee\uff0c\u53ef\u901a\u8fc7\u52a0\u6743\u4e0a\u4e0b\u6587\u5408\u5e76\u6709\u6548\u5e73\u8861\uff1b3\uff09\u6700\u4f18\u5408\u5e76\u6743\u91cd\u4e0e\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u4ea4\u4e92\u7279\u5f81\u76f8\u5173\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u6743\u91cd\u9009\u62e9\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u63a2\u7d22\u4e86\u751f\u6210\u5f0f\u63a8\u8350\u4e2d\u7684\u6a21\u578b\u5408\u5e76\uff0c\u63ed\u793a\u4e86\u5173\u952e\u6311\u6218\u5e76\u63d0\u51fa\u4e86\u89e3\u51b3\u65b9\u6848\u3002MMGRid\u6846\u67b6\u4e3a\u5206\u6790\u8de8\u4e0a\u4e0b\u6587\u6a21\u578b\u5408\u5e76\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u65b9\u6cd5\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u6a21\u578b\u5408\u5e76\u7b56\u7565\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u65f6\u95f4\u6f14\u5316\u548c\u9886\u57df\u5f02\u6784\u7684\u73b0\u5b9e\u4e16\u754c\u573a\u666f\u65f6\u3002"}}
{"id": "2601.15975", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.15975", "abs": "https://arxiv.org/abs/2601.15975", "authors": ["Chen Xu", "Zhipeng Yi", "Ruizi Wang", "Wenjie Wang", "Jun Xu", "Maarten de Rijke"], "title": "Unveiling and Simulating Short-Video Addiction Behaviors via Economic Addiction Theory", "comment": "Accepted in TheWebConf 2026", "summary": "Short-video applications have attracted substantial user traffic. However, these platforms also foster problematic usage patterns, commonly referred to as short-video addiction, which pose risks to both user health and the sustainable development of platforms. Prior studies on this issue have primarily relied on questionnaires or volunteer-based data collection, which are often limited by small sample sizes and population biases. In contrast, short-video platforms have large-scale behavioral data, offering a valuable foundation for analyzing addictive behaviors. To examine addiction-aware behavior patterns, we combine economic addiction theory with users' implicit behavior captured by recommendation systems. Our analysis shows that short-video addiction follows functional patterns similar to traditional forms of addictive behavior (e.g., substance abuse) and that its intensity is consistent with findings from previous social science studies. To develop a simulator that can learn and model these patterns, we introduce a novel training framework, AddictSim. To consider the personalized addiction patterns, AddictSim uses a mean-to-adapted strategy with group relative policy optimization training. Experiments on two large-scale datasets show that AddictSim consistently outperforms existing training strategies. Our simulation results show that integrating diversity-aware algorithms can mitigate addictive behaviors well.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7ed3\u5408\u7ecf\u6d4e\u5b66\u6210\u763e\u7406\u8bba\u4e0e\u63a8\u8350\u7cfb\u7edf\u884c\u4e3a\u6570\u636e\uff0c\u5206\u6790\u77ed\u89c6\u9891\u6210\u763e\u6a21\u5f0f\uff0c\u5e76\u63d0\u51faAddictSim\u6a21\u62df\u6846\u67b6\uff0c\u901a\u8fc7\u7fa4\u4f53\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u8bad\u7ec3\uff0c\u53d1\u73b0\u591a\u6837\u6027\u7b97\u6cd5\u53ef\u7f13\u89e3\u6210\u763e\u884c\u4e3a\u3002", "motivation": "\u77ed\u89c6\u9891\u5e73\u53f0\u7528\u6237\u6d41\u91cf\u5927\u4f46\u5b58\u5728\u6210\u763e\u95ee\u9898\uff0c\u4f20\u7edf\u95ee\u5377\u7814\u7a76\u6837\u672c\u5c0f\u4e14\u6709\u504f\u5dee\uff0c\u5e73\u53f0\u884c\u4e3a\u6570\u636e\u4e3a\u5206\u6790\u6210\u763e\u884c\u4e3a\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a\u3002", "method": "\u7ed3\u5408\u7ecf\u6d4e\u5b66\u6210\u763e\u7406\u8bba\u4e0e\u63a8\u8350\u7cfb\u7edf\u9690\u5f0f\u884c\u4e3a\u6570\u636e\uff0c\u63d0\u51faAddictSim\u8bad\u7ec3\u6846\u67b6\uff0c\u91c7\u7528\u5747\u503c\u9002\u5e94\u7b56\u7565\u548c\u7fa4\u4f53\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u8bad\u7ec3\uff0c\u5728\u4e24\u5927\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u77ed\u89c6\u9891\u6210\u763e\u9075\u5faa\u4e0e\u4f20\u7edf\u6210\u763e\u884c\u4e3a\u76f8\u4f3c\u7684\u529f\u80fd\u6a21\u5f0f\uff0c\u5f3a\u5ea6\u4e0e\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u4e00\u81f4\uff1bAddictSim\u4f18\u4e8e\u73b0\u6709\u8bad\u7ec3\u7b56\u7565\uff1b\u591a\u6837\u6027\u7b97\u6cd5\u80fd\u6709\u6548\u7f13\u89e3\u6210\u763e\u884c\u4e3a\u3002", "conclusion": "\u77ed\u89c6\u9891\u6210\u763e\u53ef\u901a\u8fc7\u884c\u4e3a\u6570\u636e\u5206\u6790\uff0cAddictSim\u80fd\u6709\u6548\u5efa\u6a21\u6210\u763e\u6a21\u5f0f\uff0c\u591a\u6837\u6027\u63a8\u8350\u7b97\u6cd5\u662f\u7f13\u89e3\u6210\u763e\u7684\u6709\u6548\u7b56\u7565\u3002"}}
