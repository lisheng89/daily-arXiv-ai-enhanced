{"id": "2510.08935", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.08935", "abs": "https://arxiv.org/abs/2510.08935", "authors": ["Yingyi Zhang", "Pengyue Jia", "Derong Xu", "Yi Wen", "Xianneng Li", "Yichao Wang", "Wenlin Zhang", "Xiaopeng Li", "Weinan Gan", "Huifeng Guo", "Yong Liu", "Xiangyu Zhao"], "title": "Personalize Before Retrieve: LLM-based Personalized Query Expansion for User-Centric Retrieval", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) critically depends on effective query\nexpansion to retrieve relevant information. However, existing expansion methods\nadopt uniform strategies that overlook user-specific semantics, ignoring\nindividual expression styles, preferences, and historical context. In practice,\nidentical queries in text can express vastly different intentions across users.\nThis representational rigidity limits the ability of current RAG systems to\ngeneralize effectively in personalized settings. Specifically, we identify two\ncore challenges for personalization: 1) user expression styles are inherently\ndiverse, making it difficult for standard expansions to preserve personalized\nintent. 2) user corpora induce heterogeneous semantic structures-varying in\ntopical focus and lexical organization-which hinders the effective anchoring of\nexpanded queries within the user's corpora space. To address these challenges,\nwe propose Personalize Before Retrieve (PBR), a framework that incorporates\nuser-specific signals into query expansion prior to retrieval. PBR consists of\ntwo components: P-PRF, which generates stylistically aligned pseudo feedback\nusing user history for simulating user expression style, and P-Anchor, which\nperforms graph-based structure alignment over user corpora to capture its\nstructure. Together, they produce personalized query representations tailored\nfor retrieval. Experiments on two personalized benchmarks show that PBR\nconsistently outperforms strong baselines, with up to 10% gains on PersonaBench\nacross retrievers. Our findings demonstrate the value of modeling\npersonalization before retrieval to close the semantic gap in user-adaptive RAG\nsystems. Our code is available at https://github.com/Zhang-Yingyi/PBR-code.", "AI": {"tldr": "\u63d0\u51fa\u4e86PBR\u6846\u67b6\uff0c\u901a\u8fc7\u7528\u6237\u7279\u5b9a\u4fe1\u53f7\u5728\u68c0\u7d22\u524d\u8fdb\u884c\u4e2a\u6027\u5316\u67e5\u8be2\u6269\u5c55\uff0c\u89e3\u51b3\u4e86\u73b0\u6709RAG\u7cfb\u7edf\u5728\u4e2a\u6027\u5316\u8bbe\u7f6e\u4e2d\u5ffd\u7565\u7528\u6237\u8868\u8fbe\u98ce\u683c\u548c\u8bed\u6599\u7ed3\u6784\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u67e5\u8be2\u6269\u5c55\u65b9\u6cd5\u91c7\u7528\u7edf\u4e00\u7b56\u7565\uff0c\u5ffd\u7565\u4e86\u7528\u6237\u7279\u5b9a\u7684\u8bed\u4e49\u7279\u5f81\uff0c\u5305\u62ec\u4e2a\u4eba\u8868\u8fbe\u98ce\u683c\u3001\u504f\u597d\u548c\u5386\u53f2\u80cc\u666f\uff0c\u9650\u5236\u4e86RAG\u7cfb\u7edf\u5728\u4e2a\u6027\u5316\u73af\u5883\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "PBR\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u7ec4\u4ef6\uff1aP-PRF\u4f7f\u7528\u7528\u6237\u5386\u53f2\u751f\u6210\u98ce\u683c\u5bf9\u9f50\u7684\u4f2a\u53cd\u9988\u6765\u6a21\u62df\u7528\u6237\u8868\u8fbe\u98ce\u683c\uff1bP-Anchor\u901a\u8fc7\u57fa\u4e8e\u56fe\u7684\u7528\u6237\u8bed\u6599\u7ed3\u6784\u5bf9\u9f50\u6765\u6355\u6349\u5176\u8bed\u4e49\u7ed3\u6784\u3002", "result": "\u5728\u4e24\u4e2a\u4e2a\u6027\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPBR\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728PersonaBench\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe10%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e14\u5728\u4e0d\u540c\u68c0\u7d22\u5668\u4e0a\u8868\u73b0\u4e00\u81f4\u3002", "conclusion": "\u5728\u68c0\u7d22\u524d\u5efa\u6a21\u4e2a\u6027\u5316\u5bf9\u4e8e\u7f29\u5c0f\u7528\u6237\u81ea\u9002\u5e94RAG\u7cfb\u7edf\u4e2d\u7684\u8bed\u4e49\u5dee\u8ddd\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0cPBR\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u7528\u6237\u8868\u8fbe\u591a\u6837\u6027\u548c\u8bed\u6599\u7ed3\u6784\u5f02\u8d28\u6027\u5e26\u6765\u7684\u6311\u6218\u3002"}}
{"id": "2510.08948", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08948", "abs": "https://arxiv.org/abs/2510.08948", "authors": ["Nan Lu", "Yurong Hu", "Jiaquan Fang", "Yan Liu", "Rui Dong", "Yiming Wang", "Rui Lin", "Shaoyi Xu"], "title": "SHERLOCK: Towards Dynamic Knowledge Adaptation in LLM-enhanced E-commerce Risk Management", "comment": null, "summary": "The growth of the e-commerce industry has intensified the adversarial\ndynamics between shadow economy actors and risk management teams. Companies\noften conduct risk investigations into suspicious cases to identify emerging\nfraud patterns, thereby enhancing both preemptive risk prevention and post-hoc\ngovernance. However, the sheer volume of case analyses imposes a substantial\nworkload on risk management analysts, as each case requires the integration of\nlong-term expert experience and meticulous scrutiny across multiple risk\ndimensions. Additionally, individual disparities among analysts hinder the\nestablishment of uniform and high-standard workflows. To address these\nchallenges, we propose the SHERLOCK framework, which leverages the reasoning\ncapabilities of large language models (LLMs) to assist analysts in risk\ninvestigations. Our approach consists of three primary components: (1)\nextracting risk management knowledge from multi-modal data and constructing a\ndomain knowledge base (KB), (2) building an intelligent platform guided by the\ndata flywheel paradigm that integrates daily operations, expert annotations,\nand model evaluations, with iteratively fine-tuning for preference alignment,\nand (3) introducing a Reflect & Refine (R&R) module that collaborates with the\ndomain KB to establish a rapid response mechanism for evolving risk patterns.\nExperiments conducted on the real-world transaction dataset from JD.com\ndemonstrate that our method significantly improves the precision of both\nfactual alignment and risk localization within the LLM analysis results.\nDeployment of the SHERLOCK-based LLM system on JD.com has substantially\nenhanced the efficiency of case investigation workflows for risk managers.", "AI": {"tldr": "\u63d0\u51fa\u4e86SHERLOCK\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u8f85\u52a9\u98ce\u9669\u8c03\u67e5\uff0c\u901a\u8fc7\u6784\u5efa\u77e5\u8bc6\u5e93\u3001\u667a\u80fd\u5e73\u53f0\u548c\u53cd\u601d\u4f18\u5316\u6a21\u5757\uff0c\u663e\u8457\u63d0\u5347\u4e86\u98ce\u9669\u5206\u6790\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u7535\u5546\u884c\u4e1a\u589e\u957f\u52a0\u5267\u4e86\u9ed1\u4ea7\u4e0e\u98ce\u63a7\u56e2\u961f\u7684\u5bf9\u6297\uff0c\u5927\u91cf\u6848\u4ef6\u5206\u6790\u7ed9\u98ce\u63a7\u5206\u6790\u5e08\u5e26\u6765\u6c89\u91cd\u8d1f\u62c5\uff0c\u4e14\u5206\u6790\u5e08\u4e2a\u4f53\u5dee\u5f02\u963b\u788d\u4e86\u6807\u51c6\u5316\u5de5\u4f5c\u6d41\u7a0b\u7684\u5efa\u7acb\u3002", "method": "1) \u4ece\u591a\u6a21\u6001\u6570\u636e\u63d0\u53d6\u98ce\u63a7\u77e5\u8bc6\u6784\u5efa\u77e5\u8bc6\u5e93\uff1b2) \u57fa\u4e8e\u6570\u636e\u98de\u8f6e\u6784\u5efa\u667a\u80fd\u5e73\u53f0\uff0c\u6574\u5408\u65e5\u5e38\u64cd\u4f5c\u3001\u4e13\u5bb6\u6807\u6ce8\u548c\u6a21\u578b\u8bc4\u4f30\uff1b3) \u5f15\u5165\u53cd\u601d\u4f18\u5316\u6a21\u5757\u4e0e\u77e5\u8bc6\u5e93\u534f\u4f5c\uff0c\u5efa\u7acb\u5feb\u901f\u54cd\u5e94\u673a\u5236\u3002", "result": "\u5728\u4eac\u4e1c\u771f\u5b9e\u4ea4\u6613\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86LLM\u5206\u6790\u7ed3\u679c\u7684\u4e8b\u5b9e\u5bf9\u9f50\u548c\u98ce\u9669\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u90e8\u7f72\u540e\u5927\u5e45\u63d0\u5347\u4e86\u6848\u4ef6\u8c03\u67e5\u6d41\u7a0b\u6548\u7387\u3002", "conclusion": "SHERLOCK\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u98ce\u63a7\u5206\u6790\u4e2d\u7684\u5de5\u4f5c\u8d1f\u8377\u548c\u6807\u51c6\u5316\u95ee\u9898\uff0c\u901a\u8fc7LLM\u63a8\u7406\u80fd\u529b\u548c\u7cfb\u7edf\u5316\u65b9\u6cd5\u63d0\u5347\u4e86\u98ce\u9669\u7ba1\u7406\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2510.08985", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.08985", "abs": "https://arxiv.org/abs/2510.08985", "authors": ["Xuan Lu", "Haohang Huang", "Rui Meng", "Yaohui Jin", "Wenjun Zeng", "Xiaoyu Shen"], "title": "Rethinking Reasoning in Document Ranking: Why Chain-of-Thought Falls Short", "comment": null, "summary": "Document reranking is a key component in information retrieval (IR), aimed at\nrefining initial retrieval results to improve ranking quality for downstream\ntasks. Recent studies--motivated by large reasoning models (LRMs)--have begun\nincorporating explicit chain-of-thought (CoT) reasoning into LLM-based\nrerankers. However, the effectiveness of such reasoning for ranking tasks\nremains underexplored. In this work, we present the first systematic study of\nreasoning in reranking across both pointwise and listwise settings, under both\nsupervised fine-tuning and reinforcement learning. Using diverse benchmarks,\nincluding reasoning-intensive datasets (BRIGHT) and standard IR benchmarks\n(BEIR), we find that reasoning-augmented rerankers consistently underperform\ntheir direct counterparts that predict rankings without CoT, despite\nsubstantially higher inference costs. Our analysis reveals three core\nlimitations: (i) in pointwise rerankers, reasoning breaks calibration and\nbiases models toward the positive class, raising TPR but lowering TNR, which\ninflates false positives and degrades ranking in negative-dominant pools; (ii)\nin listwise rerankers, reasoning improves in-domain fit but increases variance\nand fails to generalize out-of-domain, even when reinforcement learning\nshortens rationales; and (iii) overall, directly fine-tuned rerankers remain\nmore stable, effective, and robust. These findings challenge the assumption\nthat explicit reasoning is universally beneficial for reranking. We conclude by\nhighlighting future directions, including calibration-aware scoring for\npointwise rerankers and the design of concise, targeted reasoning strategies to\nmitigate overfitting and overthinking in listwise rerankers.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u63a8\u7406\u5728\u6587\u6863\u91cd\u6392\u5e8f\u4e2d\u7684\u4f5c\u7528\uff0c\u53d1\u73b0\u5728\u70b9\u5f0f\u548c\u5217\u8868\u5f0f\u91cd\u6392\u5e8f\u4e2d\uff0c\u52a0\u5165\u63a8\u7406\u94fe\u7684\u6a21\u578b\u8868\u73b0\u5747\u4e0d\u5982\u76f4\u63a5\u9884\u6d4b\u6392\u540d\u7684\u6a21\u578b\uff0c\u4e14\u63a8\u7406\u6210\u672c\u66f4\u9ad8\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u4fc3\u4f7f\u7814\u7a76\u8005\u5c06\u663e\u5f0f\u63a8\u7406\u94fe\u5f15\u5165LLM\u91cd\u6392\u5e8f\u5668\uff0c\u4f46\u63a8\u7406\u5bf9\u6392\u5e8f\u4efb\u52a1\u7684\u6709\u6548\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5728\u70b9\u5f0f\u548c\u5217\u8868\u5f0f\u91cd\u6392\u5e8f\u8bbe\u7f6e\u4e0b\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u4f7f\u7528\u5305\u62ecBRIGHT\u63a8\u7406\u5bc6\u96c6\u578b\u6570\u636e\u96c6\u548cBEIR\u6807\u51c6IR\u57fa\u51c6\u5728\u5185\u7684\u591a\u6837\u5316\u57fa\u51c6\u8fdb\u884c\u7cfb\u7edf\u7814\u7a76\u3002", "result": "\u63a8\u7406\u589e\u5f3a\u7684\u91cd\u6392\u5e8f\u5668\u5728\u70b9\u5f0f\u8bbe\u7f6e\u4e2d\u7834\u574f\u6821\u51c6\u5e76\u504f\u5411\u6b63\u7c7b\uff0c\u5728\u5217\u8868\u5f0f\u8bbe\u7f6e\u4e2d\u63d0\u9ad8\u57df\u5185\u62df\u5408\u4f46\u589e\u52a0\u65b9\u5dee\u4e14\u65e0\u6cd5\u6cdb\u5316\u5230\u57df\u5916\uff0c\u76f4\u63a5\u5fae\u8c03\u7684\u91cd\u6392\u5e8f\u5668\u66f4\u7a33\u5b9a\u6709\u6548\u3002", "conclusion": "\u663e\u5f0f\u63a8\u7406\u5e76\u975e\u666e\u904d\u6709\u76ca\u4e8e\u91cd\u6392\u5e8f\uff0c\u672a\u6765\u65b9\u5411\u5305\u62ec\u70b9\u5f0f\u91cd\u6392\u5e8f\u5668\u7684\u6821\u51c6\u611f\u77e5\u8bc4\u5206\u548c\u8bbe\u8ba1\u7b80\u6d01\u3001\u6709\u9488\u5bf9\u6027\u7684\u63a8\u7406\u7b56\u7565\u4ee5\u51cf\u8f7b\u5217\u8868\u5f0f\u91cd\u6392\u5e8f\u4e2d\u7684\u8fc7\u62df\u5408\u548c\u8fc7\u5ea6\u601d\u8003\u3002"}}
{"id": "2510.09129", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.09129", "abs": "https://arxiv.org/abs/2510.09129", "authors": ["Yansong Wang", "Qihui Lin", "Junjie Huang", "Tao Jia"], "title": "Generative Data Augmentation in Graph Contrastive Learning for Recommendation", "comment": "The 34th ACM International Conference on Information and Knowledge\n  Management", "summary": "Recommendation systems have become indispensable in various online platforms,\nfrom e-commerce to streaming services. A fundamental challenge in this domain\nis learning effective embeddings from sparse user-item interactions. While\ncontrastive learning has recently emerged as a promising solution to this\nissue, generating augmented views for contrastive learning through most\nexisting random data augmentation methods often leads to the alteration of\noriginal semantic information. In this paper, we propose a novel framework,\nGDA4Rec (Generative Data Augmentation in graph contrastive learning for\nRecommendation) to generate high-quality augmented views and provide robust\nself-supervised signals. Specifically, we employ a noise generation module that\nleverages deep generative models to approximate the distribution of original\ndata for data augmentation. Additionally, GDA4Rec further extracts an item\ncomplement matrix to characterize the latent correlations between items and\nprovide additional self-supervised signals. Lastly, a joint objective that\nintegrates recommendation, data augmentation and contrastive learning is used\nto enforce the model to learn more effective and informative embeddings.\nExtensive experiments are conducted on three public datasets to demonstrate the\nsuperiority of the model. The code is available at:\nhttps://github.com/MrYansong/GDA4Rec.", "AI": {"tldr": "\u63d0\u51faGDA4Rec\u6846\u67b6\uff0c\u4f7f\u7528\u751f\u6210\u5f0f\u6570\u636e\u589e\u5f3a\u548c\u56fe\u5bf9\u6bd4\u5b66\u4e60\u6765\u6539\u8fdb\u63a8\u8350\u7cfb\u7edf\uff0c\u901a\u8fc7\u751f\u6210\u9ad8\u8d28\u91cf\u589e\u5f3a\u89c6\u56fe\u548c\u63d0\u53d6\u7269\u54c1\u4e92\u8865\u77e9\u9635\u6765\u5b66\u4e60\u66f4\u6709\u6548\u7684\u5d4c\u5165\u8868\u793a\u3002", "motivation": "\u73b0\u6709\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u4e2d\u7684\u968f\u673a\u6570\u636e\u589e\u5f3a\u4f1a\u6539\u53d8\u539f\u59cb\u8bed\u4e49\u4fe1\u606f\uff0c\u9700\u8981\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u7684\u589e\u5f3a\u89c6\u56fe\u6765\u63d0\u4f9b\u9c81\u68d2\u7684\u81ea\u76d1\u7763\u4fe1\u53f7\u3002", "method": "\u4f7f\u7528\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u8fd1\u4f3c\u539f\u59cb\u6570\u636e\u5206\u5e03\u8fdb\u884c\u6570\u636e\u589e\u5f3a\uff0c\u63d0\u53d6\u7269\u54c1\u4e92\u8865\u77e9\u9635\u8868\u5f81\u7269\u54c1\u95f4\u6f5c\u5728\u5173\u8054\uff0c\u7ed3\u5408\u63a8\u8350\u3001\u6570\u636e\u589e\u5f3a\u548c\u5bf9\u6bd4\u5b66\u4e60\u7684\u8054\u5408\u76ee\u6807\u51fd\u6570\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6a21\u578b\u4f18\u8d8a\u6027\u3002", "conclusion": "GDA4Rec\u6846\u67b6\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u589e\u5f3a\u89c6\u56fe\uff0c\u63d0\u4f9b\u6709\u6548\u81ea\u76d1\u7763\u4fe1\u53f7\uff0c\u5b66\u4e60\u5230\u66f4\u6709\u6548\u548c\u4fe1\u606f\u4e30\u5bcc\u7684\u5d4c\u5165\u8868\u793a\u3002"}}
{"id": "2510.09136", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09136", "abs": "https://arxiv.org/abs/2510.09136", "authors": ["Marlene Holzleitner", "Stephan Leitner", "Hanna Lind Jorgensen", "Christoph Schmitz", "Jacob Welander", "Dietmar Jannach"], "title": "Controlled Personalization in Legacy Media Online Services: A Case Study in News Recommendation", "comment": null, "summary": "Personalized news recommendations have become a standard feature of large\nnews aggregation services, optimizing user engagement through automated content\nselection. In contrast, legacy news media often approach personalization\ncautiously, striving to balance technological innovation with core editorial\nvalues. As a result, online platforms of traditional news outlets typically\ncombine editorially curated content with algorithmically selected articles - a\nstrategy we term controlled personalization. In this industry paper, we\nevaluate the effectiveness of controlled personalization through an A/B test\nconducted on the website of a major Norwegian legacy news organization. Our\nfindings indicate that even a modest level of personalization yields\nsubstantial benefits. Specifically, we observe that users exposed to\npersonalized content demonstrate higher click-through rates and reduced\nnavigation effort, suggesting improved discovery of relevant content. Moreover,\nour analysis reveals that controlled personalization contributes to greater\ncontent diversity and catalog coverage and in addition reduces popularity bias.\nOverall, our results suggest that controlled personalization can successfully\nalign user needs with editorial goals, offering a viable path for legacy media\nto adopt personalization technologies while upholding journalistic values.", "AI": {"tldr": "\u4f20\u7edf\u65b0\u95fb\u5a92\u4f53\u91c7\u7528\u53d7\u63a7\u4e2a\u6027\u5316\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u7f16\u8f91\u4ef7\u503c\u89c2\u7684\u540c\u65f6\u5f15\u5165\u7b97\u6cd5\u63a8\u8350\uff0cA/B\u6d4b\u8bd5\u663e\u793a\u80fd\u663e\u8457\u63d0\u5347\u70b9\u51fb\u7387\u3001\u5185\u5bb9\u591a\u6837\u6027\u548c\u964d\u4f4e\u6d41\u884c\u5ea6\u504f\u89c1\u3002", "motivation": "\u4f20\u7edf\u65b0\u95fb\u5a92\u4f53\u5728\u91c7\u7528\u4e2a\u6027\u5316\u63a8\u8350\u6280\u672f\u65f6\u9762\u4e34\u5e73\u8861\u6280\u672f\u521b\u65b0\u4e0e\u6838\u5fc3\u7f16\u8f91\u4ef7\u503c\u89c2\u7684\u6311\u6218\uff0c\u9700\u8981\u627e\u5230\u65e2\u80fd\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u53c8\u4e0d\u8fdd\u80cc\u65b0\u95fb\u539f\u5219\u7684\u65b9\u6cd5\u3002", "method": "\u5728\u632a\u5a01\u4e3b\u8981\u4f20\u7edf\u65b0\u95fb\u673a\u6784\u7684\u7f51\u7ad9\u4e0a\u8fdb\u884c\u4e86A/B\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u53d7\u63a7\u4e2a\u6027\u5316\u7b56\u7565\u4e0e\u4f20\u7edf\u7f16\u8f91\u63a8\u8350\u7684\u6548\u679c\u3002", "result": "\u4e2a\u6027\u5316\u5185\u5bb9\u663e\u8457\u63d0\u9ad8\u4e86\u70b9\u51fb\u7387\uff0c\u51cf\u5c11\u4e86\u7528\u6237\u5bfc\u822a\u52aa\u529b\uff0c\u63d0\u5347\u4e86\u5185\u5bb9\u591a\u6837\u6027\u548c\u76ee\u5f55\u8986\u76d6\u7387\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u6d41\u884c\u5ea6\u504f\u89c1\u3002", "conclusion": "\u53d7\u63a7\u4e2a\u6027\u5316\u80fd\u591f\u6210\u529f\u534f\u8c03\u7528\u6237\u9700\u6c42\u4e0e\u7f16\u8f91\u76ee\u6807\uff0c\u4e3a\u4f20\u7edf\u5a92\u4f53\u91c7\u7528\u4e2a\u6027\u5316\u6280\u672f\u540c\u65f6\u7ef4\u62a4\u65b0\u95fb\u4ef7\u503c\u89c2\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2510.09167", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.09167", "abs": "https://arxiv.org/abs/2510.09167", "authors": ["Minmao Wang", "Xingchen Liu", "Shijie Yi", "Likang Wu", "Hongke Zhao", "Fei Pan", "Qingpeng Cai", "Peng Jiang"], "title": "Hierarchical Semantic RL: Tackling the Problem of Dynamic Action Space for RL-based Recommendations", "comment": null, "summary": "Recommender Systems (RS) are fundamental to modern online services. While\nmost existing approaches optimize for short-term engagement, recent work has\nbegun to explore reinforcement learning (RL) to model long-term user value.\nHowever, these efforts face significant challenges due to the vast, dynamic\naction spaces inherent in recommendation, which hinder stable policy learning.\nTo resolve this bottleneck, we introduce Hierarchical Semantic RL (HSRL), which\nreframes RL-based recommendation over a fixed Semantic Action Space (SAS). HSRL\nencodes items as Semantic IDs (SIDs) for policy learning, and maps SIDs back to\ntheir original items via a fixed, invertible lookup during execution. To align\ndecision-making with SID generation, the Hierarchical Policy Network (HPN)\noperates in a coarse-to-fine manner, employing hierarchical residual state\nmodeling to refine each level's context from the previous level's residual,\nthereby stabilizing training and reducing representation-decision mismatch. In\nparallel, a Multi-level Critic (MLC) provides token-level value estimates,\nenabling fine-grained credit assignment. Across public benchmarks and a\nlarge-scale production dataset from a leading Chinese short-video advertising\nplatform, HSRL consistently surpasses state-of-the-art baselines. In online\ndeployment over a seven-day A/B testing, it delivers an 18.421% CVR lift with\nonly a 1.251% increase in cost, supporting HSRL as a scalable paradigm for\nRL-based recommendation. Our code is released at\nhttps://github.com/MinmaoWang/HSRL.", "AI": {"tldr": "HSRL\u901a\u8fc7\u5f15\u5165\u56fa\u5b9a\u8bed\u4e49\u52a8\u4f5c\u7a7a\u95f4\u548c\u5206\u5c42\u7b56\u7565\u7f51\u7edc\uff0c\u89e3\u51b3\u4e86\u63a8\u8350\u7cfb\u7edf\u4e2d\u5f3a\u5316\u5b66\u4e60\u9762\u4e34\u7684\u5927\u89c4\u6a21\u52a8\u6001\u52a8\u4f5c\u7a7a\u95f4\u95ee\u9898\uff0c\u5728\u516c\u5f00\u57fa\u51c6\u548c\u5de5\u4e1a\u90e8\u7f72\u4e2d\u5747\u53d6\u5f97\u663e\u8457\u6548\u679c\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u63a8\u8350\u7cfb\u7edf\u5927\u591a\u4f18\u5316\u77ed\u671f\u53c2\u4e0e\u5ea6\uff0c\u800c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u957f\u671f\u4ef7\u503c\u5efa\u6a21\u9762\u4e34\u5927\u89c4\u6a21\u52a8\u6001\u52a8\u4f5c\u7a7a\u95f4\u7684\u6311\u6218\uff0c\u5bfc\u81f4\u7b56\u7565\u5b66\u4e60\u4e0d\u7a33\u5b9a\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u8bed\u4e49\u5f3a\u5316\u5b66\u4e60(HSRL)\uff0c\u4f7f\u7528\u8bed\u4e49ID\u7f16\u7801\u7269\u54c1\u6784\u5efa\u56fa\u5b9a\u8bed\u4e49\u52a8\u4f5c\u7a7a\u95f4\uff0c\u901a\u8fc7\u5206\u5c42\u7b56\u7565\u7f51\u7edc\u8fdb\u884c\u7c97\u5230\u7ec6\u7684\u51b3\u7b56\uff0c\u5e76\u91c7\u7528\u591a\u7ea7\u8bc4\u8bba\u5bb6\u8fdb\u884c\u7ec6\u7c92\u5ea6\u4fe1\u7528\u5206\u914d\u3002", "result": "\u5728\u516c\u5f00\u57fa\u51c6\u548c\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u5747\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\uff0c\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\u5b9e\u73b018.421%\u7684\u8f6c\u5316\u7387\u63d0\u5347\uff0c\u6210\u672c\u4ec5\u589e\u52a01.251%\u3002", "conclusion": "HSRL\u4e3a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u8303\u5f0f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u52a8\u4f5c\u7a7a\u95f4\u5e26\u6765\u7684\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u95ee\u9898\u3002"}}
{"id": "2510.09393", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09393", "abs": "https://arxiv.org/abs/2510.09393", "authors": ["Dakai Zhai", "Jiong Gao", "Boya Du", "Junwei Xu", "Qijie Shen", "Jialin Zhu", "Yuning Jiang"], "title": "ChoirRec: Semantic User Grouping via LLMs for Conversion Rate Prediction of Low-Activity Users", "comment": null, "summary": "Accurately predicting conversion rates (CVR) for low-activity users remains a\nfundamental challenge in large-scale e-commerce recommender systems.Existing\napproaches face three critical limitations: (i) reliance on noisy and\nunreliable behavioral signals; (ii) insufficient user-level information due to\nthe lack of diverse interaction data; and (iii) a systemic training bias toward\nhigh-activity users that overshadows the needs of low-activity users.To address\nthese challenges, we propose ChoirRec, a novel framework that leverages the\nsemantic capabilities of Large Language Models (LLMs) to construct semantic\nuser groups and enhance CVR prediction for low-activity users.With a\ndual-channel architecture designed for robust cross-user knowledge transfer,\nChoirRec comprises three components: (i) a Semantic Group Generation module\nthat utilizes LLMs to form reliable, cross-activity user clusters, thereby\nfiltering out noisy signals; (ii) a Group-aware Hierarchical Representation\nmodule that enriches sparse user embeddings with informative group-level priors\nto mitigate data insufficiency; and (iii) a Group-aware Multi-granularity\nModual that employs a dual-channel architecture and adaptive fusion mechanism\nto ensure effective learning and utilization of group knowledge. We conduct\nextensive offline and online experiments on Taobao, a leading industrial-scale\ne-commerce platform.ChoirRec improves GAUC by 1.16\\% in offline evaluations,\nwhile online A/B testing reveals a 7.24\\% increase in order volume,\nhighlighting its substantial practical value in real-world applications.", "AI": {"tldr": "ChoirRec\u662f\u4e00\u4e2a\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u8bed\u4e49\u7528\u6237\u7fa4\u7ec4\u6765\u63d0\u5347\u4f4e\u6d3b\u8dc3\u7528\u6237\u8f6c\u5316\u7387\u9884\u6d4b\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u901a\u9053\u67b6\u6784\u5b9e\u73b0\u8de8\u7528\u6237\u77e5\u8bc6\u8fc1\u79fb\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u4f4e\u6d3b\u8dc3\u7528\u6237CVR\u9884\u6d4b\u4e2d\u7684\u4e09\u4e2a\u5173\u952e\u5c40\u9650\uff1a\u4f9d\u8d56\u566a\u58f0\u884c\u4e3a\u4fe1\u53f7\u3001\u7528\u6237\u7ea7\u4fe1\u606f\u4e0d\u8db3\u3001\u8bad\u7ec3\u504f\u5411\u9ad8\u6d3b\u8dc3\u7528\u6237\u3002", "method": "\u91c7\u7528\u53cc\u901a\u9053\u67b6\u6784\uff0c\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a\u8bed\u4e49\u7fa4\u7ec4\u751f\u6210\u6a21\u5757\uff08\u5229\u7528LLM\u5f62\u6210\u8de8\u6d3b\u8dc3\u5ea6\u7528\u6237\u96c6\u7fa4\uff09\u3001\u7fa4\u7ec4\u611f\u77e5\u5206\u5c42\u8868\u793a\u6a21\u5757\uff08\u4e30\u5bcc\u7a00\u758f\u7528\u6237\u5d4c\u5165\uff09\u3001\u7fa4\u7ec4\u611f\u77e5\u591a\u7c92\u5ea6\u6a21\u5757\uff08\u53cc\u901a\u9053\u67b6\u6784\u548c\u81ea\u9002\u5e94\u878d\u5408\u673a\u5236\uff09\u3002", "result": "\u5728\u6dd8\u5b9d\u5e73\u53f0\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u79bb\u7ebf\u8bc4\u4f30GAUC\u63d0\u53471.16%\uff0c\u5728\u7ebfA/B\u6d4b\u8bd5\u8ba2\u5355\u91cf\u589e\u957f7.24%\u3002", "conclusion": "ChoirRec\u5728\u5de5\u4e1a\u7ea7\u7535\u5546\u5e73\u53f0\u4e0a\u5c55\u73b0\u51fa\u663e\u8457\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4f4e\u6d3b\u8dc3\u7528\u6237\u7684\u8f6c\u5316\u7387\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2510.09510", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.09510", "abs": "https://arxiv.org/abs/2510.09510", "authors": ["Siyue Zhang", "Yuan Gao", "Xiao Zhou", "Yilun Zhao", "Tingyu Song", "Arman Cohan", "Anh Tuan Luu", "Chen Zhao"], "title": "MRMR: A Realistic and Expert-Level Multidisciplinary Benchmark for Reasoning-Intensive Multimodal Retrieval", "comment": null, "summary": "We introduce MRMR, the first expert-level multidisciplinary multimodal\nretrieval benchmark requiring intensive reasoning. MRMR contains 1,502 queries\nspanning 23 domains, with positive documents carefully verified by human\nexperts. Compared to prior benchmarks, MRMR introduces three key advancements.\nFirst, it challenges retrieval systems across diverse areas of expertise,\nenabling fine-grained model comparison across domains. Second, queries are\nreasoning-intensive, with images requiring deeper interpretation such as\ndiagnosing microscopic slides. We further introduce Contradiction Retrieval, a\nnovel task requiring models to identify conflicting concepts. Finally, queries\nand documents are constructed as image-text interleaved sequences. Unlike\nearlier benchmarks restricted to single images or unimodal documents, MRMR\noffers a realistic setting with multi-image queries and mixed-modality corpus\ndocuments. We conduct an extensive evaluation of 4 categories of multimodal\nretrieval systems and 14 frontier models on MRMR. The text embedding model\nQwen3-Embedding with LLM-generated image captions achieves the highest\nperformance, highlighting substantial room for improving multimodal retrieval\nmodels. Although latest multimodal models such as Ops-MM-Embedding perform\ncompetitively on expert-domain queries, they fall short on reasoning-intensive\ntasks. We believe that MRMR paves the way for advancing multimodal retrieval in\nmore realistic and challenging scenarios.", "AI": {"tldr": "MRMR\u662f\u9996\u4e2a\u4e13\u5bb6\u7ea7\u591a\u5b66\u79d1\u591a\u6a21\u6001\u68c0\u7d22\u57fa\u51c6\uff0c\u5305\u542b1502\u4e2a\u8de823\u4e2a\u9886\u57df\u7684\u67e5\u8be2\uff0c\u9700\u8981\u6df1\u5ea6\u63a8\u7406\u80fd\u529b\uff0c\u652f\u6301\u56fe\u50cf-\u6587\u672c\u4ea4\u9519\u5e8f\u5217\u7684\u68c0\u7d22\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u68c0\u7d22\u57fa\u51c6\u7f3a\u4e4f\u5bf9\u591a\u5b66\u79d1\u4e13\u4e1a\u77e5\u8bc6\u3001\u6df1\u5ea6\u63a8\u7406\u80fd\u529b\u548c\u591a\u6a21\u6001\u4ea4\u9519\u5e8f\u5217\u7684\u652f\u6301\uff0c\u9700\u8981\u6784\u5efa\u66f4\u771f\u5b9e\u3001\u66f4\u5177\u6311\u6218\u6027\u7684\u591a\u6a21\u6001\u68c0\u7d22\u8bc4\u4f30\u6807\u51c6\u3002", "method": "\u6784\u5efa\u5305\u542b1502\u4e2a\u67e5\u8be2\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u6db5\u76d623\u4e2a\u4e13\u4e1a\u9886\u57df\uff0c\u5f15\u5165\u77db\u76fe\u68c0\u7d22\u65b0\u4efb\u52a1\uff0c\u652f\u6301\u591a\u56fe\u50cf\u67e5\u8be2\u548c\u6df7\u5408\u6a21\u6001\u6587\u6863\uff0c\u5bf94\u7c7b14\u4e2a\u524d\u6cbf\u591a\u6a21\u6001\u68c0\u7d22\u7cfb\u7edf\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "Qwen3-Embedding\u7ed3\u5408LLM\u751f\u6210\u7684\u56fe\u50cf\u63cf\u8ff0\u8868\u73b0\u6700\u4f73\uff0c\u591a\u6a21\u6001\u6a21\u578b\u5728\u4e13\u4e1a\u9886\u57df\u67e5\u8be2\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u63a8\u7406\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\u4ecd\u6709\u4e0d\u8db3\u3002", "conclusion": "MRMR\u57fa\u51c6\u4e3a\u63a8\u8fdb\u591a\u6a21\u6001\u68c0\u7d22\u5728\u66f4\u771f\u5b9e\u548c\u6311\u6218\u6027\u573a\u666f\u4e2d\u7684\u53d1\u5c55\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u73b0\u6709\u6a21\u578b\u5728\u63a8\u7406\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002"}}
{"id": "2510.09557", "categories": ["cs.IR", "H.3.3"], "pdf": "https://arxiv.org/pdf/2510.09557", "abs": "https://arxiv.org/abs/2510.09557", "authors": ["Tzu-Lin Kuo", "Wei-Ning Chiu", "Wei-Yun Ma", "Pu-Jen Cheng"], "title": "Doc2Query++: Topic-Coverage based Document Expansion and its Application to Dense Retrieval via Dual-Index Fusion", "comment": "11 pages, 4 figures", "summary": "Document expansion (DE) via query generation tackles vocabulary mismatch in\nsparse retrieval, yet faces limitations: uncontrolled generation producing\nhallucinated or redundant queries with low diversity; poor generalization from\nin-domain training (e.g., MS MARCO) to out-of-domain data like BEIR; and noise\nfrom concatenation harming dense retrieval. While Large Language Models (LLMs)\nenable cross-domain query generation, basic prompting lacks control, and\ntaxonomy-based methods rely on domain-specific structures, limiting\napplicability. To address these challenges, we introduce Doc2Query++, a DE\nframework that structures query generation by first inferring a document's\nlatent topics via unsupervised topic modeling for cross-domain applicability,\nthen using hybrid keyword selection to create a diverse and relevant keyword\nset per document. This guides LLM not only to leverage keywords, which ensure\ncomprehensive topic representation, but also to reduce redundancy through\ndiverse, relevant terms. To prevent noise from query appending in dense\nretrieval, we propose Dual-Index Fusion strategy that isolates text and query\nsignals, boosting performance in dense settings. Extensive experiments show\nDoc2Query++ significantly outperforms state-of-the-art baselines, achieving\nsubstantial gains in MAP, nDCG@10 and Recall@100 across diverse datasets on\nboth sparse and dense retrieval.", "AI": {"tldr": "Doc2Query++ \u662f\u4e00\u4e2a\u6587\u6863\u6269\u5c55\u6846\u67b6\uff0c\u901a\u8fc7\u65e0\u76d1\u7763\u4e3b\u9898\u5efa\u6a21\u548c\u6df7\u5408\u5173\u952e\u8bcd\u9009\u62e9\u6765\u6307\u5bfcLLM\u751f\u6210\u591a\u6837\u5316\u4e14\u76f8\u5173\u7684\u67e5\u8be2\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6587\u6863\u6269\u5c55\u65b9\u6cd5\u4e2d\u7684\u5e7b\u89c9\u3001\u5197\u4f59\u548c\u8de8\u57df\u6cdb\u5316\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u53cc\u7d22\u5f15\u878d\u5408\u7b56\u7565\u63d0\u5347\u7a20\u5bc6\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u6587\u6863\u6269\u5c55\u65b9\u6cd5\u5b58\u5728\u751f\u6210\u4e0d\u53ef\u63a7\uff08\u4ea7\u751f\u5e7b\u89c9\u6216\u5197\u4f59\u67e5\u8be2\uff09\u3001\u8de8\u57df\u6cdb\u5316\u80fd\u529b\u5dee\uff08\u5982\u4eceMS MARCO\u5230BEIR\u6570\u636e\u96c6\uff09\u4ee5\u53ca\u67e5\u8be2\u62fc\u63a5\u5e26\u6765\u7684\u566a\u58f0\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u7a20\u5bc6\u68c0\u7d22\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "method": "1. \u4f7f\u7528\u65e0\u76d1\u7763\u4e3b\u9898\u5efa\u6a21\u63a8\u65ad\u6587\u6863\u7684\u6f5c\u5728\u4e3b\u9898\u4ee5\u5b9e\u73b0\u8de8\u57df\u9002\u7528\u6027\uff1b2. \u901a\u8fc7\u6df7\u5408\u5173\u952e\u8bcd\u9009\u62e9\u4e3a\u6bcf\u4e2a\u6587\u6863\u521b\u5efa\u591a\u6837\u5316\u4e14\u76f8\u5173\u7684\u5173\u952e\u8bcd\u96c6\uff1b3. \u6307\u5bfcLLM\u5229\u7528\u5173\u952e\u8bcd\u751f\u6210\u67e5\u8be2\uff0c\u786e\u4fdd\u5168\u9762\u4e3b\u9898\u8868\u793a\u5e76\u51cf\u5c11\u5197\u4f59\uff1b4. \u63d0\u51fa\u53cc\u7d22\u5f15\u878d\u5408\u7b56\u7565\uff0c\u5206\u79bb\u6587\u672c\u548c\u67e5\u8be2\u4fe1\u53f7\u4ee5\u907f\u514d\u566a\u58f0\u3002", "result": "Doc2Query++\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u4f73\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728MAP\u3001nDCG@10\u548cRecall@100\u7b49\u6307\u6807\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u63d0\u5347\uff0c\u9002\u7528\u4e8e\u7a00\u758f\u548c\u7a20\u5bc6\u68c0\u7d22\u3002", "conclusion": "Doc2Query++\u901a\u8fc7\u7ed3\u6784\u5316\u67e5\u8be2\u751f\u6210\u548c\u53cc\u7d22\u5f15\u878d\u5408\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6587\u6863\u6269\u5c55\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5728\u8de8\u57df\u573a\u666f\u4e0b\u5b9e\u73b0\u4e86\u4f18\u5f02\u7684\u68c0\u7d22\u6027\u80fd\u3002"}}
