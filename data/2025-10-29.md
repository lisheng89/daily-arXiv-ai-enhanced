<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 5]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Resource-Efficient LLM Application for Structured Transformation of Unstructured Financial Contracts](https://arxiv.org/abs/2510.23990)
*Maruf Ahmed Mridul,Oshani Seneviratne*

Main category: cs.IR

TL;DR: 本文扩展了CDMizer框架，通过模板驱动的方法将法律合同转换为标准化的CDM格式，使用较小的开源LLM实现了与大型专有模型相媲美的性能。


<details>
  <summary>Details</summary>
Motivation: 将非结构化法律合同转换为机器可读的标准化格式对于自动化金融工作流程至关重要，但将复杂法律文档转换为CDM表示仍然是一个重大挑战。

Method: 扩展CDMizer框架，采用模板驱动的解决方案，确保在合同到CDM转换过程中的语法正确性和CDM模式遵从性。

Result: CDMizer与显著较小的开源大型语言模型集成后，在准确性和效率方面实现了与大型专有模型相竞争的性能。

Conclusion: 这项工作强调了资源高效解决方案在自动化法律合同转换方面的潜力，为资源受限或有严格数据隐私要求的金融机构提供了成本效益高且可扩展的方法。

Abstract: The transformation of unstructured legal contracts into standardized,
machine-readable formats is essential for automating financial workflows. The
Common Domain Model (CDM) provides a standardized framework for this purpose,
but converting complex legal documents like Credit Support Annexes (CSAs) into
CDM representations remains a significant challenge. In this paper, we present
an extension of the CDMizer framework, a template-driven solution that ensures
syntactic correctness and adherence to the CDM schema during contract-to-CDM
conversion. We apply this extended framework to a real-world task, comparing
its performance with a benchmark developed by the International Swaps and
Derivatives Association (ISDA) for CSA clause extraction. Our results show that
CDMizer, when integrated with a significantly smaller, open-source Large
Language Model (LLM), achieves competitive performance in terms of accuracy and
efficiency against larger, proprietary models. This work underscores the
potential of resource-efficient solutions to automate legal contract
transformation, offering a cost-effective and scalable approach that can meet
the needs of financial institutions with constrained resources or strict data
privacy requirements.

</details>


### [2] [DUET: Dual Model Co-Training for Entire Space CTR Prediction](https://arxiv.org/abs/2510.24369)
*Yutian Xiao,Meng Yuan,Fuzhen Zhuang,Wei Chen,Shukuan Wang,Shanqi Liu,Chao Feng,Wenhui Yu,Xiang Li,Lantao Hu,Han Li,Zhao Zhang*

Main category: cs.IR

TL;DR: DUET是一个集式预排序框架，通过集合级预测和双模型协同训练，在计算预算限制下实现表达性建模并缓解样本选择偏差问题。


<details>
  <summary>Details</summary>
Motivation: 解决预排序阶段模型表达能力与计算效率之间的内在权衡问题，传统双塔架构虽然计算高效但估计能力有限，无法捕捉候选项目间的复杂协同和抑制关系，且会加剧样本选择偏差问题。

Method: 采用集合级预测方法，在单次前向传播中对整个候选子集进行预测，实现候选项目间的信息感知交互；使用双模型协同训练机制，通过相互伪标签精化对未曝光项目进行监督扩展。

Result: 经过离线和在线A/B测试验证，DUET在多个核心业务指标上持续优于最先进的基线方法，目前已在快手和快手极速版应用中全面部署，为数亿用户提供服务。

Conclusion: DUET框架成功解决了预排序阶段的表达性与效率权衡问题，通过集合级建模和协同训练机制有效提升了推荐系统的性能。

Abstract: The pre-ranking stage plays a pivotal role in large-scale recommender systems
but faces an intrinsic trade-off between model expressiveness and computational
efficiency. Owing to the massive candidate pool and strict latency constraints,
industry systems often rely on lightweight two-tower architectures, which are
computationally efficient yet limited in estimation capability. As a result,
they struggle to capture the complex synergistic and suppressive relationships
among candidate items, which are essential for producing contextually coherent
and diverse recommendation lists. Moreover, this simplicity further amplifies
the Sample Selection Bias (SSB) problem, as coarse-grained models trained on
biased exposure data must generalize to a much larger candidate space with
distinct distributions.
  To address these issues, we propose \textbf{DUET} (\textbf{DU}al Model
Co-Training for \textbf{E}ntire Space C\textbf{T}R Prediction), a set-wise
pre-ranking framework that achieves expressive modeling under tight
computational budgets. Instead of scoring items independently, DUET performs
set-level prediction over the entire candidate subset in a single forward pass,
enabling information-aware interactions among candidates while amortizing the
computational cost across the set. Moreover, a dual model co-training mechanism
extends supervision to unexposed items via mutual pseudo-label refinement,
effectively mitigating SSB. Validated through extensive offline experiments and
online A/B testing, DUET consistently outperforms state-of-the-art baselines
and achieves improvements across multiple core business metrics. At present,
DUET has been fully deployed in Kuaishou and Kuaishou Lite Apps, serving the
main traffic for hundreds of millions of users.

</details>


### [3] [Metadata-Driven Retrieval-Augmented Generation for Financial Question Answering](https://arxiv.org/abs/2510.24402)
*Michail Dadopoulos,Anestis Ladas,Stratos Moschidis,Ioannis Negkakis*

Main category: cs.IR

TL;DR: 提出了一种针对长结构金融文档的多阶段RAG架构，通过LLM生成元数据、上下文丰富的文档块和多种增强技术，在FinanceBench数据集上实现显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统RAG在处理长结构金融文件时表现不佳，因为相关证据稀疏且存在交叉引用，需要更先进的元数据驱动方法。

Method: 采用多阶段RAG架构，包括LLM生成的元数据、预检索过滤、后检索重排和丰富嵌入，特别强调将块元数据直接与文本嵌入的"上下文块"方法。

Result: 结果显示强大的重排器对精度至关重要，但最大性能提升来自上下文块嵌入。提出的最优架构结合LLM驱动的预检索优化和上下文嵌入实现卓越性能。

Conclusion: 研究为构建稳健的元数据感知RAG系统提供了蓝图，特别适用于金融文档分析，并在性能与运营效率之间提供了实用权衡。

Abstract: Retrieval-Augmented Generation (RAG) struggles on long, structured financial
filings where relevant evidence is sparse and cross-referenced. This paper
presents a systematic investigation of advanced metadata-driven
Retrieval-Augmented Generation (RAG) techniques, proposing and evaluating a
novel, multi-stage RAG architecture that leverages LLM-generated metadata. We
introduce a sophisticated indexing pipeline to create contextually rich
document chunks and benchmark a spectrum of enhancements, including
pre-retrieval filtering, post-retrieval reranking, and enriched embeddings,
benchmarked on the FinanceBench dataset. Our results reveal that while a
powerful reranker is essential for precision, the most significant performance
gains come from embedding chunk metadata directly with text ("contextual
chunks"). Our proposed optimal architecture combines LLM-driven pre-retrieval
optimizations with these contextual embeddings to achieve superior performance.
Additionally, we present a custom metadata reranker that offers a compelling,
cost-effective alternative to commercial solutions, highlighting a practical
trade-off between peak performance and operational efficiency. This study
provides a blueprint for building robust, metadata-aware RAG systems for
financial document analysis.

</details>


### [4] [From Time and Place to Preference: LLM-Driven Geo-Temporal Context in Recommendations](https://arxiv.org/abs/2510.24430)
*Yejin Kim,Shaghayegh Agah,Mayur Nankani,Neeraj Sharma,Feifei Peng,Maria Peifer,Sardar Hamidian,H Howie Huang*

Main category: cs.IR

TL;DR: 提出使用LLM生成地理时间嵌入的框架，捕捉节假日、季节趋势和本地/全球事件，通过特征融合或辅助损失整合到序列模型中，提升推荐系统性能。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统将时间戳视为数值或周期性值，忽略了现实世界背景如节假日、事件和季节模式，需要更丰富的地理时间上下文。

Method: 使用LLM从时间戳和粗略位置生成地理时间嵌入，通过特征融合与元数据嵌入或语义与地理时间对齐的辅助损失整合到序列模型中。

Result: 在MovieLens、LastFM和生产数据集上验证，地理时间嵌入提供了与完整模型集成结果一致的预测信号。

Conclusion: 强调需要自适应或混合推荐策略，并发布了上下文丰富的MovieLens数据集支持未来研究。

Abstract: Most recommender systems treat timestamps as numeric or cyclical values,
overlooking real-world context such as holidays, events, and seasonal patterns.
We propose a scalable framework that uses large language models (LLMs) to
generate geo-temporal embeddings from only a timestamp and coarse location,
capturing holidays, seasonal trends, and local/global events. We then introduce
a geo-temporal embedding informativeness test as a lightweight diagnostic,
demonstrating on MovieLens, LastFM, and a production dataset that these
embeddings provide predictive signal consistent with the outcomes of full model
integrations. Geo-temporal embeddings are incorporated into sequential models
through (1) direct feature fusion with metadata embeddings or (2) an auxiliary
loss that enforces semantic and geo-temporal alignment. Our findings highlight
the need for adaptive or hybrid recommendation strategies, and we release a
context-enriched MovieLens dataset to support future research.

</details>


### [5] [MiniOneRec: An Open-Source Framework for Scaling Generative Recommendation](https://arxiv.org/abs/2510.24431)
*Xiaoyu Kong,Leheng Sheng,Junfei Tan,Yuxin Chen,Jiancan Wu,An Zhang,Xiang Wang,Xiangnan He*

Main category: cs.IR

TL;DR: MiniOneRec是首个完全开源的生成式推荐框架，通过语义ID序列替代传统嵌入表，验证了生成式推荐方法的参数效率，并提出轻量级后训练方法提升性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的成功引发了推荐系统是否能获得类似扩展效益的思考。传统推荐系统在嵌入维度增长时趋于饱和，而生成式方法用紧凑的语义ID序列替代嵌入表，但工业部署多为专有，缺乏公开验证。

Method: 使用残差量化VAE生成语义ID，在Amazon Review数据集上对0.5B到7B参数的Qwen骨干网络进行后训练，包括监督微调和推荐导向的强化学习，提出全流程语义ID对齐和带约束解码的混合奖励强化学习。

Result: 实验显示随着模型规模增大，训练和评估损失持续下降，验证了生成式方法的参数效率。后训练技术显著提升了排序准确性和候选多样性。

Conclusion: 生成式推荐方法确实遵循扩展定律，轻量级后训练管道能够实现竞争性性能，为开源推荐系统发展提供了重要基础。

Abstract: The recent success of large language models (LLMs) has renewed interest in
whether recommender systems can achieve similar scaling benefits. Conventional
recommenders, dominated by massive embedding tables, tend to plateau as
embedding dimensions grow. In contrast, the emerging generative paradigm
replaces embeddings with compact Semantic ID (SID) sequences produced by
autoregressive Transformers. Yet most industrial deployments remain
proprietary, leaving two fundamental questions open: (1) Do the expected
scaling laws hold on public benchmarks? (2) What is the minimal post-training
recipe that enables competitive performance?
  We present MiniOneRec, to the best of our knowledge, the first fully
open-source generative recommendation framework, which provides an end-to-end
workflow spanning SID construction, supervised fine-tuning, and
recommendation-oriented reinforcement learning. We generate SIDs via a Residual
Quantized VAE and post-train Qwen backbones ranging from 0.5B to 7B parameters
on the Amazon Review dataset. Our experiments reveal a consistent downward
trend in both training and evaluation losses with increasing model size,
validating the parameter efficiency of the generative approach. To further
enhance performance, we propose a lightweight yet effective post-training
pipeline that (1) enforces full-process SID alignment and (2) applies
reinforcement learning with constrained decoding and hybrid rewards. Together,
these techniques yield significant improvements in both ranking accuracy and
candidate diversity.

</details>
