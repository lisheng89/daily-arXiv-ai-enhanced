<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 4]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Where to Explore: A Reach and Cost-Aware Approach for Unbiased Data Collection in Recommender Systems](https://arxiv.org/abs/2512.14733)
*Qiang Chen,Venkatesh Ganapati Hegde*

Main category: cs.IR

TL;DR: 在流媒体平台中，通过优化探索内容的位置（基于覆盖面和机会成本），在低参与度的滚动区域引入"Something Completely Different"随机内容行，既保持业务指标又收集无偏交互数据。


<details>
  <summary>Details</summary>
Motivation: 探索对提升长期推荐质量很重要，但在流媒体环境中会损害短期业务表现，因为用户被动参与、期望即时相关性且纠正机会少。需要找到安全高效的探索方法。

Method: 识别参与度低的滚动深度区域，战略性地引入包含随机内容的专用容器"Something Completely Different"行。根据经验低成本、高覆盖面的位置条件化显示，最小化与平台观看时间目标的权衡。

Result: A/B测试显示该策略保持业务指标的同时收集无偏交互数据。收集的无偏数据集成到下游候选生成中显著提升用户参与度。

Conclusion: 该方法通过行为感知机制在大规模上安全高效地展示探索内容，补充现有行内多样化和基于bandit的探索技术，验证了无偏数据对推荐系统的价值。

Abstract: Exploration is essential to improve long-term recommendation quality, but it often degrades short-term business performance, especially in remote-first TV environments where users engage passively, expect instant relevance, and offer few chances for correction. This paper introduces an approach for delivering content-level exploration safely and efficiently by optimizing its placement based on reach and opportunity cost. Deployed on a large-scale streaming platform with over 100 million monthly active users, our approach identifies scroll-depth regions with lower engagement and strategically introduces a dedicated container, the "Something Completely Different" row containing randomized content. Rather than enforcing exploration uniformly across the user interface (UI), we condition its appearance on empirically low-cost, high-reach positions to ensure minimal tradeoff against platform-level watch time goals. Extensive A/B testing shows that this strategy preserves business metrics while collecting unbiased interaction data. Our method complements existing intra-row diversification and bandit-based exploration techniques by introducing a deployable, behaviorally informed mechanism for surfacing exploratory content at scale. Moreover, we demonstrate that the collected unbiased data, integrated into downstream candidate generation, significantly improves user engagement, validating its value for recommender systems.

</details>


### [2] [Image Complexity-Aware Adaptive Retrieval for Efficient Vision-Language Models](https://arxiv.org/abs/2512.15372)
*Mikel Williams-Lekuona,Georgina Cosma*

Main category: cs.IR

TL;DR: ICAR提出了一种图像复杂度感知的检索方法，让视觉Transformer根据图像复杂度动态调整计算量，简单图像使用较少计算，复杂图像使用完整网络深度，同时保持跨模态对齐，实现了20%的实际加速。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型中的视觉Transformer对所有图像都使用相同的计算量（175.33 GFLOPs），无论图像简单还是复杂，这造成了计算资源的浪费。需要一种能根据图像复杂度动态调整计算的方法，同时保持跨模态对齐能力。

Method: 1. ICAR框架：通过双路径训练，使不同处理深度产生的嵌入保持兼容，确保图像表示与文本嵌入在同一语义空间中；2. ConvNeXt-IC：将图像复杂度评估作为分类任务，使用现代分类器骨干网络而非专用架构，实现复杂度预测；3. 根据复杂度决定计算量，简单图像提前退出，复杂图像完整处理。

Result: ConvNeXt-IC在图像复杂度评估上达到0.959的皮尔逊相关性（人类判断），速度提升4.4倍；ICAR在标准基准测试和真实网络数据上实现20%的实际加速，保持类别级性能，达到实例级性能的95%。

Conclusion: ICAR通过图像复杂度感知的动态计算分配，在保持视觉语言检索性能的同时显著减少计算开销，为视觉语言系统的可持续扩展提供了有效解决方案。

Abstract: Vision transformers in vision-language models apply uniform computational effort across all images, expending 175.33 GFLOPs (ViT-L/14) whether analysing a straightforward product photograph or a complex street scene. We propose ICAR (Image Complexity-Aware Retrieval), which enables vision transformers to use less compute for simple images whilst processing complex images through their full network depth. The key challenge is maintaining cross-modal alignment: embeddings from different processing depths must remain compatible for text matching. ICAR solves this through dual-path training that produces compatible embeddings from both reduced-compute and full-compute processing. This maintains compatibility between image representations and text embeddings in the same semantic space, whether an image exits early or processes fully. Unlike existing two-stage approaches that require expensive reranking, ICAR enables direct image-text matching without additional overhead. To determine how much compute to use, we develop ConvNeXt-IC, which treats image complexity assessment as a classification task. By applying modern classifier backbones rather than specialised architectures, ConvNeXt-IC achieves state-of-the-art performance with 0.959 correlation with human judgement (Pearson) and 4.4x speedup. Evaluated on standard benchmarks augmented with real-world web data, ICAR achieves 20% practical speedup while maintaining category-level performance and 95% of instance-level performance, enabling sustainable scaling of vision-language systems.

</details>


### [3] [MedNuggetizer: Confidence-Based Information Nugget Extraction from Medical Documents](https://arxiv.org/abs/2512.15384)
*Gregor Donabauer,Samy Ateia,Udo Kruschwitz,Maximilian Burger,Matthias May,Christian Gilfrich,Maximilian Haas,Julio Ruben Rodas Garzaro,Christoph Eckl*

Main category: cs.IR

TL;DR: MedNuggetizer是一个基于大语言模型的工具，用于从医学文档中提取和聚类信息块，帮助临床医生探索医学证据。


<details>
  <summary>Details</summary>
Motivation: 临床医生需要从大量医学文献中提取可靠证据，但传统方法耗时且效率低。需要一种工具能够自动从长文档中提取查询相关的信息块，并组织成可探索的证据。

Method: 基于大语言模型重复提取信息块，然后将这些信息块进行分组聚类，生成可靠证据。该方法可在单个文档内和跨多个文档间工作。

Result: 在"前列腺活检前抗生素预防"的临床用例中，使用主要泌尿科指南和PubMed研究作为信息来源进行验证。领域专家评估表明，该工具为临床医生和研究人员提供了探索长文档和提取可靠、查询聚焦医学证据的高效方法。

Conclusion: MedNuggetizer能够有效支持临床医生探索医学证据，通过自动化信息提取和聚类，提高了从医学文献中获取可靠证据的效率。

Abstract: We present MedNuggetizer, https://mednugget-ai.de/; access is available upon request.}, a tool for query-driven extraction and clustering of information nuggets from medical documents to support clinicians in exploring underlying medical evidence. Backed by a large language model (LLM), \textit{MedNuggetizer} performs repeated extractions of information nuggets that are then grouped to generate reliable evidence within and across multiple documents. We demonstrate its utility on the clinical use case of \textit{antibiotic prophylaxis before prostate biopsy} by using major urological guidelines and recent PubMed studies as sources of information. Evaluation by domain experts shows that \textit{MedNuggetizer} provides clinicians and researchers with an efficient way to explore long documents and easily extract reliable, query-focused medical evidence.

</details>


### [4] [BERT and CNN integrated Neural Collaborative Filtering for Recommender Systems](https://arxiv.org/abs/2512.15526)
*Abdullah Al Munem,Sumona Yeasmin,Mohammad Rezwanul Huq*

Main category: cs.IR

TL;DR: 该研究提出了一种结合BERT和CNN的神经协同过滤模型，用于推荐系统，能够处理数值、分类和图像数据，在MovieLens数据集上表现优于传统NCF和BERT-NCF模型。


<details>
  <summary>Details</summary>
Motivation: 网站所有者通过用户与内容的互动获利，而强大的推荐系统能够根据用户独特偏好推荐项目，从而增加用户互动。现有推荐系统在处理多模态数据方面存在局限，需要能够同时处理数值、分类和图像数据的综合模型。

Method: 提出了BERT和CNN集成的神经协同过滤模型，该模型接收用户和项目配置文件作为输入，能够处理数值、分类和图像数据以提取潜在特征。模型在MovieLens数据集的小样本上进行25个epoch的训练和验证，并与简单的NCF模型和基于BERT的NCF模型进行比较。

Result: 提出的模型在MovieLens数据集上对799名用户取得了0.72的召回率和0.486的Hit Ratio @ 10，表现优于两个基线模型（简单NCF和BERT-NCF）。

Conclusion: 实验表明，同时考虑分类数据和图像数据可以改善推荐系统的性能，多模态数据融合有助于更准确地捕捉用户兴趣。

Abstract: Every day, a significant number of users visit the internet for different needs. The owners of a website generate profits from the user interaction with the contents or items of the website. A robust recommendation system can increase user interaction with a website by recommending items according to the user's unique preferences. BERT and CNN-integrated neural collaborative filtering (NCF) have been proposed for the recommendation system in this experiment. The proposed model takes inputs from the user and item profile and finds the user's interest. This model can handle numeric, categorical, and image data to extract the latent features from the inputs. The model is trained and validated on a small sample of the MovieLens dataset for 25 epochs. The same dataset has been used to train and validate a simple NCF and a BERT-based NCF model and compared with the proposed model. The proposed model outperformed those two baseline models. The obtained result for the proposed model is 0.72 recall and 0.486 Hit Ratio @ 10 for 799 users on the MovieLens dataset. This experiment concludes that considering both categorical and image data can improve the performance of a recommendation system.

</details>
