{"id": "2512.13848", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.13848", "abs": "https://arxiv.org/abs/2512.13848", "authors": ["Mufhumudzi Muthivhi", "Terence L van Zyl", "Hairong Wang"], "title": "BiCoRec: Bias-Mitigated Context-Aware Sequential Recommendation Model", "comment": null, "summary": "Sequential recommendation models aim to learn from users evolving preferences. However, current state-of-the-art models suffer from an inherent popularity bias. This study developed a novel framework, BiCoRec, that adaptively accommodates users changing preferences for popular and niche items. Our approach leverages a co-attention mechanism to obtain a popularity-weighted user sequence representation, facilitating more accurate predictions. We then present a new training scheme that learns from future preferences using a consistency loss function. BiCoRec aimed to improve the recommendation performance of users who preferred niche items. For these users, BiCoRec achieves a 26.00% average improvement in NDCG@10 over state-of-the-art baselines. When ranking the relevant item against the entire collection, BiCoRec achieves NDCG@10 scores of 0.0102, 0.0047, 0.0021, and 0.0005 for the Movies, Fashion, Games and Music datasets.", "AI": {"tldr": "BiCoRec\uff1a\u901a\u8fc7\u534f\u540c\u6ce8\u610f\u529b\u673a\u5236\u548c\u4e00\u81f4\u6027\u635f\u5931\u51fd\u6570\uff0c\u81ea\u9002\u5e94\u5904\u7406\u7528\u6237\u5bf9\u70ed\u95e8\u4e0e\u51b7\u95e8\u7269\u54c1\u504f\u597d\u53d8\u5316\u7684\u5e8f\u5217\u63a8\u8350\u6846\u67b6", "motivation": "\u5f53\u524d\u6700\u5148\u8fdb\u7684\u5e8f\u5217\u63a8\u8350\u6a21\u578b\u5b58\u5728\u56fa\u6709\u7684\u6d41\u884c\u5ea6\u504f\u5dee\u95ee\u9898\uff0c\u65e0\u6cd5\u5f88\u597d\u5730\u9002\u5e94\u7528\u6237\u5bf9\u70ed\u95e8\u548c\u51b7\u95e8\u7269\u54c1\u504f\u597d\u7684\u52a8\u6001\u53d8\u5316\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u504f\u597d\u51b7\u95e8\u7269\u54c1\u7684\u7528\u6237\u7fa4\u4f53", "method": "\u63d0\u51faBiCoRec\u6846\u67b6\uff0c\u91c7\u7528\u534f\u540c\u6ce8\u610f\u529b\u673a\u5236\u83b7\u53d6\u6d41\u884c\u5ea6\u52a0\u6743\u7684\u7528\u6237\u5e8f\u5217\u8868\u793a\uff0c\u5e76\u8bbe\u8ba1\u65b0\u7684\u8bad\u7ec3\u65b9\u6848\uff0c\u5229\u7528\u4e00\u81f4\u6027\u635f\u5931\u51fd\u6570\u4ece\u672a\u6765\u504f\u597d\u4e2d\u5b66\u4e60", "result": "\u5bf9\u4e8e\u504f\u597d\u51b7\u95e8\u7269\u54c1\u7684\u7528\u6237\uff0cBiCoRec\u5728NDCG@10\u6307\u6807\u4e0a\u6bd4\u73b0\u6709\u6700\u4f73\u57fa\u7ebf\u5e73\u5747\u63d0\u534726.00%\uff1b\u5728\u5b8c\u6574\u7269\u54c1\u96c6\u6392\u5e8f\u4e2d\uff0c\u5728Movies\u3001Fashion\u3001Games\u548cMusic\u6570\u636e\u96c6\u4e0a\u5206\u522b\u83b7\u5f970.0102\u30010.0047\u30010.0021\u548c0.0005\u7684NDCG@10\u5206\u6570", "conclusion": "BiCoRec\u901a\u8fc7\u81ea\u9002\u5e94\u5904\u7406\u7528\u6237\u5bf9\u70ed\u95e8\u4e0e\u51b7\u95e8\u7269\u54c1\u7684\u504f\u597d\u53d8\u5316\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u5e8f\u5217\u63a8\u8350\u4e2d\u7684\u6d41\u884c\u5ea6\u504f\u5dee\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6027\u80fd\uff0c\u7279\u522b\u662f\u5bf9\u504f\u597d\u51b7\u95e8\u7269\u54c1\u7684\u7528\u6237\u7fa4\u4f53"}}
{"id": "2512.14034", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.14034", "abs": "https://arxiv.org/abs/2512.14034", "authors": ["Yifan Shao", "Peilin Zhou"], "title": "Intent-Guided Reasoning for Sequential Recommendation", "comment": "Under Review", "summary": "Sequential recommendation systems aim to capture users' evolving preferences from their interaction histories. Recent reasoningenhanced methods have shown promise by introducing deliberate, chain-of-thought-like processes with intermediate reasoning steps. However, these methods rely solely on the next target item as supervision, leading to two critical issues: (1) reasoning instability--the process becomes overly sensitive to recent behaviors and spurious interactions like accidental clicks, and (2) surface-level reasoning--the model memorizes item-to-item transitions rather than understanding intrinsic behavior patterns. To address these challenges, we propose IGR-SR, an Intent-Guided Reasoning framework for Sequential Recommendation that anchors the reasoning process to explicitly extracted high-level intents. Our framework comprises three key components: (1) a Latent Intent Distiller (LID) that efficiently extracts multi-faceted intents using a frozen encoder with learnable tokens, (2) an Intent-aware Deliberative Reasoner (IDR) that decouples reasoning into intent deliberation and decision-making via a dual-attention architecture, and (3) an Intent Consistency Regularization (ICR) that ensures robustness by enforcing consistent representations across different intent views. Extensive experiments on three public datasets demonstrate that IGR-SR achieves an average 7.13% improvement over state-of-the-art baselines. Critically, under 20% behavioral noise, IGR-SR degrades only 10.4% compared to 16.2% and 18.6% for competing methods, validating the effectiveness and robustness of intent-guided reasoning.", "AI": {"tldr": "IGR-SR\uff1a\u4e00\u79cd\u7528\u4e8e\u5e8f\u5217\u63a8\u8350\u7684\u610f\u56fe\u5f15\u5bfc\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u63d0\u53d6\u9ad8\u5c42\u610f\u56fe\u6765\u89e3\u51b3\u73b0\u6709\u63a8\u7406\u589e\u5f3a\u65b9\u6cd5\u4e2d\u7684\u63a8\u7406\u4e0d\u7a33\u5b9a\u6027\u548c\u8868\u9762\u7ea7\u63a8\u7406\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5e8f\u5217\u63a8\u8350\u4e2d\u7684\u63a8\u7406\u589e\u5f3a\u65b9\u6cd5\u4ec5\u4ee5\u4e0b\u4e00\u4e2a\u76ee\u6807\u7269\u54c1\u4f5c\u4e3a\u76d1\u7763\uff0c\u5bfc\u81f4\u4e24\u4e2a\u5173\u952e\u95ee\u9898\uff1a1\uff09\u63a8\u7406\u4e0d\u7a33\u5b9a\u6027\u2014\u2014\u8fc7\u7a0b\u5bf9\u8fd1\u671f\u884c\u4e3a\u548c\u5076\u7136\u70b9\u51fb\u7b49\u865a\u5047\u4ea4\u4e92\u8fc7\u4e8e\u654f\u611f\uff1b2\uff09\u8868\u9762\u7ea7\u63a8\u7406\u2014\u2014\u6a21\u578b\u8bb0\u5fc6\u7269\u54c1\u95f4\u8f6c\u79fb\u800c\u975e\u7406\u89e3\u5185\u5728\u884c\u4e3a\u6a21\u5f0f\u3002", "method": "\u63d0\u51faIGR-SR\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u6f5c\u5728\u610f\u56fe\u84b8\u998f\u5668\uff08LID\uff09\u4f7f\u7528\u51bb\u7ed3\u7f16\u7801\u5668\u548c\u53ef\u5b66\u4e60token\u9ad8\u6548\u63d0\u53d6\u591a\u5c42\u9762\u610f\u56fe\uff1b2\uff09\u610f\u56fe\u611f\u77e5\u5ba1\u614e\u63a8\u7406\u5668\uff08IDR\uff09\u901a\u8fc7\u53cc\u6ce8\u610f\u529b\u67b6\u6784\u5c06\u63a8\u7406\u89e3\u8026\u4e3a\u610f\u56fe\u5ba1\u8bae\u548c\u51b3\u7b56\u5236\u5b9a\uff1b3\uff09\u610f\u56fe\u4e00\u81f4\u6027\u6b63\u5219\u5316\uff08ICR\uff09\u901a\u8fc7\u5f3a\u5236\u4e0d\u540c\u610f\u56fe\u89c6\u56fe\u95f4\u8868\u793a\u4e00\u81f4\u6027\u786e\u4fdd\u9c81\u68d2\u6027\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cIGR-SR\u76f8\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u5e73\u5747\u63d0\u53477.13%\u3002\u572820%\u884c\u4e3a\u566a\u58f0\u4e0b\uff0cIGR-SR\u6027\u80fd\u4ec5\u4e0b\u964d10.4%\uff0c\u800c\u7ade\u4e89\u65b9\u6cd5\u4e0b\u964d16.2%\u548c18.6%\uff0c\u9a8c\u8bc1\u4e86\u610f\u56fe\u5f15\u5bfc\u63a8\u7406\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "IGR-SR\u901a\u8fc7\u663e\u5f0f\u63d0\u53d6\u548c\u5229\u7528\u9ad8\u5c42\u610f\u56fe\u6765\u5f15\u5bfc\u63a8\u7406\u8fc7\u7a0b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5e8f\u5217\u63a8\u8350\u4e2d\u63a8\u7406\u589e\u5f3a\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2512.14036", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.14036", "abs": "https://arxiv.org/abs/2512.14036", "authors": ["Yifan Shao", "Peilin Zhou", "Shoujin Wang", "Weizhi Zhang", "Xu Cai", "Sunghun Kim"], "title": "DTRec: Learning Dynamic Reasoning Trajectories for Sequential Recommendation", "comment": "Under Review", "summary": "Inspired by advances in LLMs, reasoning-enhanced sequential recommendation performs multi-step deliberation before making final predictions, unlocking greater potential for capturing user preferences. However, current methods are constrained by static reasoning trajectories that are ill-suited for the diverse complexity of user behaviors. They suffer from two key limitations: (1) a static reasoning direction, which uses flat supervision signals misaligned with human-like hierarchical reasoning, and (2) a fixed reasoning depth, which inefficiently applies the same computational effort to all users, regardless of pattern complexity. These rigidity lead to suboptimal performance and significant computational waste. To overcome these challenges, we propose DTRec, a novel and effective framework that explores the Dynamic reasoning Trajectory for Sequential Recommendation along both direction and depth. To guide the direction, we develop Hierarchical Process Supervision (HPS), which provides coarse-to-fine supervisory signals to emulate the natural, progressive refinement of human cognitive processes. To optimize the depth, we introduce the Adaptive Reasoning Halting (ARH) mechanism that dynamically adjusts the number of reasoning steps by jointly monitoring three indicators. Extensive experiments on three real-world datasets demonstrate the superiority of our approach, achieving up to a 24.5% performance improvement over strong baselines while simultaneously reducing computational cost by up to 41.6%.", "AI": {"tldr": "DTRec\uff1a\u52a8\u6001\u63a8\u7406\u8f68\u8ff9\u7684\u5e8f\u5217\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u8fc7\u7a0b\u76d1\u7763\u548c\u81ea\u9002\u5e94\u63a8\u7406\u505c\u6b62\u673a\u5236\uff0c\u5728\u65b9\u5411\u548c\u6df1\u5ea6\u4e0a\u5b9e\u73b0\u52a8\u6001\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u63a8\u7406\u589e\u5f3a\u5e8f\u5217\u63a8\u8350\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff1a1\uff09\u9759\u6001\u63a8\u7406\u65b9\u5411\uff0c\u4f7f\u7528\u6241\u5e73\u76d1\u7763\u4fe1\u53f7\uff0c\u4e0e\u4eba\u7c7b\u5206\u5c42\u63a8\u7406\u4e0d\u5339\u914d\uff1b2\uff09\u56fa\u5b9a\u63a8\u7406\u6df1\u5ea6\uff0c\u5bf9\u6240\u6709\u7528\u6237\u5e94\u7528\u76f8\u540c\u8ba1\u7b97\u91cf\uff0c\u4e0d\u8003\u8651\u884c\u4e3a\u6a21\u5f0f\u590d\u6742\u6027\u3002\u8fd9\u4e9b\u521a\u6027\u5bfc\u81f4\u6027\u80fd\u6b21\u4f18\u548c\u8ba1\u7b97\u6d6a\u8d39\u3002", "method": "\u63d0\u51faDTRec\u6846\u67b6\uff0c\u5728\u65b9\u5411\u548c\u6df1\u5ea6\u4e0a\u63a2\u7d22\u52a8\u6001\u63a8\u7406\u8f68\u8ff9\uff1a1\uff09\u5206\u5c42\u8fc7\u7a0b\u76d1\u7763\uff08HPS\uff09\u63d0\u4f9b\u4ece\u7c97\u5230\u7ec6\u7684\u76d1\u7763\u4fe1\u53f7\uff0c\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u8fc7\u7a0b\u7684\u6e10\u8fdb\u7ec6\u5316\uff1b2\uff09\u81ea\u9002\u5e94\u63a8\u7406\u505c\u6b62\uff08ARH\uff09\u673a\u5236\uff0c\u901a\u8fc7\u8054\u5408\u76d1\u63a7\u4e09\u4e2a\u6307\u6807\u52a8\u6001\u8c03\u6574\u63a8\u7406\u6b65\u6570\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe24.5%\uff0c\u540c\u65f6\u8ba1\u7b97\u6210\u672c\u964d\u4f4e\u9ad8\u8fbe41.6%\u3002", "conclusion": "DTRec\u901a\u8fc7\u52a8\u6001\u63a8\u7406\u8f68\u8ff9\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u521a\u6027\u9650\u5236\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u3001\u66f4\u51c6\u786e\u7684\u5e8f\u5217\u63a8\u8350\uff0c\u5e73\u8861\u4e86\u6027\u80fd\u4e0e\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2512.14041", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.14041", "abs": "https://arxiv.org/abs/2512.14041", "authors": ["Mingjia Yin", "Junwei Pan", "Hao Wang", "Ximei Wang", "Shangyu Zhang", "Jie Jiang", "Defu Lian", "Enhong Chen"], "title": "From Feature Interaction to Feature Generation: A Generative Paradigm of CTR Prediction Models", "comment": null, "summary": "Click-Through Rate (CTR) prediction, a core task in recommendation systems, aims to estimate the probability of users clicking on items. Existing models predominantly follow a discriminative paradigm, which relies heavily on explicit interactions between raw ID embeddings. However, this paradigm inherently renders them susceptible to two critical issues: embedding dimensional collapse and information redundancy, stemming from the over-reliance on feature interactions \\emph{over raw ID embeddings}. To address these limitations, we propose a novel \\emph{Supervised Feature Generation (SFG)} framework, \\emph{shifting the paradigm from discriminative ``feature interaction\" to generative ``feature generation\"}. Specifically, SFG comprises two key components: an \\emph{Encoder} that constructs hidden embeddings for each feature, and a \\emph{Decoder} tasked with regenerating the feature embeddings of all features from these hidden representations. Unlike existing generative approaches that adopt self-supervised losses, we introduce a supervised loss to utilize the supervised signal, \\ie, click or not, in the CTR prediction task. This framework exhibits strong generalizability: it can be seamlessly integrated with most existing CTR models, reformulating them under the generative paradigm. Extensive experiments demonstrate that SFG consistently mitigates embedding collapse and reduces information redundancy, while yielding substantial performance gains across various datasets and base models. The code is available at https://github.com/USTC-StarTeam/GE4Rec.", "AI": {"tldr": "\u63d0\u51faSFG\u6846\u67b6\uff0c\u5c06CTR\u9884\u6d4b\u4ece\u5224\u522b\u5f0f\u7684\u7279\u5f81\u4ea4\u4e92\u8303\u5f0f\u8f6c\u5411\u751f\u6210\u5f0f\u7684\u7279\u5f81\u751f\u6210\u8303\u5f0f\uff0c\u89e3\u51b3\u5d4c\u5165\u7ef4\u5ea6\u584c\u7f29\u548c\u4fe1\u606f\u5197\u4f59\u95ee\u9898", "motivation": "\u73b0\u6709CTR\u9884\u6d4b\u6a21\u578b\u4e3b\u8981\u91c7\u7528\u5224\u522b\u5f0f\u8303\u5f0f\uff0c\u8fc7\u5ea6\u4f9d\u8d56\u539f\u59cbID\u5d4c\u5165\u7684\u7279\u5f81\u4ea4\u4e92\uff0c\u5bfc\u81f4\u5d4c\u5165\u7ef4\u5ea6\u584c\u7f29\u548c\u4fe1\u606f\u5197\u4f59\u4e24\u4e2a\u5173\u952e\u95ee\u9898", "method": "\u63d0\u51fa\u76d1\u7763\u7279\u5f81\u751f\u6210\uff08SFG\uff09\u6846\u67b6\uff0c\u5305\u542b\u7f16\u7801\u5668\u6784\u5efa\u7279\u5f81\u9690\u85cf\u5d4c\u5165\u548c\u89e3\u7801\u5668\u4ece\u9690\u85cf\u8868\u793a\u91cd\u6784\u7279\u5f81\u5d4c\u5165\uff0c\u4f7f\u7528\u76d1\u7763\u635f\u5931\u800c\u975e\u81ea\u76d1\u7763\u635f\u5931", "result": "SFG\u80fd\u6709\u6548\u7f13\u89e3\u5d4c\u5165\u584c\u7f29\u548c\u51cf\u5c11\u4fe1\u606f\u5197\u4f59\uff0c\u5728\u5404\u79cd\u6570\u636e\u96c6\u548c\u57fa\u7840\u6a21\u578b\u4e0a\u5e26\u6765\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u4e14\u80fd\u4e0e\u5927\u591a\u6570\u73b0\u6709CTR\u6a21\u578b\u65e0\u7f1d\u96c6\u6210", "conclusion": "SFG\u6846\u67b6\u901a\u8fc7\u8303\u5f0f\u8f6c\u53d8\u89e3\u51b3\u4e86CTR\u9884\u6d4b\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u4ece\u5224\u522b\u5f0f\u7279\u5f81\u4ea4\u4e92\u5230\u751f\u6210\u5f0f\u7279\u5f81\u751f\u6210\u7684\u6709\u6548\u6027"}}
{"id": "2512.14047", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.14047", "abs": "https://arxiv.org/abs/2512.14047", "authors": ["Kaike Zhang", "Qi Cao", "Fei Sun", "Xinran Liu"], "title": "AsarRec: Adaptive Sequential Augmentation for Robust Self-supervised Sequential Recommendation", "comment": null, "summary": "Sequential recommender systems have demonstrated strong capabilities in modeling users' dynamic preferences and capturing item transition patterns. However, real-world user behaviors are often noisy due to factors such as human errors, uncertainty, and behavioral ambiguity, which can lead to degraded recommendation performance. To address this issue, recent approaches widely adopt self-supervised learning (SSL), particularly contrastive learning, by generating perturbed views of user interaction sequences and maximizing their mutual information to improve model robustness. However, these methods heavily rely on their pre-defined static augmentation strategies~(where the augmentation type remains fixed once chosen) to construct augmented views, leading to two critical challenges: (1) the optimal augmentation type can vary significantly across different scenarios; (2) inappropriate augmentations may even degrade recommendation performance, limiting the effectiveness of SSL. To overcome these limitations, we propose an adaptive augmentation framework. We first unify existing basic augmentation operations into a unified formulation via structured transformation matrices. Building on this, we introduce AsarRec (Adaptive Sequential Augmentation for Robust Sequential Recommendation), which learns to generate transformation matrices by encoding user sequences into probabilistic transition matrices and projecting them into hard semi-doubly stochastic matrices via a differentiable Semi-Sinkhorn algorithm. To ensure that the learned augmentations benefit downstream performance, we jointly optimize three objectives: diversity, semantic invariance, and informativeness. Extensive experiments on three benchmark datasets under varying noise levels validate the effectiveness of AsarRec, demonstrating its superior robustness and consistent improvements.", "AI": {"tldr": "AsarRec\uff1a\u4e00\u79cd\u81ea\u9002\u5e94\u5e8f\u5217\u589e\u5f3a\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u8f6c\u6362\u77e9\u9635\u52a8\u6001\u751f\u6210\u589e\u5f3a\u89c6\u56fe\uff0c\u89e3\u51b3\u4f20\u7edf\u9759\u6001\u589e\u5f3a\u7b56\u7565\u5728\u5e8f\u5217\u63a8\u8350\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7528\u6237\u884c\u4e3a\u5b58\u5728\u566a\u58f0\uff08\u4eba\u4e3a\u9519\u8bef\u3001\u4e0d\u786e\u5b9a\u6027\u3001\u884c\u4e3a\u6a21\u7cca\u6027\uff09\uff0c\u4f20\u7edf\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u9884\u5b9a\u4e49\u7684\u9759\u6001\u589e\u5f3a\u7b56\u7565\uff0c\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u95ee\u9898\uff1a1\uff09\u4e0d\u540c\u573a\u666f\u4e0b\u6700\u4f18\u589e\u5f3a\u7c7b\u578b\u5dee\u5f02\u5f88\u5927\uff1b2\uff09\u4e0d\u6070\u5f53\u7684\u589e\u5f3a\u53ef\u80fd\u964d\u4f4e\u63a8\u8350\u6027\u80fd\u3002", "method": "\u63d0\u51faAsarRec\u6846\u67b6\uff1a1\uff09\u5c06\u73b0\u6709\u57fa\u672c\u589e\u5f3a\u64cd\u4f5c\u7edf\u4e00\u4e3a\u7ed3\u6784\u5316\u8f6c\u6362\u77e9\u9635\uff1b2\uff09\u901a\u8fc7\u7f16\u7801\u7528\u6237\u5e8f\u5217\u4e3a\u6982\u7387\u8f6c\u79fb\u77e9\u9635\uff0c\u4f7f\u7528\u53ef\u5fae\u5206\u7684Semi-Sinkhorn\u7b97\u6cd5\u6295\u5f71\u4e3a\u786c\u534a\u53cc\u968f\u673a\u77e9\u9635\u6765\u5b66\u4e60\u751f\u6210\u8f6c\u6362\u77e9\u9635\uff1b3\uff09\u8054\u5408\u4f18\u5316\u591a\u6837\u6027\u3001\u8bed\u4e49\u4e0d\u53d8\u6027\u548c\u4fe1\u606f\u6027\u4e09\u4e2a\u76ee\u6807\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u5728\u4e0d\u540c\u566a\u58f0\u6c34\u5e73\u4e0b\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86AsarRec\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5176\u4f18\u8d8a\u7684\u9c81\u68d2\u6027\u548c\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "AsarRec\u901a\u8fc7\u81ea\u9002\u5e94\u589e\u5f3a\u7b56\u7565\u514b\u670d\u4e86\u4f20\u7edf\u9759\u6001\u589e\u5f3a\u7684\u5c40\u9650\u6027\uff0c\u80fd\u591f\u52a8\u6001\u751f\u6210\u9002\u5408\u4e0d\u540c\u573a\u666f\u7684\u589e\u5f3a\u89c6\u56fe\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5e8f\u5217\u63a8\u8350\u7cfb\u7edf\u5728\u566a\u58f0\u73af\u5883\u4e0b\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2512.14277", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.14277", "abs": "https://arxiv.org/abs/2512.14277", "authors": ["Panayiotis Smeros", "Vincent Emonet", "Ruijie Wang", "Ana-Claudia Sima", "Tarcisio Mendes de Farias"], "title": "SPARQL-LLM: Real-Time SPARQL Query Generation from Natural Language Questions", "comment": "17 pages, 8 figures, 1 table. Under Review", "summary": "The advent of large language models is contributing to the emergence of novel approaches that promise to better tackle the challenge of generating structured queries, such as SPARQL queries, from natural language. However, these new approaches mostly focus on response accuracy over a single source while ignoring other evaluation criteria, such as federated query capability over distributed data stores, as well as runtime and cost to generate SPARQL queries. Consequently, they are often not production-ready or easy to deploy over (potentially federated) knowledge graphs with good accuracy. To mitigate these issues, in this paper, we extend our previous work and describe and systematically evaluate SPARQL-LLM, an open-source and triplestore-agnostic approach, powered by lightweight metadata, that generates SPARQL queries from natural language text. First, we describe its architecture, which consists of dedicated components for metadata indexing, prompt building, and query generation and execution. Then, we evaluate it based on a state-of-the-art challenge with multilingual questions, and a collection of questions from three of the most prevalent knowledge graphs within the field of bioinformatics. Our results demonstrate a substantial increase of 24% in the F1 Score on the state-of-the-art challenge, adaptability to high-resource languages such as English and Spanish, as well as ability to form complex and federated bioinformatics queries. Furthermore, we show that SPARQL-LLM is up to 36x faster than other systems participating in the challenge, while costing a maximum of $0.01 per question, making it suitable for real-time, low-cost text-to-SPARQL applications. One such application deployed over real-world decentralized knowledge graphs can be found at https://www.expasy.org/chat.", "AI": {"tldr": "SPARQL-LLM\u662f\u4e00\u4e2a\u5f00\u6e90\u3001\u4e09\u5143\u5b58\u50a8\u65e0\u5173\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u8f7b\u91cf\u7ea7\u5143\u6570\u636e\u4ece\u81ea\u7136\u8bed\u8a00\u751f\u6210SPARQL\u67e5\u8be2\uff0c\u5728\u51c6\u786e\u6027\u3001\u591a\u8bed\u8a00\u652f\u6301\u3001\u8054\u90a6\u67e5\u8be2\u80fd\u529b\u548c\u6210\u672c\u6548\u7387\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684SPARQL\u67e5\u8be2\u751f\u6210\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5355\u4e00\u6570\u636e\u6e90\u7684\u51c6\u786e\u6027\uff0c\u800c\u5ffd\u7565\u4e86\u8054\u90a6\u67e5\u8be2\u80fd\u529b\u3001\u8fd0\u884c\u65f6\u6027\u80fd\u548c\u6210\u672c\u7b49\u751f\u4ea7\u90e8\u7f72\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5bfc\u81f4\u96be\u4ee5\u5728\u5b9e\u9645\uff08\u7279\u522b\u662f\u8054\u90a6\uff09\u77e5\u8bc6\u56fe\u8c31\u4e2d\u90e8\u7f72\u3002", "method": "SPARQL-LLM\u91c7\u7528\u6a21\u5757\u5316\u67b6\u6784\uff0c\u5305\u542b\u5143\u6570\u636e\u7d22\u5f15\u3001\u63d0\u793a\u6784\u5efa\u3001\u67e5\u8be2\u751f\u6210\u4e0e\u6267\u884c\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff0c\u5229\u7528\u8f7b\u91cf\u7ea7\u5143\u6570\u636e\u5b9e\u73b0\u4e09\u5143\u5b58\u50a8\u65e0\u5173\u7684\u67e5\u8be2\u751f\u6210\u3002", "result": "\u5728state-of-the-art\u6311\u6218\u4e2dF1\u5206\u6570\u63d0\u534724%\uff0c\u652f\u6301\u82f1\u8bed\u548c\u897f\u73ed\u7259\u8bed\u7b49\u9ad8\u8d44\u6e90\u8bed\u8a00\uff0c\u80fd\u591f\u751f\u6210\u590d\u6742\u7684\u8054\u90a6\u751f\u7269\u4fe1\u606f\u5b66\u67e5\u8be2\uff0c\u6bd4\u5176\u4ed6\u7cfb\u7edf\u5feb\u8fbe36\u500d\uff0c\u6bcf\u4e2a\u95ee\u9898\u6210\u672c\u6700\u9ad8\u4ec50.01\u7f8e\u5143\u3002", "conclusion": "SPARQL-LLM\u662f\u4e00\u4e2a\u751f\u4ea7\u5c31\u7eea\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u3001\u4f4e\u6210\u672c\u7684\u6587\u672c\u5230SPARQL\u5e94\u7528\uff0c\u5df2\u5728\u5b9e\u9645\u7684\u5206\u6563\u77e5\u8bc6\u56fe\u8c31\u4e2d\u90e8\u7f72\uff08\u5982https://www.expasy.org/chat\uff09\u3002"}}
{"id": "2512.14313", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.14313", "abs": "https://arxiv.org/abs/2512.14313", "authors": ["Malika Iratni", "Mohand Boughanem", "Taoufiq Dkaki"], "title": "Dynamic Context Selection for Retrieval-Augmented Generation: Mitigating Distractors and Positional Bias", "comment": null, "summary": "Retrieval Augmented Generation (RAG) enhances language model performance by incorporating external knowledge retrieved from large corpora, which makes it highly suitable for tasks such as open domain question answering. Standard RAG systems typically rely on a fixed top k retrieval strategy, which can either miss relevant information or introduce semantically irrelevant passages, known as distractors, that degrade output quality. Additionally, the positioning of retrieved passages within the input context can influence the model attention and generation outcomes. Context placed in the middle tends to be overlooked, which is an issue known as the \"lost in the middle\" phenomenon. In this work, we systematically analyze the impact of distractors on generation quality, and quantify their effects under varying conditions. We also investigate how the position of relevant passages within the context window affects their influence on generation. Building on these insights, we propose a context-size classifier that dynamically predicts the optimal number of documents to retrieve based on query-specific informational needs. We integrate this approach into a full RAG pipeline, and demonstrate improved performance over fixed k baselines.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e86RAG\u7cfb\u7edf\u4e2d\u5e72\u6270\u6587\u6863\u5bf9\u751f\u6210\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u7814\u7a76\u4e86\u76f8\u5173\u6bb5\u843d\u4f4d\u7f6e\u6548\u5e94\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u67e5\u8be2\u7684\u52a8\u6001\u6587\u6863\u6570\u91cf\u9884\u6d4b\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86RAG\u6027\u80fd\u3002", "motivation": "\u6807\u51c6RAG\u7cfb\u7edf\u4f7f\u7528\u56fa\u5b9a\u7684top k\u68c0\u7d22\u7b56\u7565\u5b58\u5728\u4e24\u4e2a\u95ee\u9898\uff1a1) \u53ef\u80fd\u9057\u6f0f\u76f8\u5173\u4fe1\u606f\u6216\u5f15\u5165\u8bed\u4e49\u65e0\u5173\u7684\u5e72\u6270\u6587\u6863\uff0c\u964d\u4f4e\u8f93\u51fa\u8d28\u91cf\uff1b2) \u68c0\u7d22\u6bb5\u843d\u5728\u8f93\u5165\u4e0a\u4e0b\u6587\u4e2d\u7684\u4f4d\u7f6e\u4f1a\u5f71\u54cd\u6a21\u578b\u6ce8\u610f\u529b\uff0c\u51fa\u73b0\"\u4e2d\u95f4\u4e22\u5931\"\u73b0\u8c61\u3002\u9700\u8981\u7cfb\u7edf\u5206\u6790\u8fd9\u4e9b\u56e0\u7d20\u5e76\u6539\u8fdbRAG\u7cfb\u7edf\u3002", "method": "1) \u7cfb\u7edf\u5206\u6790\u5e72\u6270\u6587\u6863\u5bf9\u751f\u6210\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u91cf\u5316\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u6548\u679c\uff1b2) \u7814\u7a76\u76f8\u5173\u6bb5\u843d\u5728\u4e0a\u4e0b\u6587\u7a97\u53e3\u4e2d\u7684\u4f4d\u7f6e\u5982\u4f55\u5f71\u54cd\u751f\u6210\u7ed3\u679c\uff1b3) \u57fa\u4e8e\u8fd9\u4e9b\u6d1e\u5bdf\uff0c\u63d0\u51fa\u4e0a\u4e0b\u6587\u5927\u5c0f\u5206\u7c7b\u5668\uff0c\u6839\u636e\u67e5\u8be2\u7279\u5b9a\u7684\u4fe1\u606f\u9700\u6c42\u52a8\u6001\u9884\u6d4b\u6700\u4f18\u68c0\u7d22\u6587\u6863\u6570\u91cf\uff1b4) \u5c06\u8be5\u65b9\u6cd5\u96c6\u6210\u5230\u5b8c\u6574\u7684RAG\u6d41\u7a0b\u4e2d\u3002", "result": "\u63d0\u51fa\u7684\u52a8\u6001\u6587\u6863\u6570\u91cf\u9884\u6d4b\u65b9\u6cd5\u5728\u5b8c\u6574RAG\u6d41\u7a0b\u4e2d\u8868\u73b0\u51fa\u4f18\u4e8e\u56fa\u5b9ak\u57fa\u7ebf\u7684\u6027\u80fd\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5e72\u6270\u6587\u6863\u548c\u4f4d\u7f6e\u6548\u5e94\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u5206\u6790RAG\u4e2d\u7684\u5e72\u6270\u6587\u6863\u6548\u5e94\u548c\u4f4d\u7f6e\u6548\u5e94\uff0c\u63d0\u51fa\u7684\u52a8\u6001\u6587\u6863\u68c0\u7d22\u7b56\u7565\u80fd\u591f\u6839\u636e\u67e5\u8be2\u9700\u6c42\u4f18\u5316\u68c0\u7d22\u6570\u91cf\uff0c\u663e\u8457\u63d0\u5347RAG\u7cfb\u7edf\u7684\u751f\u6210\u8d28\u91cf\uff0c\u4e3a\u66f4\u667a\u80fd\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.14490", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.14490", "abs": "https://arxiv.org/abs/2512.14490", "authors": ["Shifu Bie", "Jiangxia Cao", "Zixiao Luo", "Yichuan Zou", "Lei Liang", "Lu Zhang", "Linxun Chen", "Zhaojie Liu", "Xuanping Li", "Guorui Zhou", "Kaiqiao Zhan", "Kun Gai"], "title": "PushGen: Push Notifications Generation with LLM", "comment": "Accepted by WSDM 2026", "summary": "We present PushGen, an automated framework for generating high-quality push notifications comparable to human-crafted content. With the rise of generative models, there is growing interest in leveraging LLMs for push content generation. Although LLMs make content generation straightforward and cost-effective, maintaining stylistic control and reliable quality assessment remains challenging, as both directly impact user engagement. To address these issues, PushGen combines two key components: (1) a controllable category prompt technique to guide LLM outputs toward desired styles, and (2) a reward model that ranks and selects generated candidates. Extensive offline and online experiments demonstrate its effectiveness, which has been deployed in large-scale industrial applications, serving hundreds of millions of users daily.", "AI": {"tldr": "PushGen\u662f\u4e00\u4e2a\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u63a8\u9001\u901a\u77e5\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u63a7\u7c7b\u522b\u63d0\u793a\u548c\u5956\u52b1\u6a21\u578b\u6765\u4fdd\u8bc1\u98ce\u683c\u4e00\u81f4\u6027\u548c\u8d28\u91cf\uff0c\u5df2\u5728\u5927\u89c4\u6a21\u5de5\u4e1a\u5e94\u7528\u4e2d\u90e8\u7f72", "motivation": "\u968f\u7740\u751f\u6210\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u5229\u7528LLM\u751f\u6210\u63a8\u9001\u5185\u5bb9\u53d8\u5f97\u7b80\u5355\u4e14\u6210\u672c\u6548\u76ca\u9ad8\uff0c\u4f46\u5982\u4f55\u4fdd\u6301\u98ce\u683c\u63a7\u5236\u548c\u53ef\u9760\u7684\u8d28\u91cf\u8bc4\u4f30\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u8fd9\u4e24\u8005\u76f4\u63a5\u5f71\u54cd\u7528\u6237\u53c2\u4e0e\u5ea6", "method": "PushGen\u5305\u542b\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a(1) \u53ef\u63a7\u7c7b\u522b\u63d0\u793a\u6280\u672f\uff0c\u5f15\u5bfcLLM\u8f93\u51fa\u7b26\u5408\u671f\u671b\u98ce\u683c\u7684\u5185\u5bb9\uff1b(2) \u5956\u52b1\u6a21\u578b\uff0c\u5bf9\u751f\u6210\u7684\u5019\u9009\u5185\u5bb9\u8fdb\u884c\u6392\u5e8f\u548c\u9009\u62e9", "result": "\u5927\u91cf\u79bb\u7ebf\u548c\u5728\u7ebf\u5b9e\u9a8c\u8bc1\u660e\u4e86PushGen\u7684\u6709\u6548\u6027\uff0c\u8be5\u6846\u67b6\u5df2\u5728\u5927\u89c4\u6a21\u5de5\u4e1a\u5e94\u7528\u4e2d\u90e8\u7f72\uff0c\u6bcf\u5929\u4e3a\u6570\u4ebf\u7528\u6237\u63d0\u4f9b\u670d\u52a1", "conclusion": "PushGen\u901a\u8fc7\u7ed3\u5408\u53ef\u63a7\u63d0\u793a\u548c\u5956\u52b1\u6a21\u578b\uff0c\u6210\u529f\u89e3\u51b3\u4e86LLM\u751f\u6210\u63a8\u9001\u5185\u5bb9\u65f6\u7684\u98ce\u683c\u63a7\u5236\u548c\u8d28\u91cf\u8bc4\u4f30\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u63a8\u9001\u901a\u77e5\u7684\u81ea\u52a8\u5316\u751f\u6210"}}
{"id": "2512.14503", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.14503", "abs": "https://arxiv.org/abs/2512.14503", "authors": ["Chao Yi", "Dian Chen", "Gaoyang Guo", "Jiakai Tang", "Jian Wu", "Jing Yu", "Mao Zhang", "Wen Chen", "Wenjun Yang", "Yujie Luo", "Yuning Jiang", "Zhujin Gao", "Bo Zheng", "Binbin Cao", "Changfa Wu", "Dixuan Wang", "Han Wu", "Haoyi Hu", "Kewei Zhu", "Lang Tian", "Lin Yang", "Qiqi Huang", "Siqi Yang", "Wenbo Su", "Xiaoxiao He", "Xin Tong", "Xu Chen", "Xunke Xi", "Xiaowei Huang", "Yaxuan Wu", "Yeqiu Yang", "Yi Hu", "Yujin Yuan", "Yuliang Yan", "Zile Zhou"], "title": "RecGPT-V2 Technical Report", "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable potential in transforming recommender systems from implicit behavioral pattern matching to explicit intent reasoning. While RecGPT-V1 successfully pioneered this paradigm by integrating LLM-based reasoning into user interest mining and item tag prediction, it suffers from four fundamental limitations: (1) computational inefficiency and cognitive redundancy across multiple reasoning routes; (2) insufficient explanation diversity in fixed-template generation; (3) limited generalization under supervised learning paradigms; and (4) simplistic outcome-focused evaluation that fails to match human standards.\n  To address these challenges, we present RecGPT-V2 with four key innovations. First, a Hierarchical Multi-Agent System restructures intent reasoning through coordinated collaboration, eliminating cognitive duplication while enabling diverse intent coverage. Combined with Hybrid Representation Inference that compresses user-behavior contexts, our framework reduces GPU consumption by 60% and improves exclusive recall from 9.39% to 10.99%. Second, a Meta-Prompting framework dynamically generates contextually adaptive prompts, improving explanation diversity by +7.3%. Third, constrained reinforcement learning mitigates multi-reward conflicts, achieving +24.1% improvement in tag prediction and +13.0% in explanation acceptance. Fourth, an Agent-as-a-Judge framework decomposes assessment into multi-step reasoning, improving human preference alignment. Online A/B tests on Taobao demonstrate significant improvements: +2.98% CTR, +3.71% IPV, +2.19% TV, and +11.46% NER. RecGPT-V2 establishes both the technical feasibility and commercial viability of deploying LLM-powered intent reasoning at scale, bridging the gap between cognitive exploration and industrial utility.", "AI": {"tldr": "RecGPT-V2\u901a\u8fc7\u5206\u5c42\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3001\u5143\u63d0\u793a\u6846\u67b6\u3001\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u548c\u667a\u80fd\u4f53\u5373\u6cd5\u5b98\u8bc4\u4f30\u6846\u67b6\uff0c\u89e3\u51b3\u4e86V1\u7248\u672c\u7684\u8ba1\u7b97\u6548\u7387\u3001\u89e3\u91ca\u591a\u6837\u6027\u3001\u6cdb\u5316\u80fd\u529b\u548c\u8bc4\u4f30\u6807\u51c6\u95ee\u9898\uff0c\u5728\u6dd8\u5b9dA/B\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6548\u679c\u3002", "motivation": "RecGPT-V1\u867d\u7136\u6210\u529f\u5c06LLM\u63a8\u7406\u5f15\u5165\u63a8\u8350\u7cfb\u7edf\uff0c\u4f46\u5b58\u5728\u56db\u4e2a\u6839\u672c\u9650\u5236\uff1a\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u548c\u8ba4\u77e5\u5197\u4f59\u3001\u89e3\u91ca\u591a\u6837\u6027\u4e0d\u8db3\u3001\u76d1\u7763\u5b66\u4e60\u8303\u5f0f\u4e0b\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3001\u8bc4\u4f30\u6807\u51c6\u8fc7\u4e8e\u7b80\u5355\u4e0d\u7b26\u5408\u4eba\u7c7b\u6807\u51c6\u3002\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u4ee5\u5b9e\u73b0LLM\u9a71\u52a8\u7684\u610f\u56fe\u63a8\u7406\u5728\u5de5\u4e1a\u89c4\u6a21\u4e0a\u7684\u90e8\u7f72\u3002", "method": "1. \u5206\u5c42\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff1a\u901a\u8fc7\u534f\u8c03\u534f\u4f5c\u91cd\u6784\u610f\u56fe\u63a8\u7406\uff0c\u6d88\u9664\u8ba4\u77e5\u91cd\u590d\uff0c\u5b9e\u73b0\u591a\u6837\u5316\u610f\u56fe\u8986\u76d6\uff1b\u7ed3\u5408\u6df7\u5408\u8868\u793a\u63a8\u7406\u538b\u7f29\u7528\u6237\u884c\u4e3a\u4e0a\u4e0b\u6587\n2. \u5143\u63d0\u793a\u6846\u67b6\uff1a\u52a8\u6001\u751f\u6210\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u63d0\u793a\uff0c\u63d0\u5347\u89e3\u91ca\u591a\u6837\u6027\n3. \u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\uff1a\u7f13\u89e3\u591a\u5956\u52b1\u51b2\u7a81\uff0c\u4f18\u5316\u6807\u7b7e\u9884\u6d4b\u548c\u89e3\u91ca\u63a5\u53d7\u5ea6\n4. \u667a\u80fd\u4f53\u5373\u6cd5\u5b98\u6846\u67b6\uff1a\u5c06\u8bc4\u4f30\u5206\u89e3\u4e3a\u591a\u6b65\u63a8\u7406\uff0c\u63d0\u5347\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50", "result": "1. \u8ba1\u7b97\u6548\u7387\uff1aGPU\u6d88\u8017\u964d\u4f4e60%\uff0c\u4e13\u5c5e\u53ec\u56de\u7387\u4ece9.39%\u63d0\u5347\u81f310.99%\n2. \u89e3\u91ca\u591a\u6837\u6027\uff1a\u63d0\u5347+7.3%\n3. \u9884\u6d4b\u6027\u80fd\uff1a\u6807\u7b7e\u9884\u6d4b\u63d0\u5347+24.1%\uff0c\u89e3\u91ca\u63a5\u53d7\u5ea6\u63d0\u5347+13.0%\n4. \u5728\u7ebfA/B\u6d4b\u8bd5\uff1aCTR\u63d0\u5347+2.98%\uff0cIPV\u63d0\u5347+3.71%\uff0cTV\u63d0\u5347+2.19%\uff0cNER\u63d0\u5347+11.46%\n5. \u5efa\u7acb\u4e86LLM\u9a71\u52a8\u7684\u610f\u56fe\u63a8\u7406\u5728\u5de5\u4e1a\u89c4\u6a21\u90e8\u7f72\u7684\u6280\u672f\u53ef\u884c\u6027\u548c\u5546\u4e1a\u53ef\u884c\u6027", "conclusion": "RecGPT-V2\u901a\u8fc7\u56db\u9879\u5173\u952e\u521b\u65b0\u6210\u529f\u89e3\u51b3\u4e86V1\u7248\u672c\u7684\u6839\u672c\u9650\u5236\uff0c\u5728\u8ba1\u7b97\u6548\u7387\u3001\u89e3\u91ca\u591a\u6837\u6027\u3001\u9884\u6d4b\u6027\u80fd\u548c\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u65b9\u9762\u90fd\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002\u8be5\u6846\u67b6\u4e0d\u4ec5\u8bc1\u660e\u4e86LLM\u9a71\u52a8\u7684\u610f\u56fe\u63a8\u7406\u5728\u5de5\u4e1a\u89c4\u6a21\u90e8\u7f72\u7684\u6280\u672f\u53ef\u884c\u6027\uff0c\u8fd8\u5c55\u793a\u4e86\u5176\u5546\u4e1a\u4ef7\u503c\uff0c\u6210\u529f\u5f25\u5408\u4e86\u8ba4\u77e5\u63a2\u7d22\u4e0e\u5de5\u4e1a\u5b9e\u7528\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2512.14565", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.14565", "abs": "https://arxiv.org/abs/2512.14565", "authors": ["Fabian Haak", "Philipp Schaer"], "title": "Pairwise Comparison for Bias Identification and Quantification", "comment": null, "summary": "Linguistic bias in online news and social media is widespread but difficult to measure. Yet, its identification and quantification remain difficult due to subjectivity, context dependence, and the scarcity of high-quality gold-label datasets. We aim to reduce annotation effort by leveraging pairwise comparison for bias annotation. To overcome the costliness of the approach, we evaluate more efficient implementations of pairwise comparison-based rating. We achieve this by investigating the effects of various rating techniques and the parameters of three cost-aware alternatives in a simulation environment. Since the approach can in principle be applied to both human and large language model annotation, our work provides a basis for creating high-quality benchmark datasets and for quantifying biases and other subjective linguistic aspects.\n  The controlled simulations include latent severity distributions, distance-calibrated noise, and synthetic annotator bias to probe robustness and cost-quality trade-offs. In applying the approach to human-labeled bias benchmark datasets, we then evaluate the most promising setups and compare them to direct assessment by large language models and unmodified pairwise comparison labels as baselines. Our findings support the use of pairwise comparison as a practical foundation for quantifying subjective linguistic aspects, enabling reproducible bias analysis. We contribute an optimization of comparison and matchmaking components, an end-to-end evaluation including simulation and real-data application, and an implementation blueprint for cost-aware large-scale annotation", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u6210\u5bf9\u6bd4\u8f83\u6765\u6807\u6ce8\u8bed\u8a00\u504f\u89c1\uff0c\u5f00\u53d1\u4e86\u6210\u672c\u611f\u77e5\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u5e76\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u4e3a\u5927\u89c4\u6a21\u4e3b\u89c2\u8bed\u8a00\u6807\u6ce8\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6848\u3002", "motivation": "\u5728\u7ebf\u65b0\u95fb\u548c\u793e\u4ea4\u5a92\u4f53\u4e2d\u7684\u8bed\u8a00\u504f\u89c1\u666e\u904d\u5b58\u5728\u4f46\u96be\u4ee5\u6d4b\u91cf\uff0c\u4e3b\u8981\u6311\u6218\u5305\u62ec\u4e3b\u89c2\u6027\u3001\u8bed\u5883\u4f9d\u8d56\u6027\u548c\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u3002\u73b0\u6709\u65b9\u6cd5\u6807\u6ce8\u6210\u672c\u9ad8\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u6807\u6ce8\u65b9\u6848\u3002", "method": "\u91c7\u7528\u6210\u5bf9\u6bd4\u8f83\u65b9\u6cd5\u8fdb\u884c\u504f\u89c1\u6807\u6ce8\uff0c\u901a\u8fc7\u6a21\u62df\u73af\u5883\u8bc4\u4f30\u4e0d\u540c\u8bc4\u5206\u6280\u672f\u548c\u4e09\u79cd\u6210\u672c\u611f\u77e5\u66ff\u4ee3\u65b9\u6848\u7684\u53c2\u6570\u6548\u679c\u3002\u6a21\u62df\u5305\u62ec\u6f5c\u5728\u4e25\u91cd\u6027\u5206\u5e03\u3001\u8ddd\u79bb\u6821\u51c6\u566a\u58f0\u548c\u5408\u6210\u6807\u6ce8\u8005\u504f\u89c1\u3002\u6700\u540e\u5728\u4eba\u7c7b\u6807\u6ce8\u7684\u504f\u89c1\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u6700\u6709\u524d\u666f\u7684\u8bbe\u7f6e\u3002", "result": "\u7814\u7a76\u652f\u6301\u4f7f\u7528\u6210\u5bf9\u6bd4\u8f83\u4f5c\u4e3a\u91cf\u5316\u4e3b\u89c2\u8bed\u8a00\u65b9\u9762\u7684\u5b9e\u7528\u57fa\u7840\uff0c\u5b9e\u73b0\u4e86\u53ef\u590d\u73b0\u7684\u504f\u89c1\u5206\u6790\u3002\u4f18\u5316\u4e86\u6bd4\u8f83\u548c\u5339\u914d\u7ec4\u4ef6\uff0c\u63d0\u4f9b\u4e86\u7aef\u5230\u7aef\u8bc4\u4f30\u6846\u67b6\u548c\u6210\u672c\u611f\u77e5\u5927\u89c4\u6a21\u6807\u6ce8\u7684\u5b9e\u73b0\u84dd\u56fe\u3002", "conclusion": "\u6210\u5bf9\u6bd4\u8f83\u65b9\u6cd5\u4e3a\u521b\u5efa\u9ad8\u8d28\u91cf\u57fa\u51c6\u6570\u636e\u96c6\u548c\u91cf\u5316\u504f\u89c1\u7b49\u4e3b\u89c2\u8bed\u8a00\u7279\u5f81\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u8be5\u65b9\u6cd5\u65e2\u9002\u7528\u4e8e\u4eba\u7c7b\u6807\u6ce8\u4e5f\u9002\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u6807\u6ce8\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u8bed\u8a00\u504f\u89c1\u7814\u7a76\u7684\u53ef\u91cd\u590d\u6027\u3002"}}
