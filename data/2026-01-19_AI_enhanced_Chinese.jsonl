{"id": "2601.10933", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.10933", "abs": "https://arxiv.org/abs/2601.10933", "authors": ["Yizhou Dang", "Zhifu Wei", "Minhan Huang", "Lianbo Ma", "Jianzhe Zhao", "Guibing Guo", "Xingwei Wang"], "title": "Tail-Aware Data Augmentation for Long-Tail Sequential Recommendation", "comment": "Accepted by WWW 2026", "summary": "Sequential recommendation (SR) learns user preferences based on their historical interaction sequences and provides personalized suggestions. In real-world scenarios, most users can only interact with a handful of items, while the majority of items are seldom consumed. This pervasive long-tail challenge limits the model's ability to learn user preferences. Despite previous efforts to enrich tail items/users with knowledge from head parts or improve tail learning through additional contextual information, they still face the following issues: 1) They struggle to improve the situation where interactions of tail users/items are scarce, leading to incomplete preferences learning for the tail parts. 2) Existing methods often degrade overall or head parts performance when improving accuracy for tail users/items, thereby harming the user experience. We propose Tail-Aware Data Augmentation (TADA) for long-tail sequential recommendation, which enhances the interaction frequency for tail items/users while maintaining head performance, thereby promoting the model's learning capabilities for the tail. Specifically, we first capture the co-occurrence and correlation among low-popularity items by a linear model. Building upon this, we design two tail-aware augmentation operators, T-Substitute and T-Insert. The former replaces the head item with a relevant item, while the latter utilizes co-occurrence relationships to extend the original sequence by incorporating both head and tail items. The augmented and original sequences are mixed at the representation level to preserve preference knowledge. We further extend the mix operation across different tail-user sequences and augmented sequences to generate richer augmented samples, thereby improving tail performance. Comprehensive experiments demonstrate the superiority of our method. The codes are provided at https://github.com/KingGugu/TADA.", "AI": {"tldr": "\u63d0\u51faTADA\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c3e\u90e8\u611f\u77e5\u7684\u6570\u636e\u589e\u5f3a\u89e3\u51b3\u5e8f\u5217\u63a8\u8350\u4e2d\u7684\u957f\u5c3e\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u5934\u90e8\u6027\u80fd\u7684\u540c\u65f6\u63d0\u5347\u5c3e\u90e8\u7528\u6237/\u7269\u54c1\u7684\u63a8\u8350\u6548\u679c\u3002", "motivation": "\u73b0\u5b9e\u573a\u666f\u4e2d\u5927\u591a\u6570\u7528\u6237\u53ea\u80fd\u4e0e\u5c11\u91cf\u7269\u54c1\u4ea4\u4e92\uff0c\u800c\u5927\u591a\u6570\u7269\u54c1\u5f88\u5c11\u88ab\u6d88\u8d39\uff0c\u8fd9\u79cd\u666e\u904d\u7684\u957f\u5c3e\u95ee\u9898\u9650\u5236\u4e86\u6a21\u578b\u5b66\u4e60\u7528\u6237\u504f\u597d\u7684\u80fd\u529b\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u6539\u5584\u5c3e\u90e8\u6027\u80fd\u65f6\u5f80\u5f80\u4f1a\u635f\u5bb3\u6574\u4f53\u6216\u5934\u90e8\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u5c3e\u90e8\u611f\u77e5\u6570\u636e\u589e\u5f3a(TADA)\uff1a1) \u7528\u7ebf\u6027\u6a21\u578b\u6355\u6349\u4f4e\u6d41\u884c\u5ea6\u7269\u54c1\u7684\u5171\u73b0\u548c\u76f8\u5173\u6027\uff1b2) \u8bbe\u8ba1T-Substitute\uff08\u7528\u76f8\u5173\u7269\u54c1\u66ff\u6362\u5934\u90e8\u7269\u54c1\uff09\u548cT-Insert\uff08\u5229\u7528\u5171\u73b0\u5173\u7cfb\u6269\u5c55\u5e8f\u5217\uff09\u4e24\u79cd\u589e\u5f3a\u64cd\u4f5c\uff1b3) \u5728\u8868\u793a\u5c42\u6df7\u5408\u589e\u5f3a\u548c\u539f\u59cb\u5e8f\u5217\u4ee5\u4fdd\u7559\u504f\u597d\u77e5\u8bc6\uff1b4) \u8de8\u4e0d\u540c\u5c3e\u90e8\u7528\u6237\u5e8f\u5217\u548c\u589e\u5f3a\u5e8f\u5217\u6269\u5c55\u6df7\u5408\u64cd\u4f5c\u4ee5\u751f\u6210\u66f4\u4e30\u5bcc\u7684\u589e\u5f3a\u6837\u672c\u3002", "result": "\u7efc\u5408\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u5934\u90e8\u6027\u80fd\u7684\u540c\u65f6\u63d0\u5347\u5c3e\u90e8\u7528\u6237/\u7269\u54c1\u7684\u63a8\u8350\u6548\u679c\u3002", "conclusion": "TADA\u65b9\u6cd5\u901a\u8fc7\u5c3e\u90e8\u611f\u77e5\u7684\u6570\u636e\u589e\u5f3a\u6709\u6548\u89e3\u51b3\u4e86\u5e8f\u5217\u63a8\u8350\u4e2d\u7684\u957f\u5c3e\u95ee\u9898\uff0c\u5728\u63d0\u5347\u5c3e\u90e8\u6027\u80fd\u7684\u540c\u65f6\u4e0d\u635f\u5bb3\u5934\u90e8\u6027\u80fd\uff0c\u4ece\u800c\u6539\u5584\u4e86\u6574\u4f53\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2601.10936", "categories": ["cs.IR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.10936", "abs": "https://arxiv.org/abs/2601.10936", "authors": ["Piyush Maheshwari", "Sheshera Mysore", "Hamed Zamani"], "title": "Can Instructed Retrieval Models Really Support Exploration?", "comment": null, "summary": "Exploratory searches are characterized by under-specified goals and evolving query intents. In such scenarios, retrieval models that can capture user-specified nuances in query intent and adapt results accordingly are desirable -- instruction-following retrieval models promise such a capability. In this work, we evaluate instructed retrievers for the prevalent yet under-explored application of aspect-conditional seed-guided exploration using an expert-annotated test collection. We evaluate both recent LLMs fine-tuned for instructed retrieval and general-purpose LLMs prompted for ranking with the highly performant Pairwise Ranking Prompting. We find that the best instructed retrievers improve on ranking relevance compared to instruction-agnostic approaches. However, we also find that instruction following performance, crucial to the user experience of interacting with models, does not mirror ranking relevance improvements and displays insensitivity or counter-intuitive behavior to instructions. Our results indicate that while users may benefit from using current instructed retrievers over instruction-agnostic models, they may not benefit from using them for long-running exploratory sessions requiring greater sensitivity to instructions.", "AI": {"tldr": "\u8bc4\u4f30\u6307\u4ee4\u8ddf\u968f\u68c0\u7d22\u6a21\u578b\u5728\u65b9\u9762\u6761\u4ef6\u79cd\u5b50\u5f15\u5bfc\u63a2\u7d22\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u5728\u6392\u540d\u76f8\u5173\u6027\u4e0a\u6709\u6539\u8fdb\uff0c\u4f46\u5728\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\u4e0a\u5b58\u5728\u4e0d\u8db3\u3002", "motivation": "\u63a2\u7d22\u6027\u641c\u7d22\u5177\u6709\u76ee\u6807\u4e0d\u660e\u786e\u548c\u67e5\u8be2\u610f\u56fe\u4e0d\u65ad\u6f14\u5316\u7684\u7279\u70b9\uff0c\u9700\u8981\u80fd\u591f\u6355\u6349\u7528\u6237\u6307\u5b9a\u610f\u56fe\u7ec6\u5fae\u5dee\u522b\u5e76\u76f8\u5e94\u8c03\u6574\u7ed3\u679c\u7684\u68c0\u7d22\u6a21\u578b\u3002\u6307\u4ee4\u8ddf\u968f\u68c0\u7d22\u6a21\u578b\u627f\u8bfa\u5177\u5907\u8fd9\u79cd\u80fd\u529b\uff0c\u4f46\u5c1a\u672a\u5728\u65b9\u9762\u6761\u4ef6\u79cd\u5b50\u5f15\u5bfc\u63a2\u7d22\u8fd9\u4e00\u666e\u904d\u4f46\u672a\u5145\u5206\u63a2\u7d22\u7684\u5e94\u7528\u4e2d\u5f97\u5230\u5145\u5206\u8bc4\u4f30\u3002", "method": "\u4f7f\u7528\u4e13\u5bb6\u6807\u6ce8\u7684\u6d4b\u8bd5\u96c6\u5408\uff0c\u8bc4\u4f30\u4e13\u95e8\u4e3a\u6307\u4ee4\u8ddf\u968f\u68c0\u7d22\u5fae\u8c03\u7684LLM\u548c\u4f7f\u7528Pairwise Ranking Prompting\u8fdb\u884c\u6392\u540d\u7684\u901a\u7528LLM\u3002\u6bd4\u8f83\u6307\u4ee4\u8ddf\u968f\u68c0\u7d22\u6a21\u578b\u4e0e\u6307\u4ee4\u65e0\u5173\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "result": "\u6700\u4f73\u6307\u4ee4\u8ddf\u968f\u68c0\u7d22\u5668\u5728\u6392\u540d\u76f8\u5173\u6027\u65b9\u9762\u4f18\u4e8e\u6307\u4ee4\u65e0\u5173\u65b9\u6cd5\uff0c\u4f46\u6307\u4ee4\u8ddf\u968f\u6027\u80fd\uff08\u5bf9\u7528\u6237\u4f53\u9a8c\u81f3\u5173\u91cd\u8981\uff09\u5e76\u672a\u53cd\u6620\u6392\u540d\u76f8\u5173\u6027\u7684\u6539\u8fdb\uff0c\u4e14\u5bf9\u6307\u4ee4\u8868\u73b0\u51fa\u4e0d\u654f\u611f\u6216\u53cd\u76f4\u89c9\u7684\u884c\u4e3a\u3002", "conclusion": "\u867d\u7136\u7528\u6237\u53ef\u80fd\u4ece\u4f7f\u7528\u5f53\u524d\u6307\u4ee4\u8ddf\u968f\u68c0\u7d22\u5668\u4e2d\u83b7\u76ca\uff08\u76f8\u6bd4\u6307\u4ee4\u65e0\u5173\u6a21\u578b\uff09\uff0c\u4f46\u5bf9\u4e8e\u9700\u8981\u66f4\u9ad8\u6307\u4ee4\u654f\u611f\u5ea6\u7684\u957f\u671f\u63a2\u7d22\u6027\u4f1a\u8bdd\uff0c\u7528\u6237\u53ef\u80fd\u65e0\u6cd5\u4ece\u4e2d\u53d7\u76ca\u3002\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\u3002"}}
{"id": "2601.10944", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.10944", "abs": "https://arxiv.org/abs/2601.10944", "authors": ["Xinyi Zhang", "Yutong Li", "Peijie Sun", "Letian Sha", "Zhongxuan Han"], "title": "PRISM: Personalized Recommendation via Information Synergy Module", "comment": "Accepted as a Full Paper at WWW 2026", "summary": "Multimodal sequential recommendation (MSR) leverages diverse item modalities to improve recommendation accuracy, while achieving effective and adaptive fusion remains challenging. Existing MSR models often overlook synergistic information that emerges only through modality combinations. Moreover, they typically assume a fixed importance for different modality interactions across users. To address these limitations, we propose \\textbf{P}ersonalized \\textbf{R}ecommend-ation via \\textbf{I}nformation \\textbf{S}ynergy \\textbf{M}odule (PRISM), a plug-and-play framework for sequential recommendation (SR). PRISM explicitly decomposes multimodal information into unique, redundant, and synergistic components through an Interaction Expert Layer and dynamically weights them via an Adaptive Fusion Layer guided by user preferences. This information-theoretic design enables fine-grained disentanglement and personalized fusion of multimodal signals. Extensive experiments on four datasets and three SR backbones demonstrate its effectiveness and versatility. The code is available at https://github.com/YutongLi2024/PRISM.", "AI": {"tldr": "PRISM\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u6a21\u6001\u5e8f\u5217\u63a8\u8350\u7684\u5373\u63d2\u5373\u7528\u6846\u67b6\uff0c\u901a\u8fc7\u4fe1\u606f\u7406\u8bba\u65b9\u6cd5\u5c06\u591a\u6a21\u6001\u4fe1\u606f\u5206\u89e3\u4e3a\u72ec\u7279\u3001\u5197\u4f59\u548c\u534f\u540c\u7ec4\u4ef6\uff0c\u5e76\u6839\u636e\u7528\u6237\u504f\u597d\u52a8\u6001\u878d\u5408", "motivation": "\u73b0\u6709MSR\u6a21\u578b\u5f80\u5f80\u5ffd\u89c6\u4ec5\u901a\u8fc7\u6a21\u6001\u7ec4\u5408\u51fa\u73b0\u7684\u534f\u540c\u4fe1\u606f\uff0c\u5e76\u4e14\u901a\u5e38\u5047\u8bbe\u4e0d\u540c\u6a21\u6001\u4ea4\u4e92\u5bf9\u6240\u6709\u7528\u6237\u5177\u6709\u56fa\u5b9a\u91cd\u8981\u6027\uff0c\u8fd9\u9650\u5236\u4e86\u63a8\u8350\u6548\u679c", "method": "\u63d0\u51faPRISM\u6846\u67b6\uff0c\u901a\u8fc7\u4ea4\u4e92\u4e13\u5bb6\u5c42\u5c06\u591a\u6a21\u6001\u4fe1\u606f\u5206\u89e3\u4e3a\u72ec\u7279\u3001\u5197\u4f59\u548c\u534f\u540c\u7ec4\u4ef6\uff0c\u518d\u901a\u8fc7\u81ea\u9002\u5e94\u878d\u5408\u5c42\u6839\u636e\u7528\u6237\u504f\u597d\u52a8\u6001\u52a0\u6743\u878d\u5408", "result": "\u5728\u56db\u4e2a\u6570\u636e\u96c6\u548c\u4e09\u4e2a\u5e8f\u5217\u63a8\u8350\u9aa8\u5e72\u7f51\u7edc\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86PRISM\u7684\u6709\u6548\u6027\u548c\u901a\u7528\u6027", "conclusion": "PRISM\u901a\u8fc7\u4fe1\u606f\u7406\u8bba\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u591a\u6a21\u6001\u4fe1\u53f7\u7684\u7ec6\u7c92\u5ea6\u89e3\u8026\u548c\u4e2a\u6027\u5316\u878d\u5408\uff0c\u63d0\u9ad8\u4e86\u591a\u6a21\u6001\u5e8f\u5217\u63a8\u8350\u7684\u51c6\u786e\u6027\u548c\u9002\u5e94\u6027"}}
{"id": "2601.11024", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.11024", "abs": "https://arxiv.org/abs/2601.11024", "authors": ["Shuguang Jiao", "Xinyu Xiao", "Yunfan Wei", "Shuhan Qi", "Chengkai Huang", "Quan Z. Michael Sheng", "Lina Yao"], "title": "PruneRAG: Confidence-Guided Query Decomposition Trees for Efficient Retrieval-Augmented Generation", "comment": null, "summary": "Retrieval-augmented generation (RAG) has become a powerful framework for enhancing large language models in knowledge-intensive and reasoning tasks. However, as reasoning chains deepen or search trees expand, RAG systems often face two persistent failures: evidence forgetting, where retrieved knowledge is not effectively used, and inefficiency, caused by uncontrolled query expansions and redundant retrieval. These issues reveal a critical gap between retrieval and evidence utilization in current RAG architectures. We propose PruneRAG, a confidence-guided query decomposition framework that builds a structured query decomposition tree to perform stable and efficient reasoning. PruneRAG introduces three key mechanisms: adaptive node expansion that regulates tree width and depth, confidence-guided decisions that accept reliable answers and prune uncertain branches, and fine-grained retrieval that extracts entity-level anchors to improve retrieval precision. Together, these components preserve salient evidence throughout multi-hop reasoning while significantly reducing retrieval overhead. To better analyze evidence misuse, we define the Evidence Forgetting Rate as a metric to quantify cases where golden evidence is retrieved but not correctly used. Extensive experiments across various multi-hop QA benchmarks show that PruneRAG achieves superior accuracy and efficiency over state-of-the-art baselines.", "AI": {"tldr": "PruneRAG\uff1a\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u5f15\u5bfc\u7684\u67e5\u8be2\u5206\u89e3\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u67e5\u8be2\u5206\u89e3\u6811\u89e3\u51b3RAG\u4e2d\u7684\u8bc1\u636e\u9057\u5fd8\u548c\u6548\u7387\u95ee\u9898\uff0c\u5b9e\u73b0\u7a33\u5b9a\u9ad8\u6548\u7684\u591a\u8df3\u63a8\u7406\u3002", "motivation": "\u5f53\u524dRAG\u7cfb\u7edf\u5728\u591a\u8df3\u63a8\u7406\u4e2d\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u8bc1\u636e\u9057\u5fd8\uff08\u68c0\u7d22\u5230\u7684\u77e5\u8bc6\u672a\u88ab\u6709\u6548\u5229\u7528\uff09\u548c\u6548\u7387\u4f4e\u4e0b\uff08\u67e5\u8be2\u6269\u5c55\u5931\u63a7\u548c\u5197\u4f59\u68c0\u7d22\uff09\uff0c\u8fd9\u63ed\u793a\u4e86\u68c0\u7d22\u4e0e\u8bc1\u636e\u5229\u7528\u4e4b\u95f4\u7684\u5173\u952e\u5dee\u8ddd\u3002", "method": "\u63d0\u51faPruneRAG\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u673a\u5236\uff1a1\uff09\u81ea\u9002\u5e94\u8282\u70b9\u6269\u5c55\u8c03\u8282\u6811\u5bbd\u5ea6\u548c\u6df1\u5ea6\uff1b2\uff09\u7f6e\u4fe1\u5ea6\u5f15\u5bfc\u51b3\u7b56\u63a5\u53d7\u53ef\u9760\u7b54\u6848\u5e76\u526a\u679d\u4e0d\u786e\u5b9a\u5206\u652f\uff1b3\uff09\u7ec6\u7c92\u5ea6\u68c0\u7d22\u63d0\u53d6\u5b9e\u4f53\u7ea7\u951a\u70b9\u63d0\u9ad8\u68c0\u7d22\u7cbe\u5ea6\u3002", "result": "\u5728\u591a\u4e2a\u591a\u8df3QA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPruneRAG\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u68c0\u7d22\u5f00\u9500\u3002", "conclusion": "PruneRAG\u901a\u8fc7\u7ed3\u6784\u5316\u67e5\u8be2\u5206\u89e3\u6811\u548c\u7f6e\u4fe1\u5ea6\u5f15\u5bfc\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86RAG\u4e2d\u7684\u8bc1\u636e\u9057\u5fd8\u548c\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u77e5\u8bc6\u5bc6\u96c6\u578b\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u7a33\u5b9a\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11124", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11124", "abs": "https://arxiv.org/abs/2601.11124", "authors": ["Xiaoyu Liang", "Yuchen Peng", "Jiale Luo", "Wenhao Wang", "Haoji Hu", "Xincheng Zhou"], "title": "Learn Before Represent: Bridging Generative and Contrastive Learning for Domain-Specific LLM Embeddings", "comment": "10 pages, 3 figures", "summary": "Large Language Models (LLMs) adapted via contrastive learning excel in general representation learning but struggle in vertical domains like chemistry and law, primarily due to a lack of domain-specific knowledge. This work identifies a core bottleneck: the prevailing ``LLM+CL'' paradigm focuses on semantic alignment but cannot perform knowledge acquisition, leading to failures on specialized terminology. To bridge this gap, we propose Learn Before Represent (LBR), a novel two-stage framework. LBR first injects domain knowledge via an Information Bottleneck-Constrained Generative Learning stage, preserving the LLM's causal attention to maximize knowledge acquisition while compressing semantics. It then performs Generative-Refined Contrastive Learning on the compressed representations for alignment. This approach maintains architectural consistency and resolves the objective conflict between generative and contrastive learning. Extensive experiments on medical, chemistry, and code retrieval tasks show that LBR significantly outperforms strong baselines. Our work establishes a new paradigm for building accurate and robust representations in vertical domains.", "AI": {"tldr": "LBR\u6846\u67b6\u901a\u8fc7\u4e24\u9636\u6bb5\u5b66\u4e60\u89e3\u51b3LLM\u5728\u5782\u76f4\u9886\u57df\u77e5\u8bc6\u4e0d\u8db3\u95ee\u9898\uff1a\u5148\u6ce8\u5165\u9886\u57df\u77e5\u8bc6\uff0c\u518d\u8fdb\u884c\u8868\u5f81\u5bf9\u9f50", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u7684LLM\u5728\u901a\u7528\u8868\u5f81\u5b66\u4e60\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5316\u5b66\u3001\u6cd5\u5f8b\u7b49\u5782\u76f4\u9886\u57df\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u7f3a\u4e4f\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u3002\u73b0\u6709\"LLM+CL\"\u8303\u5f0f\u53ea\u5173\u6ce8\u8bed\u4e49\u5bf9\u9f50\uff0c\u65e0\u6cd5\u8fdb\u884c\u77e5\u8bc6\u83b7\u53d6\uff0c\u5bfc\u81f4\u5728\u4e13\u4e1a\u672f\u8bed\u4e0a\u5931\u8d25\u3002", "method": "\u63d0\u51faLearn Before Represent (LBR)\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1) \u4fe1\u606f\u74f6\u9888\u7ea6\u675f\u7684\u751f\u6210\u5b66\u4e60\u9636\u6bb5\uff0c\u901a\u8fc7\u4fdd\u6301LLM\u7684\u56e0\u679c\u6ce8\u610f\u529b\u6765\u6700\u5927\u5316\u77e5\u8bc6\u83b7\u53d6\uff0c\u540c\u65f6\u538b\u7f29\u8bed\u4e49\uff1b2) \u5728\u538b\u7f29\u8868\u5f81\u4e0a\u8fdb\u884c\u751f\u6210\u7cbe\u70bc\u7684\u5bf9\u6bd4\u5b66\u4e60\u4ee5\u5b9e\u73b0\u5bf9\u9f50\u3002\u8be5\u65b9\u6cd5\u4fdd\u6301\u67b6\u6784\u4e00\u81f4\u6027\uff0c\u89e3\u51b3\u751f\u6210\u5b66\u4e60\u548c\u5bf9\u6bd4\u5b66\u4e60\u4e4b\u95f4\u7684\u76ee\u6807\u51b2\u7a81\u3002", "result": "\u5728\u533b\u7597\u3001\u5316\u5b66\u548c\u4ee3\u7801\u68c0\u7d22\u4efb\u52a1\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cLBR\u663e\u8457\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "LBR\u4e3a\u5728\u5782\u76f4\u9886\u57df\u6784\u5efa\u51c6\u786e\u4e14\u9c81\u68d2\u7684\u8868\u5f81\u5efa\u7acb\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2601.11144", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11144", "abs": "https://arxiv.org/abs/2601.11144", "authors": ["Yuejie Li", "Ke Yang", "Tao Wang", "Bolin Chen", "Bowen Li", "Chengjun Mao"], "title": "Deep GraphRAG: A Balanced Approach to Hierarchical Retrieval and Adaptive Integration", "comment": null, "summary": "Graph-based Retrieval-Augmented Generation (GraphRAG) frameworks face a trade-off between the comprehensiveness of global search and the efficiency of local search. Existing methods are often challenged by navigating large-scale hierarchical graphs, optimizing retrieval paths, and balancing exploration-exploitation dynamics, frequently lacking robust multi-stage re-ranking. To overcome these deficits, we propose Deep GraphRAG, a framework designed for a balanced approach to hierarchical retrieval and adaptive integration. It introduces a hierarchical global-to-local retrieval strategy that integrates macroscopic inter-community and microscopic intra-community contextual relations. This strategy employs a three-stage process: (1) inter-community filtering, which prunes the search space using local context; (2) community-level refinement, which prioritizes relevant subgraphs via entity-interaction analysis; and (3) entity-level fine-grained search within target communities. A beam search-optimized dynamic re-ranking module guides this process, continuously filtering candidates to balance efficiency and global comprehensiveness. Deep GraphRAG also features a Knowledge Integration Module leveraging a compact LLM, trained with Dynamic Weighting Reward GRPO (DW-GRPO). This novel reinforcement learning approach dynamically adjusts reward weights to balance three key objectives: relevance, faithfulness, and conciseness. This training enables compact models (1.5B) to approach the performance of large models (70B) in the integration task. Evaluations on Natural Questions and HotpotQA demonstrate that Deep GraphRAG significantly outperforms baseline graph retrieval methods in both accuracy and efficiency.", "AI": {"tldr": "Deep GraphRAG\u63d0\u51fa\u5206\u5c42\u5168\u5c40-\u5c40\u90e8\u68c0\u7d22\u7b56\u7565\uff0c\u7ed3\u5408\u4e09\u9636\u6bb5\u68c0\u7d22\u8fc7\u7a0b\u548c\u52a8\u6001\u91cd\u6392\u5e8f\u6a21\u5757\uff0c\u4ee5\u53ca\u4f7f\u7528\u52a8\u6001\u52a0\u6743\u5956\u52b1GRPO\u8bad\u7ec3\u7684\u7d27\u51d1LLM\u77e5\u8bc6\u96c6\u6210\u6a21\u5757\uff0c\u663e\u8457\u63d0\u5347\u56fe\u68c0\u7d22\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709GraphRAG\u6846\u67b6\u5728\u5168\u5c40\u641c\u7d22\u5168\u9762\u6027\u548c\u5c40\u90e8\u641c\u7d22\u6548\u7387\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u9762\u4e34\u5927\u89c4\u6a21\u5206\u5c42\u56fe\u5bfc\u822a\u3001\u68c0\u7d22\u8def\u5f84\u4f18\u5316\u3001\u63a2\u7d22-\u5229\u7528\u5e73\u8861\u7b49\u6311\u6218\uff0c\u4e14\u7f3a\u4e4f\u9c81\u68d2\u7684\u591a\u9636\u6bb5\u91cd\u6392\u5e8f\u673a\u5236\u3002", "method": "1) \u5206\u5c42\u5168\u5c40-\u5c40\u90e8\u68c0\u7d22\u7b56\u7565\uff1a\u4e09\u9636\u6bb5\u8fc7\u7a0b\uff08\u793e\u533a\u95f4\u8fc7\u6ee4\u3001\u793e\u533a\u7ea7\u7ec6\u5316\u3001\u5b9e\u4f53\u7ea7\u7ec6\u7c92\u5ea6\u641c\u7d22\uff09\uff1b2) \u6ce2\u675f\u641c\u7d22\u4f18\u5316\u7684\u52a8\u6001\u91cd\u6392\u5e8f\u6a21\u5757\uff1b3) \u77e5\u8bc6\u96c6\u6210\u6a21\u5757\u4f7f\u7528\u52a8\u6001\u52a0\u6743\u5956\u52b1GRPO\u8bad\u7ec3\u7d27\u51d1LLM\uff0c\u5e73\u8861\u76f8\u5173\u6027\u3001\u5fe0\u5b9e\u6027\u548c\u7b80\u6d01\u6027\u3002", "result": "\u5728Natural Questions\u548cHotpotQA\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cDeep GraphRAG\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u56fe\u68c0\u7d22\u65b9\u6cd5\uff0c\u7d27\u51d1\u6a21\u578b(1.5B)\u5728\u96c6\u6210\u4efb\u52a1\u4e2d\u63a5\u8fd1\u5927\u6a21\u578b(70B)\u7684\u6027\u80fd\u3002", "conclusion": "Deep GraphRAG\u901a\u8fc7\u5206\u5c42\u68c0\u7d22\u7b56\u7565\u548c\u52a8\u6001\u52a0\u6743\u5956\u52b1\u8bad\u7ec3\uff0c\u6709\u6548\u89e3\u51b3\u4e86GraphRAG\u6846\u67b6\u4e2d\u7684\u6743\u8861\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u51c6\u786e\u6027\u548c\u6548\u7387\u7684\u5e73\u8861\uff0c\u4e3a\u5927\u89c4\u6a21\u56fe\u68c0\u7d22\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11151", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11151", "abs": "https://arxiv.org/abs/2601.11151", "authors": ["Ji Dai", "Quan Fang", "Jun Hu", "Desheng Cai", "Yang Yang", "Can Zhao"], "title": "Cross-Modal Attention Network with Dual Graph Learning in Multimodal Recommendation", "comment": "Accepted to ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)", "summary": "Multimedia recommendation systems leverage user-item interactions and multimodal information to capture user preferences, enabling more accurate and personalized recommendations. Despite notable advancements, existing approaches still face two critical limitations: first, shallow modality fusion often relies on simple concatenation, failing to exploit rich synergic intra- and inter-modal relationships; second, asymmetric feature treatment-where users are only characterized by interaction IDs while items benefit from rich multimodal content-hinders the learning of a shared semantic space. To address these issues, we propose a Cross-modal Recursive Attention Network with dual graph Embedding (CRANE). To tackle shallow fusion, we design a core Recursive Cross-Modal Attention (RCA) mechanism that iteratively refines modality features based on cross-correlations in a joint latent space, effectively capturing high-order intra- and inter-modal dependencies. For symmetric multimodal learning, we explicitly construct users' multimodal profiles by aggregating features of their interacted items. Furthermore, CRANE integrates a symmetric dual-graph framework-comprising a heterogeneous user-item interaction graph and a homogeneous item-item semantic graph-unified by a self-supervised contrastive learning objective to fuse behavioral and semantic signals. Despite these complex modeling capabilities, CRANE maintains high computational efficiency. Theoretical and empirical analyses confirm its scalability and high practical efficiency, achieving faster convergence on small datasets and superior performance ceilings on large-scale ones. Comprehensive experiments on four public real-world datasets validate an average 5% improvement in key metrics over state-of-the-art baselines.", "AI": {"tldr": "CRANE\uff1a\u4e00\u79cd\u901a\u8fc7\u9012\u5f52\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u673a\u5236\u548c\u53cc\u56fe\u5d4c\u5165\u7684\u591a\u5a92\u4f53\u63a8\u8350\u7cfb\u7edf\uff0c\u89e3\u51b3\u6d45\u5c42\u6a21\u6001\u878d\u5408\u548c\u4e0d\u5bf9\u79f0\u7279\u5f81\u5904\u7406\u95ee\u9898\uff0c\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5e73\u5747\u63d0\u5347\u5173\u952e\u6307\u68075%\u3002", "motivation": "\u73b0\u6709\u591a\u5a92\u4f53\u63a8\u8350\u7cfb\u7edf\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u5c40\u9650\uff1a1\uff09\u6d45\u5c42\u6a21\u6001\u878d\u5408\u901a\u5e38\u4f9d\u8d56\u7b80\u5355\u62fc\u63a5\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u6a21\u6001\u5185\u548c\u6a21\u6001\u95f4\u7684\u534f\u540c\u5173\u7cfb\uff1b2\uff09\u4e0d\u5bf9\u79f0\u7279\u5f81\u5904\u7406\uff08\u7528\u6237\u4ec5\u7528\u4ea4\u4e92ID\u8868\u5f81\uff0c\u800c\u7269\u54c1\u53d7\u76ca\u4e8e\u4e30\u5bcc\u7684\u591a\u6a21\u6001\u5185\u5bb9\uff09\u963b\u788d\u4e86\u5171\u4eab\u8bed\u4e49\u7a7a\u95f4\u7684\u5b66\u4e60\u3002", "method": "\u63d0\u51faCRANE\u6846\u67b6\uff1a1\uff09\u6838\u5fc3\u9012\u5f52\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u8054\u5408\u6f5c\u5728\u7a7a\u95f4\u4e2d\u57fa\u4e8e\u8de8\u6a21\u6001\u76f8\u5173\u6027\u8fed\u4ee3\u7cbe\u70bc\u6a21\u6001\u7279\u5f81\uff1b2\uff09\u901a\u8fc7\u805a\u5408\u7528\u6237\u4ea4\u4e92\u7269\u54c1\u7684\u7279\u5f81\u663e\u5f0f\u6784\u5efa\u7528\u6237\u591a\u6a21\u6001\u753b\u50cf\uff1b3\uff09\u5bf9\u79f0\u53cc\u56fe\u6846\u67b6\uff08\u5f02\u6784\u7528\u6237-\u7269\u54c1\u4ea4\u4e92\u56fe\u548c\u540c\u6784\u7269\u54c1-\u7269\u54c1\u8bed\u4e49\u56fe\uff09\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u76ee\u6807\u878d\u5408\u884c\u4e3a\u548c\u8bed\u4e49\u4fe1\u53f7\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5f00\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5173\u952e\u6307\u6807\u5e73\u5747\u63d0\u53475%\u3002\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u8868\u660e\u5176\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u9ad8\u5b9e\u9645\u6548\u7387\uff0c\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u6536\u655b\u66f4\u5feb\uff0c\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u66f4\u4f18\u6027\u80fd\u4e0a\u9650\u3002", "conclusion": "CRANE\u901a\u8fc7\u9012\u5f52\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u548c\u5bf9\u79f0\u53cc\u56fe\u5d4c\u5165\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u5a92\u4f53\u63a8\u8350\u4e2d\u7684\u6a21\u6001\u878d\u5408\u548c\u7279\u5f81\u4e0d\u5bf9\u79f0\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9ad8\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2601.11182", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.11182", "abs": "https://arxiv.org/abs/2601.11182", "authors": ["Martin Spi\u0161\u00e1k", "Ladislav Pe\u0161ka", "Petr \u0160koda", "Vojt\u011bch Van\u010dura", "Rodrigo Alves"], "title": "From Knots to Knobs: Towards Steerable Collaborative Filtering Using Sparse Autoencoders", "comment": null, "summary": "Sparse autoencoders (SAEs) have recently emerged as pivotal tools for introspection into large language models. SAEs can uncover high-quality, interpretable features at different levels of granularity and enable targeted steering of the generation process by selectively activating specific neurons in their latent activations. Our paper is the first to apply this approach to collaborative filtering, aiming to extract similarly interpretable features from representations learned purely from interaction signals. In particular, we focus on a widely adopted class of collaborative autoencoders (CFAEs) and augment them by inserting an SAE between their encoder and decoder networks. We demonstrate that such representation is largely monosemantic and propose suitable mapping functions between semantic concepts and individual neurons. We also evaluate a simple yet effective method that utilizes this representation to steer the recommendations in a desired direction.", "AI": {"tldr": "\u5c06\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5e94\u7528\u4e8e\u534f\u540c\u8fc7\u6ee4\uff0c\u5728\u534f\u540c\u81ea\u7f16\u7801\u5668\u4e2d\u63d2\u5165SAE\u5c42\uff0c\u63d0\u53d6\u53ef\u89e3\u91ca\u7684\u5355\u8bed\u4e49\u7279\u5f81\uff0c\u5b9e\u73b0\u53ef\u63a7\u63a8\u8350", "motivation": "\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u5df2\u8bc1\u660e\u80fd\u63d0\u53d6\u9ad8\u8d28\u91cf\u53ef\u89e3\u91ca\u7279\u5f81\uff0c\u4f46\u5c1a\u672a\u5e94\u7528\u4e8e\u534f\u540c\u8fc7\u6ee4\u9886\u57df\u3002\u672c\u6587\u65e8\u5728\u5c06SAE\u65b9\u6cd5\u5f15\u5165\u534f\u540c\u8fc7\u6ee4\uff0c\u4ece\u7eaf\u4ea4\u4e92\u4fe1\u53f7\u4e2d\u63d0\u53d6\u7c7b\u4f3c\u7684\u53ef\u89e3\u91ca\u7279\u5f81", "method": "\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684\u534f\u540c\u81ea\u7f16\u7801\u5668\u67b6\u6784\u4e2d\uff0c\u5728\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u4e4b\u95f4\u63d2\u5165\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5c42\uff0c\u5e76\u63d0\u51fa\u8bed\u4e49\u6982\u5ff5\u4e0e\u5355\u4e2a\u795e\u7ecf\u5143\u4e4b\u95f4\u7684\u6620\u5c04\u51fd\u6570", "result": "\u8bc1\u660e\u8fd9\u79cd\u8868\u793a\u4e3b\u8981\u5177\u6709\u5355\u8bed\u4e49\u7279\u6027\uff0c\u80fd\u591f\u63d0\u53d6\u53ef\u89e3\u91ca\u7279\u5f81\uff0c\u5e76\u63d0\u51fa\u7b80\u5355\u6709\u6548\u7684\u5229\u7528\u8fd9\u79cd\u8868\u793a\u6765\u5f15\u5bfc\u63a8\u8350\u65b9\u5411\u7684\u65b9\u6cd5", "conclusion": "\u9996\u6b21\u5c06\u7a00\u758f\u81ea\u7f16\u7801\u5668\u6210\u529f\u5e94\u7528\u4e8e\u534f\u540c\u8fc7\u6ee4\uff0c\u5b9e\u73b0\u4e86\u4ece\u4ea4\u4e92\u4fe1\u53f7\u4e2d\u63d0\u53d6\u53ef\u89e3\u91ca\u7279\u5f81\uff0c\u4e3a\u53ef\u63a7\u63a8\u8350\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5"}}
{"id": "2601.11238", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.11238", "abs": "https://arxiv.org/abs/2601.11238", "authors": ["David Otero", "Javier Parapar"], "title": "LLM-Assisted Pseudo-Relevance Feedback", "comment": "Accepted ECIR 2026", "summary": "Query expansion is a long-standing technique to mitigate vocabulary mismatch in ad hoc Information Retrieval. Pseudo-relevance feedback methods, such as RM3, estimate an expanded query model from the top-ranked documents, but remain vulnerable to topic drift when early results include noisy or tangential content. Recent approaches instead prompt Large Language Models to generate synthetic expansions or query variants. While effective, these methods risk hallucinations and misalignment with collection-specific terminology. We propose a hybrid alternative that preserves the robustness and interpretability of classical PRF while leveraging LLM semantic judgement. Our method inserts an LLM-based filtering stage prior to RM3 estimation: the LLM judges the documents in the initial top-$k$ ranking, and RM3 is computed only over those accepted as relevant. This simple intervention improves over blind PRF and a strong baseline across several datasets and metrics.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u4f20\u7edf\u4f2a\u76f8\u5173\u53cd\u9988\u548cLLM\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u5728RM3\u4f30\u8ba1\u524d\u52a0\u5165LLM\u8fc7\u6ee4\u9636\u6bb5\uff0c\u53ea\u4f7f\u7528\u88ab\u5224\u5b9a\u4e3a\u76f8\u5173\u7684\u6587\u6863\u8fdb\u884c\u67e5\u8be2\u6269\u5c55\uff0c\u63d0\u5347\u68c0\u7d22\u6548\u679c", "motivation": "\u4f20\u7edf\u4f2a\u76f8\u5173\u53cd\u9988\u65b9\u6cd5\uff08\u5982RM3\uff09\u5bb9\u6613\u53d7\u5230\u4e3b\u9898\u6f02\u79fb\u5f71\u54cd\uff0c\u800c\u57fa\u4e8eLLM\u7684\u67e5\u8be2\u6269\u5c55\u65b9\u6cd5\u5b58\u5728\u5e7b\u89c9\u548c\u672f\u8bed\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u7ed3\u5408\u4e24\u8005\u4f18\u70b9\u7684\u6df7\u5408\u65b9\u6848", "method": "\u5728RM3\u4f30\u8ba1\u524d\u52a0\u5165LLM\u8fc7\u6ee4\u9636\u6bb5\uff1aLLM\u5bf9\u521d\u59cb\u6392\u540d\u524dk\u7684\u6587\u6863\u8fdb\u884c\u76f8\u5173\u6027\u5224\u65ad\uff0c\u53ea\u4f7f\u7528\u88ab\u63a5\u53d7\u4e3a\u76f8\u5173\u7684\u6587\u6863\u8fdb\u884cRM3\u67e5\u8be2\u6269\u5c55\u4f30\u8ba1", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6307\u6807\u4e0a\u4f18\u4e8e\u76f2\u76ee\u7684\u4f2a\u76f8\u5173\u53cd\u9988\u548c\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u68c0\u7d22\u6548\u679c", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408\u65b9\u6cd5\u65e2\u4fdd\u7559\u4e86\u4f20\u7edf\u4f2a\u76f8\u5173\u53cd\u9988\u7684\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u53c8\u5229\u7528\u4e86LLM\u7684\u8bed\u4e49\u5224\u65ad\u80fd\u529b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u67e5\u8be2\u6269\u5c55\u4e2d\u7684\u4e3b\u9898\u6f02\u79fb\u95ee\u9898"}}
{"id": "2601.11273", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.11273", "abs": "https://arxiv.org/abs/2601.11273", "authors": ["Yongqi Fan", "Yuxiang Chu", "Zhentao Xia", "Xiaoyang Chen", "Jie Liu", "Haijin Liang", "Jin Ma", "Ben He", "Yingfei Sun", "Dezhi Ye", "Tong Ruan"], "title": "Rank4Gen: RAG-Preference-Aligned Document Set Selection and Ranking", "comment": null, "summary": "In the RAG paradigm, the information retrieval module provides context for generators by retrieving and ranking multiple documents to support the aggregation of evidence. However, existing ranking models are primarily optimized for query--document relevance, which often misaligns with generators' preferences for evidence selection and citation, limiting their impact on response quality. Moreover, most approaches do not account for preference differences across generators, resulting in unstable cross-generator performance. We propose \\textbf{Rank4Gen}, a generator-aware ranker for RAG that targets the goal of \\emph{Ranking for Generators}. Rank4Gen introduces two key preference modeling strategies: (1) \\textbf{From Ranking Relevance to Response Quality}, which optimizes ranking with respect to downstream response quality rather than query--document relevance; and (2) \\textbf{Generator-Specific Preference Modeling}, which conditions a single ranker on different generators to capture their distinct ranking preferences. To enable such modeling, we construct \\textbf{PRISM}, a dataset built from multiple open-source corpora and diverse downstream generators. Experiments on five challenging and recent RAG benchmarks demonstrate that RRank4Gen achieves strong and competitive performance for complex evidence composition in RAG.", "AI": {"tldr": "Rank4Gen\u662f\u4e00\u4e2a\u4e3aRAG\u7cfb\u7edf\u8bbe\u8ba1\u7684\u751f\u6210\u5668\u611f\u77e5\u6392\u5e8f\u5668\uff0c\u901a\u8fc7\u4f18\u5316\u6392\u5e8f\u4ee5\u63d0\u5347\u4e0b\u6e38\u54cd\u5e94\u8d28\u91cf\u800c\u975e\u4f20\u7edf\u67e5\u8be2-\u6587\u6863\u76f8\u5173\u6027\uff0c\u5e76\u5efa\u6a21\u4e0d\u540c\u751f\u6210\u5668\u7684\u7279\u5b9a\u504f\u597d\uff0c\u663e\u8457\u63d0\u5347RAG\u6027\u80fd\u3002", "motivation": "\u73b0\u6709RAG\u7cfb\u7edf\u4e2d\u7684\u6392\u5e8f\u6a21\u578b\u4e3b\u8981\u4f18\u5316\u67e5\u8be2-\u6587\u6863\u76f8\u5173\u6027\uff0c\u4e0e\u751f\u6210\u5668\u5728\u8bc1\u636e\u9009\u62e9\u548c\u5f15\u7528\u65b9\u9762\u7684\u504f\u597d\u5b58\u5728\u504f\u5dee\uff0c\u9650\u5236\u4e86\u5176\u5bf9\u54cd\u5e94\u8d28\u91cf\u7684\u63d0\u5347\u6548\u679c\u3002\u6b64\u5916\uff0c\u5927\u591a\u6570\u65b9\u6cd5\u672a\u8003\u8651\u4e0d\u540c\u751f\u6210\u5668\u4e4b\u95f4\u7684\u504f\u597d\u5dee\u5f02\uff0c\u5bfc\u81f4\u8de8\u751f\u6210\u5668\u6027\u80fd\u4e0d\u7a33\u5b9a\u3002", "method": "\u63d0\u51faRank4Gen\u6392\u5e8f\u5668\uff0c\u91c7\u7528\u4e24\u79cd\u5173\u952e\u504f\u597d\u5efa\u6a21\u7b56\u7565\uff1a1) \u4ece\u6392\u5e8f\u76f8\u5173\u6027\u5230\u54cd\u5e94\u8d28\u91cf\uff1a\u4f18\u5316\u6392\u5e8f\u4ee5\u63d0\u5347\u4e0b\u6e38\u54cd\u5e94\u8d28\u91cf\u800c\u975e\u67e5\u8be2-\u6587\u6863\u76f8\u5173\u6027\uff1b2) \u751f\u6210\u5668\u7279\u5b9a\u504f\u597d\u5efa\u6a21\uff1a\u4f7f\u5355\u4e2a\u6392\u5e8f\u5668\u80fd\u591f\u6839\u636e\u4e0d\u540c\u751f\u6210\u5668\u8c03\u6574\u4ee5\u6355\u6349\u5176\u72ec\u7279\u7684\u6392\u5e8f\u504f\u597d\u3002\u4e3a\u6b64\u6784\u5efa\u4e86PRISM\u6570\u636e\u96c6\uff0c\u5305\u542b\u591a\u4e2a\u5f00\u6e90\u8bed\u6599\u5e93\u548c\u591a\u6837\u5316\u4e0b\u6e38\u751f\u6210\u5668\u3002", "result": "\u5728\u4e94\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u6700\u65b0RAG\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRank4Gen\u5728RAG\u7684\u590d\u6742\u8bc1\u636e\u7ec4\u5408\u65b9\u9762\u5b9e\u73b0\u4e86\u5f3a\u5927\u4e14\u5177\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002", "conclusion": "Rank4Gen\u901a\u8fc7\u5c06\u6392\u5e8f\u4f18\u5316\u76ee\u6807\u4ece\u67e5\u8be2-\u6587\u6863\u76f8\u5173\u6027\u8f6c\u5411\u4e0b\u6e38\u54cd\u5e94\u8d28\u91cf\uff0c\u5e76\u5efa\u6a21\u751f\u6210\u5668\u7279\u5b9a\u504f\u597d\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709RAG\u6392\u5e8f\u6a21\u578b\u4e0e\u751f\u6210\u5668\u504f\u597d\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8de8\u751f\u6210\u5668\u7684RAG\u6027\u80fd\u3002"}}
{"id": "2601.11282", "categories": ["cs.IR", "cs.AI", "cs.HC", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.11282", "abs": "https://arxiv.org/abs/2601.11282", "authors": ["Junjie Wang", "Gaole He", "Alisa Rieger", "Ujwal Gadiraju"], "title": "From SERPs to Sound: How Search Engine Result Pages and AI-generated Podcasts Interact to Influence User Attitudes on Controversial Topics", "comment": "ACM CHIIR 2026", "summary": "Compared to search engine result pages (SERPs), AI-generated podcasts represent a relatively new and relatively more passive modality of information consumption, delivering narratives in a naturally engaging format. As these two media increasingly converge in everyday information-seeking behavior, it is essential to explore how their interaction influences user attitudes, particularly in contexts involving controversial, value-laden, and often debated topics. Addressing this need, we aim to understand how information mediums of present-day SERPs and AI-generated podcasts interact to shape the opinions of users. To this end, through a controlled user study (N=483), we investigated user attitudinal effects of consuming information via SERPs and AI-generated podcasts, focusing on how the sequence and modality of exposure shape user opinions. A majority of users in our study corresponded to attitude change outcomes, and we found an effect of sequence on attitude change. Our results further revealed a role of viewpoint bias and the degree of topic controversiality in shaping attitude change, although we found no effect of individual moderators.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u641c\u7d22\u5f15\u64ce\u7ed3\u679c\u9875\u9762(SERPs)\u4e0eAI\u751f\u6210\u64ad\u5ba2\u5bf9\u7528\u6237\u6001\u5ea6\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4fe1\u606f\u6d88\u8d39\u987a\u5e8f\u548c\u5a92\u4ecb\u5f62\u6001\u4f1a\u5f71\u54cd\u7528\u6237\u89c2\u70b9\u6539\u53d8\uff0c\u7279\u522b\u662f\u6d89\u53ca\u4e89\u8bae\u6027\u8bdd\u9898\u65f6\u3002", "motivation": "\u968f\u7740AI\u751f\u6210\u64ad\u5ba2\u6210\u4e3a\u65b0\u5174\u7684\u88ab\u52a8\u4fe1\u606f\u6d88\u8d39\u65b9\u5f0f\uff0c\u4e14\u4e0eSERPs\u5728\u4fe1\u606f\u641c\u7d22\u884c\u4e3a\u4e2d\u65e5\u76ca\u878d\u5408\uff0c\u9700\u8981\u4e86\u89e3\u8fd9\u4e24\u79cd\u5a92\u4ecb\u5982\u4f55\u76f8\u4e92\u4f5c\u7528\u5f71\u54cd\u7528\u6237\u6001\u5ea6\uff0c\u7279\u522b\u662f\u5728\u6d89\u53ca\u4e89\u8bae\u6027\u3001\u4ef7\u503c\u5bfc\u5411\u6027\u8bdd\u9898\u65f6\u3002", "method": "\u901a\u8fc7\u53d7\u63a7\u7528\u6237\u7814\u7a76(N=483)\uff0c\u8c03\u67e5\u7528\u6237\u901a\u8fc7SERPs\u548cAI\u751f\u6210\u64ad\u5ba2\u6d88\u8d39\u4fe1\u606f\u7684\u6001\u5ea6\u6548\u5e94\uff0c\u91cd\u70b9\u5173\u6ce8\u66dd\u5149\u987a\u5e8f\u548c\u5a92\u4ecb\u5f62\u6001\u5982\u4f55\u5851\u9020\u7528\u6237\u89c2\u70b9\u3002", "result": "\u591a\u6570\u7528\u6237\u51fa\u73b0\u6001\u5ea6\u6539\u53d8\uff0c\u53d1\u73b0\u987a\u5e8f\u6548\u5e94\u5bf9\u6001\u5ea6\u6539\u53d8\u6709\u5f71\u54cd\u3002\u7ed3\u679c\u8fdb\u4e00\u6b65\u663e\u793a\u89c2\u70b9\u504f\u89c1\u548c\u8bdd\u9898\u4e89\u8bae\u7a0b\u5ea6\u5728\u5851\u9020\u6001\u5ea6\u6539\u53d8\u4e2d\u8d77\u4f5c\u7528\uff0c\u4f46\u672a\u53d1\u73b0\u4e2a\u4f53\u8c03\u8282\u53d8\u91cf\u7684\u5f71\u54cd\u3002", "conclusion": "\u4fe1\u606f\u5a92\u4ecb(SERPs\u4e0eAI\u64ad\u5ba2)\u7684\u4ea4\u4e92\u4f5c\u7528\u4f1a\u5f71\u54cd\u7528\u6237\u6001\u5ea6\u5f62\u6210\uff0c\u7279\u522b\u662f\u5728\u4e89\u8bae\u6027\u8bdd\u9898\u4e2d\uff0c\u4fe1\u606f\u6d88\u8d39\u987a\u5e8f\u548c\u5a92\u4ecb\u5f62\u6001\u662f\u91cd\u8981\u5f71\u54cd\u56e0\u7d20\uff0c\u8fd9\u5bf9\u8bbe\u8ba1\u4fe1\u606f\u5448\u73b0\u65b9\u5f0f\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2601.11412", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.11412", "abs": "https://arxiv.org/abs/2601.11412", "authors": ["Andreas Konstantin Kruff", "Nolwenn Bernard", "Philipp Schaer"], "title": "Validating Search Query Simulations: A Taxonomy of Measures", "comment": null, "summary": "Assessing the validity of user simulators when used for the evaluation of information retrieval systems remains an open question, constraining their effective use and the reliability of simulation-based results. To address this issue, we conduct a comprehensive literature review with a particular focus on methods for the validation of simulated user queries with regard to real queries. Based on the review, we develop a taxonomy that structures the current landscape of available measures. We empirically corroborate the taxonomy by analyzing the relationships between the different measures applied to four different datasets representing diverse search scenarios. Finally, we provide concrete recommendations on which measures or combinations of measures should be considered when validating user simulation in different contexts. Furthermore, we release a dedicated library with the most commonly used measures to facilitate future research.", "AI": {"tldr": "\u672c\u6587\u5bf9\u7528\u6237\u6a21\u62df\u5668\u5728\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u8bc4\u4f30\u4e2d\u7684\u6709\u6548\u6027\u9a8c\u8bc1\u65b9\u6cd5\u8fdb\u884c\u4e86\u5168\u9762\u7efc\u8ff0\uff0c\u63d0\u51fa\u4e86\u9a8c\u8bc1\u63aa\u65bd\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u9a8c\u8bc1\u4e86\u5206\u7c7b\u6cd5\u7684\u6709\u6548\u6027\uff0c\u6700\u540e\u7ed9\u51fa\u4e86\u4e0d\u540c\u60c5\u5883\u4e0b\u7684\u9a8c\u8bc1\u63aa\u65bd\u9009\u62e9\u5efa\u8bae\u3002", "motivation": "\u7528\u6237\u6a21\u62df\u5668\u5728\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u8bc4\u4f30\u4e2d\u7684\u6709\u6548\u6027\u9a8c\u8bc1\u4ecd\u7136\u662f\u4e00\u4e2a\u5f00\u653e\u6027\u95ee\u9898\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u6709\u6548\u4f7f\u7528\u548c\u57fa\u4e8e\u6a21\u62df\u7ed3\u679c\u7684\u53ef\u9760\u6027\u3002\u9700\u8981\u7cfb\u7edf\u6027\u5730\u89e3\u51b3\u7528\u6237\u6a21\u62df\u67e5\u8be2\u4e0e\u771f\u5b9e\u67e5\u8be2\u4e4b\u95f4\u7684\u9a8c\u8bc1\u95ee\u9898\u3002", "method": "1. \u8fdb\u884c\u5168\u9762\u7684\u6587\u732e\u7efc\u8ff0\uff0c\u7279\u522b\u5173\u6ce8\u6a21\u62df\u7528\u6237\u67e5\u8be2\u4e0e\u771f\u5b9e\u67e5\u8be2\u7684\u9a8c\u8bc1\u65b9\u6cd5\uff1b2. \u57fa\u4e8e\u7efc\u8ff0\u5f00\u53d1\u9a8c\u8bc1\u63aa\u65bd\u7684\u5206\u7c7b\u6cd5\uff1b3. \u901a\u8fc7\u5206\u6790\u56db\u79cd\u4e0d\u540c\u641c\u7d22\u573a\u666f\u6570\u636e\u96c6\u4e0a\u5404\u9a8c\u8bc1\u63aa\u65bd\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5b9e\u8bc1\u9a8c\u8bc1\u5206\u7c7b\u6cd5\u3002", "result": "1. \u5f00\u53d1\u4e86\u7ed3\u6784\u5316\u5f53\u524d\u53ef\u7528\u9a8c\u8bc1\u63aa\u65bd\u7684\u5206\u7c7b\u6cd5\uff1b2. \u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u9a8c\u8bc1\u4e86\u5206\u7c7b\u6cd5\u7684\u6709\u6548\u6027\uff1b3. \u63d0\u4f9b\u4e86\u4e0d\u540c\u60c5\u5883\u4e0b\u5e94\u9009\u62e9\u7684\u9a8c\u8bc1\u63aa\u65bd\u6216\u7ec4\u5408\u7684\u5177\u4f53\u5efa\u8bae\uff1b4. \u53d1\u5e03\u4e86\u5305\u542b\u6700\u5e38\u7528\u9a8c\u8bc1\u63aa\u65bd\u7684\u4e13\u7528\u5e93\u4ee5\u4fc3\u8fdb\u672a\u6765\u7814\u7a76\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6027\u7684\u7efc\u8ff0\u548c\u5b9e\u8bc1\u5206\u6790\uff0c\u4e3a\u4fe1\u606f\u68c0\u7d22\u4e2d\u7528\u6237\u6a21\u62df\u5668\u7684\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u6846\u67b6\u548c\u5b9e\u7528\u6307\u5357\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u6a21\u62df\u8bc4\u4f30\u7684\u53ef\u9760\u6027\uff0c\u5e76\u901a\u8fc7\u5f00\u6e90\u5e93\u4fc3\u8fdb\u8be5\u9886\u57df\u7684\u7814\u7a76\u53d1\u5c55\u3002"}}
{"id": "2601.11427", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11427", "abs": "https://arxiv.org/abs/2601.11427", "authors": ["Ali Khreis", "Anthony Nasr", "Yusuf Hilal"], "title": "Isotropy-Optimized Contrastive Learning for Semantic Course Recommendation", "comment": "7 pages, 7 figures", "summary": "This paper presents a semantic course recommendation system for students using a self-supervised contrastive learning approach built upon BERT (Bidirectional Encoder Representations from Transformers). Traditional BERT embeddings suffer from anisotropic representation spaces, where course descriptions exhibit high cosine similarities regardless of semantic relevance. To address this limitation, we propose a contrastive learning framework with data augmentation and isotropy regularization that produces more discriminative embeddings. Our system processes student text queries and recommends Top-N relevant courses from a curated dataset of over 500 engineering courses across multiple faculties. Experimental results demonstrate that our fine-tuned model achieves improved embedding separation and more accurate course recommendations compared to vanilla BERT baselines.", "AI": {"tldr": "\u57fa\u4e8eBERT\u7684\u81ea\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u8bed\u4e49\u8bfe\u7a0b\u63a8\u8350\u7cfb\u7edf\uff0c\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u548c\u5404\u5411\u540c\u6027\u6b63\u5219\u5316\u89e3\u51b3\u4f20\u7edfBERT\u5d4c\u5165\u7684\u5404\u5411\u5f02\u6027\u95ee\u9898\uff0c\u63d0\u9ad8\u8bfe\u7a0b\u63a8\u8350\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edfBERT\u5d4c\u5165\u5b58\u5728\u5404\u5411\u5f02\u6027\u8868\u793a\u7a7a\u95f4\u95ee\u9898\uff0c\u8bfe\u7a0b\u63cf\u8ff0\u65e0\u8bba\u8bed\u4e49\u76f8\u5173\u6027\u5982\u4f55\u90fd\u8868\u73b0\u51fa\u9ad8\u4f59\u5f26\u76f8\u4f3c\u5ea6\uff0c\u8fd9\u9650\u5236\u4e86\u8bfe\u7a0b\u63a8\u8350\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u533a\u5206\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eBERT\u7684\u81ea\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u6570\u636e\u589e\u5f3a\u548c\u5404\u5411\u540c\u6027\u6b63\u5219\u5316\u6280\u672f\uff0c\u5904\u7406\u5b66\u751f\u6587\u672c\u67e5\u8be2\u5e76\u4ece500\u591a\u95e8\u5de5\u7a0b\u8bfe\u7a0b\u6570\u636e\u96c6\u4e2d\u63a8\u8350Top-N\u76f8\u5173\u8bfe\u7a0b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5fae\u8c03\u540e\u7684\u6a21\u578b\u76f8\u6bd4\u539f\u59cbBERT\u57fa\u7ebf\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u5d4c\u5165\u5206\u79bb\u6548\u679c\u548c\u66f4\u51c6\u786e\u7684\u8bfe\u7a0b\u63a8\u8350\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86BERT\u5d4c\u5165\u7684\u5404\u5411\u5f02\u6027\u95ee\u9898\uff0c\u80fd\u591f\u751f\u6210\u66f4\u5177\u533a\u5206\u6027\u7684\u5d4c\u5165\u8868\u793a\uff0c\u4ece\u800c\u63d0\u5347\u8bfe\u7a0b\u63a8\u8350\u7cfb\u7edf\u7684\u8bed\u4e49\u5339\u914d\u80fd\u529b\u3002"}}
