<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 6]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Association via Entropy Reduction](https://arxiv.org/abs/2511.04901)
*Anthony Gamst,Lawrence Wilson*

Main category: cs.IR

TL;DR: 本文提出了一种新的文档关联度评分方法aver，在大型图数据中优于传统的tf-idf方法，特别适用于神经网络不占优势的场景。


<details>
  <summary>Details</summary>
Motivation: 在神经网络成功应用之前，tf-idf被认为是文档关联度计算的最佳选择，但作者发现tf-idf在某些场景下存在局限性，特别是在大型图数据中寻找关联顶点时。

Method: 提出aver评分方法，该方法基于简单统计模型的熵推导而来，相比tf-idf具有更自然的理论基础。

Result: 在具有真实关联标注的数据集上，aver在寻找关联文档对方面表现优于tf-idf，特别是在tf-idf得分为1.0的情况下仍能区分不同关联度。

Conclusion: aver方法在文档关联度计算中具有优势，特别是在大型图数据场景下，虽然计算复杂度高于tf-idf，但其理论基础更自然且适用性更广。

Abstract: Prior to recent successes using neural networks, term frequency-inverse
document frequency (tf-idf) was clearly regarded as the best choice for
identifying documents related to a query. We provide a different score, aver,
and observe, on a dataset with ground truth marking for association, that aver
does do better at finding assciated pairs than tf-idf. This example involves
finding associated vertices in a large graph and that may be an area where
neural networks are not currently an obvious best choice. Beyond this one
anecdote, we observe that (1) aver has a natural threshold for declaring pairs
as unassociated while tf-idf does not, (2) aver can distinguish between pairs
of documents for which tf-idf gives a score of 1.0, (3) aver can be applied to
larger collections of documents than pairs while tf-idf cannot, and (4) that
aver is derived from entropy under a simple statistical model while tf-idf is a
construction designed to achieve a certain goal and hence aver may be more
"natural." To be fair, we also observe that (1) writing down and computing the
aver score for a pair is more complex than for tf-idf and (2) that the fact
that the aver score is naturally scale-free makes it more complicated to
interpret aver scores.

</details>


### [2] [Search Is Not Retrieval: Decoupling Semantic Matching from Contextual Assembly in RAG](https://arxiv.org/abs/2511.04939)
*Harshit Nainwani,Hediyeh Baban*

Main category: cs.IR

TL;DR: 提出了SINR框架，将检索系统分为细粒度搜索表示和粗粒度检索上下文两个层次，提升系统的可组合性、可扩展性和上下文保真度。


<details>
  <summary>Details</summary>
Motivation: 现有检索系统混淆了两个独立过程：查找相关信息与提供足够推理上下文。需要区分搜索和检索的不同需求。

Method: 采用双层架构设计，将小的语义准确搜索块与大的上下文完整检索块直接连接，不增加额外处理成本。

Result: SINR框架将检索从被动步骤转变为主动过程，使系统架构更符合人类信息处理方式。

Conclusion: 为下一代使用检索的AI系统提供了实用基础，解决了检索系统中搜索与检索过程的混淆问题。

Abstract: Retrieval systems are essential to contemporary AI pipelines, although most
confuse two separate processes: finding relevant information and giving enough
context for reasoning. We introduce the Search-Is-Not-Retrieve (SINR)
framework, a dual-layer architecture that distinguishes between fine-grained
search representations and coarse-grained retrieval contexts. SINR enhances the
composability, scalability, and context fidelity of retrieval systems by
directly connecting small, semantically accurate search chunks to larger,
contextually complete retrieve chunks, all without incurring extra processing
costs. This design changes retrieval from a passive step to an active one,
making the system architecture more like how people process information. We
discuss the SINR framework's conceptual foundation, formal structure,
implementation issues, and qualitative outcomes. This provides a practical
foundation for the next generation of AI systems that use retrieval.

</details>


### [3] [Query Generation Pipeline with Enhanced Answerability Assessment for Financial Information Retrieval](https://arxiv.org/abs/2511.05000)
*Hyunkyu Kim,Yeeun Yoo,Youngjun Kwak*

Main category: cs.IR

TL;DR: 提出了一种基于LLM的系统化方法来构建领域特定的信息检索基准，特别是在金融银行领域，解决了现有基准无法捕捉真实银行场景复杂信息需求的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法充分反映真实银行场景中复杂和领域特定的信息需求，而构建领域特定基准成本高且受限于客户数据的法律限制。

Method: 采用基于LLM的查询生成方法，结合单文档和多文档查询生成，以及增强的推理增强可回答性评估方法，构建了KoBankIR基准数据集。

Result: 构建了包含815个查询和204个官方银行文档的KoBankIR基准，实验显示现有检索模型在处理复杂多文档查询时表现不佳。

Conclusion: 该方法为领域特定基准构建提供了系统化解决方案，并突显了金融领域需要改进检索技术的必要性。

Abstract: As financial applications of large language models (LLMs) gain attention,
accurate Information Retrieval (IR) remains crucial for reliable AI services.
However, existing benchmarks fail to capture the complex and domain-specific
information needs of real-world banking scenarios. Building domain-specific IR
benchmarks is costly and constrained by legal restrictions on using real
customer data. To address these challenges, we propose a systematic methodology
for constructing domain-specific IR benchmarks through LLM-based query
generation. As a concrete implementation of this methodology, our pipeline
combines single and multi-document query generation with an enhanced and
reasoning-augmented answerability assessment method, achieving stronger
alignment with human judgments than prior approaches. Using this methodology,
we construct KoBankIR, comprising 815 queries derived from 204 official banking
documents. Our experiments show that existing retrieval models struggle with
the complex multi-document queries in KoBankIR, demonstrating the value of our
systematic approach for domain-specific benchmark construction and underscoring
the need for improved retrieval techniques in financial domains.

</details>


### [4] [Wikipedia-based Datasets in Russian Information Retrieval Benchmark RusBEIR](https://arxiv.org/abs/2511.05079)
*Grigory Kovalev,Natalia Loukachevitch,Mikhail Tikhomirov,Olga Babina,Pavel Mamaev*

Main category: cs.IR

TL;DR: 本文构建了基于俄语维基百科的新信息检索数据集，支持事实核查、检索增强生成等任务，并通过实验比较了词汇检索模型与神经模型在不同任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 扩展俄语信息检索资源，弥补现有俄语IR数据集的不足，为俄语检索研究提供更丰富的评估基准。

Method: 从俄语维基百科的"你知道吗..."部分构建数据集，包含句子级分级相关性标注。通过实验比较BM25等词汇检索模型与针对俄语优化的神经架构及多语言模型。

Result: 词汇方法在全文档检索中表现优于神经模型，而神经方法在短文本（如事实核查）中能更好地捕捉词汇语义。结合检索与神经重排序能持续提升性能。

Conclusion: 新数据集扩展了俄语信息检索研究资源，强调了准确评估检索模型对优化性能的重要性，所有数据集和实现代码均已公开。

Abstract: In this paper, we present a novel series of Russian information retrieval
datasets constructed from the "Did you know..." section of Russian Wikipedia.
Our datasets support a range of retrieval tasks, including fact-checking,
retrieval-augmented generation, and full-document retrieval, by leveraging
interesting facts and their referenced Wikipedia articles annotated at the
sentence level with graded relevance. We describe the methodology for dataset
creation that enables the expansion of existing Russian Information Retrieval
(IR) resources. Through extensive experiments, we extend the RusBEIR research
by comparing lexical retrieval models, such as BM25, with state-of-the-art
neural architectures fine-tuned for Russian, as well as multilingual models.
Results of our experiments show that lexical methods tend to outperform neural
models on full-document retrieval, while neural approaches better capture
lexical semantics in shorter texts, such as in fact-checking or fine-grained
retrieval. Using our newly created datasets, we also analyze the impact of
document length on retrieval performance and demonstrate that combining
retrieval with neural reranking consistently improves results. Our contribution
expands the resources available for Russian information retrieval research and
highlights the importance of accurate evaluation of retrieval models to achieve
optimal performance. All datasets are publicly available at HuggingFace. To
facilitate reproducibility and future research, we also release the full
implementation on GitHub.

</details>


### [5] [QUESTER: Query Specification for Generative Retrieval](https://arxiv.org/abs/2511.05301)
*Arthur Satouf,Yuxuan Zong,Habiboulaye Amadou-Boubacar,Pablo Piantanida,Benjamin Piwowarski*

Main category: cs.IR

TL;DR: QUESTER将生成式检索重构为查询规范生成，使用小型LLM生成BM25可处理的关键词查询，通过强化学习训练，在领域内外评估中优于BM25，与神经IR模型竞争，同时保持良好效率


<details>
  <summary>Details</summary>
Motivation: 生成式检索通常难以泛化且扩展成本高，需要更有效的方法

Method: 使用小型LLM将生成式检索重构为查询规范生成（生成BM25可处理的关键词查询），采用GRPO强化学习技术训练策略

Result: 在领域内外评估中，模型效果优于BM25，与神经IR模型竞争力相当，同时保持良好效率

Conclusion: QUESTER方法通过查询规范生成实现了有效的生成式检索，在效果和效率之间取得了良好平衡

Abstract: Generative Retrieval (GR) differs from the traditional index-then-retrieve
pipeline by storing relevance in model parameters and directly generating
document identifiers. However, GR often struggles to generalize and is costly
to scale. We introduce QUESTER (QUEry SpecificaTion gEnerative Retrieval),
which reframes GR as query specification generation - in this work, a simple
keyword query handled by BM25 - using a (small) LLM. The policy is trained
using reinforcement learning techniques (GRPO). Across in- and out-of-domain
evaluations, we show that our model is more effective than BM25, and
competitive with neural IR models, while maintaining a good efficiency

</details>


### [6] [TeaRAG: A Token-Efficient Agentic Retrieval-Augmented Generation Framework](https://arxiv.org/abs/2511.05385)
*Chao Zhang,Yuhao Wang,Derong Xu,Haoxin Zhang,Yuanjie Lyu,Yuhao Chen,Shuochen Liu,Tong Xu,Xiangyu Zhao,Yan Gao,Yao Hu,Enhong Chen*

Main category: cs.IR

TL;DR: TeaRAG是一个token高效的代理式RAG框架，通过压缩检索内容和推理步骤来提高效率，在保持准确性的同时显著减少token使用量。


<details>
  <summary>Details</summary>
Motivation: 现有的代理式RAG系统虽然通过强化学习提高了准确性，但搜索和推理过程会产生大量token开销，这种权衡以效率为代价优先考虑准确性。

Method: 1) 通过图检索使用简洁三元组增强基于块的语义检索来压缩检索内容，构建知识关联图并利用个性化PageRank突出关键知识；2) 提出迭代过程感知直接偏好优化(IP-DPO)，通过知识匹配机制评估知识充分性并惩罚过度推理步骤。

Result: 在六个数据集上，TeaRAG将Llama3-8B-Instruct的平均精确匹配提高了4%，输出token减少了61%；在Qwen2.5-14B-Instruct上平均精确匹配提高了2%，输出token减少了59%。

Conclusion: TeaRAG在保持准确性的同时显著提高了效率，证明了在代理式RAG系统中平衡准确性和效率的可行性。

Abstract: Retrieval-Augmented Generation (RAG) utilizes external knowledge to augment
Large Language Models' (LLMs) reliability. For flexibility, agentic RAG employs
autonomous, multi-round retrieval and reasoning to resolve queries. Although
recent agentic RAG has improved via reinforcement learning, they often incur
substantial token overhead from search and reasoning processes. This trade-off
prioritizes accuracy over efficiency. To address this issue, this work proposes
TeaRAG, a token-efficient agentic RAG framework capable of compressing both
retrieval content and reasoning steps. 1) First, the retrieved content is
compressed by augmenting chunk-based semantic retrieval with a graph retrieval
using concise triplets. A knowledge association graph is then built from
semantic similarity and co-occurrence. Finally, Personalized PageRank is
leveraged to highlight key knowledge within this graph, reducing the number of
tokens per retrieval. 2) Besides, to reduce reasoning steps, Iterative
Process-aware Direct Preference Optimization (IP-DPO) is proposed.
Specifically, our reward function evaluates the knowledge sufficiency by a
knowledge matching mechanism, while penalizing excessive reasoning steps. This
design can produce high-quality preference-pair datasets, supporting iterative
DPO to improve reasoning conciseness. Across six datasets, TeaRAG improves the
average Exact Match by 4% and 2% while reducing output tokens by 61% and 59% on
Llama3-8B-Instruct and Qwen2.5-14B-Instruct, respectively. Code is available at
https://github.com/Applied-Machine-Learning-Lab/TeaRAG.

</details>
