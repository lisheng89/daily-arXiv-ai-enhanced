{"id": "2602.02514", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02514", "abs": "https://arxiv.org/abs/2602.02514", "authors": ["Pratik Lahiri", "Bingqing Ge", "Zhou Qin", "Aditya Jumde", "Shuning Huo", "Lucas Scottini", "Yi Liu", "Mahmoud Mamlouk", "Wenyang Liu"], "title": "Design and Evaluation of Whole-Page Experience Optimization for E-commerce Search", "comment": null, "summary": "E-commerce Search Results Pages (SRPs) are evolving from linear lists to complex, non-linear layouts, rendering traditional position-biased ranking models insufficient. Moreover, existing optimization frameworks typically maximize short-term signals (e.g., clicks, same-day revenue) because long-term satisfaction metrics (e.g., expected two-week revenue) involve delayed feedback and challenging long-horizon credit attribution. To bridge these gaps, we propose a novel Whole-Page Experience Optimization Framework. Unlike traditional list-wise rankers, our approach explicitly models the interplay between item relevance, 2D positional layout, and visual elements. We use a causal framework to develop metrics for measuring long-term user satisfaction based on quasi-experimental data. We validate our approach through industry-scale A/B testing, where the model demonstrated a 1.86% improvement in brand relevance (our primary customer experience metric) while simultaneously achieving a statistically significant revenue uplift of +0.05%", "AI": {"tldr": "\u63d0\u51fa\u5168\u9875\u9762\u4f53\u9a8c\u4f18\u5316\u6846\u67b6\uff0c\u89e3\u51b3\u7535\u5546\u641c\u7d22\u7ed3\u679c\u9875\u4ece\u7ebf\u6027\u5217\u8868\u5230\u590d\u6742\u975e\u7ebf\u6027\u5e03\u5c40\u7684\u8f6c\u53d8\u95ee\u9898\uff0c\u540c\u65f6\u4f18\u5316\u77ed\u671f\u4fe1\u53f7\u548c\u957f\u671f\u7528\u6237\u6ee1\u610f\u5ea6\u3002", "motivation": "\u7535\u5546\u641c\u7d22\u7ed3\u679c\u9875\u6b63\u4ece\u7ebf\u6027\u5217\u8868\u6f14\u53d8\u4e3a\u590d\u6742\u7684\u975e\u7ebf\u6027\u5e03\u5c40\uff0c\u4f20\u7edf\u57fa\u4e8e\u4f4d\u7f6e\u7684\u6392\u5e8f\u6a21\u578b\u5df2\u4e0d\u518d\u9002\u7528\u3002\u73b0\u6709\u4f18\u5316\u6846\u67b6\u901a\u5e38\u53ea\u6700\u5927\u5316\u77ed\u671f\u4fe1\u53f7\uff08\u5982\u70b9\u51fb\u3001\u5f53\u65e5\u6536\u5165\uff09\uff0c\u800c\u957f\u671f\u6ee1\u610f\u5ea6\u6307\u6807\uff08\u5982\u9884\u671f\u4e24\u5468\u6536\u5165\uff09\u6d89\u53ca\u5ef6\u8fdf\u53cd\u9988\u548c\u56f0\u96be\u7684\u957f\u671f\u4fe1\u7528\u5f52\u56e0\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5168\u9875\u9762\u4f53\u9a8c\u4f18\u5316\u6846\u67b6\uff0c\u4e0e\u4f20\u7edf\u5217\u8868\u5f0f\u6392\u5e8f\u5668\u4e0d\u540c\uff0c\u8be5\u65b9\u6cd5\u660e\u786e\u5efa\u6a21\u5546\u54c1\u76f8\u5173\u6027\u3001\u4e8c\u7ef4\u4f4d\u7f6e\u5e03\u5c40\u548c\u89c6\u89c9\u5143\u7d20\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002\u4f7f\u7528\u56e0\u679c\u6846\u67b6\u57fa\u4e8e\u51c6\u5b9e\u9a8c\u6570\u636e\u5f00\u53d1\u957f\u671f\u7528\u6237\u6ee1\u610f\u5ea6\u5ea6\u91cf\u6307\u6807\u3002", "result": "\u901a\u8fc7\u884c\u4e1a\u89c4\u6a21\u7684A/B\u6d4b\u8bd5\u9a8c\u8bc1\uff0c\u6a21\u578b\u5728\u54c1\u724c\u76f8\u5173\u6027\uff08\u4e3b\u8981\u5ba2\u6237\u4f53\u9a8c\u6307\u6807\uff09\u4e0a\u63d0\u5347\u4e861.86%\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86+0.05%\u7684\u7edf\u8ba1\u663e\u8457\u6536\u5165\u589e\u957f\u3002", "conclusion": "\u63d0\u51fa\u7684\u5168\u9875\u9762\u4f53\u9a8c\u4f18\u5316\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u73b0\u4ee3\u7535\u5546\u641c\u7d22\u7ed3\u679c\u9875\u7684\u590d\u6742\u5e03\u5c40\u6311\u6218\uff0c\u540c\u65f6\u4f18\u5316\u77ed\u671f\u548c\u957f\u671f\u7528\u6237\u6ee1\u610f\u5ea6\u6307\u6807\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6548\u679c\u3002"}}
{"id": "2602.02827", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.02827", "abs": "https://arxiv.org/abs/2602.02827", "authors": ["Roi Pony", "Adi Raz", "Oshri Naparstek", "Idan Friedman", "Udi Barzelay"], "title": "Col-Bandit: Zero-Shot Query-Time Pruning for Late-Interaction Retrieval", "comment": null, "summary": "Multi-vector late-interaction retrievers such as ColBERT achieve state-of-the-art retrieval quality, but their query-time cost is dominated by exhaustively computing token-level MaxSim interactions for every candidate document. While approximating late interaction with single-vector representations reduces cost, it often incurs substantial accuracy loss. We introduce Col-Bandit, a query-time pruning algorithm that reduces this computational burden by casting reranking as a finite-population Top-$K$ identification problem. Col-Bandit maintains uncertainty-aware bounds over partially observed document scores and adaptively reveals only the (document, query token) MaxSim entries needed to determine the top results under statistical decision bounds with a tunable relaxation. Unlike coarse-grained approaches that prune entire documents or tokens offline, Col-Bandit sparsifies the interaction matrix on the fly. It operates as a zero-shot, drop-in layer over standard multi-vector systems, requiring no index modifications, offline preprocessing, or model retraining. Experiments on textual (BEIR) and multimodal (REAL-MM-RAG) benchmarks show that Col-Bandit preserves ranking fidelity while reducing MaxSim FLOPs by up to 5$\\times$, indicating that dense late-interaction scoring contains substantial redundancy that can be identified and pruned efficiently at query time.", "AI": {"tldr": "Col-Bandit\u662f\u4e00\u79cd\u67e5\u8be2\u65f6\u526a\u679d\u7b97\u6cd5\uff0c\u901a\u8fc7\u5c06\u91cd\u6392\u5e8f\u5efa\u6a21\u4e3a\u6709\u9650\u603b\u4f53Top-K\u8bc6\u522b\u95ee\u9898\uff0c\u81ea\u9002\u5e94\u5730\u63ed\u793a\u5fc5\u8981\u7684MaxSim\u6761\u76ee\uff0c\u5728\u4fdd\u6301\u6392\u5e8f\u8d28\u91cf\u7684\u540c\u65f6\u5c06\u591a\u5411\u91cf\u68c0\u7d22\u5668\u7684\u8ba1\u7b97\u6210\u672c\u964d\u4f4e5\u500d\u3002", "motivation": "\u591a\u5411\u91cf\u5ef6\u8fdf\u4ea4\u4e92\u68c0\u7d22\u5668\uff08\u5982ColBERT\uff09\u867d\u7136\u68c0\u7d22\u8d28\u91cf\u9ad8\uff0c\u4f46\u67e5\u8be2\u65f6\u8ba1\u7b97\u6210\u672c\u5de8\u5927\uff0c\u9700\u8981\u5bf9\u6bcf\u4e2a\u5019\u9009\u6587\u6863\u8fdb\u884c\u8be6\u5c3d\u7684token\u7ea7MaxSim\u4ea4\u4e92\u8ba1\u7b97\u3002\u73b0\u6709\u7684\u5355\u5411\u91cf\u8fd1\u4f3c\u65b9\u6cd5\u867d\u7136\u964d\u4f4e\u4e86\u6210\u672c\uff0c\u4f46\u5f80\u5f80\u5bfc\u81f4\u663e\u8457\u7684\u7cbe\u5ea6\u635f\u5931\u3002", "method": "Col-Bandit\u5c06\u91cd\u6392\u5e8f\u5efa\u6a21\u4e3a\u6709\u9650\u603b\u4f53Top-K\u8bc6\u522b\u95ee\u9898\uff0c\u7ef4\u62a4\u90e8\u5206\u89c2\u5bdf\u6587\u6863\u5206\u6570\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u8fb9\u754c\uff0c\u81ea\u9002\u5e94\u5730\u63ed\u793a\u786e\u5b9atop\u7ed3\u679c\u6240\u9700\u7684\uff08\u6587\u6863\uff0c\u67e5\u8be2token\uff09MaxSim\u6761\u76ee\u3002\u8be5\u65b9\u6cd5\u4f5c\u4e3a\u96f6\u6837\u672c\u3001\u5373\u63d2\u5373\u7528\u5c42\u8fd0\u884c\u5728\u6807\u51c6\u591a\u5411\u91cf\u7cfb\u7edf\u4e4b\u4e0a\uff0c\u65e0\u9700\u7d22\u5f15\u4fee\u6539\u3001\u79bb\u7ebf\u9884\u5904\u7406\u6216\u6a21\u578b\u91cd\u8bad\u7ec3\u3002", "result": "\u5728\u6587\u672c\uff08BEIR\uff09\u548c\u591a\u6a21\u6001\uff08REAL-MM-RAG\uff09\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCol-Bandit\u5728\u4fdd\u6301\u6392\u5e8f\u4fdd\u771f\u5ea6\u7684\u540c\u65f6\uff0c\u5c06MaxSim FLOPs\u51cf\u5c11\u9ad8\u8fbe5\u500d\uff0c\u8868\u660e\u5bc6\u96c6\u5ef6\u8fdf\u4ea4\u4e92\u8bc4\u5206\u5305\u542b\u5927\u91cf\u5197\u4f59\uff0c\u53ef\u4ee5\u5728\u67e5\u8be2\u65f6\u9ad8\u6548\u8bc6\u522b\u548c\u526a\u679d\u3002", "conclusion": "Col-Bandit\u8bc1\u660e\u4e86\u591a\u5411\u91cf\u68c0\u7d22\u5668\u5728\u67e5\u8be2\u65f6\u5b58\u5728\u663e\u8457\u7684\u8ba1\u7b97\u5197\u4f59\uff0c\u901a\u8fc7\u667a\u80fd\u7684\u81ea\u9002\u5e94\u526a\u679d\u7b56\u7565\u53ef\u4ee5\u5728\u4fdd\u6301\u68c0\u7d22\u8d28\u91cf\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u4e3a\u9ad8\u6548\u7684\u591a\u5411\u91cf\u68c0\u7d22\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.02883", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.02883", "abs": "https://arxiv.org/abs/2602.02883", "authors": ["Parker Carlson", "Wentai Xie", "Rohil Shah", "Tao Yang"], "title": "Efficiency Optimizations for Superblock-based Sparse Retrieval", "comment": "11 pages, 5 figures, 9 tables. Under review", "summary": "Learned sparse retrieval (LSR) is a popular method for first-stage retrieval because it combines the semantic matching of language models with efficient CPU-friendly algorithms. Previous work aggregates blocks into \"superblocks\" to quickly skip the visitation of blocks during query processing by using an advanced pruning heuristic. This paper proposes a simple and effective superblock pruning scheme that reduces the overhead of superblock score computation while preserving competitive relevance. It combines this scheme with a compact index structure and a robust zero-shot configuration that is effective across LSR models and multiple datasets. This paper provides an analytical justification and evaluation on the MS MARCO and BEIR datasets, demonstrating that the proposed scheme can be a strong alternative for efficient sparse retrieval.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u8d85\u5757\u526a\u679d\u65b9\u6848\uff0c\u7ed3\u5408\u7d27\u51d1\u7d22\u5f15\u7ed3\u6784\u548c\u96f6\u914d\u7f6e\uff0c\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u540c\u65f6\u51cf\u5c11LSR\u68c0\u7d22\u5f00\u9500", "motivation": "\u5b66\u4e60\u7a00\u758f\u68c0\u7d22\u7ed3\u5408\u4e86\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u5339\u914d\u548c\u9ad8\u6548CPU\u53cb\u597d\u7b97\u6cd5\uff0c\u4f46\u73b0\u6709\u8d85\u5757\u805a\u5408\u65b9\u6cd5\u5728\u67e5\u8be2\u5904\u7406\u65f6\u4f7f\u7528\u9ad8\u7ea7\u526a\u679d\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u5b58\u5728\u8ba1\u7b97\u5f00\u9500\u95ee\u9898", "method": "\u63d0\u51fa\u7b80\u5355\u6709\u6548\u7684\u8d85\u5757\u526a\u679d\u65b9\u6848\uff0c\u7ed3\u5408\u7d27\u51d1\u7d22\u5f15\u7ed3\u6784\u548c\u9c81\u68d2\u7684\u96f6\u914d\u7f6e\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u591a\u79cdLSR\u6a21\u578b\u548c\u6570\u636e\u96c6", "result": "\u5728MS MARCO\u548cBEIR\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u8bc1\u660e\u8be5\u65b9\u6848\u80fd\u51cf\u5c11\u8d85\u5757\u5206\u6570\u8ba1\u7b97\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u529b\uff0c\u53ef\u4f5c\u4e3a\u9ad8\u6548\u7a00\u758f\u68c0\u7d22\u7684\u5f3a\u6709\u529b\u66ff\u4ee3\u65b9\u6848", "conclusion": "\u63d0\u51fa\u7684\u8d85\u5757\u526a\u679d\u65b9\u6848\u7b80\u5355\u6709\u6548\uff0c\u901a\u8fc7\u5206\u6790\u8bba\u8bc1\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u4e3a\u9ad8\u6548\u7a00\u758f\u68c0\u7d22\u63d0\u4f9b\u4e86\u6709\u7ade\u4e89\u529b\u7684\u66ff\u4ee3\u65b9\u6848"}}
{"id": "2602.03056", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.03056", "abs": "https://arxiv.org/abs/2602.03056", "authors": ["Lu Ren", "Junda She", "Xinchen Luo", "Tao Wang", "Xin Ye", "Xu Zhang", "Muxuan Wang", "Xiao Yang", "Chenguang Wang", "Fei Xie", "Yiwei Zhou", "Danjun Wu", "Guodong Zhang", "Yifei Hu", "Guoying Zheng", "Shujie Yang", "Xingmei Wang", "Shiyao Wang", "Yukun Zhou", "Fan Yang", "Size Li", "Kuo Cai", "Qiang Luo", "Ruiming Tang", "Han Li", "Kun Gai"], "title": "ALPBench: A Benchmark for Attribution-level Long-term Personal Behavior Understanding", "comment": null, "summary": "Recent advances in large language models have highlighted their potential for personalized recommendation, where accurately capturing user preferences remains a key challenge. Leveraging their strong reasoning and generalization capabilities, LLMs offer new opportunities for modeling long-term user behavior. To systematically evaluate this, we introduce ALPBench, a Benchmark for Attribution-level Long-term Personal Behavior Understanding. Unlike item-focused benchmarks, ALPBench predicts user-interested attribute combinations, enabling ground-truth evaluation even for newly introduced items. It models preferences from long-term historical behaviors rather than users' explicitly expressed requests, better reflecting enduring interests. User histories are represented as natural language sequences, allowing interpretable, reasoning-based personalization. ALPBench enables fine-grained evaluation of personalization by focusing on the prediction of attribute combinations task that remains highly challenging for current LLMs due to the need to capture complex interactions among multiple attributes and reason over long-term user behavior sequences.", "AI": {"tldr": "ALPBench\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u5c5e\u6027\u7ea7\u522b\u957f\u671f\u4e2a\u4eba\u884c\u4e3a\u7406\u89e3\u80fd\u529b\u7684\u65b0\u57fa\u51c6\uff0c\u4e13\u6ce8\u4e8e\u9884\u6d4b\u7528\u6237\u611f\u5174\u8da3\u7684\u5c5e\u6027\u7ec4\u5408\u800c\u975e\u5177\u4f53\u7269\u54c1\uff0c\u652f\u6301\u5bf9\u65b0\u7269\u54c1\u7684\u8bc4\u4f30", "motivation": "\u5f53\u524dLLM\u5728\u4e2a\u6027\u5316\u63a8\u8350\u4e2d\u51c6\u786e\u6355\u6349\u7528\u6237\u504f\u597d\u4ecd\u5177\u6311\u6218\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30LLM\u5728\u957f\u671f\u7528\u6237\u884c\u4e3a\u5efa\u6a21\u65b9\u9762\u7684\u80fd\u529b\uff0c\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u7269\u54c1\u9884\u6d4b\u800c\u975e\u7528\u6237\u504f\u597d\u5c5e\u6027\u7406\u89e3", "method": "\u5f15\u5165ALPBench\u57fa\u51c6\uff0c\u5c06\u7528\u6237\u5386\u53f2\u884c\u4e3a\u8868\u793a\u4e3a\u81ea\u7136\u8bed\u8a00\u5e8f\u5217\uff0c\u9884\u6d4b\u7528\u6237\u611f\u5174\u8da3\u7684\u5c5e\u6027\u7ec4\u5408\u800c\u975e\u5177\u4f53\u7269\u54c1\uff0c\u652f\u6301\u5bf9\u5168\u65b0\u7269\u54c1\u7684\u8bc4\u4f30\uff0c\u4e13\u6ce8\u4e8e\u5c5e\u6027\u7ec4\u5408\u9884\u6d4b\u4efb\u52a1", "result": "ALPBench\u80fd\u591f\u8fdb\u884c\u7ec6\u7c92\u5ea6\u4e2a\u6027\u5316\u8bc4\u4f30\uff0c\u63ed\u793a\u5f53\u524dLLM\u5728\u6355\u6349\u591a\u5c5e\u6027\u590d\u6742\u4ea4\u4e92\u548c\u957f\u671f\u884c\u4e3a\u5e8f\u5217\u63a8\u7406\u65b9\u9762\u7684\u6311\u6218\uff0c\u4e3a\u8bc4\u4f30LLM\u7684\u957f\u671f\u504f\u597d\u7406\u89e3\u80fd\u529b\u63d0\u4f9b\u7cfb\u7edf\u6846\u67b6", "conclusion": "ALPBench\u586b\u8865\u4e86LLM\u5728\u957f\u671f\u4e2a\u4eba\u884c\u4e3a\u7406\u89e3\u8bc4\u4f30\u65b9\u9762\u7684\u7a7a\u767d\uff0c\u901a\u8fc7\u5c5e\u6027\u7ec4\u5408\u9884\u6d4b\u4efb\u52a1\u63d0\u4f9b\u53ef\u89e3\u91ca\u3001\u57fa\u4e8e\u63a8\u7406\u7684\u4e2a\u6027\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8LLM\u5728\u4e2a\u6027\u5316\u63a8\u8350\u9886\u57df\u7684\u53d1\u5c55"}}
{"id": "2602.03158", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.03158", "abs": "https://arxiv.org/abs/2602.03158", "authors": ["Zongwei Wang", "Min Gao", "Junliang Yu", "Tong Chen", "Chenghua Lin"], "title": "PAMAS: Self-Adaptive Multi-Agent System with Perspective Aggregation for Misinformation Detection", "comment": "12 pages", "summary": "Misinformation on social media poses a critical threat to information credibility, as its diverse and context-dependent nature complicates detection. Large language model-empowered multi-agent systems (MAS) present a promising paradigm that enables cooperative reasoning and collective intelligence to combat this threat. However, conventional MAS suffer from an information-drowning problem, where abundant truthful content overwhelms sparse and weak deceptive cues. With full input access, agents tend to focus on dominant patterns, and inter-agent communication further amplifies this bias. To tackle this issue, we propose PAMAS, a multi-agent framework with perspective aggregation, which employs hierarchical, perspective-aware aggregation to highlight anomaly cues and alleviate information drowning. PAMAS organizes agents into three roles: Auditors, Coordinators, and a Decision-Maker. Auditors capture anomaly cues from specialized feature subsets; Coordinators aggregate their perspectives to enhance coverage while maintaining diversity; and the Decision-Maker, equipped with evolving memory and full contextual access, synthesizes all subordinate insights to produce the final judgment. Furthermore, to improve efficiency in multi-agent collaboration, PAMAS incorporates self-adaptive mechanisms for dynamic topology optimization and routing-based inference, enhancing both efficiency and scalability. Extensive experiments on multiple benchmark datasets demonstrate that PAMAS achieves superior accuracy and efficiency, offering a scalable and trustworthy way for misinformation detection.", "AI": {"tldr": "PAMAS\u662f\u4e00\u4e2a\u7528\u4e8e\u793e\u4ea4\u5a92\u4f53\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u89c6\u89d2\u805a\u5408\u673a\u5236\u89e3\u51b3\u4f20\u7edf\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u4fe1\u606f\u6df9\u6ca1\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u865a\u5047\u4fe1\u606f\u5177\u6709\u591a\u6837\u6027\u548c\u4e0a\u4e0b\u6587\u4f9d\u8d56\u6027\uff0c\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\u9762\u4e34\u6311\u6218\u3002\u4f20\u7edf\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5b58\u5728\"\u4fe1\u606f\u6df9\u6ca1\"\u95ee\u9898\uff0c\u5373\u5927\u91cf\u771f\u5b9e\u5185\u5bb9\u6df9\u6ca1\u4e86\u7a00\u758f\u800c\u5fae\u5f31\u7684\u6b3a\u9a97\u7ebf\u7d22\uff0c\u5bfc\u81f4\u68c0\u6d4b\u56f0\u96be\u3002", "method": "\u63d0\u51faPAMAS\u6846\u67b6\uff0c\u91c7\u7528\u5206\u5c42\u89c6\u89d2\u611f\u77e5\u805a\u5408\u673a\u5236\uff1a1\uff09\u5ba1\u8ba1\u5458\u4ece\u4e13\u95e8\u7279\u5f81\u5b50\u96c6\u4e2d\u6355\u83b7\u5f02\u5e38\u7ebf\u7d22\uff1b2\uff09\u534f\u8c03\u5458\u805a\u5408\u5ba1\u8ba1\u5458\u89c6\u89d2\u4ee5\u589e\u5f3a\u8986\u76d6\u540c\u65f6\u4fdd\u6301\u591a\u6837\u6027\uff1b3\uff09\u51b3\u7b56\u8005\u901a\u8fc7\u6f14\u5316\u8bb0\u5fc6\u548c\u5b8c\u6574\u4e0a\u4e0b\u6587\u8bbf\u95ee\u7efc\u5408\u6240\u6709\u4e0b\u7ea7\u6d1e\u5bdf\u505a\u51fa\u6700\u7ec8\u5224\u65ad\u3002\u6b64\u5916\uff0c\u5f15\u5165\u81ea\u9002\u5e94\u673a\u5236\u8fdb\u884c\u52a8\u6001\u62d3\u6251\u4f18\u5316\u548c\u57fa\u4e8e\u8def\u7531\u7684\u63a8\u7406\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cPAMAS\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u5747\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u4fe1\u8d56\u7684\u65b9\u6cd5\u3002", "conclusion": "PAMAS\u901a\u8fc7\u89c6\u89d2\u805a\u5408\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u4fe1\u606f\u6df9\u6ca1\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u6027\u80fd\uff0c\u4e3a\u793e\u4ea4\u5a92\u4f53\u53ef\u4fe1\u4fe1\u606f\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.03223", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03223", "abs": "https://arxiv.org/abs/2602.03223", "authors": ["Jiahao Liu", "Hongji Ruan", "Weimin Zhang", "Ziye Tong", "Derick Tang", "Zhanpeng Zeng", "Qinsong Zeng", "Peng Zhang", "Tun Lu", "Ning Gu"], "title": "Distribution-Aware End-to-End Embedding for Streaming Numerical Features in Click-Through Rate Prediction", "comment": "Under review", "summary": "This paper explores effective numerical feature embedding for Click-Through Rate prediction in streaming environments. Conventional static binning methods rely on offline statistics of numerical distributions; however, this inherently two-stage process often triggers semantic drift during bin boundary updates. While neural embedding methods enable end-to-end learning, they often discard explicit distributional information. Integrating such information end-to-end is challenging because streaming features often violate the i.i.d. assumption, precluding unbiased estimation of the population distribution via the expectation of order statistics. Furthermore, the critical context dependency of numerical distributions is often neglected. To this end, we propose DAES, an end-to-end framework designed to tackle numerical feature embedding in streaming training scenarios by integrating distributional information with an adaptive modulation mechanism. Specifically, we introduce an efficient reservoir-sampling-based distribution estimation method and two field-aware distribution modulation strategies to capture streaming distributions and field-dependent semantics. DAES significantly outperforms existing approaches as demonstrated by extensive offline and online experiments and has been fully deployed on a leading short-video platform with hundreds of millions of daily active users.", "AI": {"tldr": "DAES\uff1a\u9762\u5411\u6d41\u5f0f\u8bad\u7ec3\u573a\u666f\u7684\u6570\u503c\u7279\u5f81\u5d4c\u5165\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u5236\u673a\u5236\u6574\u5408\u5206\u5e03\u4fe1\u606f\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u4e2d\u7684\u8bed\u4e49\u6f02\u79fb\u548c\u5206\u5e03\u4fe1\u606f\u4e22\u5931\u95ee\u9898", "motivation": "\u4f20\u7edf\u9759\u6001\u5206\u7bb1\u65b9\u6cd5\u4f9d\u8d56\u79bb\u7ebf\u7edf\u8ba1\uff0c\u5728\u6d41\u5f0f\u73af\u5883\u4e2d\u5bb9\u6613\u4ea7\u751f\u8bed\u4e49\u6f02\u79fb\uff1b\u795e\u7ecf\u5d4c\u5165\u65b9\u6cd5\u867d\u652f\u6301\u7aef\u5230\u7aef\u5b66\u4e60\uff0c\u4f46\u4e22\u5f03\u4e86\u663e\u5f0f\u7684\u5206\u5e03\u4fe1\u606f\u3002\u6d41\u5f0f\u7279\u5f81\u5e38\u8fdd\u53cdi.i.d.\u5047\u8bbe\uff0c\u4e14\u6570\u503c\u5206\u5e03\u7684\u4e0a\u4e0b\u6587\u4f9d\u8d56\u6027\u5e38\u88ab\u5ffd\u89c6", "method": "\u63d0\u51faDAES\u7aef\u5230\u7aef\u6846\u67b6\uff1a1\uff09\u57fa\u4e8e\u84c4\u6c34\u6c60\u91c7\u6837\u7684\u9ad8\u6548\u5206\u5e03\u4f30\u8ba1\u65b9\u6cd5\uff1b2\uff09\u4e24\u79cd\u573a\u611f\u77e5\u5206\u5e03\u8c03\u5236\u7b56\u7565\uff0c\u4ee5\u6355\u6349\u6d41\u5f0f\u5206\u5e03\u548c\u573a\u4f9d\u8d56\u8bed\u4e49", "result": "DAES\u5728\u79bb\u7ebf\u548c\u5728\u7ebf\u5b9e\u9a8c\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5df2\u5728\u62e5\u6709\u6570\u4ebf\u65e5\u6d3b\u7528\u6237\u7684\u9886\u5148\u77ed\u89c6\u9891\u5e73\u53f0\u5168\u9762\u90e8\u7f72", "conclusion": "DAES\u6210\u529f\u89e3\u51b3\u4e86\u6d41\u5f0f\u8bad\u7ec3\u4e2d\u6570\u503c\u7279\u5f81\u5d4c\u5165\u7684\u6311\u6218\uff0c\u901a\u8fc7\u6574\u5408\u5206\u5e03\u4fe1\u606f\u548c\u81ea\u9002\u5e94\u8c03\u5236\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u70b9\u51fb\u7387\u9884\u6d4b\u6027\u80fd"}}
{"id": "2602.03304", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.03304", "abs": "https://arxiv.org/abs/2602.03304", "authors": ["Wenlin Zhang", "Kuicai Dong", "Junyi Li", "Yingyi Zhang", "Xiaopeng Li", "Pengyue Jia", "Yi Wen", "Derong Xu", "Maolin Wang", "Yichao Wang", "Yong Liu", "Xiangyu Zhao"], "title": "To Search or Not to Search: Aligning the Decision Boundary of Deep Search Agents via Causal Intervention", "comment": null, "summary": "Deep search agents, which autonomously iterate through multi-turn web-based reasoning, represent a promising paradigm for complex information-seeking tasks. However, current agents suffer from critical inefficiency: they conduct excessive searches as they cannot accurately judge when to stop searching and start answering. This stems from outcome-centric training that prioritize final results over the search process itself. We identify the root cause as misaligned decision boundaries, the threshold determining when accumulated information suffices to answer. This causes over-search (redundant searching despite sufficient knowledge) and under-search (premature termination yielding incorrect answers). To address these errors, we propose a comprehensive framework comprising two key components. First, we introduce causal intervention-based diagnosis that identifies boundary errors by comparing factual and counterfactual trajectories at each decision point. Second, we develop Decision Boundary Alignment for Deep Search agents (DAS), which constructs preference datasets from causal feedback and aligns policies via preference optimization. Experiments on public datasets demonstrate that decision boundary errors are pervasive across state-of-the-art agents. Our DAS method effectively calibrates these boundaries, mitigating both over-search and under-search to achieve substantial gains in accuracy and efficiency. Our code and data are publicly available at: https://github.com/Applied-Machine-Learning-Lab/WWW2026_DAS.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faDAS\u6846\u67b6\uff0c\u901a\u8fc7\u56e0\u679c\u5e72\u9884\u8bca\u65ad\u51b3\u7b56\u8fb9\u754c\u9519\u8bef\uff0c\u5e76\u4f7f\u7528\u504f\u597d\u4f18\u5316\u5bf9\u9f50\u7b56\u7565\uff0c\u89e3\u51b3\u6df1\u5ea6\u641c\u7d22\u4ee3\u7406\u4e2d\u8fc7\u5ea6\u641c\u7d22\u548c\u641c\u7d22\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u6df1\u5ea6\u641c\u7d22\u4ee3\u7406\u5b58\u5728\u4e25\u91cd\u6548\u7387\u95ee\u9898\uff1a\u7531\u4e8e\u65e0\u6cd5\u51c6\u786e\u5224\u65ad\u4f55\u65f6\u505c\u6b62\u641c\u7d22\u5e76\u5f00\u59cb\u56de\u7b54\uff0c\u5bfc\u81f4\u8fc7\u5ea6\u641c\u7d22\u3002\u6839\u672c\u539f\u56e0\u662f\u51b3\u7b56\u8fb9\u754c\u9519\u4f4d\uff0c\u5373\u5224\u65ad\u4f55\u65f6\u79ef\u7d2f\u8db3\u591f\u4fe1\u606f\u6765\u56de\u7b54\u7684\u9608\u503c\u4e0d\u51c6\u786e\uff0c\u8fd9\u6e90\u4e8e\u7ed3\u679c\u5bfc\u5411\u7684\u8bad\u7ec3\u65b9\u5f0f\u4f18\u5148\u8003\u8651\u6700\u7ec8\u7ed3\u679c\u800c\u975e\u641c\u7d22\u8fc7\u7a0b\u672c\u8eab\u3002", "method": "\u63d0\u51fa\u5305\u542b\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\u7684\u7efc\u5408\u6846\u67b6\uff1a1) \u57fa\u4e8e\u56e0\u679c\u5e72\u9884\u7684\u8bca\u65ad\u65b9\u6cd5\uff0c\u901a\u8fc7\u6bd4\u8f83\u6bcf\u4e2a\u51b3\u7b56\u70b9\u7684\u5b9e\u9645\u8f68\u8ff9\u548c\u53cd\u4e8b\u5b9e\u8f68\u8ff9\u6765\u8bc6\u522b\u8fb9\u754c\u9519\u8bef\uff1b2) \u51b3\u7b56\u8fb9\u754c\u5bf9\u9f50\u65b9\u6cd5(DAS)\uff0c\u4ece\u56e0\u679c\u53cd\u9988\u6784\u5efa\u504f\u597d\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u504f\u597d\u4f18\u5316\u5bf9\u9f50\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u51b3\u7b56\u8fb9\u754c\u9519\u8bef\u5728\u73b0\u6709\u5148\u8fdb\u4ee3\u7406\u4e2d\u666e\u904d\u5b58\u5728\u3002DAS\u65b9\u6cd5\u6709\u6548\u6821\u51c6\u4e86\u8fd9\u4e9b\u8fb9\u754c\uff0c\u663e\u8457\u51cf\u8f7b\u4e86\u8fc7\u5ea6\u641c\u7d22\u548c\u641c\u7d22\u4e0d\u8db3\u95ee\u9898\uff0c\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u53d6\u5f97\u4e86\u5b9e\u8d28\u6027\u63d0\u5347\u3002", "conclusion": "DAS\u6846\u67b6\u901a\u8fc7\u56e0\u679c\u5e72\u9884\u8bca\u65ad\u548c\u504f\u597d\u4f18\u5316\u5bf9\u9f50\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u6df1\u5ea6\u641c\u7d22\u4ee3\u7406\u4e2d\u7684\u51b3\u7b56\u8fb9\u754c\u9519\u4f4d\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u3001\u9ad8\u6548\u7684\u81ea\u4e3b\u641c\u7d22\u63a8\u7406\u3002"}}
{"id": "2602.03306", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03306", "abs": "https://arxiv.org/abs/2602.03306", "authors": ["Zhanyu Wu", "Richong Zhang", "Zhijie Nie"], "title": "Learning to Select: Query-Aware Adaptive Dimension Selection for Dense Retrieval", "comment": null, "summary": "Dense retrieval represents queries and docu-002 ments as high-dimensional embeddings, but003 these representations can be redundant at the004 query level: for a given information need, only005 a subset of dimensions is consistently help-006 ful for ranking. Prior work addresses this via007 pseudo-relevance feedback (PRF) based dimen-008 sion importance estimation, which can produce009 query-aware masks without labeled data but010 often relies on noisy pseudo signals and heuris-011 tic test-time procedures. In contrast, super-012 vised adapter methods leverage relevance labels013 to improve embedding quality, yet they learn014 global transformations shared across queries015 and do not explicitly model query-aware di-016 mension importance. We propose a Query-017 Aware Adaptive Dimension Selection frame-018 work that learns to predict per-dimension im-019 portance directly from query embedding. We020 first construct oracle dimension importance dis-021 tributions over embedding dimensions using022 supervised relevance labels, and then train a023 predictor to map a query embedding to these024 label-distilled importance scores. At inference,025 the predictor selects a query-aware subset of026 dimensions for similarity computation based027 solely on the query embedding, without pseudo-028 relevance feedback. Experiments across multi-029 ple dense retrievers and benchmarks show that030 our learned dimension selector improves re-031 trieval effectiveness over the full-dimensional032 baseline as well as PRF-based masking and033 supervised adapter baselines.", "AI": {"tldr": "\u63d0\u51faQuery-Aware Adaptive Dimension Selection\u6846\u67b6\uff0c\u901a\u8fc7\u76d1\u7763\u5b66\u4e60\u76f4\u63a5\u4ece\u67e5\u8be2\u5d4c\u5165\u9884\u6d4b\u7ef4\u5ea6\u91cd\u8981\u6027\uff0c\u65e0\u9700\u4f2a\u76f8\u5173\u53cd\u9988\uff0c\u63d0\u9ad8\u5bc6\u96c6\u68c0\u7d22\u6548\u679c", "motivation": "\u5bc6\u96c6\u68c0\u7d22\u4e2d\u67e5\u8be2\u548c\u6587\u6863\u7684\u9ad8\u7ef4\u5d4c\u5165\u8868\u793a\u5b58\u5728\u5197\u4f59\uff1a\u5bf9\u4e8e\u7279\u5b9a\u4fe1\u606f\u9700\u6c42\uff0c\u53ea\u6709\u90e8\u5206\u7ef4\u5ea6\u5bf9\u6392\u5e8f\u6709\u5e2e\u52a9\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u566a\u58f0\u5927\u7684\u4f2a\u76f8\u5173\u53cd\u9988\uff0c\u8981\u4e48\u5b66\u4e60\u5168\u5c40\u53d8\u6362\u800c\u4e0d\u663e\u5f0f\u5efa\u6a21\u67e5\u8be2\u611f\u77e5\u7684\u7ef4\u5ea6\u91cd\u8981\u6027\u3002", "method": "\u9996\u5148\u4f7f\u7528\u76d1\u7763\u76f8\u5173\u6027\u6807\u7b7e\u6784\u5efa\u7ef4\u5ea6\u91cd\u8981\u6027\u5206\u5e03\u7684oracle\uff0c\u7136\u540e\u8bad\u7ec3\u4e00\u4e2a\u9884\u6d4b\u5668\u5c06\u67e5\u8be2\u5d4c\u5165\u6620\u5c04\u5230\u8fd9\u4e9b\u6807\u7b7e\u84b8\u998f\u7684\u91cd\u8981\u6027\u5206\u6570\u3002\u63a8\u7406\u65f6\uff0c\u9884\u6d4b\u5668\u4ec5\u57fa\u4e8e\u67e5\u8be2\u5d4c\u5165\u9009\u62e9\u67e5\u8be2\u611f\u77e5\u7684\u7ef4\u5ea6\u5b50\u96c6\u8fdb\u884c\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u3002", "result": "\u5728\u591a\u4e2a\u5bc6\u96c6\u68c0\u7d22\u5668\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5b66\u4e60\u7684\u7ef4\u5ea6\u9009\u62e9\u5668\u5728\u68c0\u7d22\u6548\u679c\u4e0a\u4f18\u4e8e\u5168\u7ef4\u5ea6\u57fa\u7ebf\u3001\u57fa\u4e8ePRF\u7684\u63a9\u7801\u65b9\u6cd5\u548c\u76d1\u7763\u9002\u914d\u5668\u57fa\u7ebf\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u6709\u6548\u5b66\u4e60\u67e5\u8be2\u611f\u77e5\u7684\u7ef4\u5ea6\u91cd\u8981\u6027\uff0c\u65e0\u9700\u4f2a\u76f8\u5173\u53cd\u9988\uff0c\u663e\u8457\u63d0\u5347\u5bc6\u96c6\u68c0\u7d22\u6027\u80fd\uff0c\u4e3a\u67e5\u8be2\u7279\u5b9a\u7684\u7ef4\u5ea6\u9009\u62e9\u63d0\u4f9b\u4e86\u76d1\u7763\u5b66\u4e60\u65b9\u6848\u3002"}}
{"id": "2602.03324", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.03324", "abs": "https://arxiv.org/abs/2602.03324", "authors": ["Chao Chen", "Longfei Xu", "Daohan Su", "Tengfei Liu", "Hanyu Guo", "Yihai Duan", "Kaikui Liu", "Xiangxiang Chu"], "title": "SCASRec: A Self-Correcting and Auto-Stopping Model for Generative Route List Recommendation", "comment": null, "summary": "Route recommendation systems commonly adopt a multi-stage pipeline involving fine-ranking and re-ranking to produce high-quality ordered recommendations. However, this paradigm faces three critical limitations. First, there is a misalignment between offline training objectives and online metrics. Offline gains do not necessarily translate to online improvements. Actual performance must be validated through A/B testing, which may potentially compromise the user experience. Second, redundancy elimination relies on rigid, handcrafted rules that lack adaptability to the high variance in user intent and the unstructured complexity of real-world scenarios. Third, the strict separation between fine-ranking and re-ranking stages leads to sub-optimal performance. Since each module is optimized in isolation, the fine-ranking stage remains oblivious to the list-level objectives (e.g., diversity) targeted by the re-ranker, thereby preventing the system from achieving a jointly optimized global optimum. To overcome these intertwined challenges, we propose \\textbf{SCASRec} (\\textbf{S}elf-\\textbf{C}orrecting and \\textbf{A}uto-\\textbf{S}topping \\textbf{Rec}ommendation), a unified generative framework that integrates ranking and redundancy elimination into a single end-to-end process. SCASRec introduces a stepwise corrective reward (SCR) to guide list-wise refinement by focusing on hard samples, and employs a learnable End-of-Recommendation (EOR) token to terminate generation adaptively when no further improvement is expected. Experiments on two large-scale, open-sourced route recommendation datasets demonstrate that SCASRec establishes an SOTA in offline and online settings. SCASRec has been fully deployed in a real-world navigation app, demonstrating its effectiveness.", "AI": {"tldr": "SCASRec\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u751f\u6210\u5f0f\u63a8\u8350\u6846\u67b6\uff0c\u5c06\u6392\u5e8f\u548c\u5197\u4f59\u6d88\u9664\u6574\u5408\u5230\u7aef\u5230\u7aef\u8fc7\u7a0b\u4e2d\uff0c\u89e3\u51b3\u4e86\u591a\u9636\u6bb5\u63a8\u8350\u7cfb\u7edf\u4e2d\u8bad\u7ec3\u76ee\u6807\u4e0e\u5728\u7ebf\u6307\u6807\u4e0d\u5bf9\u9f50\u3001\u5197\u4f59\u6d88\u9664\u89c4\u5219\u50f5\u5316\u3001\u5404\u9636\u6bb5\u5206\u79bb\u5bfc\u81f4\u6b21\u4f18\u6027\u80fd\u7b49\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u591a\u9636\u6bb5\u63a8\u8350\u7cfb\u7edf\u5b58\u5728\u4e09\u4e2a\u5173\u952e\u95ee\u9898\uff1a1\uff09\u79bb\u7ebf\u8bad\u7ec3\u76ee\u6807\u4e0e\u5728\u7ebf\u6307\u6807\u4e0d\u5bf9\u9f50\uff0c\u79bb\u7ebf\u589e\u76ca\u4e0d\u4e00\u5b9a\u8f6c\u5316\u4e3a\u5728\u7ebf\u6539\u8fdb\uff1b2\uff09\u5197\u4f59\u6d88\u9664\u4f9d\u8d56\u50f5\u5316\u7684\u624b\u5de5\u89c4\u5219\uff0c\u65e0\u6cd5\u9002\u5e94\u7528\u6237\u610f\u56fe\u7684\u9ad8\u65b9\u5dee\u548c\u73b0\u5b9e\u573a\u666f\u7684\u590d\u6742\u6027\uff1b3\uff09\u7cbe\u7ec6\u6392\u5e8f\u548c\u91cd\u6392\u5e8f\u9636\u6bb5\u4e25\u683c\u5206\u79bb\u5bfc\u81f4\u6b21\u4f18\u6027\u80fd\uff0c\u5404\u6a21\u5757\u5b64\u7acb\u4f18\u5316\u65e0\u6cd5\u5b9e\u73b0\u8054\u5408\u4f18\u5316\u7684\u5168\u5c40\u6700\u4f18\u3002", "method": "\u63d0\u51faSCASRec\uff08\u81ea\u6821\u6b63\u548c\u81ea\u505c\u6b62\u63a8\u8350\uff09\u7edf\u4e00\u751f\u6210\u6846\u67b6\uff0c\u5f15\u5165\u9010\u6b65\u6821\u6b63\u5956\u52b1\uff08SCR\uff09\u901a\u8fc7\u5173\u6ce8\u56f0\u96be\u6837\u672c\u6765\u6307\u5bfc\u5217\u8868\u7ea7\u4f18\u5316\uff0c\u5e76\u91c7\u7528\u53ef\u5b66\u4e60\u7684\u63a8\u8350\u7ed3\u675f\uff08EOR\uff09\u6807\u8bb0\u6765\u81ea\u9002\u5e94\u7ec8\u6b62\u751f\u6210\u8fc7\u7a0b\u3002", "result": "\u5728\u4e24\u4e2a\u5927\u89c4\u6a21\u5f00\u6e90\u8def\u7ebf\u63a8\u8350\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSCASRec\u5728\u79bb\u7ebf\u548c\u5728\u7ebf\u8bbe\u7f6e\u4e2d\u90fd\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6c34\u5e73\u3002\u8be5\u6846\u67b6\u5df2\u5728\u771f\u5b9e\u5bfc\u822a\u5e94\u7528\u4e2d\u5b8c\u5168\u90e8\u7f72\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "SCASRec\u901a\u8fc7\u7aef\u5230\u7aef\u7684\u7edf\u4e00\u6846\u67b6\u89e3\u51b3\u4e86\u591a\u9636\u6bb5\u63a8\u8350\u7cfb\u7edf\u7684\u6838\u5fc3\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u6392\u5e8f\u548c\u5197\u4f59\u6d88\u9664\u7684\u8054\u5408\u4f18\u5316\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2602.03345", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.03345", "abs": "https://arxiv.org/abs/2602.03345", "authors": ["Xuancheng Li", "Tao Yang", "Yujia Zhou", "Qingyao Ai", "Yiqun Liu"], "title": "Beyond Exposure: Optimizing Ranking Fairness with Non-linear Time-Income Functions", "comment": null, "summary": "Ranking is central to information distribution in web search and recommendation. Nowadays, in ranking optimization, the fairness to item providers is viewed as a crucial factor alongside ranking relevance for users. There are currently numerous concepts of fairness and one widely recognized fairness concept is Exposure Fairness. However, it relies primarily on exposure determined solely by position, overlooking other factors that significantly influence income, such as time. To address this limitation, we propose to study ranking fairness when the provider utility is influenced by other contextual factors and is neither equal to nor proportional to item exposure. We give a formal definition of Income Fairness and develop a corresponding measurement metric. Simulated experiments show that existing-exposure-fairness-based ranking algorithms fail to optimize the proposed income fairness. Therefore, we propose the Dynamic-Income-Derivative-aware Ranking Fairness algorithm, which, based on the marginal income gain at the present timestep, uses Taylor-expansion-based gradients to simultaneously optimize effectiveness and income fairness. In both offline and online settings with diverse time-income functions, DIDRF consistently outperforms state-of-the-art methods.", "AI": {"tldr": "\u63d0\u51fa\u6536\u5165\u516c\u5e73\u6027\u6982\u5ff5\uff0c\u8003\u8651\u65f6\u95f4\u7b49\u4e0a\u4e0b\u6587\u56e0\u7d20\u5bf9\u63d0\u4f9b\u5546\u6548\u7528\u7684\u5f71\u54cd\uff0c\u5f00\u53d1\u4e86DIDRF\u7b97\u6cd5\u6765\u540c\u65f6\u4f18\u5316\u6392\u540d\u6548\u679c\u548c\u6536\u5165\u516c\u5e73\u6027", "motivation": "\u5f53\u524d\u6392\u540d\u4f18\u5316\u4e2d\uff0c\u66dd\u5149\u516c\u5e73\u6027\u4e3b\u8981\u57fa\u4e8e\u4f4d\u7f6e\u51b3\u5b9a\u66dd\u5149\uff0c\u5ffd\u7565\u4e86\u65f6\u95f4\u7b49\u5176\u4ed6\u5f71\u54cd\u6536\u5165\u7684\u91cd\u8981\u56e0\u7d20\uff0c\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u63d0\u4f9b\u5546\u7684\u771f\u5b9e\u6548\u7528", "method": "\u63d0\u51fa\u6536\u5165\u516c\u5e73\u6027\u6b63\u5f0f\u5b9a\u4e49\u548c\u5ea6\u91cf\u6307\u6807\uff0c\u5f00\u53d1DIDRF\u7b97\u6cd5\uff0c\u57fa\u4e8e\u5f53\u524d\u65f6\u95f4\u6b65\u7684\u8fb9\u9645\u6536\u5165\u589e\u76ca\uff0c\u4f7f\u7528\u6cf0\u52d2\u5c55\u5f00\u68af\u5ea6\u540c\u65f6\u4f18\u5316\u6548\u679c\u548c\u6536\u5165\u516c\u5e73\u6027", "result": "\u6a21\u62df\u5b9e\u9a8c\u663e\u793a\u73b0\u6709\u57fa\u4e8e\u66dd\u5149\u516c\u5e73\u6027\u7684\u7b97\u6cd5\u65e0\u6cd5\u4f18\u5316\u6536\u5165\u516c\u5e73\u6027\uff0cDIDRF\u5728\u79bb\u7ebf\u548c\u5728\u7ebf\u8bbe\u7f6e\u4e2d\uff0c\u5728\u4e0d\u540c\u65f6\u95f4-\u6536\u5165\u51fd\u6570\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "conclusion": "\u6536\u5165\u516c\u5e73\u6027\u6bd4\u4f20\u7edf\u66dd\u5149\u516c\u5e73\u6027\u66f4\u80fd\u51c6\u786e\u53cd\u6620\u63d0\u4f9b\u5546\u6548\u7528\uff0cDIDRF\u7b97\u6cd5\u80fd\u6709\u6548\u540c\u65f6\u4f18\u5316\u6392\u540d\u6548\u679c\u548c\u6536\u5165\u516c\u5e73\u6027"}}
{"id": "2602.03416", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.03416", "abs": "https://arxiv.org/abs/2602.03416", "authors": ["Wenxin Ye", "Lin Li", "Ming Li", "Yang Shen", "Kanghong Wang", "Jimmy Xiangji Huang"], "title": "AesRec: A Dataset for Aesthetics-Aligned Clothing Outfit Recommendation", "comment": null, "summary": "Clothing recommendation extends beyond merely generating personalized outfits; it serves as a crucial medium for aesthetic guidance. However, existing methods predominantly rely on user-item-outfit interaction behaviors while overlooking explicit representations of clothing aesthetics. To bridge this gap, we present the AesRec benchmark dataset featuring systematic quantitative aesthetic annotations, thereby enabling the development of aesthetics-aligned recommendation systems. Grounded in professional apparel quality standards and fashion aesthetic principles, we define a multidimensional set of indicators. At the item level, six dimensions are independently assessed: silhouette, chromaticity, materiality, craftsmanship, wearability, and item-level impression. Transitioning to the outfit level, the evaluation retains the first five core attributes while introducing stylistic synergy, visual harmony, and outfit-level impression as distinct metrics to capture the collective aesthetic impact. Given the increasing human-like proficiency of Vision-Language Models in multimodal understanding and interaction, we leverage them for large-scale aesthetic scoring. We conduct rigorous human-machine consistency validation on a fashion dataset, confirming the reliability of the generated ratings. Experimental results based on AesRec further demonstrate that integrating quantified aesthetic information into clothing recommendation models can provide aesthetic guidance for users while fulfilling their personalized requirements.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86AesRec\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b\u7cfb\u7edf\u5316\u7684\u670d\u88c5\u7f8e\u5b66\u91cf\u5316\u6807\u6ce8\uff0c\u7528\u4e8e\u5f00\u53d1\u7f8e\u5b66\u5bf9\u9f50\u7684\u63a8\u8350\u7cfb\u7edf\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6574\u5408\u7f8e\u5b66\u4fe1\u606f\u80fd\u540c\u65f6\u6ee1\u8db3\u7528\u6237\u4e2a\u6027\u5316\u9700\u6c42\u548c\u63d0\u4f9b\u7f8e\u5b66\u6307\u5bfc\u3002", "motivation": "\u73b0\u6709\u670d\u88c5\u63a8\u8350\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u7528\u6237-\u7269\u54c1-\u642d\u914d\u4ea4\u4e92\u884c\u4e3a\uff0c\u5ffd\u89c6\u4e86\u670d\u88c5\u7f8e\u5b66\u7684\u663e\u5f0f\u8868\u5f81\uff0c\u5bfc\u81f4\u65e0\u6cd5\u6709\u6548\u63d0\u4f9b\u7f8e\u5b66\u6307\u5bfc\u3002", "method": "\u57fa\u4e8e\u4e13\u4e1a\u670d\u88c5\u8d28\u91cf\u6807\u51c6\u548c\u65f6\u5c1a\u7f8e\u5b66\u539f\u5219\uff0c\u5b9a\u4e49\u591a\u7ef4\u7f8e\u5b66\u6307\u6807\uff1a\u5355\u54c1\u5c42\u9762\u8bc4\u4f306\u4e2a\u7ef4\u5ea6\uff0c\u642d\u914d\u5c42\u9762\u8bc4\u4f308\u4e2a\u7ef4\u5ea6\uff1b\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5927\u89c4\u6a21\u7f8e\u5b66\u8bc4\u5206\uff0c\u5e76\u901a\u8fc7\u4eba\u673a\u4e00\u81f4\u6027\u9a8c\u8bc1\u786e\u4fdd\u53ef\u9760\u6027\u3002", "result": "\u5728\u65f6\u5c1a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u4e25\u683c\u7684\u4eba\u673a\u4e00\u81f4\u6027\u9a8c\u8bc1\uff0c\u786e\u8ba4\u4e86\u751f\u6210\u8bc4\u5206\u7684\u53ef\u9760\u6027\uff1b\u57fa\u4e8eAesRec\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5c06\u91cf\u5316\u7f8e\u5b66\u4fe1\u606f\u6574\u5408\u5230\u670d\u88c5\u63a8\u8350\u6a21\u578b\u4e2d\uff0c\u65e2\u80fd\u6ee1\u8db3\u7528\u6237\u4e2a\u6027\u5316\u9700\u6c42\uff0c\u53c8\u80fd\u63d0\u4f9b\u7f8e\u5b66\u6307\u5bfc\u3002", "conclusion": "AesRec\u57fa\u51c6\u6570\u636e\u96c6\u586b\u8865\u4e86\u670d\u88c5\u63a8\u8350\u4e2d\u7f8e\u5b66\u8868\u5f81\u7684\u7a7a\u767d\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u7f8e\u5b66\u91cf\u5316\u6807\u6ce8\uff0c\u4f7f\u5f97\u63a8\u8350\u7cfb\u7edf\u80fd\u591f\u540c\u65f6\u517c\u987e\u4e2a\u6027\u5316\u548c\u7f8e\u5b66\u6307\u5bfc\uff0c\u4e3a\u7f8e\u5b66\u5bf9\u9f50\u7684\u63a8\u8350\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\u3002"}}
{"id": "2602.03422", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.03422", "abs": "https://arxiv.org/abs/2602.03422", "authors": ["Yumeng Wang", "Catherine Chen", "Suzan Verberne"], "title": "RankSteer: Activation Steering for Pointwise LLM Ranking", "comment": null, "summary": "Large language models (LLMs) have recently shown strong performance as zero-shot rankers, yet their effectiveness is highly sensitive to prompt formulation, particularly role-play instructions. Prior analyses suggest that role-related signals are encoded along activation channels that are largely separate from query-document representations, raising the possibility of steering ranking behavior directly at the activation level rather than through brittle prompt engineering. In this work, we propose RankSteer, a post-hoc activation steering framework for zero-shot pointwise LLM ranking. We characterize ranking behavior through three disentangled and steerable directions in representation space: a \\textbf{decision direction} that maps hidden states to relevance scores, an \\textbf{evidence direction} that captures relevance signals not directly exploited by the decision head, and a \\textbf{role direction} that modulates model behavior without injecting relevance information. Using projection-based interventions at inference time, RankSteer jointly controls these directions to calibrate ranking behavior without modifying model weights or introducing explicit cross-document comparisons. Experiments on TREC DL 20 and multiple BEIR benchmarks show that RankSteer consistently improves ranking quality using only a small number of anchor queries, demonstrating that substantial ranking capacity remains under-utilized in pointwise LLM rankers. We further provide a geometric analysis revealing that steering improves ranking by stabilizing ranking geometry and reducing dispersion, offering new insight into how LLMs internally represent and calibrate relevance judgments.", "AI": {"tldr": "RankSteer\uff1a\u4e00\u79cd\u540e\u6fc0\u6d3b\u5bfc\u5411\u6846\u67b6\uff0c\u901a\u8fc7\u63a7\u5236\u8868\u793a\u7a7a\u95f4\u4e2d\u7684\u4e09\u4e2a\u89e3\u8026\u65b9\u5411\uff08\u51b3\u7b56\u3001\u8bc1\u636e\u3001\u89d2\u8272\uff09\u6765\u6821\u51c6\u96f6\u6837\u672c\u70b9\u5f0fLLM\u6392\u5e8f\u884c\u4e3a\uff0c\u65e0\u9700\u4fee\u6539\u6a21\u578b\u6743\u91cd\u6216\u8fdb\u884c\u663e\u5f0f\u8de8\u6587\u6863\u6bd4\u8f83\u3002", "motivation": "LLM\u4f5c\u4e3a\u96f6\u6837\u672c\u6392\u5e8f\u5668\u6027\u80fd\u5bf9\u63d0\u793a\u5de5\u7a0b\uff08\u7279\u522b\u662f\u89d2\u8272\u626e\u6f14\u6307\u4ee4\uff09\u9ad8\u5ea6\u654f\u611f\u3002\u7814\u7a76\u53d1\u73b0\u89d2\u8272\u76f8\u5173\u4fe1\u53f7\u7f16\u7801\u5728\u4e0e\u67e5\u8be2-\u6587\u6863\u8868\u793a\u5206\u79bb\u7684\u6fc0\u6d3b\u901a\u9053\u4e2d\uff0c\u56e0\u6b64\u53ef\u4ee5\u76f4\u63a5\u5728\u6fc0\u6d3b\u5c42\u9762\u5f15\u5bfc\u6392\u5e8f\u884c\u4e3a\uff0c\u907f\u514d\u8106\u5f31\u7684\u63d0\u793a\u5de5\u7a0b\u3002", "method": "\u63d0\u51faRankSteer\u6846\u67b6\uff0c\u8bc6\u522b\u8868\u793a\u7a7a\u95f4\u4e2d\u4e09\u4e2a\u53ef\u5f15\u5bfc\u7684\u89e3\u8026\u65b9\u5411\uff1a1\uff09\u51b3\u7b56\u65b9\u5411\uff1a\u5c06\u9690\u85cf\u72b6\u6001\u6620\u5c04\u5230\u76f8\u5173\u6027\u5206\u6570\uff1b2\uff09\u8bc1\u636e\u65b9\u5411\uff1a\u6355\u83b7\u51b3\u7b56\u5934\u672a\u76f4\u63a5\u5229\u7528\u7684\u76f8\u5173\u6027\u4fe1\u53f7\uff1b3\uff09\u89d2\u8272\u65b9\u5411\uff1a\u5728\u4e0d\u6ce8\u5165\u76f8\u5173\u6027\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\u8c03\u8282\u6a21\u578b\u884c\u4e3a\u3002\u901a\u8fc7\u63a8\u7406\u65f6\u7684\u6295\u5f71\u5e72\u9884\u8054\u5408\u63a7\u5236\u8fd9\u4e9b\u65b9\u5411\u3002", "result": "\u5728TREC DL 20\u548c\u591a\u4e2aBEIR\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRankSteer\u4ec5\u4f7f\u7528\u5c11\u91cf\u951a\u70b9\u67e5\u8be2\u5c31\u6301\u7eed\u63d0\u5347\u4e86\u6392\u5e8f\u8d28\u91cf\uff0c\u8868\u660e\u70b9\u5f0fLLM\u6392\u5e8f\u5668\u4e2d\u5b58\u5728\u5927\u91cf\u672a\u5145\u5206\u5229\u7528\u7684\u6392\u5e8f\u80fd\u529b\u3002\u51e0\u4f55\u5206\u6790\u663e\u793a\u5bfc\u5411\u901a\u8fc7\u7a33\u5b9a\u6392\u5e8f\u51e0\u4f55\u548c\u51cf\u5c11\u79bb\u6563\u5ea6\u6765\u6539\u8fdb\u6392\u5e8f\u3002", "conclusion": "\u6fc0\u6d3b\u5bfc\u5411\u662f\u6821\u51c6LLM\u6392\u5e8f\u884c\u4e3a\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u65e0\u9700\u4fee\u6539\u6743\u91cd\u6216\u8de8\u6587\u6863\u6bd4\u8f83\u3002\u7814\u7a76\u63ed\u793a\u4e86LLM\u5185\u90e8\u5982\u4f55\u8868\u793a\u548c\u6821\u51c6\u76f8\u5173\u6027\u5224\u65ad\uff0c\u4e3a\u7406\u89e3LLM\u6392\u5e8f\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2602.03432", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.03432", "abs": "https://arxiv.org/abs/2602.03432", "authors": ["Joohyung Yun", "Doyup Lee", "Wook-Shin Han"], "title": "Failure is Feedback: History-Aware Backtracking for Agentic Traversal in Multimodal Graphs", "comment": "Project page: https://failureisfeedback.github.io/", "summary": "Open-domain multimodal document retrieval aims to retrieve specific components (paragraphs, tables, or images) from large and interconnected document corpora. Existing graph-based retrieval approaches typically rely on a uniform similarity metric that overlooks hop-specific semantics, and their rigid pre-defined plans hinder dynamic error correction. These limitations suggest that a retriever should adapt its reasoning to the evolving context and recover intelligently from dead ends. To address these needs, we propose Failure is Feedback (FiF), which casts subgraph retrieval as a sequential decision process and introduces two key innovations. (i) We introduce a history-aware backtracking mechanism; unlike standard backtracking that simply reverts the state, our approach piggybacks on the context of failed traversals, leveraging insights from previous failures. (ii) We implement an economically-rational agentic workflow. Unlike conventional agents with static strategies, our orchestrator employs a cost-aware traversal method to dynamically manage the trade-off between retrieval accuracy and inference costs, escalating to intensive LLM-based reasoning only when the prior failure justifies the additional computational investment. Extensive experiments show that FiF achieves state-of-the-art retrieval on the benchmarks of MultimodalQA, MMCoQA and WebQA.", "AI": {"tldr": "FiF \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5931\u8d25\u53cd\u9988\u7684\u5f00\u653e\u57df\u591a\u6a21\u6001\u6587\u6863\u68c0\u7d22\u65b9\u6cd5\uff0c\u901a\u8fc7\u5386\u53f2\u611f\u77e5\u56de\u6eaf\u673a\u5236\u548c\u7ecf\u6d4e\u7406\u6027\u4ee3\u7406\u5de5\u4f5c\u6d41\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u56fe\u7684\u68c0\u7d22\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u4f7f\u7528\u7edf\u4e00\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\uff0c\u5ffd\u7565\u4e86\u8df3\u8f6c\u7279\u5b9a\u7684\u8bed\u4e49\uff1b2\uff09\u91c7\u7528\u50f5\u5316\u7684\u9884\u5b9a\u4e49\u8def\u5f84\u89c4\u5212\uff0c\u7f3a\u4e4f\u52a8\u6001\u9519\u8bef\u7ea0\u6b63\u80fd\u529b\u3002\u8fd9\u8981\u6c42\u68c0\u7d22\u5668\u80fd\u591f\u6839\u636e\u6f14\u5316\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u63a8\u7406\uff0c\u5e76\u80fd\u667a\u80fd\u5730\u4ece\u6b7b\u80e1\u540c\u4e2d\u6062\u590d\u3002", "method": "FiF \u5c06\u5b50\u56fe\u68c0\u7d22\u5efa\u6a21\u4e3a\u5e8f\u5217\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u521b\u65b0\uff1a1\uff09\u5386\u53f2\u611f\u77e5\u56de\u6eaf\u673a\u5236\uff0c\u5229\u7528\u5931\u8d25\u904d\u5386\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u7b80\u5355\u56de\u9000\u72b6\u6001\uff1b2\uff09\u7ecf\u6d4e\u7406\u6027\u4ee3\u7406\u5de5\u4f5c\u6d41\uff0c\u91c7\u7528\u6210\u672c\u611f\u77e5\u7684\u904d\u5386\u65b9\u6cd5\uff0c\u52a8\u6001\u6743\u8861\u68c0\u7d22\u7cbe\u5ea6\u548c\u63a8\u7406\u6210\u672c\uff0c\u4ec5\u5728\u5148\u524d\u5931\u8d25\u8bc1\u660e\u5408\u7406\u65f6\u624d\u5347\u7ea7\u5230\u8ba1\u7b97\u5bc6\u96c6\u7684LLM\u63a8\u7406\u3002", "result": "\u5728 MultimodalQA\u3001MMCoQA \u548c WebQA \u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cFiF \u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u68c0\u7d22\u6027\u80fd\u3002", "conclusion": "FiF \u901a\u8fc7\u5c06\u5931\u8d25\u4f5c\u4e3a\u53cd\u9988\uff0c\u5b9e\u73b0\u4e86\u66f4\u667a\u80fd\u3001\u66f4\u9ad8\u6548\u7684\u5f00\u653e\u57df\u591a\u6a21\u6001\u6587\u6863\u68c0\u7d22\uff0c\u80fd\u591f\u81ea\u9002\u5e94\u5730\u5904\u7406\u590d\u6742\u67e5\u8be2\u5e76\u5728\u9519\u8bef\u4e2d\u5b66\u4e60\u6539\u8fdb\u3002"}}
{"id": "2602.03640", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.03640", "abs": "https://arxiv.org/abs/2602.03640", "authors": ["Mohanna Hoveyda", "Panagiotis Efstratiadis", "Arjen de Vries", "Maarten de Rijke"], "title": "Tutorial on Reasoning for IR & IR for Reasoning", "comment": "Accepted to ECIR 2026", "summary": "Information retrieval has long focused on ranking documents by semantic relatedness. Yet many real-world information needs demand more: enforcement of logical constraints, multi-step inference, and synthesis of multiple pieces of evidence. Addressing these requirements is, at its core, a problem of reasoning. Across AI communities, researchers are developing diverse solutions for the problem of reasoning, from inference-time strategies and post-training of LLMs, to neuro-symbolic systems, Bayesian and probabilistic frameworks, geometric representations, and energy-based models. These efforts target the same problem: to move beyond pattern-matching systems toward structured, verifiable inference. However, they remain scattered across disciplines, making it difficult for IR researchers to identify the most relevant ideas and opportunities. To help navigate the fragmented landscape of research in reasoning, this tutorial first articulates a working definition of reasoning within the context of information retrieval and derives from it a unified analytical framework. The framework maps existing approaches along axes that reflect the core components of the definition. By providing a comprehensive overview of recent approaches and mapping current methods onto the defined axes, we expose their trade-offs and complementarities, highlight where IR can benefit from cross-disciplinary advances, and illustrate how retrieval process itself can play a central role in broader reasoning systems. The tutorial will equip participants with both a conceptual framework and practical guidance for enhancing reasoning-capable IR systems, while situating IR as a domain that both benefits and contributes to the broader development of reasoning methodologies.", "AI": {"tldr": "\u8be5\u6559\u7a0b\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u63a8\u7406\u5206\u6790\u6846\u67b6\uff0c\u5e2e\u52a9\u4fe1\u606f\u68c0\u7d22\u7814\u7a76\u8005\u7406\u89e3\u8de8\u5b66\u79d1\u63a8\u7406\u65b9\u6cd5\uff0c\u5e76\u6307\u5bfc\u6784\u5efa\u5177\u5907\u63a8\u7406\u80fd\u529b\u7684\u68c0\u7d22\u7cfb\u7edf\u3002", "motivation": "\u4f20\u7edf\u4fe1\u606f\u68c0\u7d22\u4e3b\u8981\u5173\u6ce8\u8bed\u4e49\u76f8\u5173\u6027\u6392\u5e8f\uff0c\u4f46\u73b0\u5b9e\u4fe1\u606f\u9700\u6c42\u9700\u8981\u903b\u8f91\u7ea6\u675f\u3001\u591a\u6b65\u63a8\u7406\u548c\u8bc1\u636e\u7efc\u5408\u7b49\u63a8\u7406\u80fd\u529b\u3002\u5f53\u524dAI\u793e\u533a\u4e2d\u63a8\u7406\u65b9\u6cd5\u5206\u6563\u5728\u4e0d\u540c\u5b66\u79d1\uff0c\u4f7f\u5f97IR\u7814\u7a76\u8005\u96be\u4ee5\u8bc6\u522b\u76f8\u5173\u601d\u8def\u548c\u673a\u4f1a\u3002", "method": "\u9996\u5148\u5728IR\u80cc\u666f\u4e0b\u5b9a\u4e49\u63a8\u7406\u7684\u5de5\u4f5c\u5b9a\u4e49\uff0c\u5e76\u4ece\u4e2d\u63a8\u5bfc\u51fa\u7edf\u4e00\u7684\u5206\u6790\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5c06\u73b0\u6709\u65b9\u6cd5\u6620\u5c04\u5230\u53cd\u6620\u5b9a\u4e49\u6838\u5fc3\u7ec4\u4ef6\u7684\u8f74\u4e0a\uff0c\u63d0\u4f9b\u5168\u9762\u6982\u8ff0\u5e76\u5c55\u793a\u6743\u8861\u4e0e\u4e92\u8865\u6027\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u5e2e\u52a9\u5bfc\u822a\u788e\u7247\u5316\u63a8\u7406\u7814\u7a76\u666f\u89c2\u7684\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u65b9\u6cd5\u7684\u6743\u8861\u4e0e\u4e92\u8865\u6027\uff0c\u5c55\u793a\u4e86IR\u5982\u4f55\u4ece\u8de8\u5b66\u79d1\u8fdb\u5c55\u4e2d\u53d7\u76ca\uff0c\u4ee5\u53ca\u68c0\u7d22\u8fc7\u7a0b\u5982\u4f55\u5728\u66f4\u5e7f\u6cdb\u63a8\u7406\u7cfb\u7edf\u4e2d\u53d1\u6325\u6838\u5fc3\u4f5c\u7528\u3002", "conclusion": "\u8be5\u6559\u7a0b\u4e3a\u53c2\u4e0e\u8005\u63d0\u4f9b\u4e86\u6982\u5ff5\u6846\u67b6\u548c\u5b9e\u8df5\u6307\u5bfc\uff0c\u4ee5\u589e\u5f3a\u5177\u5907\u63a8\u7406\u80fd\u529b\u7684IR\u7cfb\u7edf\uff0c\u540c\u65f6\u5c06IR\u5b9a\u4f4d\u4e3a\u65e2\u53d7\u76ca\u4e8e\u53c8\u80fd\u8d21\u732e\u4e8e\u66f4\u5e7f\u6cdb\u63a8\u7406\u65b9\u6cd5\u53d1\u5c55\u7684\u9886\u57df\u3002"}}
{"id": "2602.03692", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.03692", "abs": "https://arxiv.org/abs/2602.03692", "authors": ["Xinyu Lin", "Pengyuan Liu", "Wenjie Wang", "Yicheng Hu", "Chen Xu", "Fuli Feng", "Qifan Wang", "Tat-Seng Chua"], "title": "Bringing Reasoning to Generative Recommendation Through the Lens of Cascaded Ranking", "comment": "Accepted by WWW2026", "summary": "Generative Recommendation (GR) has become a promising end-to-end approach with high FLOPS utilization for resource-efficient recommendation. Despite the effectiveness, we show that current GR models suffer from a critical \\textbf{bias amplification} issue, where token-level bias escalates as token generation progresses, ultimately limiting the recommendation diversity and hurting the user experience. By comparing against the key factor behind the success of traditional multi-stage pipelines, we reveal two limitations in GR that can amplify the bias: homogeneous reliance on the encoded history, and fixed computational budgets that prevent deeper user preference understanding.\n  To combat the bias amplification issue, it is crucial for GR to 1) incorporate more heterogeneous information, and 2) allocate greater computational resources at each token generation step. To this end, we propose CARE, a simple yet effective cascaded reasoning framework for debiased GR. To incorporate heterogeneous information, we introduce a progressive history encoding mechanism, which progressively incorporates increasingly fine-grained history information as the generation process advances. To allocate more computations, we propose a query-anchored reasoning mechanism, which seeks to perform a deeper understanding of historical information through parallel reasoning steps. We instantiate CARE on three GR backbones. Empirical results on four datasets show the superiority of CARE in recommendation accuracy, diversity, efficiency, and promising scalability. The codes and datasets are available at https://github.com/Linxyhaha/CARE.", "AI": {"tldr": "CARE\u63d0\u51fa\u7ea7\u8054\u63a8\u7406\u6846\u67b6\u89e3\u51b3\u751f\u6210\u5f0f\u63a8\u8350\u4e2d\u7684\u504f\u5dee\u653e\u5927\u95ee\u9898\uff0c\u901a\u8fc7\u6e10\u8fdb\u5386\u53f2\u7f16\u7801\u548c\u67e5\u8be2\u951a\u5b9a\u63a8\u7406\u673a\u5236\u63d0\u5347\u63a8\u8350\u591a\u6837\u6027\u548c\u51c6\u786e\u6027", "motivation": "\u5f53\u524d\u751f\u6210\u5f0f\u63a8\u8350\u6a21\u578b\u5b58\u5728\u504f\u5dee\u653e\u5927\u95ee\u9898\uff0c\u968f\u7740token\u751f\u6210\u8fc7\u7a0b\u63a8\u8fdb\uff0ctoken\u7ea7\u504f\u5dee\u4e0d\u65ad\u653e\u5927\uff0c\u9650\u5236\u4e86\u63a8\u8350\u591a\u6837\u6027\u5e76\u635f\u5bb3\u7528\u6237\u4f53\u9a8c\u3002\u4e0e\u4f20\u7edf\u591a\u9636\u6bb5\u6d41\u6c34\u7ebf\u76f8\u6bd4\uff0c\u751f\u6210\u5f0f\u63a8\u8350\u5b58\u5728\u4e24\u4e2a\u5c40\u9650\u6027\uff1a\u5bf9\u7f16\u7801\u5386\u53f2\u7684\u540c\u8d28\u4f9d\u8d56\uff0c\u4ee5\u53ca\u56fa\u5b9a\u7684\u8ba1\u7b97\u9884\u7b97\u963b\u788d\u4e86\u66f4\u6df1\u5c42\u7684\u7528\u6237\u504f\u597d\u7406\u89e3\u3002", "method": "\u63d0\u51faCARE\u7ea7\u8054\u63a8\u7406\u6846\u67b6\uff1a1) \u6e10\u8fdb\u5386\u53f2\u7f16\u7801\u673a\u5236 - \u968f\u7740\u751f\u6210\u8fc7\u7a0b\u63a8\u8fdb\u9010\u6b65\u7eb3\u5165\u66f4\u7ec6\u7c92\u5ea6\u7684\u5386\u53f2\u4fe1\u606f\uff1b2) \u67e5\u8be2\u951a\u5b9a\u63a8\u7406\u673a\u5236 - \u901a\u8fc7\u5e76\u884c\u63a8\u7406\u6b65\u9aa4\u5bf9\u5386\u53f2\u4fe1\u606f\u8fdb\u884c\u66f4\u6df1\u5c42\u7406\u89e3\uff0c\u5206\u914d\u66f4\u591a\u8ba1\u7b97\u8d44\u6e90\u3002\u5728\u4e09\u4e2a\u751f\u6210\u5f0f\u63a8\u8350\u9aa8\u5e72\u7f51\u7edc\u4e0a\u5b9e\u4f8b\u5316CARE\u3002", "result": "\u5728\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCARE\u5728\u63a8\u8350\u51c6\u786e\u6027\u3001\u591a\u6837\u6027\u3001\u6548\u7387\u65b9\u9762\u5177\u6709\u4f18\u8d8a\u6027\uff0c\u5e76\u5c55\u73b0\u51fa\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "CARE\u901a\u8fc7\u89e3\u51b3\u751f\u6210\u5f0f\u63a8\u8350\u4e2d\u7684\u504f\u5dee\u653e\u5927\u95ee\u9898\uff0c\u6709\u6548\u63d0\u5347\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u4e3a\u8d44\u6e90\u9ad8\u6548\u7684\u7aef\u5230\u7aef\u63a8\u8350\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.03713", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.03713", "abs": "https://arxiv.org/abs/2602.03713", "authors": ["Moritz Vandenhirtz", "Kaveh Hassani", "Shervin Ghasemlou", "Shuai Shao", "Hamid Eghbalzadeh", "Fuchun Peng", "Jun Liu", "Michael Louis Iuzzolino"], "title": "Multimodal Generative Recommendation for Fusing Semantic and Collaborative Signals", "comment": null, "summary": "Sequential recommender systems rank relevant items by modeling a user's interaction history and computing the inner product between the resulting user representation and stored item embeddings. To avoid the significant memory overhead of storing large item sets, the generative recommendation paradigm instead models each item as a series of discrete semantic codes. Here, the next item is predicted by an autoregressive model that generates the code sequence corresponding to the predicted item. However, despite promising ranking capabilities on small datasets, these methods have yet to surpass traditional sequential recommenders on large item sets, limiting their adoption in the very scenarios they were designed to address. To resolve this, we propose MSCGRec, a Multimodal Semantic and Collaborative Generative Recommender. MSCGRec incorporates multiple semantic modalities and introduces a novel self-supervised quantization learning approach for images based on the DINO framework. Additionally, MSCGRec fuses collaborative and semantic signals by extracting collaborative features from sequential recommenders and treating them as a separate modality. Finally, we propose constrained sequence learning that restricts the large output space during training to the set of permissible tokens. We empirically demonstrate on three large real-world datasets that MSCGRec outperforms both sequential and generative recommendation baselines and provide an extensive ablation study to validate the impact of each component.", "AI": {"tldr": "MSCGRec\u662f\u4e00\u79cd\u591a\u6a21\u6001\u8bed\u4e49\u4e0e\u534f\u540c\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u5408\u591a\u79cd\u8bed\u4e49\u6a21\u6001\u3001\u81ea\u76d1\u7763\u91cf\u5316\u5b66\u4e60\u548c\u534f\u540c\u7279\u5f81\u878d\u5408\uff0c\u5728\u5927\u578b\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u4e86\u4f20\u7edf\u5e8f\u5217\u63a8\u8350\u548c\u751f\u6210\u5f0f\u63a8\u8350\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u751f\u6210\u5f0f\u63a8\u8350\u65b9\u6cd5\u867d\u7136\u901a\u8fc7\u79bb\u6563\u8bed\u4e49\u7f16\u7801\u51cf\u5c11\u5185\u5b58\u5f00\u9500\uff0c\u4f46\u5728\u5927\u578b\u9879\u76ee\u96c6\u4e0a\u8868\u73b0\u4ecd\u4e0d\u53ca\u4f20\u7edf\u5e8f\u5217\u63a8\u8350\u5668\uff0c\u9650\u5236\u4e86\u5176\u5728\u5b9e\u9645\u5927\u89c4\u6a21\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002", "method": "1) \u7ed3\u5408\u591a\u79cd\u8bed\u4e49\u6a21\u6001\uff1b2) \u57fa\u4e8eDINO\u6846\u67b6\u7684\u56fe\u50cf\u81ea\u76d1\u7763\u91cf\u5316\u5b66\u4e60\uff1b3) \u4ece\u5e8f\u5217\u63a8\u8350\u5668\u4e2d\u63d0\u53d6\u534f\u540c\u7279\u5f81\u4f5c\u4e3a\u72ec\u7acb\u6a21\u6001\u8fdb\u884c\u878d\u5408\uff1b4) \u63d0\u51fa\u53d7\u9650\u5e8f\u5217\u5b66\u4e60\uff0c\u5728\u8bad\u7ec3\u65f6\u9650\u5236\u8f93\u51fa\u7a7a\u95f4\u5230\u5141\u8bb8\u7684\u6807\u8bb0\u96c6\u5408\u3002", "result": "\u5728\u4e09\u4e2a\u5927\u578b\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMSCGRec\u8d85\u8d8a\u4e86\u5e8f\u5217\u63a8\u8350\u548c\u751f\u6210\u5f0f\u63a8\u8350\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u5404\u7ec4\u4ef6\u7684\u5f71\u54cd\u3002", "conclusion": "MSCGRec\u901a\u8fc7\u591a\u6a21\u6001\u8bed\u4e49\u4e0e\u534f\u540c\u7279\u5f81\u7684\u878d\u5408\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u751f\u6210\u5f0f\u63a8\u8350\u5728\u5927\u578b\u9879\u76ee\u96c6\u4e0a\u7684\u6027\u80fd\u74f6\u9888\uff0c\u4e3a\u5b9e\u9645\u5927\u89c4\u6a21\u63a8\u8350\u573a\u666f\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
