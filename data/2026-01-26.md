<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 7]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [LLM-based Semantic Search for Conversational Queries in E-commerce](https://arxiv.org/abs/2601.16492)
*Emad Siddiqui,Venkatesh Terikuti,Xuan Lu*

Main category: cs.IR

TL;DR: 提出基于LLM的语义搜索框架，通过领域特定嵌入和结构化过滤来理解对话式查询意图，使用合成数据微调嵌入模型和生成模型，结合相似性检索和约束过滤提升电商搜索效果。


<details>
  <summary>Details</summary>
Motivation: 传统电商平台的搜索系统主要针对关键词查询优化，难以处理日益增长的对话式用户查询。需要开发能够理解自然语言意图的语义搜索框架。

Method: 1) 使用LLM生成合成数据指导微调；2) 微调嵌入模型，使语义相似产品在表示空间中靠近；3) 微调生成模型，将自然语言查询转换为结构化约束；4) 结合相似性检索和约束过滤进行搜索。

Result: 在真实世界数据集上，相比基线方法，该框架在各种设置下实现了较高的精确率和召回率，证明其有效性。

Conclusion: 提出的LLM语义搜索框架能够有效处理对话式查询，通过合成数据解决标注数据不足问题，结合嵌入相似性和结构化过滤提升了电商搜索性能。

Abstract: Conversational user queries are increasingly challenging traditional e-commerce platforms, whose search systems are typically optimized for keyword-based queries. We present an LLM-based semantic search framework that effectively captures user intent from conversational queries by combining domain-specific embeddings with structured filters. To address the challenge of limited labeled data, we generate synthetic data using LLMs to guide the fine-tuning of two models: an embedding model that positions semantically similar products close together in the representation space, and a generative model for converting natural language queries into structured constraints. By combining similarity-based retrieval with constraint-based filtering, our framework achieves strong precision and recall across various settings compared to baseline approaches on a real-world dataset.

</details>


### [2] [PRISM: Purified Representation and Integrated Semantic Modeling for Generative Sequential Recommendation](https://arxiv.org/abs/2601.16556)
*Dengzhao Fang,Jingtong Gao,Yu Li,Xiangyu Zhao,Yi Chang*

Main category: cs.IR

TL;DR: PRISM是一个新的生成式序列推荐框架，通过纯化表示和集成语义建模解决现有方法在语义标记化和生成过程中的两个关键限制。


<details>
  <summary>Details</summary>
Motivation: 现有生成式序列推荐框架面临两个关键问题：1) 不纯且不稳定的语义标记化，量化方法难以处理交互噪声和码本崩溃，导致语义ID具有模糊区分性；2) 有损且弱结构化的生成，仅依赖粗粒度离散标记会引入信息损失并忽略项目的层次逻辑。

Method: 提出PRISM框架，包含两个核心组件：1) 纯化语义量化器，通过自适应协作去噪和层次语义锚定机制构建鲁棒码本；2) 集成语义推荐器，通过动态语义集成机制整合细粒度语义，并通过语义结构对齐目标强制逻辑有效性。

Result: PRISM在四个真实世界数据集上持续优于最先进的基线方法，表现出显著的性能提升，特别是在高稀疏性场景中。

Conclusion: PRISM通过解决现有生成式序列推荐框架在语义标记化和生成过程中的关键限制，提供了一个更有效的推荐解决方案，特别是在数据稀疏的情况下表现优异。

Abstract: Generative Sequential Recommendation (GSR) has emerged as a promising paradigm, reframing recommendation as an autoregressive sequence generation task over discrete Semantic IDs (SIDs), typically derived via codebook-based quantization. Despite its great potential in unifying retrieval and ranking, existing GSR frameworks still face two critical limitations: (1) impure and unstable semantic tokenization, where quantization methods struggle with interaction noise and codebook collapse, resulting in SIDs with ambiguous discrimination; and (2) lossy and weakly structured generation, where reliance solely on coarse-grained discrete tokens inevitably introduces information loss and neglects items' hierarchical logic. To address these issues, we propose a novel generative recommendation framework, PRISM, with Purified Representation and Integrated Semantic Modeling. Specifically, to ensure high-quality tokenization, we design a Purified Semantic Quantizer that constructs a robust codebook via adaptive collaborative denoising and hierarchical semantic anchoring mechanisms. To compensate for information loss during quantization, we further propose an Integrated Semantic Recommender, which incorporates a dynamic semantic integration mechanism to integrate fine-grained semantics and enforces logical validity through a semantic structure alignment objective. PRISM consistently outperforms state-of-the-art baselines across four real-world datasets, demonstrating substantial performance gains, particularly in high-sparsity scenarios.

</details>


### [3] [LLM-powered Real-time Patent Citation Recommendation for Financial Technologies](https://arxiv.org/abs/2601.16775)
*Tianang Deng,Yu Deng,Tianchen Gao,Yonghong Hu,Rui Pan*

Main category: cs.IR

TL;DR: 提出一个实时专利引用推荐框架，针对大规模快速变化的金融专利语料库，使用LLM嵌入、近似最近邻搜索和增量索引策略，在动态环境中提高推荐准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 金融创新快速发展导致专利申请活动急剧增加，使得及时全面的现有技术发现更加困难。现有专利检索和引用推荐方法通常依赖静态索引或定期重新训练，在动态环境中效果有限。

Method: 构建三阶段推荐流程：1) 使用LLM嵌入表示专利摘要的语义内容；2) 应用高效近似最近邻搜索构建候选集；3) 按语义相似度对候选者排序生成top-k引用推荐。采用基于HNSW图的增量索引策略，支持新专利添加而无需重建整个索引。

Result: 使用428,843个中国金融专利数据集进行实验，增量更新策略在提高召回率的同时显著降低计算成本。该方法持续优于传统文本基线和替代最近邻检索方法。

Conclusion: 提出的实时专利引用推荐框架有效解决了金融专利语料库的动态特性，通过增量索引策略实现了高效更新，为快速变化的金融技术领域提供了实用的引用推荐解决方案。

Abstract: Rapid financial innovation has been accompanied by a sharp increase in patenting activity, making timely and comprehensive prior-art discovery more difficult. This problem is especially evident in financial technologies, where innovations develop quickly, patent collections grow continuously, and citation recommendation systems must be updated as new applications arrive. Existing patent retrieval and citation recommendation methods typically rely on static indexes or periodic retraining, which limits their ability to operate effectively in such dynamic settings. In this study, we propose a real-time patent citation recommendation framework designed for large and fast-changing financial patent corpora. Using a dataset of 428,843 financial patents granted by the China National Intellectual Property Administration (CNIPA) between 2000 and 2024, we build a three-stage recommendation pipeline. The pipeline uses large language model (LLM) embeddings to represent the semantic content of patent abstracts, applies efficient approximate nearest-neighbor search to construct a manageable candidate set, and ranks candidates by semantic similarity to produce top-k citation recommendations. In addition to improving recommendation accuracy, the proposed framework directly addresses the dynamic nature of patent systems. By using an incremental indexing strategy based on hierarchical navigable small-world (HNSW) graphs, newly issued patents can be added without rebuilding the entire index. A rolling day-by-day update experiment shows that incremental updating improves recall while substantially reducing computational cost compared with rebuild-based indexing. The proposed method also consistently outperforms traditional text-based baselines and alternative nearest-neighbor retrieval approaches.

</details>


### [4] [PI2I: A Personalized Item-Based Collaborative Filtering Retrieval Framework](https://arxiv.org/abs/2601.16815)
*Shaoqing Wang,Yingcai Ma,Kairui Fu,Ziyang Wang,Dunxian Huang,Yuliang Yan,Jian Wu*

Main category: cs.IR

TL;DR: 提出PI2I两阶段检索框架，通过放宽截断阈值和引入交互式评分模型，提升推荐系统的个性化能力，在淘宝"猜你喜欢"中实现交易率提升1.05%


<details>
  <summary>Details</summary>
Motivation: 传统推荐方法（如协同过滤和双塔模型）存在统一截断策略和用户-物品交互建模不足的问题，无法有效处理海量候选池中的复杂用户-物品交互

Method: 提出PI2I两阶段框架：1）索引构建阶段放宽截断阈值最大化命中率；2）个性化检索阶段引入交互式评分模型替代内积计算，并基于触发-目标关系构建负样本

Result: 在大规模真实数据集上超越传统协同过滤方法，与双塔模型相当；在淘宝"猜你喜欢"部署后在线交易率提升1.05%；发布了包含1.3亿用户交互的公开数据集

Conclusion: PI2I框架通过两阶段个性化检索有效解决了传统方法的局限性，提升了推荐系统的性能，并为研究社区提供了有价值的基准数据集

Abstract: Efficiently selecting relevant content from vast candidate pools is a critical challenge in modern recommender systems. Traditional methods, such as item-to-item collaborative filtering (CF) and two-tower models, often fall short in capturing the complex user-item interactions due to uniform truncation strategies and overdue user-item crossing. To address these limitations, we propose Personalized Item-to-Item (PI2I), a novel two-stage retrieval framework that enhances the personalization capabilities of CF. In the first Indexer Building Stage (IBS), we optimize the retrieval pool by relaxing truncation thresholds to maximize Hit Rate, thereby temporarily retaining more items users might be interested in. In the second Personalized Retrieval Stage (PRS), we introduce an interactive scoring model to overcome the limitations of inner product calculations, allowing for richer modeling of intricate user-item interactions. Additionally, we construct negative samples based on the trigger-target (item-to-item) relationship, ensuring consistency between offline training and online inference. Offline experiments on large-scale real-world datasets demonstrate that PI2I outperforms traditional CF methods and rivals Two-Tower models. Deployed in the "Guess You Like" section on Taobao, PI2I achieved a 1.05% increase in online transaction rates. In addition, we have released a large-scale recommendation dataset collected from Taobao, containing 130 million real-world user interactions used in the experiments of this paper. The dataset is publicly available at https://huggingface.co/datasets/PI2I/PI2I, which could serve as a valuable benchmark for the research community.

</details>


### [5] [Navigating the Shift: A Comparative Analysis of Web Search and Generative AI Response Generation](https://arxiv.org/abs/2601.16858)
*Mahe Chen,Xiaoxuan Wang,Kaiwen Chen,Nick Koudas*

Main category: cs.IR

TL;DR: 该论文通过大规模实证研究，量化了谷歌搜索与生成式AI服务在搜索结果上的根本差异，分析了来源领域、查询意图、信息新鲜度等多个维度，并探讨了LLM预训练对差异的影响，对比了AEO与SEO的区别。


<details>
  <summary>Details</summary>
Motivation: 生成式AI作为主要信息来源的兴起，正在从传统网络搜索转向新的范式。研究者需要量化谷歌搜索与领先生成式AI服务在结果上的根本差异，以理解这两种信息生态系统的不同机制。

Method: 采用大规模实证研究方法，分析多个维度：咨询的来源领域、领域类型（如付费媒体vs自有媒体、社交媒体）、查询意图和信息新鲜度。同时研究LLM预训练作为关键因素如何塑造这些差异，分析其内在知识库如何影响和交互实时网络搜索。

Result: 研究发现AI生成的答案与网络搜索结果在多个维度上存在显著差异。LLM预训练是塑造这些差异的关键因素，其内在知识库与实时网络搜索的交互方式影响了结果呈现。研究揭示了两种信息生态系统的不同机制。

Conclusion: 研究揭示了生成式AI与传统网络搜索在信息生态系统上的根本差异，这对新兴的答案引擎优化（AEO）领域具有重要意义，并需要与传统搜索引擎优化（SEO）进行对比和区分。

Abstract: The rise of generative AI as a primary information source presents a paradigm shift from traditional web search. This paper presents a large-scale empirical study quantifying the fundamental differences between the results returned by Google Search and leading generative AI services. We analyze multiple dimensions, demonstrating that AI-generated answers and web search results diverge significantly in their consulted source domains, the typology of these domains (e.g., earned media vs. owned, social), query intent and the freshness of the information provided. We then investigate the role of LLM pre-training as a key factor shaping these differences, analyzing how this intrinsic knowledge base interacts with and influences real-time web search when enabled. Our findings reveal the distinct mechanics of these two information ecosystems, leading to critical observations on the emergent field of Answer Engine Optimization (AEO) and its contrast with traditional Search Engine Optimization (SEO).

</details>


### [6] [From Atom to Community: Structured and Evolving Agent Memory for User Behavior Modeling](https://arxiv.org/abs/2601.16872)
*Yuxin Liao,Le Wu,Min Hou,Yu Wang,Han Wu,Meng Wang*

Main category: cs.IR

TL;DR: STEAM是一个结构化、演化的智能体记忆框架，将用户偏好分解为原子记忆单元，通过社区组织和原型记忆利用协同信号，自适应演化机制提升推荐准确性、模拟保真度和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体的记忆机制主要针对文本对话设计，在建模非文本行为（如点击）时面临挑战。单一非结构化摘要会混淆用户的多方面兴趣，简单覆盖更新会导致遗忘，稀疏的个体交互需要协同信号。

Method: STEAM将用户偏好分解为原子记忆单元，每个单元捕捉一个独立的兴趣维度并与观察到的行为显式链接。通过将相似记忆组织成社区并生成原型记忆来利用协同模式。采用自适应演化机制，包括记忆精炼的巩固机制和捕捉新兴兴趣的形成机制。

Result: 在三个真实世界数据集上的实验表明，STEAM在推荐准确性、模拟保真度和多样性方面显著优于最先进的基线方法。

Conclusion: STEAM通过结构化组织和自适应演化重新构想了智能体记忆的表示和更新方式，有效解决了现有方法在建模非文本行为和利用协同信号方面的局限性。

Abstract: User behavior modeling lies at the heart of personalized applications like recommender systems. With LLM-based agents, user preference representation has evolved from latent embeddings to semantic memory. While existing memory mechanisms show promise in textual dialogues, modeling non-textual behaviors remains challenging, as preferences must be inferred from implicit signals like clicks without ground truth supervision. Current approaches rely on a single unstructured summary, updated through simple overwriting. However, this is suboptimal: users exhibit multi-faceted interests that get conflated, preferences evolve yet naive overwriting causes forgetting, and sparse individual interactions necessitate collaborative signals. We present STEAM (\textit{\textbf{ST}ructured and \textbf{E}volving \textbf{A}gent \textbf{M}emory}), a novel framework that reimagines how agent memory is organized and updated. STEAM decomposes preferences into atomic memory units, each capturing a distinct interest dimension with explicit links to observed behaviors. To exploit collaborative patterns, STEAM organizes similar memories across users into communities and generates prototype memories for signal propagation. The framework further incorporates adaptive evolution mechanisms, including consolidation for refining memories and formation for capturing emerging interests. Experiments on three real-world datasets demonstrate that STEAM substantially outperforms state-of-the-art baselines in recommendation accuracy, simulation fidelity, and diversity.

</details>


### [7] [Explaining Group Recommendations via Counterfactuals](https://arxiv.org/abs/2601.16882)
*Maria Stratigi,Nikos Bikakis*

Main category: cs.IR

TL;DR: 提出群体反事实解释框架，通过移除特定历史交互来揭示推荐变化，平衡效用与公平性


<details>
  <summary>Details</summary>
Motivation: 现有群体推荐系统缺乏透明度，现有解释方法主要针对个体，无法有效处理群体中多个偏好的交互问题

Method: 提出群体反事实解释框架，形式化定义概念，引入群体效用和公平性度量，设计启发式算法（如帕累托过滤和生长-剪枝策略）进行高效解释发现

Result: 在MovieLens和Amazon数据集上的实验显示明显权衡：低成本方法产生更大但公平性较差的解释，其他方法以更高成本产生简洁平衡的结果；帕累托过滤启发式在稀疏设置中显著提升效率

Conclusion: 群体反事实解释框架能有效揭示推荐机制，不同方法在解释质量、公平性和计算成本间存在权衡，帕累托过滤在稀疏场景下特别高效

Abstract: Group recommender systems help users make collective choices but often lack transparency, leaving group members uncertain about why items are suggested. Existing explanation methods focus on individuals, offering limited support for groups where multiple preferences interact. In this paper, we propose a framework for group counterfactual explanations, which reveal how removing specific past interactions would change a group recommendation. We formalize this concept, introduce utility and fairness measures tailored to groups, and design heuristic algorithms, such as Pareto-based filtering and grow-and-prune strategies, for efficient explanation discovery. Experiments on MovieLens and Amazon datasets show clear trade-offs: low-cost methods produce larger, less fair explanations, while other approaches yield concise and balanced results at higher cost. Furthermore, the Pareto-filtering heuristic demonstrates significant efficiency improvements in sparse settings.

</details>
